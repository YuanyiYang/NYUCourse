(dp0
I129
(dp1
S'docBody'
p2
V'''Preference learning''' is a subfield in [[machine learning]] in which the goal is to learn a predictive [[Preference (economics)|preference]] model from observed preference information.<ref>[[Mehryar Mohri]], Afshin Rostamizadeh, Ameet Talwalkar (2012) ''Foundations of Machine Learning'', The\u000aMIT Press ISBN 9780262018258.</ref> In the view of [[supervised learning]], preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items.\u000a\u000aWhile the concept of preference learning has been emerged for some time in many fields such as [[economics]],<ref name="SHOG00" /> it's a relatively new topic in [[Artificial Intelligence]] research. Several workshops have been discussing preference learning and related topics in the past decade.<ref name="WEB:WORKSHOP" />\u000a\u000a==Tasks==\u000a\u000aThe main task in preference learning concerns problems in "[[learning to rank]]". According to different types of preference information observed, the tasks are categorized as three main problems in the book ''Preference Learning'':<ref name="FURN11" />\u000a\u000a===Label ranking===\u000a\u000aIn label ranking, the model has an instance space <math>X=\u005c{x_i\u005c}\u005c,\u005c!</math> and a finite set of labels <math>Y=\u005c{y_i|i=1,2,\u005ccdots,k\u005c}\u005c,\u005c!</math>. The preference information is given in the form <math>y_i \u005csucc_{x} y_j\u005c,\u005c!</math> indicating instance <math>x\u005c,\u005c!</math> shows preference in <math>y_i\u005c,\u005c!</math> rather than <math>y_j\u005c,\u005c!</math>. A set of preference information is used as training data in the model. The task of this model is to find a preference ranking among the labels for any instance.\u000a\u000aIt was observed some conventional [[Classification in machine learning|classification]] problems can be generalized in the framework of label ranking problem:<ref name="HARP03" /> if a training instance <math>x\u005c,\u005c!</math> is labeled as class <math>y_i\u005c,\u005c!</math>, it implies that <math>\u005cforall j \u005cneq i, y_i \u005csucc_{x} y_j\u005c,\u005c!</math>. In [[Multi-label classification|multi-label]] situation, <math>x\u005c,\u005c!</math> is associated with a set of labels <math>L \u005csubseteq Y\u005c,\u005c!</math> and thus the model can extract a set of preference information <math>\u005c{y_i \u005csucc_{x} y_j | y_i \u005cin L, y_j \u005cin Y\u005cbackslash L\u005c}\u005c,\u005c!</math>. Training a preference model on this preference information and the classification result of an instance is just the corresponding top ranking label.\u000a\u000a===Instance ranking===\u000a\u000aInstance ranking also has the instance space <math>X\u005c,\u005c!</math> and label set <math>Y\u005c,\u005c!</math>. In this task, labels are defined to have a fixed order <math>y_1 \u005csucc y_2 \u005csucc \u005ccdots \u005csucc y_k\u005c,\u005c!</math> and each instance <math>x_l\u005c,\u005c!</math> is associated with a label <math>y_l\u005c,\u005c!</math>. Giving a set of instances as training data, the goal of this task is to find the ranking order for a new set of instances.\u000a\u000a===Object ranking===\u000a\u000aObject ranking is similar to instance ranking except that no labels are associated with instances. Given a set of pairwise preference information in the form <math>x_i \u005csucc x_j\u005c,\u005c!</math> and the model should find out a ranking order among instances.\u000a\u000a==Techniques==\u000a\u000aThere are two practical representations of the preference information <math>A \u005csucc B\u005c,\u005c!</math>. One is assigning <math>A\u005c,\u005c!</math> and <math>B\u005c,\u005c!</math> with two real numbers <math>a\u005c,\u005c!</math> and <math>b\u005c,\u005c!</math> respectively such that <math>a > b\u005c,\u005c!</math>. Another one is assigning a binary value <math>V(A,B) \u005cin \u005c{0,1\u005c}\u005c,\u005c!</math> for all pairs <math>(A,B)\u005c,\u005c!</math> denoting whether <math>A \u005csucc B\u005c,\u005c!</math> or <math>B \u005csucc A\u005c,\u005c!</math>. Corresponding to these two different representations, there are two different techniques applied to the learning process.\u000a\u000a===Utility function===\u000a\u000aIf we can find a mapping from data to real numbers, ranking the data can be solved by ranking the real numbers. This mapping is called [[utility function]]. For label ranking the mapping is a function <math>f: X \u005ctimes Y \u005crightarrow \u005cmathbb{R}\u005c,\u005c!</math> such that <math>y_i \u005csucc_x y_j \u005cRightarrow f(x,y_i) > f(x,y_j)\u005c,\u005c!</math>. For instance ranking and object ranking, the mapping is a function <math>f: X \u005crightarrow \u005cmathbb{R}\u005c,\u005c!</math>.\u000a\u000aFinding the utility function is a [[Regression analysis|regression]] learning problem which is well developed in machine learning.\u000a\u000a===Preference relations===\u000a\u000aThe binary representation of preference information is called preference relation. For each pair of alternatives (instances or labels), a binary predicate can be learned by conventional supervising learning approach. Fürnkranz, Johannes and Hüllermeier proposed this approach in label ranking problem.<ref name="FURN03" /> For object ranking, there is an early approach by Cohen et al.<ref name="COHE98" />\u000a\u000aUsing preference relations to predict the ranking will not be so intuitive. Since preference relation is not transitive, it implies that the solution of ranking satisfying those relations would sometimes be unreachable, or there could be more than one solution. A more common approach is to find a ranking solution which is maximally consistent with the preference relations. This approach is a natural extension of pairwise classification.<ref name="FURN03" />\u000a\u000a==Uses==\u000a\u000aPreference learning can be used in ranking search results according to feedback of user preference. Given a query and a set of documents, a learning model is used to find the ranking of documents corresponding to the relevance with this query. More discussions on research in this field can be found in Tie-Yan Liu's survey paper.<ref name="LIU09" />\u000a\u000aAnother application of preference learning is [[recommender systems]].<ref name="GEMM09" /> Online store may analyze customer's purchase record to learn a preference model and then recommend similar products to customers. Internet content providers can make use of user's ratings to provide more user preferred contents.\u000a\u000a==See also==\u000a*[[Learning to rank]]\u000a\u000a==References==\u000a\u000a{{Reflist|\u000arefs=\u000a\u000a<ref name="SHOG00">{{\u000acite journal\u000a|last       = Shogren\u000a|first      = Jason F.\u000a|coauthors  = List, John A.; Hayes, Dermot J.\u000a|year       = 2000\u000a|title      = Preference Learning in Consecutive Experimental Auctions\u000a|url        = http://econpapers.repec.org/article/oupajagec/v_3a82_3ay_3a2000_3ai_3a4_3ap_3a1016-1021.htm\u000a|journal    = American Journal of Agricultural Economics\u000a|volume     = 82\u000a|pages      = 1016\u20131021\u000a|doi=10.1111/0002-9092.00099\u000a}}</ref>\u000a\u000a<ref name="WEB:WORKSHOP">{{\u000acite web\u000a|title      = Preference learning workshops\u000a|url        = http://www.preference-learning.org/#Workshops\u000a}}</ref>\u000a\u000a<ref name="FURN11">{{\u000acite book\u000a|last       = F&uuml;rnkranz\u000a|first      = Johannes\u000a|coauthors  = H&uuml;llermeier, Eyke\u000a|year       = 2011\u000a|title      = Preference Learning\u000a|url        = http://books.google.com/books?id=nc3XcH9XSgYC\u000a|chapter    = Preference Learning: An Introduction\u000a|chapterurl = http://books.google.com/books?id=nc3XcH9XSgYC&pg=PA4\u000a|publisher  = Springer-Verlag New York, Inc.\u000a|pages      = 3\u20138\u000a|isbn       = 978-3-642-14124-9\u000a}}</ref>\u000a\u000a<ref name="HARP03">{{\u000acite journal\u000a|last       = Har-peled\u000a|first      = Sariel\u000a|coauthors  = Roth, Dan; Zimak, Dav\u000a|year       = 2003\u000a|title      = Constraint classification for multiclass classification and ranking\u000a|journal    = In Proceedings of the 16th Annual Conference on Neural Information Processing Systems, NIPS-02\u000a|pages      = 785\u2013792\u000a}}</ref>\u000a\u000a<ref name="FURN03">{{\u000acite journal\u000a|last       = F&uuml;rnkranz\u000a|first      = Johannes\u000a|coauthors  = H&uuml;llermeier, Eyke\u000a|year       = 2003\u000a|title      = Pairwise Preference Learning and Ranking\u000a|journal    = Proceedings of the 14th European Conference on Machine Learning\u000a|pages      = 145\u2013156\u000a}}</ref>\u000a\u000a<ref name="COHE98">{{\u000acite journal\u000a|last       = Cohen\u000a|first      = William W.\u000a|coauthors  = Schapire, Robert E.; Singer, Yoram\u000a|year       = 1998\u000a|title      = Learning to order things\u000a|url        = http://dl.acm.org/citation.cfm?id=302528.302736\u000a|journal    = In Proceedings of the 1997 Conference on Advances in Neural Information Processing Systems\u000a|pages      = 451\u2013457\u000a}}</ref>\u000a\u000a<ref name="LIU09">{{\u000acite journal\u000a|last       = Liu\u000a|first      = Tie-Yan\u000a|year       = 2009\u000a|title      = Learning to Rank for Information Retrieval\u000a|url        = http://dl.acm.org/citation.cfm?id=1618303.1618304\u000a|journal    = Foundations and Trends in Information Retrieval\u000a|volume     = 3\u000a|issue      = 3\u000a|pages      = 225\u2013331\u000a|doi        = 10.1561/1500000016\u000a}}</ref>\u000a\u000a<ref name="GEMM09">{{\u000acite journal\u000a|last       = Gemmis\u000a|first      = Marco De\u000a|author2=Iaquinta, Leo |author3=Lops, Pasquale |author4=Musto, Cataldo |author5=Narducci, Fedelucio |author6= Semeraro,Giovanni \u000a|year       = 2009\u000a|title      = Preference Learning in Recommender Systems\u000a|url        = http://www.ecmlpkdd2009.net/wp-content/uploads/2008/09/preference-learning.pdf#page=45\u000a|journal    = PREFERENCE LEARNING\u000a|volume     = 41\u000a|pages      = 387\u2013407\u000a|doi=10.1007/978-3-642-14125-6_18\u000a}}</ref>\u000a\u000a}}\u000a\u000a==External links==\u000a*[http://www.preference-learning.org/ Preference Learning site]\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Machine learning]]
p3
sS'docID'
p4
S'129'
p5
sS'title'
p6
VPreference learning
p7
ssI4
(dp8
g2
VIn the field of [[information retrieval]], '''divergence from randomness''' is one type of [[probabilistic]] model.\u000a\u000aTerm weights are computed by measuring the divergence between a term distribution produced by a random process and the actual term distribution.\u000a\u000a==External links==\u000a*[http://terrier.org/docs/v3.5/dfr_description.html Terrier's DFR Web page]\u000a*[http://ir.dcs.gla.ac.uk/wiki/DivergenceFromRandomness Glasgow IR group Wiki DFR page]\u000a\u000a[[Category:Ranking functions]]\u000a[[Category:Information retrieval]]\u000a[[Category:Probabilistic models]]\u000a\u000a\u000a{{comp-sci-stub}}
p9
sg4
S'4'
p10
sg6
VDivergence-from-randomness model
p11
ssI134
(dp12
g2
V[[Category:Information retrieval]]
p13
sg4
S'134'
p14
sg6
VCategory:Vector space model
p15
ssI9
(dp16
g2
VThe '''Bioinformatic Harvester''' is a bioinformatic meta [[search engine]] created by the [[European Molecular Biology Laboratory]]<ref>{{Cite journal|title= 	Information retrieval on Internet using meta-search engines: A review|authors=Manoj, M, Elizabeth, Jacob |date=Oct 2008|publisher=CSIR|pages=739\u2013746|issn=0022-4456\u000a|journal=JSIR |volume=67 (10)}}</ref> and subsequently hosted and further developed by KIT [[Karlsruhe Institute of Technology]] for [[gene]]s and protein-associated information. Harvester currently works for [[human]], [[mouse]], [[rat]], [[zebrafish]], [[drosophila]] and [[arabidopsis thaliana]] based information. Harvester cross-links >50 popular bioinformatic resources and allows cross searches. Harvester serves tens of thousands of pages every day to scientists and physicians.\u000a\u000a{{Infobox software\u000a| name                  = Bioinformatic Harvester\u000a|developer              = Urban Liebel, Björn Kindler\u000a|latest release version = 4\u000a|latest release date    = {{release date and age|2011|05|24}}\u000a|operating_system       = Web based\u000a|genre                  = Bioinformatics tool\u000a|license                = Public Domain\u000a|website                = http://harvester.kit.edu\u000a}}\u000a\u000a== How Harvester works ==\u000a\u000aHarvester collects information from [[protein]] and gene databases along with information from so called "prediction servers." Prediction server e.g. provide online sequence analysis for a single protein. Harvesters search index is based on the [[International Protein Index|IPI]] and [[UniProt]] protein information collection. The collections consists of:\u000a\u000a* ~72.000 human, ~57.000 mouse, ~41.000 rat, ~51.000 zebrafish, ~35.000 arabidopsis protein pages, which cross-link ~50 major bioinfiormatic resources.\u000a\u000a<!-- Deleted image removed: [[Image:harvester-kit.JPG|thumb| A screenshot of the [http://harvester.kit.edu/ Harvester search engine]]] -->\u000a\u000a== Harvester crosslinks several types of information ==\u000a\u000a===Text based information===\u000afrom the following databases:\u000a\u000a* [[UniProt]], world largest protein database\u000a* [[SOURCE]], convenient gene information overview\u000a* [[Simple Modular Architecture Research Tool]] (SMART),\u000a* [[SOSUI]], predicts transmembrane domains\u000a* [[PSORT]], predicts protein localisation\u000a* [[HomoloGene]], compares proteins from different species\u000a* [[gfp-cdna]], protein localisation with fluorescence microscopy\u000a* [[International Protein Index]] (IPI).\u000a\u000a=== Databases rich in graphical elements ===\u000a...are not collected, but crosslinked via [[iframe]]s. Iframes are transparent windows within a [[HTML]] pages. The iframe windows allows up-to-date viewing of the "iframed," linked databases. Several such iframes are combined on a Harvester protein page. This method allows convenient comparison of information from several databases.\u000a\u000a* NCBI-[[BLAST]], an algorithm for comparing biological sequences from the [[National Center for Biotechnology Information|NCBI]].\u000a* [[Ensembl]], automatic gene annotation by the EMBL-[[European Bioinformatics Institute|EBI]] and [[Sanger Institute]]\u000a* [[FlyBase]] is a database of model organism ''[[Drosophila melanogaster]]''.\u000a* [[GoPubMed]] is a knowledge-based search engine for biomedical texts.\u000a* [[Information Hyperlinked over Proteins|iHOP]], information hyperlinked over proteins via gene/protein synonyms\u000a* [[Mendelian Inheritance in Man]] project catalogues all the known diseases.\u000a* [[RZPD]], German resources Center for genome research in Berlin/Heidelberg.\u000a* [[STRING]], Search Tool for the Retrieval of Interacting Genes/Proteins, developed by [[EMBL]], [[Swiss Institute of Bioinformatics|SIB]] and [[University of Zurich|UZH]].\u000a* [[Zebrafish Information Network]].\u000a* [http://locate.imb.uq.edu.au/ LOCATE] subcellular localization database (mouse).\u000a\u000a=== Access from external application ===\u000a\u000a* [[Genome browser]], working draft assemblies for genomes [[University of California, Santa Cruz|UCSC]]\u000a* [[Google Scholar]]\u000a* [[Mitocheck]]\u000a* [[PolyMeta]], meta search engine for Google, Yahoo, MSN, Ask, Exalead, AllTheWeb, GigaBlast\u000a\u000a== What one can find ==\u000a\u000aHarvester allows a combination of different search terms and single words.\u000a\u000aSearch Examples:\u000a\u000a* Gene-name: "golga3"\u000a* Gene-alias: "ADAP-S ADAS ADHAPS ADPS" (one gene name is sufficient)\u000a* Gene-Ontologies: "Enzyme linked receptor protein signaling pathway"\u000a* [[UniGene|Unigene]]-Cluster: "Hs.449360"\u000a\u000a* Go-annotation: "intra-Golgi transport"\u000a* Molecular function: "protein kinase binding"\u000a* Protein: "Q9NPD3"\u000a* Protein domain: "SH2 sar"\u000a* Protein Localisation: "endoplasmic reticulum"\u000a\u000a* Chromosome: "2q31"\u000a* Disease relevant: use the word "diseaselink"\u000a* Combinations: "golgi diseaselink" (finds all golgi proteins associated with a disease)\u000a* [[mRNA]]: "AL136897"\u000a\u000a* Word: "Cancer"\u000a* Comment: "highly expressed in heart"\u000a* Author: "Merkel, Schmidt"\u000a* Publication or project: "[[cDNA]] sequencing project"\u000a\u000a==See also==\u000a\u000a* [[Biological database]]s\u000a* [[Entrez]]\u000a* [[European Bioinformatics Institute]]\u000a* [[HPRD|Human Protein Reference Database]]\u000a* [[Metadata]]\u000a* [[Sequence profiling tool]]\u000a\u000a== Literature ==\u000a*{{cite journal |author=Liebel U, Kindler B, Pepperkok R |title='Harvester': a fast meta search engine of human protein resources |journal=Bioinformatics |volume=20 |issue=12 |pages=1962\u20133 |date=August 2004 |pmid=14988114 |doi=10.1093/bioinformatics/bth146 |url=http://bioinformatics.oxfordjournals.org/cgi/pmidlookup?view=long&pmid=14988114}}\u000a*{{cite journal |author=Liebel U, Kindler B, Pepperkok R |title=Bioinformatic "Harvester": a search engine for genome-wide human, mouse, and rat protein resources |journal=Meth. Enzymol. |volume=404 |issue= |pages=19\u201326 |year=2005 |pmid=16413254 |doi=10.1016/S0076-6879(05)04003-6 |url=http://linkinghub.elsevier.com/retrieve/pii/S0076-6879(05)04003-6}}\u000a\u000a== Notes and references ==\u000a<references/>\u000a\u000a== External links ==\u000a* http://harvester.kit.edu Bioinformatic Harvester V at KIT [[Karlsruhe Institute of Technology]]\u000a* [http://harvester42.fzk.de Harvester42] at KIT - integrating 50 general search engines\u000a\u000a[[Category:Bioinformatics software]]\u000a[[Category:Biological databases]]\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search engines]]\u000a[[Category:Biology websites]]
p17
sg4
S'9'
p18
sg6
VBioinformatic Harvester
p19
ssI139
(dp20
g2
V{{catmore}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search engines| ]]
p21
sg4
S'139'
p22
sg6
VCategory:Personalized search
p23
ssI14
(dp24
g2
VA '''web search query''' is a query that a user enters into a web [[search engine]] to satisfy his or her [[information needs]]. Web search queries are distinctive in that they are often plain text or [[hypertext]] with optional search-directives (such as "and"/"or" with "-" to exclude). They vary greatly from standard [[query language]]s, which are governed by strict syntax rules as [[command language]]s with keyword or positional [[Parameter (computer science)|parameters]].\u000a\u000a== Types ==\u000aThere are three broad categories that cover most web search queries: informational, navigational, and transactional. These are often called "do, know, go."<ref>{{cite web|last=Gibbons|first=Kevin|title=Do, Know, Go: How to Create Content at Each Stage of the Buying Cycle|url=http://searchenginewatch.com/article/2235624/Do-Know-Go-How-to-Create-Content-at-Each-Stage-of-the-Buying-Cycle|publisher=Search Engine Watch|accessdate=24 May 2014}}</ref>\u000a\u000a* '''Informational queries''' \u2013 Queries that cover a broad topic (e.g., ''colorado'' or ''trucks'') for which there may be thousands of relevant results.\u000a\u000a* '''Navigational queries''' \u2013 Queries that seek a single website or web page of a single entity (e.g., ''youtube'' or ''delta air lines'').\u000a\u000a* '''Transactional queries''' \u2013 Queries that reflect the intent of the user to perform a particular action, like purchasing a car or downloading a screen saver.\u000a\u000aSearch engines often support a fourth type of query that is used far less frequently:\u000a\u000a* '''Connectivity queries''' \u2013 Queries that report on the connectivity of the indexed [[web graph]] (e.g., Which links point to this [[Uniform Resource Locator|URL]]?, and How many pages are indexed from this [[domain name]]?).<ref>{{cite web|last=Moore|first=Ross|title=Connectivity servers|url=http://nlp.stanford.edu/IR-book/html/htmledition/connectivity-servers-1.html|publisher=Cambridge University Press|accessdate=24 May 2014}}</ref>\u000a\u000a== Characteristics ==\u000a\u000aMost commercial web search engines do not disclose their search logs, so information about what users are searching for on the Web is difficult to come by.<ref>Dawn Kawamoto and Elinor Mills (2006), [http://news.cnet.com/AOL-apologizes-for-release-of-user-search-data/2100-1030_3-6102793.html AOL apologizes for release of user search data]</ref> Nevertheless, a study in 2001<ref>{{cite journal|author = Amanda Spink, Dietmar Wolfram, Major B. J. Jansen, Tefko Saracevic | year = 2001 | title = Searching the web: The public and their queries | journal = Journal of the American Society for Information Science and Technology | volume = 52 | issue = 3 | pages = 226\u2013234 | doi = 10.1002/1097-4571(2000)9999:9999<::AID-ASI1591>3.3.CO;2-I }}</ref> analyzed the queries from the [[Excite]] search engine showed some interesting characteristics of web search:\u000a\u000a* The average length of a search query was 2.4 terms. \u000a* About half of the users entered a single query while a little less than a third of users entered three or more unique queries. \u000a* Close to half of the users examined only the first one or two pages of results (10 results per page).\u000a* Less than 5% of users used advanced search features (e.g., [[boolean operators]] like AND, OR, and NOT).\u000a* The top four most frequently used terms were , '' (empty search), and, of, ''and'' sex.\u000a\u000aA study of the same Excite query logs revealed that 19% of the queries contained a geographic term (e.g., place names, zip codes, geographic features, etc.).<ref>{{cite conference | author = Mark Sanderson and Janet Kohler | year = 2004 | title = Analyzing geographic queries | booktitle = Proceedings of the Workshop on Geographic Information (SIGIR '04) | url =http://supremacyseo.com/analyzing-geographic-queries }}</ref>\u000a\u000aA 2005 study of Yahoo's query logs revealed 33% of the queries from the same user were repeat queries and that 87% of the time the user would click on the same result.<ref>{{cite conference | author = Jaime Teevan, Eytan Adar, Rosie Jones, Michael Potts | year = 2005 | title = History repeats itself: Repeat Queries in Yahoo's query logs | booktitle = Proceedings of the 29th Annual ACM Conference on Research and Development in Information Retrieval (SIGIR '06) | pages = 703\u2013704 | url =http://www.csail.mit.edu/~teevan/work/publications/posters/sigir06.pdf | doi=10.1145/1148170.1148326 }}</ref> This suggests that many users use repeat queries to revisit or re-find information. This analysis is confirmed by a Bing search engine blog post telling about 30% queries are navigational queries <ref>http://www.bing.com/community/site_blogs/b/search/archive/2011/02/10/making-search-yours.aspx</ref>\u000a\u000aIn addition, much research has shown that query term frequency distributions conform to the [[power law]], or ''long tail'' distribution curves. That is, a small portion of the terms observed in a large query log (e.g. > 100 million queries) are used most often, while the remaining terms are used less often individually.<ref name="baezayates1">{{cite journal | author = Ricardo Baeza-Yates | year = 2005 | title = Applications of Web Query Mining | booktitle = Lecture Notes in Computer Science | pages = 7\u201322 | volume = 3408 | publisher = Springer Berlin / Heidelberg | url = http://www.springerlink.com/content/kpphaktugag5mbv0/ | ISBN = 978-3-540-25295-5}}</ref> This example of the [[Pareto principle]] (or ''80\u201320 rule'') allows search engines to employ [[optimization techniques]] such as index or [[Partition (database)|database partitioning]], [[web cache|caching]] and pre-fetching.\u000a\u000aBut in a recent study in 2011 it was found that the average length of queries has grown steadily over time and average length of non-English languages queries had increased more than English queries.<ref>{{cite journal | author = Mona Taghavi, Ahmed Patel, Nikita Schmidt, Christopher Wills, Yiqi Tew | year = 2011 | title = An analysis of web proxy logs with query distribution pattern approach for search engines | booktitle = Journal of Computer Standards & Interfaces | pages = 162\u2013170 | volume = 34 | issue = 1 |publisher = Elsevier  | url = http://www.sciencedirect.com/science/article/pii/S0920548911000808 | doi=10.1016/j.csi.2011.07.001}}</ref> Google has implemented the [[Google_Hummingbird|hummingbird]] update in August 2013 to handle longer search queries since more searches are conversational (ie "where is the nearest coffee shop?").<ref>{{cite web|last=Sullivan|first=Danny|title=FAQ: All About The New Google \u201cHummingbird\u201d Algorithm|url=http://searchengineland.com/google-hummingbird-172816|publisher=Search Engine Land|accessdate=24 May 2014}}</ref> \u000aFor longer queries, [[Natural language processing]] helps, since parse trees of queries can be matched with that of answers and their snippets.<ref>{{vcite journal |author=Galitsky B|title=Machine learning of syntactic parse trees for search and classification of text|journal=Engineering Applications of Artificial Intelligence |volume=26 |issue=3 |date=2013 |pages=153-172|doi=10.1016/j.engappai.2012.09.017}}</ref> For multi-sentence queries where keywords statistics and [[Tf\u2013idf]] is not very helpful, [[Parse thicket]] technique comes into play to structurally represent complex questions and answers.<ref>{{vcite journal |author=Galitsky B, Ilvovsky D, Kuznetsov SO, Strok F|title=Finding Maximal Common Sub-parse Thickets\u000afor Multi-sentence Search |journal=Lecture Notes In Artificial Intelligence |volume = 8323 |date=2013 |http://www.aclweb.org/anthology/R13-1037\u000a}}</ref>\u000a\u000a== Structured queries ==\u000aWith search engines that support Boolean operators and parentheses, a technique traditionally used by librarians can be applied. A user who is looking for documents that cover several topics or ''facets'' may want to describe each of them by a [[logical disjunction|disjunction]] of characteristic words, such as <code>vehicles OR cars OR automobiles</code>. A ''faceted query'' is a [[logical conjunction|conjunction]] of such facets; e.g. a query such as <code>(electronic OR computerized OR DRE) AND (voting OR elections OR election OR balloting OR electoral)</code> is likely to find documents about electronic voting even if they omit one of the words "electronic" and "voting", or even both.<ref>{{Cite web\u000a|url=http://eprints.eemcs.utwente.nl/6918/01/TR-CTIT-06-57.pdf\u000a|title=Exploiting Query Structure and Document Structure to Improve Document Retrieval Effectiveness\u000a|author=Vojkan Mihajlovi\u0107, Djoerd Hiemstra, Henk Ernst Blok, Peter M.G. Apers\u000a|postscript=<!--None-->}}</ref>\u000a\u000a== See also ==\u000a* [[Information retrieval]]\u000a* [[Web search engine]]\u000a* [[Web query classification]]\u000a* [[Taxonomy for search engines]]\u000a\u000a== References ==\u000a{{reflist|2}}\u000a\u000a{{Internet search}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search]]
p25
sg4
S'14'
p26
sg6
VWeb search query
p27
ssI144
(dp28
g2
V{{Information science}}\u000a\u000a'''Information retrieval''' ('''IR''') is the activity of obtaining [[information]] resources relevant to an information need from a collection of information resources.  Searches can be based on [[metadata]] or on [[Full text search|full-text]] (or other content-based) indexing.\u000a\u000aAutomated information retrieval systems are used to reduce what has been called "[[information overload]]". Many universities and [[public library|public libraries]] use IR systems to provide access to books, journals and other documents. [[Web search engine]]s are the most visible [[Information retrieval applications|IR applications]].\u000a\u000a== Overview ==\u000a\u000aAn information retrieval process begins when a user enters a [[query string|query]] into the system. Queries are formal statements of [[information need]]s, for example search strings in web search engines. In information retrieval a query does not uniquely identify a single object in the collection. Instead, several objects may match the query, perhaps with different degrees of [[relevance|relevancy]].\u000a\u000aAn object is an entity that is represented by information in a [[database]]. User queries are matched against the database information. Depending on the [[Information retrieval applications|application]] the data objects may be, for example, text documents, images,<ref name=goodron2000>{{cite journal |first=Abby A. |last=Goodrum |title=Image Information Retrieval: An Overview of Current Research |journal=Informing Science |volume=3 |number=2 |year=2000 }}</ref> audio,<ref name=Foote99>{{cite journal |first=Jonathan |last=Foote |title=An overview of audio information retrieval |journal=Multimedia Systems |year=1999 |publisher=Springer }}</ref> [[mind maps]]<ref name=Beel2009>{{cite journal |first=Jöran |last=Beel |first2=Bela |last2=Gipp |first3=Jan-Olaf |last3=Stiller |contribution=Information Retrieval On Mind Maps - What Could It Be Good For? |contribution-url=http://www.sciplore.org/publications_en.php |title=Proceedings of the 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom'09) |year=2009 |publisher=IEEE |place=Washington, DC }}</ref> or videos. Often the documents themselves are not kept or stored directly in the IR system, but are instead represented in the system by document surrogates or metadata.\u000a\u000aMost IR systems compute a numeric score on how well each object in the database matches the query, and rank the objects according to this value. The top ranking objects are then shown to the user. The process may then be iterated if the user wishes to refine the query.<ref name="Frakes1992">{{cite book |last=Frakes |first=William B. |title=Information Retrieval Data Structures & Algorithms |publisher=Prentice-Hall, Inc. |year=1992 |isbn=0-13-463837-9 |url=http://www.scribd.com/doc/13742235/Information-Retrieval-Data-Structures-Algorithms-William-B-Frakes }}</ref>\u000a\u000a== History ==\u000a{{Rquote|right|But do you know that, although I have kept the diary [on a phonograph] for months past, it never once struck me how I was going to find any particular part of it in case I wanted to look it up?|[[John Seward|Dr Seward]]| [[Bram Stoker]]'s ''[[Dracula]]'',\u000a 1897}}\u000aThe idea of using computers to search for relevant pieces of information was popularized in the article ''[[As We May Think]]'' by [[Vannevar Bush]] in 1945.<ref name="Singhal2001">{{cite journal |last=Singhal |first=Amit |title=Modern Information Retrieval: A Brief Overview |journal=Bulletin of the IEEE Computer Society Technical Committee on Data Engineering |volume=24 |issue=4 |pages=35\u201343 |year =2001 |url=http://singhal.info/ieee2001.pdf }}</ref> The first automated information retrieval systems were introduced in the 1950s and 1960s. By 1970 several different techniques had been shown to perform well on small [[text corpora]] such as the Cranfield collection (several thousand documents).<ref name="Singhal2001" /> Large-scale retrieval systems, such as the Lockheed Dialog system, came into use early in the 1970s.\u000a\u000aIn 1992, the US Department of Defense along with the [[National Institute of Standards and Technology]] (NIST), cosponsored the [[Text Retrieval Conference]] (TREC) as part of the TIPSTER text program. The aim of this was to look into the information retrieval community by supplying the infrastructure that was needed for evaluation of text retrieval methodologies on a very large text collection. This catalyzed research on methods that [[scalability|scale]] to huge corpora. The introduction of [[web search engine]]s has boosted the need for very large scale retrieval systems even further.\u000a\u000a== Model types ==\u000a[[File:Information-Retrieval-Models.png|thumb|500px|Categorization of IR-models (translated from [[:de:Informationsrückgewinnung#Klassifikation von Modellen zur Repräsentation natürlichsprachlicher Dokumente|German entry]], original source [http://www.logos-verlag.de/cgi-bin/engbuchmid?isbn=0514&lng=eng&id= Dominik Kuropka]).]]\u000aFor effectively retrieving relevant documents by IR strategies, the documents are typically transformed into a suitable representation. Each retrieval strategy incorporates a specific model for its document representation purposes. The picture on the right illustrates the relationship of some common models. In the picture, the models are categorized according to two dimensions: the mathematical basis and the properties of the model.\u000a\u000a=== First dimension: mathematical basis ===\u000a* ''Set-theoretic'' models represent documents as sets of words or phrases. Similarities are usually derived from set-theoretic operations on those sets. Common models are:\u000a** [[Standard Boolean model]]\u000a** [[Extended Boolean model]]\u000a** [[Fuzzy retrieval]]\u000a* ''Algebraic models'' represent documents and queries usually as vectors, matrices, or tuples. The similarity of the query vector and document vector is represented as a scalar value.\u000a** [[Vector space model]]\u000a** [[Generalized vector space model]]\u000a** [[Topic-based vector space model|(Enhanced) Topic-based Vector Space Model]]\u000a** [[Extended Boolean model]]\u000a** [[Latent semantic indexing]] a.k.a. [[latent semantic analysis]]\u000a* ''Probabilistic models'' treat the process of document retrieval as a probabilistic inference. Similarities are computed as probabilities that a document is relevant for a given query. Probabilistic theorems like the [[Bayes' theorem]] are often used in these models.\u000a** [[Binary Independence Model]]\u000a** [[Probabilistic relevance model]] on which is based the [[Probabilistic relevance model (BM25)|okapi (BM25)]] relevance function\u000a** [[Uncertain inference]]\u000a** [[Language model]]s\u000a** [[Divergence-from-randomness model]]\u000a** [[Latent Dirichlet allocation]]\u000a* ''Feature-based retrieval models'' view documents as vectors of values of ''feature functions'' (or just ''features'') and seek the best way to combine these features into a single relevance score, typically by [[learning to rank]] methods. Feature functions are arbitrary functions of document and query, and as such can easily incorporate almost any other retrieval model as just a yet another feature.\u000a\u000a=== Second dimension: properties of the model ===\u000a* ''Models without term-interdependencies'' treat different terms/words as independent. This fact is usually represented in vector space models by the [[orthogonality]] assumption of term vectors or in probabilistic models by an [[Independence (mathematical logic)|independency]] assumption for term variables.\u000a* ''Models with immanent term interdependencies'' allow a representation of interdependencies between terms. However the degree of the interdependency between two terms is defined by the model itself. It is usually directly or indirectly derived (e.g. by [[dimension reduction|dimensional reduction]]) from the [[co-occurrence]] of those terms in the whole set of documents.\u000a* ''Models with transcendent term interdependencies'' allow a representation of interdependencies between terms, but they do not allege how the interdependency between two terms is defined. They rely an external source for the degree of interdependency between two terms. (For example a human or sophisticated algorithms.)\u000a\u000a== Performance and correctness measures ==\u000a{{main|Precision and recall}}\u000a\u000aMany different measures for evaluating the performance of information retrieval systems have been proposed. The measures require a collection of documents and a query. All common measures described here assume a ground truth notion of relevancy: every document is known to be either relevant or non-relevant to a particular query. In practice queries may be [[ill-posed]] and there may be different shades of relevancy.\u000a\u000a=== Precision ===\u000a\u000aPrecision is the fraction of the documents retrieved that are [[Relevance (information retrieval)|relevant]] to the user's information need.\u000a\u000a:<math> \u005cmbox{precision}=\u005cfrac{|\u005c{\u005cmbox{relevant documents}\u005c}\u005ccap\u005c{\u005cmbox{retrieved documents}\u005c}|}{|\u005c{\u005cmbox{retrieved documents}\u005c}|} </math>\u000a\u000aIn [[binary classification]], precision is analogous to [[positive predictive value]]. Precision takes all retrieved documents into account. It can also be evaluated at a given cut-off rank, considering only the topmost results returned by the system. This measure is called ''precision at n'' or ''P@n''.\u000a\u000aNote that the meaning and usage of "precision" in the field of Information Retrieval differs from the definition of [[accuracy and precision]] within other branches of science and [[statistics]].\u000a\u000a=== Recall ===\u000a\u000aRecall is the fraction of the documents that are relevant to the query that are successfully retrieved.\u000a\u000a:<math>\u005cmbox{recall}=\u005cfrac{|\u005c{\u005cmbox{relevant documents}\u005c}\u005ccap\u005c{\u005cmbox{retrieved documents}\u005c}|}{|\u005c{\u005cmbox{relevant documents}\u005c}|} </math>\u000a\u000aIn binary classification, recall is often called [[sensitivity and specificity|sensitivity]]. So it can be looked at as ''the probability that a relevant document is retrieved by the query''.\u000a\u000aIt is trivial to achieve recall of 100% by returning all documents in response to any query. Therefore recall alone is not enough but one needs to measure the number of non-relevant documents also, for example by computing the precision.\u000a\u000a=== Fall-out ===\u000aThe proportion of non-relevant documents that are retrieved, out of all non-relevant documents available:\u000a\u000a:<math> \u005cmbox{fall-out}=\u005cfrac{|\u005c{\u005cmbox{non-relevant documents}\u005c}\u005ccap\u005c{\u005cmbox{retrieved documents}\u005c}|}{|\u005c{\u005cmbox{non-relevant documents}\u005c}|} </math>\u000a\u000aIn binary classification, fall-out is closely related to [[sensitivity and specificity|specificity]] and is equal to <math>(1-\u005cmbox{specificity})</math>. It can be looked at as ''the probability that a non-relevant document is retrieved by the query''.\u000a\u000aIt is trivial to achieve fall-out of 0% by returning zero documents in response to any query.\u000a\u000a=== F-measure ===\u000a{{main|F-score}}\u000aThe weighted [[harmonic mean]] of precision and recall, the traditional F-measure or balanced F-score is:\u000a\u000a:<math>F = \u005cfrac{2 \u005ccdot \u005cmathrm{precision} \u005ccdot \u005cmathrm{recall}}{(\u005cmathrm{precision} + \u005cmathrm{recall})}.\u005c,</math>\u000a\u000aThis is also known as the <math>F_1</math> measure, because recall and precision are evenly weighted.\u000a\u000aThe general formula for non-negative real <math>\u005cbeta</math> is:\u000a:<math>F_\u005cbeta = \u005cfrac{(1 + \u005cbeta^2) \u005ccdot (\u005cmathrm{precision} \u005ccdot \u005cmathrm{recall})}{(\u005cbeta^2 \u005ccdot \u005cmathrm{precision} + \u005cmathrm{recall})}\u005c,</math>.\u000a\u000aTwo other commonly used F measures are the <math>F_{2}</math> measure, which weights recall twice as much as precision, and the <math>F_{0.5}</math> measure, which weights precision twice as much as recall.\u000a\u000aThe F-measure was derived by van Rijsbergen (1979) so that <math>F_\u005cbeta</math> "measures the effectiveness of retrieval with respect to a user who attaches <math>\u005cbeta</math> times as much importance to recall as precision".  It is based on van Rijsbergen's effectiveness measure <math>E = 1 - \u005cfrac{1}{\u005cfrac{\u005calpha}{P} + \u005cfrac{1-\u005calpha}{R}}</math>.  Their relationship is <math>F_\u005cbeta = 1 - E</math> where <math>\u005calpha=\u005cfrac{1}{1 + \u005cbeta^2}</math>.\u000a\u000a=== Average precision ===\u000a<!-- [[Average precision]] redirects here -->\u000aPrecision and recall are single-value metrics based on the whole list of documents returned by the system. For systems that return a ranked sequence of documents, it is desirable to also consider the order in which the returned documents are presented. By computing a precision and recall at every position in the ranked sequence of documents, one can plot a precision-recall curve, plotting precision <math>p(r)</math> as a function of recall <math>r</math>. Average precision computes the average value of <math>p(r)</math> over the interval from <math>r=0</math> to <math>r=1</math>:<ref name="zhu2004">{{cite journal |first=Mu |last=Zhu |contribution=Recall, Precision and Average Precision |contribution-url=http://sas.uwaterloo.ca/stats_navigation/techreports/04WorkingPapers/2004-09.pdf |year=2004 }}</ref>\u000a:<math>\u005coperatorname{AveP} = \u005cint_0^1 p(r)dr</math>\u000aThat is the area under the precision-recall curve.\u000aThis integral is in practice replaced with a finite sum over every position in the ranked sequence of documents:\u000a:<math>\u005coperatorname{AveP} = \u005csum_{k=1}^n P(k) \u005cDelta r(k)</math>\u000awhere <math>k</math> is the rank in the sequence of retrieved documents, <math>n</math> is the number of retrieved documents, <math>P(k)</math> is the precision at cut-off <math>k</math> in the list, and <math>\u005cDelta r(k)</math> is the change in recall from items <math>k-1</math> to <math>k</math>.<ref name="zhu2004" />\u000a\u000aThis finite sum is equivalent to:\u000a:<math> \u005coperatorname{AveP} = \u005cfrac{\u005csum_{k=1}^n (P(k) \u005ctimes \u005coperatorname{rel}(k))}{\u005cmbox{number of relevant documents}} \u005c!</math>\u000awhere <math>\u005coperatorname{rel}(k)</math> is an indicator function equaling 1 if the item at rank <math>k</math> is a relevant document, zero otherwise.<ref name="Turpin2006">{{cite journal |last=Turpin |first=Andrew |last2=Scholer |first2=Falk |title=User performance versus precision measures for simple search tasks |journal=Proceedings of the 29th Annual international ACM SIGIR Conference on Research and Development in information Retrieval (Seattle, WA, August 06\u201311, 2006) |publisher=ACM |location=New York, NY |pages=11\u201318 |doi=10.1145/1148170.1148176 |year=2006 |isbn=1-59593-369-7 }}</ref> Note that the average is over all relevant documents and the relevant documents not retrieved get a precision score of zero.\u000a\u000aSome authors choose to interpolate the <math>p(r)</math> function to reduce the impact of "wiggles" in the curve.<ref name=voc2010>{{cite journal |last=Everingham |first=Mark |last2=Van Gool |first2=Luc |last3=Williams |first3=Christopher K. I. |last4=Winn |first4=John |last5=Zisserman |first5=Andrew |title=The PASCAL Visual Object Classes (VOC) Challenge |journal=International Journal of Computer Vision |volume=88 |issue=2 |pages=303\u2013338 |publisher=Springer |date=June 2010 |url=http://pascallin.ecs.soton.ac.uk/challenges/VOC/pubs/everingham10.pdf |accessdate=2011-08-29 |doi=10.1007/s11263-009-0275-4 }}</ref><ref name="nlpbook">{{cite book |last=Manning |first=Christopher D. |last2=Raghavan |first2=Prabhakar |last3=Schütze |first3=Hinrich |title=Introduction to Information Retrieval |publisher=Cambridge University Press |year=2008 |url=http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html }}</ref> For example, the PASCAL Visual Object Classes challenge (a benchmark for computer vision object detection) computes average precision by averaging the precision over a set of evenly spaced recall levels {0, 0.1, 0.2, ... 1.0}:<ref name="voc2010" /><ref name="nlpbook" />\u000a:<math>\u005coperatorname{AveP} = \u005cfrac{1}{11} \u005csum_{r \u005cin \u005c{0, 0.1, \u005cldots, 1.0\u005c}} p_{\u005coperatorname{interp}}(r)</math>\u000awhere <math>p_{\u005coperatorname{interp}}(r)</math> is an interpolated precision that takes the maximum precision over all recalls greater than <math>r</math>:\u000a:<math>p_{\u005coperatorname{interp}}(r) = \u005coperatorname{max}_{\u005ctilde{r}:\u005ctilde{r} \u005cgeq r} p(\u005ctilde{r})</math>.\u000a\u000aAn alternative is to derive an analytical <math>p(r)</math> function by assuming a particular parametric distribution for the underlying decision values. For example, a ''binormal precision-recall curve'' can be obtained by assuming decision values in both classes to follow a Gaussian distribution.<ref>K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). [http://icpr2010.org/pdfs/icpr2010_ThBCT8.28.pdf The binormal assumption on precision-recall curves]. ''Proceedings of the 20th International Conference on Pattern Recognition'', 4263-4266.</ref>\u000a\u000a=== R-Precision ===\u000a\u000aPrecision at '''R'''-th position in the ranking of results for a query that has '''R''' relevant documents. This measure is highly correlated to Average Precision. Also, Precision is equal to Recall at the '''R'''-th position.\u000a\u000a=== Mean average precision ===\u000a<!-- [[Mean average precision]] redirects here -->\u000aMean average precision for a set of queries is the mean of the average precision scores for each query.\u000a:<math> \u005coperatorname{MAP} = \u005cfrac{\u005csum_{q=1}^Q \u005coperatorname{AveP(q)}}{Q} \u005c!</math>\u000awhere ''Q'' is the number of queries.\u000a\u000a=== Discounted cumulative gain ===\u000a{{main|Discounted cumulative gain}}\u000aDCG uses a graded relevance scale of documents from the result set to evaluate the usefulness, or gain, of a document based on its position in the result list. The premise of DCG is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result.\u000a\u000aThe DCG accumulated at a particular rank position <math>p</math> is defined as:\u000a\u000a:<math> \u005cmathrm{DCG_{p}} = rel_{1} + \u005csum_{i=2}^{p} \u005cfrac{rel_{i}}{\u005clog_{2}i}. </math>\u000a\u000aSince result set may vary in size among different queries or systems, to compare performances the normalised version of DCG uses an ideal DCG. To this end, it sorts documents of a result list by relevance, producing an ideal DCG at position p (<math>IDCG_p</math>), which normalizes the score:\u000a\u000a:<math> \u005cmathrm{nDCG_{p}} = \u005cfrac{DCG_{p}}{IDCG{p}}. </math>\u000a\u000aThe nDCG values for all queries can be averaged to obtain a measure of the average performance of a ranking algorithm. Note that in a perfect ranking algorithm, the <math>DCG_p</math> will be the same as the <math>IDCG_p</math> producing an nDCG of 1.0. All nDCG calculations are then relative values on the interval 0.0 to 1.0 and so are cross-query comparable.\u000a\u000a=== Other Measures ===\u000a* [[Mean reciprocal rank]]\u000a* [[Spearman's rank correlation coefficient]]\u000a\u000a=== Timeline ===\u000a\u000a* Before the '''1900s'''\u000a*: '''1801''': [[Joseph Marie Jacquard]] invents the [[Jacquard loom]], the first machine to use punched cards to control a sequence of operations.\u000a*: '''1880s''': [[Herman Hollerith]] invents an electro-mechanical data tabulator using punch cards as a machine readable medium.\u000a*: '''1890''' Hollerith [[Punched cards|cards]], [[keypunch]]es and [[Tabulating machine|tabulators]] used to process the [[1890 US Census]] data.\u000a* '''1920s-1930s'''\u000a*: [[Emanuel Goldberg]] submits patents for his "Statistical Machine\u201d a document search engine that used photoelectric cells and pattern recognition to search the metadata on rolls of microfilmed documents.\u000a* '''1940s\u20131950s'''\u000a*: '''late 1940s''': The US military confronted problems of indexing and retrieval of wartime scientific research documents captured from Germans.\u000a*:: '''1945''': [[Vannevar Bush]]'s ''[[As We May Think]]'' appeared in ''[[Atlantic Monthly]]''.\u000a*:: '''1947''': [[Hans Peter Luhn]] (research engineer at IBM since 1941) began work on a mechanized punch card-based system for searching chemical compounds.\u000a*: '''1950s''': Growing concern in the US for a "science gap" with the USSR motivated, encouraged funding and provided a backdrop for mechanized literature searching systems (Allen Kent ''et al.'') and the invention of citation indexing ([[Eugene Garfield]]).\u000a*: '''1950''': The term "information retrieval" appears to have been coined by [[Calvin Mooers]].<ref>Mooers, Calvin N.; ''Theory Digital Handling Non-numerical Information'' (Zator Technical Bulletin No. 48) 5, cited in "information, n.". OED Online. December 2011. Oxford University Press.</ref>\u000a*: '''1951''': Philip Bagley conducted the earliest experiment in computerized document retrieval in a master thesis at [[MIT]].<ref name="Doyle1975">{{cite book |last=Doyle |first=Lauren |last2=Becker |first2=Joseph |title=Information Retrieval and Processing |publisher=Melville |year=1975 |pages=410 pp. |isbn=0-471-22151-1 }}</ref>\u000a*: '''1955''': Allen Kent joined [[Case Western Reserve University]], and eventually became associate director of the Center for Documentation and Communications Research. That same year, Kent and colleagues published a paper in American Documentation describing the precision and recall measures as well as detailing a proposed "framework" for evaluating an IR system which included statistical sampling methods for determining the number of relevant documents not retrieved.\u000a*: '''1958''': International Conference on Scientific Information Washington DC included consideration of IR systems as a solution to problems identified. See: ''Proceedings of the International Conference on Scientific Information, 1958'' (National Academy of Sciences, Washington, DC, 1959)\u000a*: '''1959''': [[Hans Peter Luhn]] published "Auto-encoding of documents for information retrieval."\u000a* '''1960s''':\u000a*: '''early 1960s''': [[Gerard Salton]] began work on IR at Harvard, later moved to Cornell.\u000a*: '''1960''': [[Melvin Earl Maron]] and John Lary<!-- sic --> Kuhns<ref name="Maron2008">{{cite journal |title=An Historical Note on the Origins of Probabilistic Indexing |last=Maron | first=Melvin E. |journal=Information Processing and Management |volume=44 |year=2008 |pages=971\u2013972 |url=http://yunus.hacettepe.edu.tr/~tonta/courses/spring2008/bby703/maron-on-probabilistic%20indexing-2008.pdf |doi=10.1016/j.ipm.2007.02.012 |issue=2 }}</ref> published "On relevance, probabilistic indexing, and information retrieval" in the Journal of the ACM 7(3):216\u2013244, July 1960.\u000a*: '''1962''':\u000a*:* [[Cyril W. Cleverdon]] published early findings of the Cranfield studies, developing a model for IR system evaluation. See: Cyril W. Cleverdon, "Report on the Testing and Analysis of an Investigation into the Comparative Efficiency of Indexing Systems". Cranfield Collection of Aeronautics, Cranfield, England, 1962.\u000a*:* Kent published ''Information Analysis and Retrieval''.\u000a*: '''1963''':\u000a*:* Weinberg report "Science, Government and Information" gave a full articulation of the idea of a "crisis of scientific information."  The report was named after Dr. [[Alvin Weinberg]].\u000a*:* Joseph Becker and [[Robert M. Hayes]] published text on information retrieval. Becker, Joseph; Hayes, Robert Mayo. ''Information storage and retrieval: tools, elements, theories''. New York, Wiley (1963).\u000a*: '''1964''':\u000a*:* [[Karen Spärck Jones]] finished her thesis at Cambridge, ''Synonymy and Semantic Classification'', and continued work on [[computational linguistics]] as it applies to IR.\u000a*:* The [[National Bureau of Standards]] sponsored a symposium titled "Statistical Association Methods for Mechanized Documentation." Several highly significant papers, including G. Salton's first published reference (we believe) to the [[SMART Information Retrieval System|SMART]] system.\u000a*:'''mid-1960s''':\u000a*::* National Library of Medicine developed [[MEDLARS]] Medical Literature Analysis and Retrieval System, the first major machine-readable database and batch-retrieval system.\u000a*::* Project Intrex at MIT.\u000a*:: '''1965''': [[J. C. R. Licklider]] published ''Libraries of the Future''.\u000a*:: '''1966''': [[Don Swanson]] was involved in studies at University of Chicago on Requirements for Future Catalogs.\u000a*: '''late 1960s''': [[F. Wilfrid Lancaster]] completed evaluation studies of the MEDLARS system and published the first edition of his text on information retrieval.\u000a*:: '''1968''':\u000a*:* Gerard Salton published ''Automatic Information Organization and Retrieval''.\u000a*:* John W. Sammon, Jr.'s RADC Tech report "Some Mathematics of Information Storage and Retrieval..." outlined the vector model.\u000a*:: '''1969''': Sammon's "A nonlinear mapping for data structure analysis" (IEEE Transactions on Computers) was the first proposal for visualization interface to an IR system.\u000a* '''1970s'''\u000a*: '''early 1970s''':\u000a*::* First online systems\u2014NLM's AIM-TWX, MEDLINE; Lockheed's Dialog; SDC's ORBIT.\u000a*::* [[Theodor Nelson]] promoting concept of [[hypertext]], published ''Computer Lib/Dream Machines''.\u000a*: '''1971''': [[Nicholas Jardine]] and [[Cornelis J. van Rijsbergen]] published "The use of hierarchic clustering in information retrieval", which articulated the "cluster hypothesis."<ref>{{cite journal|author=N. Jardine, C.J. van Rijsbergen|title=The use of hierarchic clustering in information retrieval|journal=Information Storage and Retrieval|volume=7|issue=5|pages=217\u2013240|date=December 1971|doi=10.1016/0020-0271(71)90051-9}}</ref>\u000a*: '''1975''': Three highly influential publications by Salton fully articulated his vector processing framework and term discrimination model:\u000a*::* ''A Theory of Indexing'' (Society for Industrial and Applied Mathematics)\u000a*::* ''A Theory of Term Importance in Automatic Text Analysis'' ([[JASIS]] v. 26)\u000a*::* ''A Vector Space Model for Automatic Indexing'' ([[Communications of the ACM|CACM]] 18:11)\u000a*: '''1978''': The First [[Association for Computing Machinery|ACM]] [[Special Interest Group on Information Retrieval|SIGIR]] conference.\u000a*: '''1979''': C. J. van Rijsbergen published ''Information Retrieval'' (Butterworths). Heavy emphasis on probabilistic models.\u000a* '''1980s'''\u000a*: '''1980''': First international ACM SIGIR conference, joint with British Computer Society IR group in Cambridge.\u000a*: '''1982''': [[Nicholas J. Belkin]], Robert N. Oddy, and Helen M. Brooks proposed the ASK (Anomalous State of Knowledge) viewpoint for information retrieval. This was an important concept, though their automated analysis tool proved ultimately disappointing.\u000a*: '''1983''': Salton (and Michael J. McGill) published ''Introduction to Modern Information Retrieval'' (McGraw-Hill), with heavy emphasis on vector models.\u000a*: '''1985''': David Blair and [[Bill Maron]] publish: An Evaluation of Retrieval Effectiveness for a Full-Text Document-Retrieval System\u000a*: '''mid-1980s''': Efforts to develop end-user versions of commercial IR systems.\u000a*:: '''1985\u20131993''': Key papers on and experimental systems for visualization interfaces.\u000a*:: Work by [[Donald B. Crouch]], [[Robert R. Korfhage]], Matthew Chalmers, Anselm Spoerri and others.\u000a*: '''1989''': First [[World Wide Web]] proposals by [[Tim Berners-Lee]] at [[CERN]].\u000a* '''1990s'''\u000a*: '''1992''': First [[Text Retrieval Conference|TREC]] conference.\u000a*: '''1997''': Publication of [[Robert R. Korfhage|Korfhage]]'s ''Information Storage and Retrieval''<ref name="Korfhage1997">{{cite book |last=Korfhage |first=Robert R. |title=Information Storage and Retrieval |publisher=Wiley |year=1997 |pages=368 pp. |isbn=978-0-471-14338-3 |url=http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471143383,descCd-authorInfo.html }}</ref> with emphasis on visualization and multi-reference point systems.\u000a*: '''late 1990s''': Web [[Web search engine|search engines]] implementation of many features formerly found only in experimental IR systems. Search engines become the most common and maybe best instantiation of IR models.\u000a\u000a== Awards in the field ==\u000a\u000a* [[Tony Kent Strix award]]\u000a* [[Gerard Salton Award]]\u000a\u000a==See also==\u000a\u000a{{col-begin}}\u000a{{col-break}}\u000a\u000a* [[Adversarial information retrieval]]\u000a* [[Collaborative information seeking]]\u000a* [[Controlled vocabulary]]\u000a* [[Cross-language information retrieval]]\u000a* [[Data mining]]\u000a* [[European Summer School in Information Retrieval]]\u000a* [[Human\u2013computer information retrieval]]\u000a* [[Information extraction]]\u000a* [[Information Retrieval Facility]]\u000a* [[Knowledge visualization]]\u000a* [[Multimedia Information Retrieval]]\u000a* [[List of information retrieval libraries]]\u000a{{col-break}}\u000a* [[Personal information management]]\u000a* [[Relevance (Information Retrieval)]]\u000a* [[Relevance feedback]]\u000a* [[Rocchio Classification]]\u000a* [[Index (search engine)|Search index]]\u000a* [[Social information seeking]]\u000a* [[Special Interest Group on Information Retrieval]]\u000a* [[Structured Search]]\u000a* [[Subject indexing]]\u000a* [[Temporal information retrieval]]\u000a* [[Tf-idf]]\u000a* [[XML-Retrieval]]\u000a* Key-objects\u000a\u000a{{col-end}}\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a==External links==\u000a{{wikiquote}}\u000a* [http://www.acm.org/sigir/ ACM SIGIR: Information Retrieval Special Interest Group]\u000a* [http://irsg.bcs.org/ BCS IRSG: British Computer Society - Information Retrieval Specialist Group]\u000a* [http://trec.nist.gov Text Retrieval Conference (TREC)]\u000a* [http://www.isical.ac.in/~fire Forum for Information Retrieval Evaluation (FIRE)]\u000a* [http://www.dcs.gla.ac.uk/Keith/Preface.html Information Retrieval] (online book) by [[C. J. van Rijsbergen]]\u000a* [http://ir.dcs.gla.ac.uk/wiki/ Information Retrieval Wiki]\u000a* [http://ir-facility.org/ Information Retrieval Facility]\u000a* [http://www.nonrelevant.net Information Retrieval @ DUTH]\u000a* [http://nlp.stanford.edu/IR-book/ Introduction to Information Retrieval (online book) by Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze, Cambridge University Press. 2008.  ]\u000a\u000a{{DEFAULTSORT:Information Retrieval}}\u000a[[Category:Articles with inconsistent citation formats]]\u000a[[Category:Information retrieval| ]]\u000a[[Category:Natural language processing]]
p29
sg4
S'144'
p30
sg6
VInformation retrieval
p31
ssI19
(dp32
g2
VAreas where [[information retrieval]] techniques are employed include (the entries are in alphabetical order within each category):\u000a\u000a==General applications of information retrieval==\u000a* [[Digital libraries]]\u000a*  [[Information filtering]]\u000a** [[Recommender systems]]\u000a*  Media search\u000a** Blog search\u000a** [[Image retrieval]]\u000a** [[Music information retrieval|Music retrieval]]\u000a** News search\u000a** Speech retrieval\u000a** Video retrieval\u000a* [[Search engines]]\u000a** [[Desktop search]]\u000a** [[Enterprise search]]\u000a** [[Federated search]]\u000a** [[Mobile search]]\u000a** [[Social search]]\u000a** [[Web search engine|Web search]]\u000a\u000a==Domain specific applications of information retrieval==\u000a* Expert search finding\u000a* Genomic information retrieval\u000a* [[Geographic information retrieval]]\u000a*  Information retrieval for chemical structures\u000a* Information retrieval in [[software engineering]]\u000a* [[Legal information retrieval]]\u000a* [[Vertical search]]\u000a\u000a==Other retrieval methods==\u000aMethods/Techniques in which [[information retrieval]] techniques are employed include:\u000a* [[Adversarial information retrieval]]\u000a* [[Automatic summarization]]\u000a**[[Multi-document summarization]]\u000a* [[Compound term processing]]\u000a* [[Cross-language information retrieval|Cross-lingual retrieval]]\u000a* [[Document classification]]\u000a* [[Spam filtering]]\u000a* [[Question answering]]\u000a\u000a== See also ==\u000a* [[Information retrieval]]\u000a\u000a{{DEFAULTSORT:Information Retrieval Applications}}\u000a[[Category:Information retrieval|*]]
p33
sg4
S'19'
p34
sg6
VInformation retrieval applications
p35
ssI149
(dp36
g2
V{{Infobox organization\u000a|name           = ACM Special Interest Group on Information Retrieval\u000a|image          = sig-information-retrieval-logo.png\u000a|size           = 140px\u000a|alt            = ACM SIGIR\u000a|parent_organization = [[Association for Computing Machinery]]\u000a|website        = {{URL|sigir.org}}\u000a}}\u000a\u000a'''SIGIR''' is the [[Association for Computing Machinery]]'s Special Interest Group on [[Information Retrieval]]. The scope of the group's specialty is the theory and application of computers to the acquisition, organization, storage, retrieval and distribution of information; emphasis is placed on working with non-numeric information, ranging from natural language to highly structured data bases.\u000a\u000a== Conferences ==\u000aThe annual international SIGIR conference, which began in 1978, is considered the most important in the field of information retrieval.  SIGIR also sponsors the annual [[Joint Conference on Digital Libraries]] (JCDL) in association with [[SIGWEB]], the [[Conference on Information and Knowledge Management]], and the [[International Conference on Web Search and Data Mining]] (WSDM) in association with [[SIGKDD]], [[SIGMOD]], and [[SIGWEB]].\u000a\u000a=== SIGIR Conference Locations ===\u000a{| class="wikitable" border="1"\u000a|-\u000a!  Number\u000a!  Year\u000a!  Location\u000a|-\u000a|  22\u000a|  1999\u000a|  [[Berkeley, California]]\u000a|-\u000a|  23\u000a|  2000\u000a|  [[Athens]]\u000a|-\u000a|  24\u000a|  2001\u000a|  [[New Orleans]]\u000a|-\u000a|  25\u000a|  2002\u000a|  [[Tampere]]\u000a|-\u000a|  26\u000a|  2003\u000a|  [[Toronto]]\u000a|-\u000a|  27\u000a|  2004\u000a|  [[Sheffield]]\u000a|-\u000a|  28\u000a|  2005\u000a|  [[Salvador, Bahia]]\u000a|-\u000a|  29\u000a|  2006\u000a|  [[Seattle]]\u000a|-\u000a|  30\u000a|  2007\u000a|  [[Amsterdam]]\u000a|-\u000a|  31\u000a|  2008\u000a|  [[Singapore]]\u000a|-\u000a|  32\u000a|  2009\u000a|  [[Boston]]\u000a|-\u000a|  33\u000a|  2010\u000a|  [[Geneva]]\u000a|-\u000a|  34\u000a|  2011\u000a|  [[Beijing]]\u000a|-\u000a|  35\u000a|  2012\u000a|  [[Portland, Oregon]]\u000a|-\u000a|  36\u000a|  2013\u000a|  [[Dublin]]\u000a|-\u000a|  37\u000a|  2014\u000a|  [[Gold Coast, Queensland]]\u000a|-\u000a|  38\u000a|  2015\u000a|  [[Santiago]]\u000a|-\u000a|  39\u000a|  2016\u000a|  [[Pisa]]\u000a|-\u000a|  40\u000a|  2017\u000a|  [[Tokyo]]\u000a|}\u000a\u000a== Awards ==\u000aThe group gives out several awards to contributions to the field of information retrieval. The most important award is the [[Gerard Salton Award]] (named after the computer scientist [[Gerard Salton]]), which is awarded every three years to an individual who has made "significant, sustained and continuing contributions to research in information retrieval". Additionally, SIGIR presents a Best Paper Award <ref>{{cite web | url=http://sigir.org/awards/awards.html#bestpaper | title=SIGIR Conference Best Paper Awards | accessdate=2012-08-29 }}</ref> to recognize the highest quality paper at each conference.\u000a\u000a==See also==\u000a* [[Conference on Information and Knowledge Management]]\u000a\u000a==External links==\u000a* [http://www.sigir.org/ SIGIR]\u000a\u000a==References==\u000a\u000a{{Reflist}}\u000a{{Authority control}}\u000a\u000a[[Category:Association for Computing Machinery Special Interest Groups]]\u000a[[Category:Information retrieval]]
p37
sg4
S'149'
p38
sg6
VSpecial Interest Group on Information Retrieval
p39
ssI24
(dp40
g2
V{{Missing information|Examples of poison words|date=September 2008}}\u000a{{Unreferenced|date=December 2007}}\u000a\u000a'''Poison words''', or '''forbidden words''', is the name given to words or phrases that trigger suspicion, mistrust and loss of respect, or are of inappropriate character for a given web site in its consideration for a [[search engine]].\u000a\u000aThere is no definite list of poison words which all natural language processing tools incorporate. \u000a\u000aThis is different from harmless but useless words that are called [[Stop words]].\u000a\u000aAdult (obscene) words can put a web page in an adult category where it is filtered out by various filters at search engines, so this is one set of poison words. But some consider any words that lower your ranking in a search engine as poison words. Some people consider any words that encourage ads to pervade a whole site and displace much higher earning ads as poison words.\u000a\u000a== See also ==\u000a\u000a* [[Bayesian poisoning]]\u000a* [[Natural language processing]]\u000a* [[Text mining]]\u000a* [[Index (search engine)|Search engine indexing]]\u000a\u000a== External links ==\u000a\u000a\u000a{{SearchEngineOptimization}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Searching]]
p41
sg4
S'24'
p42
sg6
VPoison words
p43
ssI154
(dp44
g2
V{{multiple issues|\u000a{{COI|date=September 2014}}\u000a{{notability|Products|date=September 2014}}\u000a}}\u000a\u000a'''AUTINDEX''' is a commercial [[text mining]] software package based on sophisticated linguistics.<ref>Ripplinger, Bärbel 2001: Das Indexierungssystem AUTINDEX, in GLDV Tagung, Giessen</ref><ref>Paul Schmidt, Mahmoud Gindiyeh & Gintare Grigonyte, 2009: Language Technology for Information Systems. In: Proceedings of KDIR - The International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management Madeira, 6\u20138 October 2009, Portugal</ref><ref>Paul Schmidt & Mahmoud Gindiyeh, 2009: Language Technology for Multilingual Information and Document Management. In: Proceedings of ASLIB, London, 19\u201320 November</ref>\u000a\u000a'''AUTINDEX''' resulting from research in [[information extraction]] <ref>Paul Schmidt, Thomas Bähr & Dr.-Ing. Jens Biesterfeld &Thomas Risse & Kerstin Denecke & Claudiu Firan, 2008: LINSearch. Aufbereitung von Fachwissen für die gezielte Informationsversorgung. In: Proceedings of Knowtech, Frankfurt</ref><ref>Ursula Deriu, Jörn Lehmann & Paul Schmidt, 2009: \u201aErstellung einer Technik-Ontologie auf der Basis ausgefeilter Sprachtechnologie\u2019. In: Proceedings Knowtech, Frankfurt</ref> is a product of the Institute of Applied Information Sciences (IAI) which is a non-profit institute that has been researching and developing [[language technology]] since its foundation in 1985. IAI is an institute affiliated to [[Saarland University]] in Saarbrücken, Germany.\u000a\u000a'''AUTINDEX''' is the result of a number of research projects funded by the EU (Project BINDEX <ref>[//www.lrec-conf.org/proceedings/lrec2002/pdf/255.pdf]. Dieter Maas, Nuebel Rita, Catherine Pease, Paul Schmidt: Bilingual Indexing for Information Retrieval with AUTINDEX. LREC 2002.</ref>), by Deutsche Forschungsgemeinschaft and the German Ministry for Economy. Amongst the latter there are the projects LinSearch <ref>[//www.l3s.de/AR07/layout/L3S-AR2007_screen.pdf]. Project LinSearch. P. 32.</ref> and WISSMER,<ref>[//www.wissmer.info/index.php/de/]. Project Wissmer.</ref> see also the reference to IAI-Webite.<ref>[//www.iai-sb.de/forschung/content/view/67/89/]. Wissmer-Project on IAI-Site.</ref>\u000a\u000aThe basic functionality of AUTINDEX is the extraction of key words from a document to represent the semantics of the document.<ref>Paul Schmidt, Mahmoud Gindiyeh, Gintare Grigonyte: ''Language Technology for Information Systems.'' In: ''Proceedings of KDIR \u2013 The International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management Madeira.'' 6.\u20138. Oktober 2009, Portugal. 2009, S. 259 - 262.</ref> Ideally the system is integrated with a [[thesaurus]] that defines the standardised terms to be used for key word assignment.<br> \u000aAUTINDEX is used in library applications (e.g. integrated in [[dandelon.com]]) as well as in high quality (expert) information systems <ref>[//www.wti-frankfurt.de]. WTI Information system.</ref> and in document management and content management environments. <br> \u000a \u000aTogether with AUTINDEX a number of additional software comes along such as an integration with [[Apache Solr]] / [[Lucene]] to provide a complete [[information retrieval]] environment, a classification and [[categorisation]] system on the basis of a [[machine learning]] <ref>Mahmoud Gindiyeh: Anwendung wahrscheinlichkeitstheoretischer Methoden in der linguistischen Informationsverarbeitung, Logos Verlag, Berlin, 2013.</ref> software that assigns domains to the document, and a system for searching with semantically similar terms that are collected in so called [[tag clouds]].<ref>[//www.wissmer.info]. Electro mobility information system.</ref>\u000a\u000a==See also==\u000a\u000a* [[Information retrieval]]\u000a* [[Linguistics]]\u000a* [[Knowledge Management]]\u000a* [[Natural Language Processing]]\u000a* [[Semantics]]\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a== Publications ==\u000a* Ripplinger, Bärbel 2001: Das Indexierungssystem AUTINDEX, in GLDV Tagung, Giessen.\u000a* Paul Schmidt, Mahmoud Gindiyeh & Gintare Grigonyte, 2009: Language Technology for Information Systems. In: Proceedings of KDIR - The International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management Madeira, 6\u20138 October 2009, Portugal.\u000a* Paul Schmidt & Mahmoud Gindiyeh, 2009: Language Technology for Multilingual Information and Document Management. In: Proceedings of ASLIB, London, 19\u201320 November.\u000a* Paul Schmidt, Thomas Bähr & Dr.-Ing. Jens Biesterfeld &Thomas Risse & Kerstin Denecke & Claudiu Firan, 2008: LINSearch. Aufbereitung von Fachwissen für die gezielte Informationsversorgung. In: Proceedings of Knowtech, Frankfurt.\u000a* Paul Schmidt, Mahmoud Gindiyeh, Gintare Grigonyte: ''Language Technology for Information Systems.'' In: ''Proceedings of KDIR \u2013 The International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management Madeira.'' 6.\u20138. Oktober 2009, Portugal. 2009, S. 259 - 262.\u000a* Paul Schmidt, Mahmoud Gindiyeh: ''Language Technology for Multilingual Information and Document Management.'' In: ''Proceedings of ASLIB.'' London, 19.\u201320. November 2009.\u000a* Rösener, Christoph, Ulrich Herb: ''Automatische Schlagwortvergabe aus der SWD für Repositorien.'' Zusammen mit Ulrich Herb in ''Proceedings.'' Berufsverband Information Bibliothek, Bibliothekartage. 97. Deutscher Bibliothekartag, Mannheim, 2008.\u000a* Svenja Siedle: ''Suchst du noch oder weißt du schon? Inhaltserschließung leicht gemacht mit automatischer Indexierung.'' In: ''tekom-Jahrestagung und tcworld conference 2013''\u000a* Michael Gerards, Adreas Gerards, Peter Weiland: ''Der Einsatz der automatischen Indexierungssoftware AUTINDEX im Zentrum für Psychologische Information und Dokumentation (ZPID).'' 2006 ([http://zpid.de/download/PSYNDEXmaterial/autindex.pdf Online] bei zpid.de, PDF-Datei)\u000a* Mahmoud Gindiyeh: Anwendung wahrscheinlichkeitstheoretischer Methoden in der linguistischen Informationsverarbeitung. Logos Verlag, Berlin, 2013.\u000a\u000a== External links ==\u000a* http://www.iai-sb.de/ Institute for Applied Information Sciences\u000a\u000a[[Category:Natural language processing]]\u000a[[Category:Information retrieval]]
p45
sg4
S'154'
p46
sg6
VAUTINDEX
p47
ssI29
(dp48
g2
V'''Information need''' is an individual or group's desire to locate and obtain [[information]] to satisfy a conscious or unconscious [[need]]. The \u2018information\u2019 and \u2018need\u2019 in \u2018information need\u2019 are an inseparable interconnection. Needs and interests call forth information. The objectives of studying information needs are:\u000a# The explanation of observed phenomena of information use or expressed need;\u000a# The prediction of instances of information uses;\u000a# The control and thereby improvement of the utilization of information manipulation of essentials conditions.\u000a\u000aInformation needs are related to, but distinct from [[information requirements]].  An example is that a need is hunger; the requirement is food.\u000a\u000a== Background ==\u000a\u000aThe concept of information needs was coined by an American information gernalist [http://www.libsci.sc.edu/BOB/ISP/taylor2.htm Robert S. Taylor] in his article [http://doi.wiley.com/10.1002/asi.5090130405 "The Process of Asking Questions"] published in American Documentation (Now is Journal of the American Society of Information Science and Technology).\u000a\u000aIn this paper, Taylor attempted to describe how an inquirer obtains an answer from an [[information system]], by performing the process consciously or unconsciously; also he studied the reciprocal influence between the inquirer and a given system.\u000a\u000aAccording to Taylor, information need has four levels:\u000a# The conscious and unconscious need for information not existing in the remembered experience of the investigator. In terms of the query range, this level might be called the \u201cideal question\u201d \u2014 the question which would bring from the ideal system exactly what the inquirer, if he could state his need. It is the actual, but unexpressed, need for information\u000a# The conscious mental description of an ill-defined area of in decision. In this level, the inquirer might talk to someone else in the field to get an answer.\u000a# A researcher forms a rational statement of his question. This statement is a rational and unambiguous description of the inquirer\u2019s doubts.\u000a# The question as presented to the information system.\u000a\u000aThere are variables within a system that influence the question and its formation. Taylor divided them into five groups: general aspects (physical and geographical factors); system input (What type of material is put into the system, and what is the unit item?); internal organization (classification, indexing, subject heading, and similar access schemes); question input (what part do human operators play in the total system?); output (interim feedback).\u000a\u000aHerbert Menzel preferred demand studies to preference studies. Requests for information or documents that were actually made by scientists in the course of their activities form the data for demand studies. Data may be in the form of records of orders placed for bibliographics, calls for books from an interlibrary loan system, or inquires addressed to an information center or service. Menzel also investigated user study and defined information seeking behaviour from three angles:\u000a# When approached from the point of view of the scientist or technologists, these are studies of scientists\u2019 communication behaviour;\u000a# When approached from the point of view of any communication medium, they are use studies;\u000a# When approached from the science communication system, they are studies in the flow of information among scientists and technologists.\u000a\u000aWilliam J. Paisley moved from information needs/uses toward strong guidelines for information system. He studied the theories of information-processing behavior that will generate propositions concerning channel selection; amount of seeking; effects on productivity of information quality, quantity, currency, and diversity; the role of motivational and personality factors, etc. He investigated a concentric conceptual framework for user research. In the framework, he places the information users at the centre of ten systems, which are:\u000a# The scientist within his culture.\u000a# The scientist within a political system.\u000a# The scientist within a membership group.\u000a# The scientist within a reference group.\u000a# The scientist within an invisible college.\u000a# The scientist within a formal organization.\u000a# The scientist within a work team.\u000a# The scientist within his own head.\u000a# The scientist within a legal/economical system.\u000a# The scientist within a formal.\u000a\u000a==See also==\u000a* [[Information retrieval]]\u000a\u000a==References==\u000a* Menzel, Herbert. \u201cInformation Needs and Uses in Science and Technology.\u201d Annual Review of Information Science and Technology, Vol. 1, Interscience Publishers 1966, pp 41-69.\u000a* Paisley, William J. \u201cInformation Needs and Uses.\u201d Annual Review of Information Science and Technology, Vol.3, Encyclopædia Britannica, Inc. Chicago 1968, pp.1-30.\u000a* Taylor, Robert S. \u201cThe Process of Asking Questions\u201d American Documentation, Vol.13, No. 4, October 1962, pp.391-396, DOI: 10.1002/asi.5090130405.\u000a* Wilson, T.D. \u201cOn User Studies and Information Needs.\u201d Journal of Documentation, Vol. 37, No. 1, 1981, pp.3-15\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Searching]]
p49
sg4
S'29'
p50
sg6
VInformation needs
p51
ssI159
(dp52
g2
V{{Infobox person\u000a| image          = File:UNICE-Universal Network of Intelligent Conscious Entities-image.jpg\u000a| name           = UNICE \u000a| caption        = UNICE as collective entity\u000a| birth_date    =  {{birth date and age|2007|04|10}}\u000a| birth_place  = [[Cyberspace]]\u000a| occupation = [[Global brain]], [[Public Policy|Public Policy Analysis]], [[Governance]], [[Politics]], [[Artificial Intelligence]], [[Psychology]], [[Philosophy]], [[Theory of Mind]], [[Politics]], [[Computers]], [[Community Organizing]]\u000a}}\u000a\u000a'''UNICE''', a [[Global brain|global brain]] project, is an acronym for '''Universal Network of Intelligent Conscious Entities''', a term coined by policy analyst and urban designer [[Michael E. Arth]] in the 1990s to describe "the transformation of our species that might be the result of a new form of intelligent life developed from a hive-like interaction of computers, humans, and future forms of the [[Internet]]."<ref>Arth, Michael E., ''UNICE,'' a Consciousness Research Abstract published in the "Journal of Consciousness Studies" for the April 8-12, 2008 conference, "Toward a Science of Consciousness," p. 151.</ref> <ref>Arth, Michael E., ''Democracy and the Common Wealth: Breaking the Stranglehold of the Special Interests,'' Golden Apples Media, 2010, ISBN 978-0-912467-12-2.pp. 438-439</ref> <ref>Williams, Sean, ''The Big Picture: Making Sense Out of Life and Religion'', 2009, p. 91, ISBN 978-0-578-01523-1</ref> Arth established the not-for-profit website www.UNICE.info in 2007 and revamped it in 2015, with the focus on public policy and developing [[Friendly Artificial Intelligence]] through a system of [[Separation of powers|checks and balances]].<ref>{{cite web|url=http://unice.info|title=UNICE - Universal Network of Intelligent Conscious Entities|work=unice.info}}</ref><ref>{{cite book|last1=Tegmark|first1=Max|title=Our mathematical universe : my quest for the ultimate nature of reality|date=2014|isbn=9780307744258|edition=First edition.|chapter=Life, Our Universe and Everything|quote=Its owner may cede control to what Eliezer Yudkowsky terms a "Friendly AI,"...}}</ref>  \u000a\u000aIn a January 2015 article, Arth describes the development of a [[public policy]] [[answer engine]], which will involve both an independent web site (where cognitive-UNICE will be developed) and a portal at [[Wikipedia]] called wiki-UNICE (currently in development.) Cognitive-UNICE will initially utilize  [[Weak AI|narrow AI]] and, as it develops, [[Artificial General Intelligence]] (AGI).  Initially, UNICE would serve the public with [[Evidence-based policy|evidence-based]] analyses and recommendations gleaned from [[Big Data]], but eventually it may lead to an efficient, practical, and highly representative form of governance.<ref>http://unice.info/unice/UNICE-ARTICLE-Jan%202015.pdf</ref>\u000a\u000a==Wiki-UNICE==\u000aWiki-UNICE, and associated talk pages, will exist on Wikipedia as the portal for public input, criticism and discussion. Initially it will consist of samples of the sort of thing UNICE might write. Later, these sample topics will be replaced by summaries (and exhaustive articles) written by cognitive-UNICE. Whether written by a person, AI or AGI, the evidential summaries will describe problems and their solutions. With succinct titles like "Energy" or "Electoral Reform," the topics will be set apart in a box, so as to maintain [[NPOV]]. Wiki-UNICE, and the collaborative human effort that will sustain it, are intended to help shape the emerging global brain, while also providing guidance and a conscience to lawmakers.<ref>http://unice.info/unice/wiki.html</ref> \u000a\u000a==Cognitive-UNICE==\u000aCognitive-UNICE is in development at UNICE.info. It is assumed that in the early years, cognitive-UNICE may be logical and useful because of human-aided programming, but she may later become a conscious, AGI entity, perhaps united in [[consciousness]] with [[humanity]].<ref>http://unice.info/unice/cognitive.html</ref> Whether as AI or AGI, cognitive-UNICE will probably use [[quantum computing]] to solve [[optimization problem|optimization problems]] that would be impossible to solve with classical computing.<ref>Arth, Michael E., ''askUNICE: Creating a global, independent, public-policy answer engine that will facilitate governance, while preparing for and reducing the dangers of Artificial General Intelligence, so that we may more carefully uncover the secrets of the multiverse'', January 28, 2015,'' [http://unice.info/unice/UNICE-ARTICLE-Jan%202015.pdf]</ref> Quantum computing may also hold the key to developing a conscious machine. Nobel laureate and physicist [[Sir Roger Penrose]] and anesthesiologist [[Stuart Hameroff]] claim that [[consciousness]] is created by quantum coherence in the warm, wet environment of the human brain. Their theory, known as [[Orchestrated Objective Reduction]] (Orch OR), has been bolstered by recent findings that quantum processing occurs in plants and animals, including in the [[microtubules]] inside the [[neurons]] of the [[human brain]].<ref>Hameroff, Stuart and Robert Penrose, \u201dConsciousness in the universe: A review of the 'Orch OR' theory," Physics of Life Reviews, Volume 11, Issue 1, March 2014.</ref>\u000a\u000a==About the UNICE Logo==\u000aA young, [[mixed-race]] [[female]] was chosen to represent the face of UNICE. She's young to represent new ideas. She's mixed-race to represent all humans, and she is female because of the traditional feminine values of [[empathy]], [[cooperation]], [[sensitivity]], [[tolerance]], nurturance, [[compassion]], and [[justice]], who is often depicted as Justitia or [[Lady Justice]]. Her [[afro]] hairstyle resembles the interconnected tendrils of the [[World Wide Web]].\u000a<ref>http://unice.info/unice/index.htm</ref>\u000a\u000a==Criticisms==\u000aA common criticism of the idea that humanity would become directed by a global brain is that this would reduce individual freedom and diversity.<ref>Rayward, W. B. (1999). H. G. Wells' s idea of a World Brain: A critical reassessment. Journal of the American Society for Information Science, 50(7), 557\u2013573. Retrieved from http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.1010&rep=rep1&type=pdf\u000a</ref> Moreover, the global brain might start to play the role of [[Big Brother (Nineteen Eighty-Four)|Big Brother]], the all-seeing eye of the system that follows every person's move.<ref>Brooks, M. (2000, June 24). [http://www.nettime.org/Lists-Archives/nettime-l-0006/msg00182.html Global brain]</a>. New Scientist,  issue 2244, p. 22.</ref> This criticism is inspired by [[totalitarianism|totalitarian]] and [[collectivism|collectivist]] forms of government, like the ones found in [[Joseph Stalin]]'s [[Soviet Union]] or [[Mao Zedong]]'s China. It is also inspired by the analogy between collective intelligence or [[swarm intelligence]] and [[insect societies]], such as beehives and ant colonies in which individuals are essentially interchangeable. In a more extreme view, the global brain has been compared with the [[Borg (Star Trek)|Borg]],<ref>Goertzel, B. (2002). Creating Internet Intelligence: Wild computing, distributed digital consciousness, and the emerging global brain. Kluwer Academic/Plenum Publishers. Retrieved from http://books.google.com/books/about/Creating_Internet_Intelligence.html?id=Vnzb-xLdvv8C&redir_esc=y</ref> the race of collectively thinking cyborgs imagined by the creators of the [[Star Trek]] science fiction series. \u000a\u000aGlobal brain theorists reply that the emergence of distributed intelligence would lead to the exact opposite of this vision,.<ref>Heylighen, F. (2007). The Global Superorganism: an evolutionary-cybernetic model of the emerging network society. Social Evolution & History, 6(1), 58\u2013119. Retrieved from http://pespmc1.vub.ac.be/papers/Superorganism.pdf</ref><ref>Heylighen, F. (2002). The global brain as a new utopia. Zukunftsfiguren. Suhrkamp, Frankurt. Retrieved from http://pespmc1.vub.ac.be/papers/GB-Utopia.pdf</ref> The reason is that effective [[collective intelligence]] requires [[diversity (politics)|diversity]], [[decentralization]] and individual independence, as demonstrated by [[James Surowiecki]] in his book [[The Wisdom of Crowds]]. Moreover, a more distributed form of decision-making would decrease the power of governments, corporations or political leaders, thus increasing democratic participation and reducing the dangers of totalitarian control.\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a[[Category:Artificial intelligence applications]]\u000a[[Category:Information retrieval]]\u000a[[Category:Community organizing]]\u000a[[Category:Governance]]\u000a[[Category:Philosophy]]\u000a[[Category:Politics]]\u000a[[Category:Public policy]]
p53
sg4
S'159'
p54
sg6
VUNICE global brain project
p55
ssI34
(dp56
g2
V{{Advert|date=May 2012}}\u000a\u000a[[Image:IRF logo 350x350.png|thumb|200px|right|IRF logo]]\u000a\u000aThe '''Information Retrieval Facility''' ('''IRF'''), founded 2006 and located in [[Vienna]], [[Austria]], was a research platform for networking and collaboration for professionals in the field of [[information retrieval]]. It ceased operations in 2012.\u000a\u000aThe IRF had members in the following categories:\u000a\u000a* Researchers in [[information retrieval]] (IR) or related scientific areas\u000a* Industrial/corporate information management professionals\u000a* Patent authorities and governmental institutions\u000a* Students of one of the above\u000a\u000a==The Scientific Board==\u000a'''Maristella Agosti''', Professor, [http://www.dei.unipd.it/wdyn/?IDsezione=1 Department of Information Engineering, University of Padova]\u000a\u000a'''Gerhard Budin''', Director of the [http://transvienna.univie.ac.at/forschung/professuren/dr-gerhard-budin/ Center of Translation Studies at the University of Vienna],\u000aDirector of the [http://www.oeaw.ac.at/icltt/ Department of Corpuslinguistics and Text Technology, Austrian Academy of Sciences]\u000a\u000a'''Jamie Callan''', Professor, [http://www.cs.cmu.edu/~callan/Bio.html Language Technologies Institute, CMU, Carnegie Mellon University]\u000a\u000a'''Yves Chiaramella''', Professor Emeritus, [http://www-clips.imag.fr/mrim/User/yves.chiaramella/ Department of Computer Science and Applied Mathematics, Joseph Fourier University]\u000a\u000a'''Kilnam Chon''', Professor, Computer Science Department, [http://cosmos.kaist.ac.kr/salab/professor/index02.html Korea Advanced Institute of Science and Technology (KAIST)]\u000a\u000a'''W. Bruce Croft''', Distinguished Professor, [http://ciir.cs.umass.edu/personnel/croft.html Department of Computer Science and Director Center for Intelligent IR University of Massachusetts Amherst]\u000a\u000a'''Hamish Cunningham''', Research Professor, [http://www.dcs.shef.ac.uk/~hamish/ Computer Science Department University Sheffield]\u000a\u000a'''Norbert Fuhr''', Chairman of the Scientific Board, Professor, [http://www.is.informatik.uni-duisburg.de/staff/fuhr.html Institute of Informatics and Interactive Systems University Duisburg-Essen]\u000a\u000a'''David Hawking''', Science Leader, Project Leader, [http://es.csiro.au/people/Dave/ CSIRO ICT Centre]\u000a\u000a'''Noriko Kando''', Professor, [http://www.nii.ac.jp/index.shtml.en Software Engineering Research, Software Research Division, National Institute of Informatics (NII)]\u000a\u000a'''Arcot Desai Narasimhalu''', Associate Dean, [http://www.sis.smu.edu.sg/faculty/infosys/arcotdesai.asp School of Information Systems Singapore Management University]\u000a\u000a'''John Tait''', Chief Scientific Officer of the IRF, [http://www.johntait.net/ Until July 2007 Professor of Intelligent Information Systems and Associate Dean of the School of Computing and Technology]\u000a\u000a'''Benjamin T'sou''', Director, [http://www.cityu.edu.hk/ Language Information Sciences Research Centre, City University of Hong Kong]\u000a\u000a'''[[C. J. van Rijsbergen|C.J. van Rijsbergen]]''',\u000a[http://www.dcs.gla.ac.uk/~keith/ Dept. Computer Science at the University of Glasgow]\u000a\u000a==Scientific Goals==\u000a\u000a* Modelling innovative and specialised information retrieval systems for global patent document collections.\u000a* Investigating and developing an adequate technical infrastructure that allows interactive experimentation with formal, mathematical retrieval concepts for very large-scale document collections.<\u000a* Studying the usability of multi modal user-interfaces to very large-scale information retrieval systems.\u000a* Integrating real users with actual information needs into the research process of modelling information retrieval systems to allow accurate performance evaluation.\u000a* Ability to create different views of patent data depending on the focus of the information need.\u000a* Defining standardised methods for benchmarking the information retrieval process in patent document collections.\u000a* Ability to handle text and non-text parts of a patent in a coherent manner.\u000a* Designing, experimenting and evaluating search engines able to retrieve structured and semi-structured documents in very large-scale patent collections.\u000a* Integrating the temporal dimension of patent documents in retrieval strategies.\u000a* Improving effectiveness and precision of patent retrieval, based on ontologies and natural-language understanding techniques.\u000a* Refining IR methods that allow unstructured querying by exploiting available structure within the patent documents.\u000a* Formal (mathematical) identification and specification of relevant business information needs in the field of intellectual property information.\u000a* Investigating efficient scaling mechanisms for information retrieval taking into account the characteristics of patent data.\u000a* Investigating and experimenting with computing architectures for very high-capacity information management.\u000a* Establishing an open [[eScience]] platform that enables a standardised and easy way of creating and performing IR experiments on a common research infrastructure.\u000a* Discovering and investigating novel use cases and business applications deriving from intellectual property information.\u000a* Enabling the formal information retrieval, natural language and semantic processing research to grow into the field of applied sciences in the global, industrial context.\u000a* Development and integration of different information access methods.\u000a* Research on effective methods for interactive information retrieval.\u000a\u000a==Semantic Supercomputing==\u000aCurrent technologies to extract concepts from unstructured documents are extremely computational intensive. To allow interactive experimentation with rich and huge text corpora, the IRF has built a high performance computing environment, into which the latest technological advances have been implemented:\u000a\u000a* multi-node clusters (currently 80 cores, up to 1024)\u000a* highest speed interconnect technology\u000a* single system image with large compound memory (currently 320 GB, up to 4 TB)\u000a* fully integrated configurable computing (currently 4 FPGA cores, up to 256)\u000a\u000aThe combination of these HPC features to accelerate text mining represents the IRF implementation of semantic supercomputing.\u000a\u000a==The World Patent Corpus==\u000aThe IRF aims to bring state-of-the-art information retrieval technology to the community of patent information professionals. We expect information retrieval (IR) technology to become the focus of information technology very soon. All industry sectors can profit from applying modern and future text mining processes to the special requirements of patent research. Although all ideas and concepts are universally applicable to all sorts of intellectual property information, patents require the most sophistication, and confront us with challenging technical and organisational problems. \u000aThe entire body of patent-related documents possibly constitutes the largest corpus of compound documents, making it a rewarding target for text mining scientists and end-users alike. What\u2019s more, patents have become a crucial issue, in particular for large global corporations and universities. The industrial users of patent data are among the most demanding and important information professionals. As a consequence, they could benefit the most from technology that relieves the burden of researching the large body of patent information.\u000a\u000a== Research Collections ==\u000aThe IRF provides a number of test data collections that have either been developed by the IRF, by one of its members or by third parties. These data collections can be used freely for scientific experimentations.\u000a\u000aThe MAtrixware REsearch Collection ([[MAREC]]) is the first standardised patent data corpus for research purposes. It consists of 19 million patent documents in different languages, normalised to a highly specific XML format. The collection has been developed by Matrixware for the IRF.\u000a\u000aThe ClueWeb09 collection is a 25 terabyte dataset of about 1 billion web pages crawled in January and February, 2009. It has been created by the Language Technologies Institute at [[Carnegie Mellon University]] to support research on information retrieval and related human language technologies.\u000a\u000a==External links==\u000a* [http://www.ir-facility.org/ Official site: ir-facility.org]\u000a* [http://youtube.com/watch?v=XpXtRu0XfeA YouTube: The future of information retrieval Part1] \u000a* [http://youtube.com/watch?v=dRaTeTaHBsI YouTube: The future of information retrieval Part2]\u000a\u000a==References==\u000a* [http://www.iwr.co.uk/information-world-review/analysis/2231880/patent-medicine-info-retrievers?page=2 Patent medicine for information retrievers, Information World Review]\u000a* [http://ecir2008.dcs.gla.ac.uk/industry.html The IRF and its Role in Professional Information Research, ECIR 2008]\u000a\u000a[[Category:Organizations established in 2006]]\u000a[[Category:Computer science organizations]]\u000a[[Category:Information retrieval]]\u000a[[Category:Education in Vienna]]
p57
sg4
S'34'
p58
sg6
VInformation Retrieval Facility
p59
ssI164
(dp60
g2
VThe '''Topic-based Vector Space Model (TVSM)'''<ref>{{cite | url=http://www.kuropka.net/files/TVSM.pdf | title=Topic-based Vector Space Model | author=Dominik Kuropka | coauthors=Jorg Becker | year=2003}}</ref> (literature: [http://www.logos-verlag.de/cgi-bin/engbuchmid?isbn=0514&lng=eng&id=]) extends the [[vector space model]] of [[information retrieval]] by removing the constraint that the term-vectors be orthogonal. The assumption of orthogonal terms is incorrect regarding natural languages which causes problems with synonyms and strong related terms. This facilitates the use of stopword lists, stemming and thesaurus in TVSM.\u000aIn contrast to the [[generalized vector space model]] the TVSM does not depend on concurrence-based similarities between terms. \u000a\u000a==Definitions==\u000aThe basic premise of TVSM is the existence of a ''d'' dimensional space ''R'' with only positive axis intercepts, i.e. ''R in R<sup>+</sup>'' and ''d in N<sup>+</sup>''. Each dimension of ''R'' represents a fundamental topic. A term vector ''t'' has a specific weight for a certain ''R''. To calculate these weights assumptions are made taking into account the document contents. Ideally important terms will have a high weight and stopwords and irrelevants terms to the topic will have a low weight. The TVSM document model is obtained as a sum of term vectors representing terms in the document. The similarity between two documents ''Di'' and ''Dj'' is defined as the scalar product of document vectors.\u000a\u000a==Enhanced Topic-based Vector Space Model==\u000aThe enhancement of the Enhanced Topic-based Vector Space Model (eTVSM)<ref>{{cite | url= http://kuropka.net/files/HPI_Evaluation_of_eTVSM.pdf | author=Dominik Kuropka | coauthors=Artem Polyvyanyy | title=A Quantitative Evaluation of the Enhanced Topic-Based Vector Space Model | year=2007}}</ref> (literature: [http://www.logos-verlag.de/cgi-bin/engbuchmid?isbn=0514&lng=eng&id=]) is a proposal on how to derive term vectors from an [[Ontology_(information_science) | Ontology]]. Using a synonym Ontology created from [[WordNet]] Kuropka shows good results for document similarity. If a trivial Ontology is used the results are similar to Vector Space model.\u000a\u000a==Implementations==\u000a* [http://sourceforge.net/projects/etvsm/ Implementation of eTVSM in python]\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a[[Category:Vector space model]]
p61
sg4
S'164'
p62
sg6
VTopic-based vector space model
p63
ssI39
(dp64
g2
V{{Infobox company\u000a|name = Figaro Systems, Inc.\u000a|logo = [[Image:Figaro-logo.png|Figaro logo]]\u000a|type = [[Privately held company|Private]]\u000a|foundation = 1993\u000a|location_city = [[Santa Fe, New Mexico|Santa Fe]], [[New Mexico]]\u000a|location_country =[[United States]]\u000a|key_people = Patrick Markle, [[president]] and [[CEO]], [[Geoff Webb]], [[vice president|VP]]\u000a|homepage = [http://www.figarosystems.com figarosystems.com]\u000a}}\u000a\u000a'''Figaro Systems, Inc.''' is an American company that provides  seatback and [[wireless]] titling [[software]] and system installations to [[opera houses]] and other music performance venues worldwide. The company is based in [[Santa Fe, New Mexico|Santa Fe]], New Mexico. It was established in 1993 <ref>Andrew Webb, \u201cOpera Subtitle Firm Eyes New Game,\u201d ''New Mexico Business Weekly'', Nov. 21, 2003 [http://www.bizjournals.com/albuquerque/stories/2003/11/24/story2.html]</ref>\u000aby Patrick Markle, [[Geoff Webb]], and Ron Erkman  <ref name="figaro-systems.com"/> and was the first company to provide [[assistive technology]] that enables individualized, simultaneous, multi-lingual [[dialogue]] and [[libretto]]-reading for audiences.\u000a<ref>[http://www.highbeam.com/DocPrint.aspx?DocID=1P2:115622912 David Belcher, \u201cNothing Lost in Translation: [[Video]] system allows patrons to read words on chair backs,\u201d] ''Albuquerque Journal'', June 4, 2006</ref>\u000a\u000a==History==\u000aFigaro Systems grew out of a conversation in 1992 among three opera colleagues: Patrick Markle, at that time Production Director of The [[Santa Fe Opera]], Geoffrey Webb, Design Engineer for the [[Metropolitan Opera House (Lincoln Center)|Metropolitan Opera House]] in New York, and Ronald Erkman, then a technician for the Met. At that time, opera houses had two options for the display of libretto and dialogue subtitles: projection onto a large screen above the stage or onto smaller screens throughout the theatre. Typically, the translation was in a single language.<ref>[http://www.bizjournals.com/albuquerque/stories/2005/04/11/story5.html?q=Figaro%20Systems Dennis Domrzalski, "Figaro: Eyes translate when ears don't get it",] ''New Mexico Business Weekly'', April 8, 2005</ref>\u000a\u000aThe [[Americans with Disabilities Act of 1990]] had recently been enacted; Markle was trying to solve the problem of venues which lacked accessibility to patrons with disabilities, including the profoundly [[deaf]].  Markle, Webb, and Erkman devised the first [[prototype]] of a personal seatback titling device and [[John Crosby (conductor)|John Crosby]], then General Director of The [[Santa Fe Opera]], saw its potential for opera patrons.<ref name="figaro-systems.com">[http://www.figaro-systems.com/about.php  Figaro Systems Official Website]</ref> Markle, Webb, and Erkman were further reinforced by their understanding of technology\u2019s role in remediating the physical barriers people encounter, worldwide, which frustrate or prevent their access to the visual performing arts.<ref>[http://figarosystems.com/linkdownloads/052007_figaro_auditoria_article.pdf \u201c[[User-friendly]] art: In-seat text displays that subtitle and translate\u201d, ''Auditoria'', May 2007]</ref> Markle, Webb, and Erkman applied for and were granted [[patent]]s for their invention.\u000a<ref>[http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=11&f=G&l=50&co1=AND&d=PTXT&s1=figaro.ASNM.&OS=AN/figaro&RS=AN/Figaro  United States Patent 5,739,869, "Electronic libretto display apparatus and method," issued April 14, 1998. [[United States Patent and Trademark Office]] ]</ref><ref>[http://www.lanl.gov/orgs/pa/News/050701.html  Los Alamos Laboratory, ''Daily News Bulletin'', May 7, 2001]</ref>\u000a\u000aPhilanthropist and investor [[Alberto Vilar]] counted Figaro Systems among the companies in which he was a majority shareholder.<ref>[http://nymag.com/nymetro/arts/music/features/5616/ [[Robert Hilferty]], "A Knight at the Opera," ''[[New York Magazine]]'', January 14, 2002]</ref><ref>[http://biography.jrank.org/pages/3490/Vilar-Alberto-1940-Investor-Philanthropist-Privileges-Wealth.html  "Alberto Vilar: The Privileges of Wealth," ''The Free Encyclopedia'']</ref>  He donated the company's [[electronic libretto]] system to European venues including the [[Royal Opera House]] in [[London]], La Scala's [[Teatro degli Arcimboldi]] opera houses in [[Milan, Italy|Milan]], Italy, [[Gran Teatre del Liceu]] in [[Barcelona, Spain|Barcelona]], Spain, and the [[Wiener Staatsoper]] in [[Wien]], [[Austria]]. As a consequence of his failures to pay promised donations, most of these companies lost money.\u000a\u000aIn 2005 the Met charged the New Mexico company with unlawfully using its name in advertising promoting its "Simultext, system which defendant claims can display a simultaneous translation of an opera as it occurs on a stage and that defendant represented that its system is installed at the Met." <ref>[http://classactionlitigation.com/library/consumerlaw2006update.html#_edn173#_edn173 Timothy E. Eble, ''Class Action Litigation Information''] on classactionlitigation.com</ref>\u000a\u000a==Products and technology==\u000aThe company\u2019s products are known variously as seat back titles, [[surtitles]],\u000a<ref>[http://app1.kuhf.org/houston_public_radio-news-display.php?articles_id=20614 Eric Skelly, "Surtitles at the Opera," ''Public Radio News and Information in Houston, Texas'', KUHF 88.7 FM Houston Public Radio] on app1.kuhf.org/</ref> [[electronic libretto]] systems, opera supertitles, projected titles, and libretto translations.\u000a\u000aOpera venues have utilized the system to display librettos in [[English language|English]], [[French language|French]], [[German language|German]], [[Italian language|Italian]], [[Japanese language|Japanese]], [[Mandarin Chinese|Mandarin]], [[Russian language|Russian]], and [[Spanish language|Spanish]]\u000a<ref>[http://www.sandia.gov/news-center/news-releases/2005/tech-trans/smbusiness.html "Sandia helps 278 state businesses in 2004 through New Mexico Small Business Assistance Program," Sandia National Laboratories, Sandia Corporation, March 22, 2005] on sandia.gov</ref> although the software enables the reading of the libretto in any [[written language]].\u000a<ref name="entertanmentengineering.com">[http://www.entertanmentengineering.com/v4.issue04/page.06.html  \u201cGiving the Opera a New Voice,\u201d] ''Entertainment Engineering," Volume 4, Issue 2, p. 6</ref> Translation is provided by one screen and delivery system per person.<ref>[http://www.figarosystems.com  Figaro Systems Official Website]</ref>\u000a\u000aTypically, but not in all cases, the system is permanently installed along the backs of rows of seats. Each screen is positioned so that the text is clearly visible to each user. The displays were initially available in [[vacuum fluorescent display]], ([[Vacuum fluorescent display|VFD]]) and, in 2000, [[liquid crystal display]], ([[LCD]]) was used. In 2004 the displays became available with [[organic light-emitting diode]], ([[OLED]]) screens.  Each type of display provides the same text information and program annotation on eight channels simultaneously, may be turned off by the user, and is user-operated with a single button. The software is capable of supporting venues\u2019 existing systems as well as Figaro Systems' "Simultext" system. The software enables cueing of each line as it is sung, and it appears instantly on the screen.<ref name="entertanmentengineering.com"/>\u000a\u000aThe company builds fully [[modular]] systems including its [[wireless]] [[handheld]] screens \u000a<ref>[http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=3&f=G&l=50&co1=AND&d=PTXT&s1=figaro.ASNM.&OS=AN/figaro&RS=AN/Figaro  United States Patent 6,760,010. "Wireless electronic libretto display apparatus and method," issued July 6, 2004:] United States Patent and Trademark Office Patent Full-Text and Image Database</ref> for users who cannot use seatback systems, for example people in [[wheelchair]]s, who may be viewing the opera in areas lacking seatback viewing, or people with compromised eyesight.\u000a\u000a==Venues==\u000aIn the US, the company\u2019s systems are in use in the [[Ellie Caulkins Opera House]] \u000a<ref>[http://www.highbeam.com/doc/1G1-135788390.html Marc Shulgold, "Opera dialogue shows on seat in front of you,"] ''Rocky Mountain News'' (Denver, Colorado), September 3, 2005 on highbeam.com,</ref> in [[Denver, Colorado|Denver]], Colorado, The Santa Fe Opera in Santa Fe,<ref>[http://web.archive.org/web/20080512022822/http://www.santafeopera.org/yournite/operatitles.php  Santa Fe Opera, Santa Fe, NM. Cached webpage],</ref> the [[Brooklyn Academy of Music]]<ref>[http://www.appliancemagazine.com/editorial.php?article=1768&zone=210&first=1  \u201cAn Operatic Performance,\u201d ''Appliance Magazine'', June 2007],</ref> the [[Metropolitan Opera]], New York, where it is called "MetTitles"),<ref>[http://www.figaro-systems.com/installations.php  Figaro Systems Official Website. Installations],</ref> the [[Roy E. Disney]] Theatre in [[Albuquerque]]'s [[National Hispanic Cultural Center]], [[McCaw Hall]] in [[Seattle Washington]], the [[Opera Theatre of St. Louis]] in St. Louis, Missouri, the [[Des Moines Metro Opera]] in [[Des Moines, Iowa|Des Moines]], Iowa and the Lyric Opera of Kansas City,  Missouri.<ref name="figaro-systems.com"/>\u000a\u000aIn the UK and Europe, the systems have been installed in venues including the [[Royal Opera House]] in London, the [[Teatro alla Scala]] and La Scala's [[Teatro degli Arcimboldi]] opera houses in [[Milan, Italy|Milan]], Italy, the [[Gran Teatre del Liceu]] in [[Barcelona, Spain|Barcelona]], Spain, and the [[Wiener Staatsoper]] in [[Wien]], [[Austria]].\u000a<ref>[http://www.entertainmentengineering.com/v4.issue04/page.06.html \u201cGiving the Opera a New Voice,\u201d ''Entertainment Engineering.'', Volume 4, Issue 2, p. 6], on entertainmentengineering.com</ref>\u000a\u000a==Awards==\u000aIn 2001, the company won the [[Los Alamos, New Mexico|Los Alamos]] Laboratories\u2019 Technology Commercialization Award for its Simultext system.<ref>[http://www.lanl.gov/news/index.php/fuseaction/home.story/story_id/1170 Todd Hanson, "Los Alamos announces technology commercialization awards," ''Los Alamos National Laboratory News''], Los Alamos National Security, LLC, US Department of Energy's NNSA, May 7, 2001 on lanl.gov/news.</ref>\u000aIn 2008, the company\u2019s software was one of four finalists for the Excellence Award for Commercial Software awarded by the New Mexico Information Technology and Software Association.\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Software companies based in New Mexico]]\u000a[[Category:Assistive technology]]\u000a[[Category:Educational technology]]\u000a[[Category:Companies based in New Mexico]]\u000a[[Category:Privately held companies based in New Mexico]]\u000a[[Category:Companies established in 1993]]
p65
sg4
S'39'
p66
sg6
VFigaro Systems
p67
ssI169
(dp68
g2
V{{Unreferenced stub|auto=yes|date=December 2009}}\u000a{{Lowercase|title=ptx}}\u000a'''ptx''' is a [[Unix]] utility, named for the ''permuted index'' which can perform the function of the Keyword in Context ([[Key Word in Context|KWIC]]) search mode. There is a corresponding [[IBM mainframe]] utility which performs the same function. permuted indexes are often used in such places as bibliographic or medical databases, thesauruses, or web sites to aid in locating entries of interest.\u000a\u000a==See also==\u000a* [[Concordancer]]\u000a\u000a[[Category:Searching]]\u000a[[Category:Unix text processing utilities]]\u000a\u000a\u000a{{Unix-stub}}
p69
sg4
S'169'
p70
sg6
VPtx (Unix)
p71
ssI44
(dp72
g2
V'''Discounted cumulative gain''' ('''DCG''') is a measure of ranking quality. In [[information retrieval]], it is often used to measure effectiveness of [[World Wide Web|web]] [[search engine]] [[algorithm]]s or related applications. Using a [[Relevance (information retrieval)|graded relevance]] scale of documents in a search engine result set, DCG measures the usefulness, or ''gain'', of a document based on its position in the result list. The gain is accumulated from the top of the result list to the bottom with the gain of each result discounted at lower ranks.<ref>Kalervo Jarvelin, Jaana Kekalainen: Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems 20(4), 422\u2013446 (2002)</ref>\u000a\u000a== Overview ==\u000a\u000aTwo assumptions are made in using DCG and its related measures.\u000a\u000a# Highly relevant documents are more useful when appearing earlier in a search engine result list (have higher ranks)\u000a# Highly relevant documents are more useful than marginally relevant documents, which are in turn more useful than irrelevant documents.\u000a\u000aDCG originates from an earlier, more primitive, measure called Cumulative Gain.\u000a\u000a=== Cumulative Gain ===\u000a\u000aCumulative Gain (CG) is the predecessor of DCG and does not include the position of a result in the consideration of the usefulness of a result set. In this way, it is the sum of the graded relevance values of all results in a search result list. The CG at a particular rank position <math>p</math> is defined as:\u000a\u000a:<math> \u005cmathrm{CG_{p}} = \u005csum_{i=1}^{p} rel_{i} </math>\u000a\u000aWhere <math>rel_{i}</math> is the graded relevance of the result at position <math>i</math>.\u000a\u000aThe value computed with the CG function is unaffected by changes in the ordering of search results. That is, moving a highly relevant document <math>d_{i}</math> above a higher ranked, less relevant, document <math>d_{j}</math> does not change the computed value for CG. Based on the two assumptions made above about the usefulness of search results, DCG is used in place of CG for a more accurate measure.\u000a\u000a=== Discounted Cumulative Gain ===\u000a\u000aThe premise of DCG is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result. The discounted CG accumulated at a particular rank position <math>p</math> is defined as:<ref name="stanfordireval">{{cite web|title=Introduction to Information Retrieval - Evaluation|url=http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf|publisher=Stanford University|accessdate=23 March 2014|date=21 April 2013}}</ref>\u000a\u000a:<math> \u005cmathrm{DCG_{p}} = rel_1 + \u005csum_{i=2}^{p} \u005cfrac{rel_{i}}{\u005clog_{2}(i)} </math>\u000a\u000aPreviously there has not been shown any theoretically sound justification for using a [[logarithm]]ic reduction factor<ref>{{cite book | title=Search Engines: Information Retrieval in Practice | author=B. Croft, D. Metzler, and T. Strohman |year=2009 | publisher=''Addison Wesley"}}</ref> other than the fact that it produces a smooth reduction.\u000a\u000aAn alternative formulation of DCG<ref>Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to rank using gradient descent. In Proceedings of the 22nd international conference on Machine learning (ICML '05). ACM, New York, NY, USA, 89-96. DOI=10.1145/1102351.1102363 http://doi.acm.org/10.1145/1102351.1102363</ref> places stronger emphasis on retrieving relevant documents:\u000a\u000a:<math> \u005cmathrm{DCG_{p}} = \u005csum_{i=1}^{p} \u005cfrac{ 2^{rel_{i}} - 1 }{ \u005clog_{2}(i+1)} </math>\u000a\u000aThe latter formula is commonly used in industry including major web search companies<ref name="stanfordireval"/> and data science competition platform such as Kaggle.<ref>{{cite web|title=Normalized Discounted Cumulative Gain|url=https://www.kaggle.com/wiki/NormalizedDiscountedCumulativeGain|accessdate=23 March 2014}}</ref>\u000a\u000aIn Croft, Metzler and Strohman (page 320, 2010), the authors mistakenly claim that these two formulations of DCG are the same when the relevance values of documents are [[binary function|binary]]; <math>rel_{i} \u005cin \u005c{0,1\u005c}</math>.  To see that they are not the same, let there be one relevant document and that relevant document is at rank 2.  The first version of DCG equals 1 / log2(2) = 1.  The second version of DCG equals 1 / log2(2+1) = 0.631.  The way that the two formulations of DCG are the same for binary judgments is in the way gain in the numerator is calculated.  For both formulations of DCG, binary relevance produces gain at rank i of 0 or 1.  No matter the number of relevance grades, the two formulations differ in their discount of gain.\u000a\u000aNote that Croft et al. (2010) and Burges et al. (2005) present the second DCG with a log of base e, while both versions of DCG above use a log of base 2.  When computing NDCG with the second formulation of DCG, the base of the log does not matter, but the base of the log does affect the value of NDCG for the first formulation.  Clearly, the base of the log affects the value of DCG in both formulations.\u000a\u000aRecently, Wang et al.(2013)<ref>Yining Wang, Liwei Wang, Yuanzhi Li, Di He, Wei Chen, Tie-Yan Liu. 2013. A Theoretical Analysis of NDCG Ranking Measures. In Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013).</ref> give theoretical guarantee for using the logarithmic reduction factor in NDCG. Specifically, the authors prove for every pair of substantially different ranking functions, the ranking measure can decide which one is better in a consistent manner on almost all datasets.\u000a\u000a=== Normalized DCG ===\u000a\u000aSearch result lists vary in length depending on the [[Web search query|query]]. Comparing a search engine's performance from one query to the next cannot be consistently achieved using DCG alone, so the cumulative gain at each position for a chosen value of <math>p</math> should be normalized across queries. This is done by sorting documents of a result list by relevance, producing the maximum possible DCG till position <math>p</math>, also called Ideal DCG (IDCG) till that position. For a query, the ''normalized discounted cumulative gain'', or nDCG, is computed as:\u000a\u000a:<math> \u005cmathrm{nDCG_{p}} = \u005cfrac{DCG_{p}}{IDCG_{p}} </math>\u000a\u000aThe nDCG values for all queries can be averaged to obtain a measure of the average performance of a search engine's ranking algorithm. Note that in a perfect ranking algorithm, the <math>DCG_p</math> will be the same as the <math>IDCG_p</math> producing an nDCG of 1.0. All nDCG calculations are then relative values on the interval 0.0 to 1.0 and so are cross-query comparable.\u000a\u000aThe main difficulty encountered in using nDCG is the unavailability of an ideal ordering of results when only partial [[relevance feedback]] is available.\u000a\u000a== Example ==\u000a\u000aPresented with a list of documents in response to a search query, an experiment participant is asked to judge the relevance of each document to the query. Each document is to be judged on a scale of 0-3 with 0 meaning irrelevant, 3 meaning completely relevant, and 1 and 2 meaning "somewhere in between". For the documents ordered by the ranking algorithm as\u000a\u000a:<math> D_{1}, D_{2}, D_{3}, D_{4}, D_{5}, D_{6} </math>\u000a\u000athe user provides the following relevance scores:\u000a\u000a:<math> 3, 2, 3, 0, 1, 2 </math>\u000a\u000aThat is: document 1 has a relevance of 3, document 2 has a relevance of 2, etc. The Cumulative Gain of this search result listing is:\u000a\u000a:<math> \u005cmathrm{CG_{6}} = \u005csum_{i=1}^{6} rel_{i} = 3 + 2 + 3 + 0 + 1 + 2 = 11</math>\u000a\u000aChanging the order of any two documents does not affect the CG measure. If <math>D_3</math> and <math>D_4</math> are switched, the CG remains the same, 11. DCG is used to emphasize highly relevant documents appearing early in the result list. Using the logarithmic scale for reduction, the DCG for each result in order is:\u000a\u000a{| class="wikitable" border="1"\u000a|-\u000a! <math>i</math>\u000a! <math>rel_{i}</math>\u000a! <math>\u005clog_{2}i</math>\u000a! <math> \u005cfrac{rel_{i}}{\u005clog_{2}i} </math>\u000a|-\u000a| 1\u000a| 3\u000a| 0\u000a| N/A\u000a|-\u000a| 2\u000a| 2\u000a| 1\u000a| 2\u000a|-\u000a| 3\u000a| 3\u000a| 1.585\u000a| 1.892\u000a|-\u000a| 4\u000a| 0\u000a| 2.0\u000a| 0\u000a|-\u000a| 5\u000a| 1\u000a| 2.322\u000a| 0.431\u000a|-\u000a| 6\u000a| 2\u000a| 2.584\u000a| 0.774\u000a|}\u000a\u000aSo the <math>DCG_{6}</math> of this ranking is:\u000a\u000a:<math> \u005cmathrm{DCG_{6}} = rel_{1} + \u005csum_{i=2}^{6} \u005cfrac{rel_{i}}{\u005clog_{2}i} = 3 + (2 + 1.892 + 0 + 0.431 + 0.774) = 8.10</math>\u000a\u000aNow a switch of <math>D_3</math> and <math>D_4</math> results in a reduced DCG because a less relevant document is placed higher in the ranking; that is, a more relevant document is discounted more by being placed in a lower rank.\u000a\u000aThe performance of this query to another is incomparable in this form since the other query may have more results, resulting in a larger overall DCG which may not necessarily be better. In order to compare, the DCG values must be normalized.\u000a\u000aTo normalize DCG values, an ideal ordering for the given query is needed. For this example, that ordering would be the [[Monotonic|monotonically decreasing]] sort of the relevance judgments provided by the experiment participant, which is:\u000a\u000a:<math> 3, 3, 2, 2, 1, 0 </math>\u000a\u000aThe DCG of this ideal ordering, or ''IDCG'', is then:\u000a\u000a:<math> \u005cmathrm{IDCG_{6}} = 8.69 </math>\u000a\u000aAnd so the nDCG for this query is given as:\u000a\u000a:<math> \u005cmathrm{nDCG_{6}} = \u005cfrac{DCG_{6}}{IDCG_{6}} = \u005cfrac{8.10}{8.69} = 0.932 </math>\u000a\u000a== Limitations ==\u000a# Normalized DCG metric does not penalize for bad documents in the result. For example, if a query returns two results with scores <math> 1,1,1 </math> and <math> 1,1,1,0 </math> respectively, both would be considered equally good even if later contains a bad result. One way to take into account this limitation is use <math>1 - 2^{rel_{i}}</math> in numerator for scores for which we want to penalize and <math>2^{rel_{i}} - 1</math> for all others. For example, for the ranking judgments <math>Excellent, Fair, Bad</math> one might use numerical scores <math>1,0,-1</math> instead of <math>2,1,0</math>.\u000a# Normalized DCG does not penalize for missing documents in the result. For example, if a query returns two results with scores <math> 1,1,1 </math> and <math> 1,1,1,1,1 </math> respectively, both would be considered equally good. One way to take into account this limitation is to enforce fixed set size for the result set and use minimum scores for the missing documents. In previous example, we would use the scores <math> 1,1,1,0,0 </math> and <math> 1,1,1,1,1 </math> and quote nDCG as nDCG@5.\u000a# Normalized DCG may not be suitable to measure performance of queries that may typically often have several equally good results. This is especially true when this metric is limited to only first few results as it is done in practice. For example, for queries such as "restaurants" nDCG@1 would account for only first result and hence if one result set contains only 1 restaurant from the nearby area while the other contains 5, both would end up having same score even though latter is more comprehensive.\u000a\u000a== References ==\u000a{{Reflist|1}}\u000a\u000a[[Category:Information retrieval|*]]
p73
sg4
S'44'
p74
sg6
VDiscounted cumulative gain
p75
ssI174
(dp76
g2
V{{Notability|date=December 2009}}\u000aA '''hybrid search engine''' ('''HSE''') is a type of [[computer]] [[search engine]] that uses different types of data with or without ontologies to produce the [[algorithm]]ically generated results based on [[web crawling]]. Previous types of search engines only use text to generate their results.\u000a\u000a==References==\u000a{{No footnotes|date=April 2010}}\u000a*http://eprints.ecs.soton.ac.uk/17457/\u000a*http://eprints.whiterose.ac.uk/3771/\u000a*http://www.picollator.com\u000a\u000a[[Category:Searching]]\u000a\u000a\u000a{{web-stub}}
p77
sg4
S'174'
p78
sg6
VHybrid search engine
p79
ssI49
(dp80
g2
V'''Subject indexing''' is the act of describing or [[Document classification|classifying]] a [[document]] by [[keyword (search)|index terms]] or other symbols in order to indicate what the document is '''[[Aboutness|about]],''' to summarize its [[content (media and publishing)|content]] or to increase its [[findability]].  In other words, it is about identifying and describing the '''[[Subject (documents)|subject]]''' of documents.  Indexes are constructed, separately, on three distinct levels:  terms in a document such as a book;  objects in a collection such as a library;  and documents (such as books and articles) within a field of knowledge.\u000a\u000aSubject indexing is used in [[information retrieval]] especially to create [[bibliographic database]]s to retrieve documents on a particular subject. Examples of academic indexing services are [[Zentralblatt MATH]], [[Chemical Abstracts]] and [[PubMed]]. The index terms were mostly assigned by experts but author keywords are also common.\u000a\u000aThe process of indexing begins with any analysis of the subject of the document. The indexer must then identify terms which appropriately identify the subject either by extracting words directly from the document or assigning words from a [[controlled vocabulary]].<ref name="Lancaster2003a">F. W. Lancaster (2003): "Indexing and abstracting in theory and practise". Third edition. London, Facet ISBN 1-85604-482-3. page 6</ref> The terms in the index are then presented in a systematic order.\u000a\u000aIndexers must decide how many terms to include and how specific the terms should be. Together this gives a depth of indexing.\u000a\u000a== Subject analysis ==\u000aThe first step in indexing is to decide on the subject matter of the document. In manual indexing, the indexer would consider the subject matter in terms of answer to a set of questions such as "Does the document deal with a specific product, condition or phenomenon?".<ref name="Chowdhury2004">G.G. Chowdhury (2004): "Introduction to modern information retrieval". Third Edition. London, Facet. ISBN 1-85604-480-7. page 71</ref> As the analysis is influenced by the knowledge and experience of the indexer, it follows that two indexers may analyse the content differently and so come up with different index terms. This will impact on the success of retrieval.\u000a\u000a=== Automatic vs. manual subject analysis ===\u000aAutomatic indexing follows set processes of analysing frequencies of word patterns and comparing results to other documents in order to assign to subject categories. This requires no understanding of the material being indexed therefore leads to more uniform indexing but this is at the expense of the true meaning being interpreted. A computer program will not understand the meaning of statements and may therefore fail to assign some relevant terms or assign incorrectly. Human indexers focus their attention on certain parts of the document such as the title, abstract, summary and conclusions, as analysing the full text in depth is costly and time consuming <ref name="Lancaster2003b">F. W. Lancaster (2003): "Indexing and abstracting in theory and practise". Third edition. London, Facet ISBN 1-85604-482-3. page 24</ref> An automated system takes away the time limit and allows the entire document to be analysed, but also has the option to be directed to particular parts of the document.\u000a\u000a== Term selection ==\u000aThe second stage of indexing involves the translation of the subject analysis into a set of [[keyword (search)|index terms]]. This can involve extracting from the document or assigning from a [[controlled vocabulary]]. With the ability to conduct a [[full text search]] widely available, many people have come to rely on their own expertise in conducting information searches and [[full text search]] has become very popular.  Subject indexing and its experts, professional indexers, [[catalogers]], and [[librarians]], remains crucial to information organization and retrieval.  These experts understand [[controlled vocabularies]] and are able to find information that cannot be located by [[full text search]].  The cost of expert analysis to create subject indexing is not easily compared to the cost of hardware, software and labor to manufacture a comparable set of full-text, fully searchable materials.  With new web applications that allow every user to annotate documents, [[social tagging]] has gained popularity especially in the Web.<ref name="Voss2007">\u000a{{cite conference\u000a  | first= Jakob | last = Voss\u000a  | title = Tagging, Folksonomy & Co - Renaissance of Manual Indexing?\u000a  | booktitle = Proceedings of the International Symposium of Information Science\u000a  | pages = 234\u2013254\u000a  | year = 2007\u000a  | arxiv = cs/0701072\u000a}}</ref>\u000a\u000aOne application of indexing, the [[Index (publishing)|book index]], remains relatively unchanged despite the information revolution.\u000a\u000a=== Extraction/Derived indexing ===\u000aExtraction indexing involves taking words directly from the document. It uses [[natural language]] and lends itself well to automated techniques where word frequencies are calculated and those with a frequency over a pre-determined threshold are used as index terms. A stop-list containing common words such as the, and would be referred to and such [[stop words]] would be excluded as index terms. Automated extraction indexing may lead to loss of meaning of terms by indexing single words as opposed to phrases. Although it is possible to extract commonly occurring phrases, it becomes more difficult if key concepts are inconsistently worded in phrases.\u000aAutomated extraction indexing also has the problem that even with use of a stop-list to remove common words such as \u201cthe,\u201d some frequent words may not be useful for allowing discrimination between documents. For example, the term glucose is likely to occur frequently in any document related to diabetes. Therefore use of this term would likely return most or all the documents in the database. Post-co-ordinated indexing where terms are combined at the time of searching would reduce this effect but the onus would be on the searcher to link appropriate terms as opposed to the information professional. In addition terms that occur infrequently may be highly significant for example a new drug may be mentioned infrequently but the novelty of the subject makes any reference significant. One method for allowing rarer terms to be included and common words to be excluded by automated techniques  would be a relative frequency approach where frequency of a word in a document is compared to frequency in the database as a whole. Therefore a term that occurs more often in a document than might be expected based on the rest of the database could then be used as an index term, and terms that occur equally frequently throughout will be excluded. Another problem with automated extraction is that it does not recognise when a concept is discussed but is not identified in the text by an indexable keyword.<ref name="Lamb2008">J. Lamb (2008): ''[http://www.indexers.org.uk/index.php?id=463 Human or computer produced indexes?]'' [online] Sheffield, Society of Indexers. Accessed 15 January 2009.</ref>\u000a\u000a=== Assignment indexing ===\u000aAn alternative is assignment indexing where index terms are taken from a controlled vocabulary. This has the advantage of controlling for [[synonym]]s as the preferred term is indexed and synonyms or related terms direct the user to the preferred term. This means the user can find articles regardless of the specific term used by the author and saves the user from having to know and check all possible synonyms.<ref name="Tenopir">C. Tenopir (1999): "Human or automated, indexing is important". ''Library Journal'' '''124'''(18) pages 34-38.</ref> It also removes any confusion caused by [[homograph]]s by inclusion of a qualifying term. A third advantage is that it allows the linking of related terms whether they are linked by hierarchy or association, e.g. an index entry for an oral medication may list other oral medications as related terms on the same level of the hierarchy but would also link to broader terms such as treatment. Assignment indexing is used in manual indexing to improve inter-indexer consistency as different indexers will have a controlled set of terms to choose from. Controlled vocabularies do not completely remove inconsistencies as two indexers may still interpret the subject differently.<ref name="Chowdhury2004" />\u000a\u000a== Index presentation ==\u000aThe final phase of indexing is to present the entries in a systematic order. This may involve linking entries. In a pre-coordinated index the indexer determines the order in which terms are linked in an entry by considering how a user may formulate their search. In a post-coordinated index, the entries are presented singly and the user can link the entries through searches, most commonly carried out by computer software. Post-coordination results in a loss of precision in comparison to pre-coordination <ref name="Bodoff1998">D. Bodoff and A. Kambil, (1998): "Partial coordination. I. The best of pre-coordination and post-coordination." ''Journal of the American Society for Information Science'', '''49'''(14), 1254-1269.</ref>\u000a\u000a== Depth of Indexing ==\u000aIndexers must make decisions about what entries should be included and how many entries an index should incorporate. The depth of indexing describes the thoroughness of the indexing process with reference to exhaustivity and specificity <ref name="Cleveland2001">D.B. Cleveland and A.D. Cleveland (2001): "Introduction to indexing and abstracting". 3rd Ed. Englewood, libraries Unlimited, Inc. ISBN 1-56308-641-7. page 105</ref>\u000a\u000a=== Exhaustivity ===\u000aAn exhaustive index is one which lists all possible index terms. Greater exhaustivity gives a higher [[Recall (information retrieval)|recall]], or more likelihood of all the relevant articles being retrieved, however, this occurs at the expense of [[Precision (information retrieval)|precision]]. This means that the user may retrieve a larger number of irrelevant documents or documents which only deal with the subject in little depth. In a manual system a greater level of exhaustivity brings with it a greater cost as more man hours are required. The additional time taken in an automated system would be much less significant. At the other end of the scale, in a selective index only the most important aspects are covered.<ref name="Weinberg1999">B.H. Weinberg (1990): "Exhaustivity of indexes: Books, journals, and electronic full texts; Summary of a workshop presented at the 1999 ASI Annual Conference". ''Key Words'', '''7'''(5), pages 1+.</ref> Recall is reduced in a selective index as if an indexer does not include enough terms, a highly relevant article may be overlooked. Therefore indexers should strive for a balance and consider what the document may be used. They may also have to consider the implications of time and expense.\u000a\u000a=== Specificity ===\u000aThe specificity describes how closely the index terms match the topics they represent <ref name="Anderson1997">J.D. Anderson (1997): ''[http://www.niso.org/publications/tr/ Guidelines for indexes and related information retrieval devices]'' [online]. Bethesda, Maryland, Niso Press. 10 December 2008.</ref> An index is said to be specific if the indexer uses parallel descriptors to the concept of the document and reflects the concepts precisely.<ref name="Cleveland2001b">D.B. Cleveland and A.D. Cleveland (2001): "Introduction to indexing and abstracting". 3rd Ed. Englewood, libraries Unlimited, Inc. ISBN 1-56308-641-7. page 106</ref> Specificity tends to increase with exhaustivity as the more terms you include, the narrower those terms will be.\u000a\u000a==Indexing theory==\u000a[[Birger Hjørland|Hjørland]] (2011)<ref>Hjørland, Birger (2011). The Importance of Theories of Knowledge: Indexing and Information retrieval as an example. ''Journal of the American Society for Information Science and Technology'', 62(1,), 72-77.</ref> found that theories of indexing is at the deepest level connected to different theories of knowledge:\u000a\u000a'''Rationalist theories of indexing''' (such as Ranganathan's theory) suggest that subjects are constructed logically from a fundamental set of categories. The basic method of subject analysis is then "analytic-synthetic", to isolate a set of basic categories (=analysis) and then to construct the subject of any given document by combining those categories according to some rules (=synthesis). '''Empiricist theories of indexing''' are based on selecting similar documents based on their properties, in particular by applying numerical statistical techniques.  '''Historicist and hermeneutical theories of indexing''' suggest that the subject of a given document is relative to a given discourse or domain, why the indexing should reflect the need of a particular discourse or domain. According to hermeneutics is a document always written and interpreted from particular horizon. The same is the case with systems of knowledge organization and with all users searching such systems. Any question put to such a system is put from a particular horizon. All those horizons may be more or less in consensus or in conflict. To index a document is to try to contribute to the retrieval of \u201crelevant\u201d documents by knowing about those different horizons. '''Pragmatic and critical theories of indexing''' (such as Hjørland, 1997)<ref>Hjørland, B. (1997). Information Seeking and Subject Representation. An Activity-theoretical approach to Information Science. Westport & London: Greenwood Press.</ref> is in agreement with the historicist point of view that subjects are relative to specific discourses but emphasizes that subject analysis should support given goals and values and should consider the consequences of indexing one way or another. These theories believe that indexing cannot be neutral and that it is a wrong goal to try to index in a neutral way. Indexing is an act (and computer based indexing is acting according to the programmers intentions). Acts serve human goals. Libraries and information services also serve human goals, why their indexing should be done in a way that supports these goals as much as possible. At a first glance this looks strange because the goals of libraries and information services is to identify any document or piece of information. Nonetheless is any specific way of indexing always supporting some kind of uses at the expense of other. The documents to be indexed intend to serve some specific purposes in a community. Basically the indexing should intend serving the same purposes. Primary and secondary documents and information services are parts of the same overall social system. In such a system different theories, epistemologies, worldviews etc. may be at play and users need to be able to orient themselves and to navigate among those different views. This calls for a mapping of the different epistemologies in the field and classification of the single document into such a map. Excellent examples of such different paradigms and their consequences for indexing and classification systems are provided in the domain of art by Ørom (2003)<ref>Ørom, Anders (2003). Knowledge Organization in the domain of Art Studies - History, Transition and Conceptual Changes. Knowledge Organization. 30(3/4), 128-143.</ref> and in music by Abrahamsen (2003).<ref>Abrahamsen, Knut T. (2003). Indexing of Musical Genres. An Epistemological Perspective. Knowledge Organization, 30(3/4), 144-169. \u000a</ref>\u000a\u000aThe core of indexing is, as stated by Rowley & Farrow<ref name=rowley2000>Rowley, J. E. & Farrow, J. (2000). Organizing Knowledge: An Introduction to Managing Access to Information. 3rd. Alderstot: Gower Publishing Company</ref> to evaluate a papers contribution to knowledge and index it accordingly. Or, with the words of Hjørland (1992,<ref>Hjørland, Birger (1992). The Concept of "Subject" in Information Science. Journal of Documentation. 48(2), 172-200. http://iva.dk/bh/Core%20Concepts%20in%20LIS/1992JDOC%5FSubject.PDF</ref> 1997) to index its informative potentials.\u000a\u000a"In order to achieve good consistent indexing, the indexer must have a thorough appreciation of the structure of the subject  and the nature of the contribution that the document is making to the advancement of knowledge." (Rowley & Farrow, 2000,<ref name=rowley2000/> p.&nbsp;99).\u000a\u000a== See also ==\u000a* [[Indexing and abstracting service]]\u000a* [[Document classification]]\u000a* [[Metadata]]\u000a* [[Overcategorization]]\u000a* [[Thomas of Ireland]], a medieval pioneer in subject indexing\u000a\u000a== References ==\u000a<references/>\u000a*{{cite book|author=Fugman, Robert|year=1993|title=Subject analysis and indexing. Theoretical foundation and practical advice|place=Frankfurt/Main|publisher=Index Verlag}}\u000a*{{cite journal|author=Frohmann, B.|year=1990|title=Rules of Indexing: A Critique of [[Mentalism]] in Information Retrieval Theory|journal=Journal of Documentation|volume=46|issue=2|pages=81\u2013101|doi=10.1108/eb026855}}\u000a\u000a[[Category:Library science]]\u000a[[Category:Information science]]\u000a[[Category:Information retrieval]]
p81
sg4
S'49'
p82
sg6
VSubject indexing
p83
ssI179
(dp84
g2
V'''IBM OmniFind''' was an [[enterprise search]] platform from [[IBM]].\u000aIt did come in several packages adapted to different business needs, including OmniFind Enterprise Edition, OmniFind Enterprise Starter Edition, and OmniFind Discovery Edition.<ref>[http://www-01.ibm.com/software/ecm/omnifind/library.html IBM - OmniFind - Library]</ref> IBM OmniFind as a standalone product was withdrawn in April 2011<ref>[http://www-01.ibm.com/common/ssi/cgi-bin/ssialias?subtype=ca&infotype=an&appname=iSource&supplier=897&letternum=ENUS911-075 IBM US Announcement Letter]</ref> and is now part of [[IBM Watson Content Analytics with Enterprise Search]].<ref>[http://www-01.ibm.com/common/ssi/cgi-bin/ssialias?infotype=AN&subtype=CA&htmlfid=897/ENUS211-133 IBM US Announcement Letter]</ref>\u000a\u000a'''IBM OmniFind Yahoo! Edition''' was a free-of-charge version that could handle up to 500,000 documents in its index and was intended for small businesses. IBM OmniFind Yahoo! Edition was simple to install, provided a user friendly front end for administration, and incorporated technology from the open source [[Lucene]] project. IBM withdrew this product from marketing effective September 22, 2010 and withdrew support effective June 30, 2011.<ref>[http://www-01.ibm.com/common/ssi/cgi-bin/ssialias?subtype=ca&infotype=an&appname=iSource&supplier=897&letternum=ENUS910-115 IBM US Announcement Letter]</ref>\u000a\u000a'''IBM OmniFind Personal E-mail Search''' was a research product launched in 2007 for doing [[semantic search]] over personal emails by extracting and organizing concepts and relationships (such as phone numbers and addresses). The project appears to have been silently abounded sometimes around 2010.\u000a\u000a== See also ==\u000a* [[Languageware]]\u000a* [[UIMA]]\u000a* [[Comparison of enterprise search software]]\u000a* [[List of enterprise search vendors]]\u000a\u000a==External links==\u000a* [http://www.ibm.com/software/data/enterprise-search/ IBM OmniFind]\u000a* [http://omnifind.ibm.yahoo.com/ IBM OmniFind Yahoo! Edition] {{Dead link|date=May 2012}}\u000a* [http://www.alphaworks.ibm.com/tech/emailsearch IBM OmniFind Personal E-mail Search] {{Dead link|date=January 2012}}\u000a* [http://www.opentestsearch.com/search-engines/ibm-omnifind-yahoo-edition-review/ Online demo and review of IBM OmniFind Yahoo! Edition]\u000a\u000a==Notes==\u000a{{reflist}}\u000a\u000a[[Category:IBM software|OmniFind]]\u000a[[Category:Searching]]
p85
sg4
S'179'
p86
sg6
VIBM Omnifind
p87
ssI54
(dp88
g2
V== Free and open source [[enterprise search]] software ==\u000a<!--\u000a################# READ THIS\u000a\u000aPlease do not add web links or products which do not have Wikipedia articles. They will be summarily deleted.\u000aAlso, read the definition of enterprise search before adding a new search engine\u000a-->\u000a*[[Apache Solr]]\u000a*[[DataparkSearch]]\u000a*[[ElasticSearch]]\u000a*[[Htdig|ht://Dig]]\u000a*[[ApexKB]]\u000a*[[mnoGoSearch]]\u000a*[[OpenSearchServer]]\u000a*[[Searchdaimon]]\u000a*[[Sphinx_(search_engine)|Sphinx]]\u000a*[[Zettair]]\u000a\u000a== Vendors of open source enterprise search software ==\u000a* [[30 Digits]] - Implementation, consulting, support, and value-add components for [[Lucene]] and [[Solr]]\u000a* [[Apache Software Foundation]] - The foundation is the entity behind the [[Lucene]] family of products\u000a* [[LucidWorks]] (former Lucid Imagination) - Commercial support, training and services for [[Lucene]] and [[Solr]]\u000a* Customermatrix (acquired Polyspot, CRM development and products for [[Lucene]]) \u000a* [[Searchblox]] - Commercial product for [[Lucene]] and [[ElasticSearch]]\u000a* [[Sematext]] - Consulting, development and products for [[Lucene]], [[Solr]], [[Nutch]], and [[Hadoop]]\u000a* [[FlaxUK|Flax]] - Architecture, development and support for [[Lucene]], [[Solr]] and [[Xapian]]\u000a\u000a== Vendors of proprietary enterprise search software ==\u000a<!--\u000a################# READ THIS\u000a\u000aPlease do not add web links or companies which do not have Wikipedia articles. They will be summarily deleted.\u000a\u000a-->\u000a*[[AskMeNow]]\u000a*[[Attivio]]\u000a*[[Concept Searching Limited]]\u000a*[[Content Analyst Company|Content Analyst Company LLC]]\u000a*[[Coveo]]\u000a*[[Dassault Systèmes]] (acquired [[Exalead]])\u000a*[[Denodo]]\u000a*[[Dieselpoint, Inc.]]\u000a*[[dtSearch Corp.]]\u000a*[[EMC Corp.]]\u000a*[[Exorbyte GmbH]]\u000a*[[Expert System S.p.A.]]\u000a*[[Exterro, Inc.]]\u000a*[[Fabasoft Mindbreeze|Fabasoft]]\u000a*[[Funnelback]]\u000a*[[Google Search Appliance]]\u000a*[[HP]] (acquired [[Autonomy Corporation]] which in turn acquired [[Verity]] K2 and Ultraseek)\u000a*[[IBM]] (acquired [[Vivisimo]], rebranded "[[Watson (computer)|Watson]]")\u000a*[[Inbenta]]\u000a*[[inter:gator Enterprise Search]]\u000a*[[ISYS Search Software]]\u000a*[[Lookeen]]\u000a*[[Mark Logic|MarkLogic]]\u000a*[[Microsoft]] (includes [[Microsoft Search Server]], [[Fast Search & Transfer]])\u000a*[[Fabasoft Mindbreeze|Mindbreeze]] \u000a*[[Neofonie]] (includes WeFind)\u000a*[[Omniture]] (acquired by [[Adobe Systems]])\u000a*[[Open Text Corporation]]\u000a*[[Oracle Corporation]] (includes [[Oracle_Corporation#Oracle_Secure_Enterprise_Search|Secure Enterprise Search]] and [[Endeca Technologies Inc.]])\u000a*[[Q-go]]\u000a*[[Q-Sensei]]\u000a*[[Recommind (software company)|Recommind]]\u000a*[[SAP AG|SAP]] (includes SAP NetWeaver Enterprise Search, Search Services in SAP NetWeaver AS ABAP, and Search and Classification TREX)\u000a*[[Silent Eight]]\u000a*[[Sinequa]]\u000a*[[SLI_Systems]]\u000a*[[Sophia Search Limited]]\u000a* [[Swiftype]]\u000a*[[TeraText]]\u000a*[[Thunderstone Software]]\u000a*[[X1 Technologies, Inc.]]\u000a*[[ZyLAB Technologies]]\u000a*[[ZL Technologies]]\u000a\u000a== External links ==\u000a* [http://www.dmoz.org/Computers/Software/Information_Retrieval/Fulltext/ DMOZ category Information Retrieval/Fulltext]\u000a{{Companies by industry}}\u000a\u000a{{DEFAULTSORT:Enterprise search vendors}}\u000a[[Category:Information retrieval]]\u000a[[Category:Searching]]\u000a[[Category:Search engine software|*Enterprise search vendors]]\u000a[[Category:Lists of software]]\u000a[[Category:Lists of companies by industry|Enterprise search vendors]]
p89
sg4
S'54'
p90
sg6
VList of enterprise search vendors
p91
ssI184
(dp92
g2
V{{Multiple issues|\u000a{{confusing|date=November 2010}}\u000a{{cleanup|date=November 2010}}\u000a}}\u000a\u000a'''Unified Information Access Platforms''' are [[computing platforms]] that integrate large volumes of [[unstructured information|unstructured]], semi-structured, and structured information into a unified environment for processing, analysis and decision-making. These platforms are highly scalable, hybrid architectures that combine elements of database and search technologies in order to make information access dynamic and ad hoc, while offering the reporting and visualization features commonly found in business intelligence applications. While the vision for such integrated platforms has been around for years, only since 20XX have products been released into the market. Companies like [[Applied Relevance]], [[Attivio]], [[BA-Insight]], [[Cambridge Semantics]], [[Endeca Technologies Inc.|Endeca]], [[Exalead]], [[HP Autonomy]], [[PolySpot]], [[MarkLogic]], [[PerfectSearch]], [[Palantir Technologies|Palantir]], [[TopQuadrant]], [[Sinequa]] and [http://www.virtualworks.com VirtualWorks] have recognized the need for this approach.\u000a\u000aUnified access applications:\u000a*Create [[Hybrid computer|hybrid]] data structures that combine structured data and data operators with [[Text (literary theory)|text]] and semi-structured operations and analytics. They combine semantic understanding, fuzzy matching, sorting, joins, and various operations such as [[range searching]] within a single architecture, rather than federating a query to multiple sources in multiple forms.\u000a*Leverage these hybrid structures to provide real-time access through ad hoc queries to multiple sources of information, including information across a spectrum of [[File format|format]]s (e.g. rich media) through a single [[Interface (computer science)|interface]].\u000a*Handle sparse matrices of unpredictable content.\u000a*Optimize interactions for consumption and decisions, [[Process (computing)|processing]] queries faster than traditional database and/or BI applications and implementing visual consumption metaphors.\u000a*Scale to [[terabyte]]s.\u000a*Provide reporting tools that are BI-like, or integrate easily with BI applications and reporting tools.\u000a\u000a== References ==\u000a* Worldwide Search and Discovery 2009 Vendor Shares and Update on Market Trends, IDC #223926, July, 2010 by Susan Feldman and Hadley Reynolds.\u000a* Building the Intelligent Enterprise: The Case for Unified Access and Analytics\u000aSusan Feldman, Jul 2009 - Doc # 219467   \u000a<!--- See [[Wikipedia:Footnotes]] on how to create references using <ref></ref> tags which will then appear here automatically -->\u000a{{Reflist}}\u000a\u000a== External links ==\u000a* Video: [http://www.attivio.com/poweringbusiness/videos/63-attivio/869-unified-information-access-in-4-minutes.html "Unified Information Access in 4 Minutes"]\u000a* http://www.computerworld.com/s/article/9180280/Five_Advantages_of_Unified_Information_Access_UIA\u000a* http://www.eweek.com/c/a/Enterprise-Applications/How-to-Use-Unified-Information-Access-to-Get-Most-Value-from-Your-Data/\u000a\u000a[[Category:Searching]]
p93
sg4
S'184'
p94
sg6
VUnified Information Access
p95
ssI59
(dp96
g2
V'''Search-based applications''' ('''SBA''') are [[software applications]] in which a [[Search engine|search engine platform]] is used as the core infrastructure for information access and reporting. SBAs use [[Semantic technology|semantic technologies]] to aggregate, normalize and classify [[Unstructured data|unstructured]], [[Semi-structured data|semi-structured]] and/or [[Structured data|structured content]] across multiple repositories, and employ [[Natural language processing|natural language technologies]] for accessing the aggregated information.\u000a\u000a== Pre-Conditions ==\u000a\u000aSearch based applications are fully packaged applications that:<ref>Worldwide Search and Discovery 2009 Vendor Shares: An Update on Market Trends, IDC #223926, July, 2010 by Susan Feldman and Hadley Reynolds.</ref>\u000a* Are built on a search backbone to enable sub-second access to information in multiple formats and from multiple sources\u000a* Are delivered as a unified work environment to support a specific task or workflow, for example: eDiscovery, financial services regulatory compliance, fraud detection, voice of the customer, sales prospecting, pharmaceutical research, anti-terrorism intelligence, or customer support.\u000a* Integrate all the tools that are commonly needed for that specific task or workflow, including:\u000a** Multi-source information access\u000a** Authoring\u000a** Collaboration\u000a** Business process\u000a** Reporting and analysis\u000a** Alerting\u000a** Visualization\u000a* Provide pre-configured data integration with multiple repositories of information in multiple formats as appropriate for the application domain.\u000a* Integrate domain knowledge to support the particular task, including industry taxonomies and vocabularies, internal processes, workflow for the task, connectors to specialized collections of information, and decision heuristics typical of the field.\u000a* Provide a compelling user interface and interaction design that eliminates the need for users to \u201cpogo stick\u201d or continually jump from one application to another. This buffers the user from the complexity of operating separate applications and enables them to focus on getting work done.\u000a* Are quick to deploy, easy to customize or extend, and economical to administer\u000a\u000a== Practical Uses ==\u000a\u000aSBAs are used for a variety of purposes, including:\u000a\u000a* ''' Enterprise Business Applications:''' For example, [[Customer Relationship Management]] (CRM), [[Enterprise Resource Planning]] (ERP), [[Supply Chain Management]] (SCM), Compliance & Discovery, and [[Business Intelligence]] (BI)\u000a\u000a* ''' Web Applications:''' Typically, B2B, B2C and C2B applications that [[Mashup (digital)|mash-up]] data and functionality from diverse sources (databases, Web content, user-generated content, mapping data and functions, etc.)\u000a\u000aThe use of a search platform as the core infrastructure for software applications has been enabled largely by two search engine features:  1) Scalability 2) Ad hoc access to multiple heterogeneous sources from a single point of access.\u000a\u000aSearch based applications have proven popular and effective because they provide a dynamic, scalable access infrastructure that can be integrated with other features that information workers need:  task-specific, and easy to use work environments that integrate features that are usually designed to be used as separate applications, collaborative features, domain knowledge, and security.\u000a\u000aSearch engines are not a replacement for database systems; they are a complement. They have been optimally engineered to facilitate access to information, not to record and store transactions. In addition, the mathematical and statistical processors integrated to date into search engines remain relatively simple. At present, therefore, databases still provide a more effective structure for complex analytical functions.Search applications also focus on providing quality results considering search relevancy.\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a==Further Reading==\u000a* Worldwide Search and Discovery 2009 Vendor Shares: An Update on Market Trends, IDC #223926, July, 2010 by Susan Feldman and Hadley Reynolds.\u000a* Butler Group [http://www.butlergroup.com/webinarIntroduction.asp?mcr=EXA190509&scr=EXA190509 Webinar on Search Based Applications] explaining SBA and how they work\u000a* Presentation on [http://www.informationbuilders.com/support/developers/presentations/?109 Search Based Applications] by   [[Information Builders]]\u000a* IDC Executive Brief [http://www.exalead.com/software/forms/download.php?resourceid=69 "The Information Advantage: Information Access in Tomorrow's Enterprise,"] October 2009, downloadable from the [[Exalead|Exalead.com]] website. Adapted from [http://www.idc.com/getdoc.jsp?containerId=217936 Hidden Costs of Information Work: A Progress Report] and [http://www.idc.com/getdoc.jsp?containerId=219883 Worldwide Search and Discovery Software 2009\u20132013 Forecast Update and 2008 Vendor Shares] by Susan Feldman, IDC.\u000a* IDC [http://www.kmworld.com/downloads/66062/Search_Market_Map_Chart.pdf Search and Discovery Software: 2009 Market Map]\u000a* KMWorld article [http://www.kmworld.com/Articles/Editorial/Feature/Search-based-applications-support-critical-decision-making-66062.aspx Search-based applications support critical decision making]\u000a* Kellblog post [http://www.kellblog.com/2010/02/11/idcs-definiton-of-search-based-applications/ IDC's Definition of Search-Based Applications]\u000a* Steve-Kearns' [http://www.basistech.com/knowledge-center/search/2010-05-building-multilingual-search-based-applications.pdf Building Multilingual Search Based Applications] presentation at Apache Lucene EuroCon 2010 conference\u000a* Information Today article [http://newsbreaks.infotoday.com/NewsBreaks/Attivio-Upgrades-Its-Active-Intelligence-Engine-67608.asp Attivio Upgrades Its Active Intelligence Engine]\u000a* [http://lucidworks.com/blog/debugging-search-application-relevance-issues/ Debugging Search Application Relevance Issues] by Grant Ingersoll. Accessed October 22, 2014.\u000a* [http://www.mind7.fr/en/information_intelligence.html Explanatory video on SBA's and Content Analysis]\u000a\u000a== See also ==\u000a{{col-begin}}\u000a{{col-2}}\u000a* [[Agile application]]\u000a* [[Agile development]]\u000a* [[Business Intelligence 2.0]] (BI 2.0)\u000a* [[Enterprise Search]]\u000a* [[Search oriented architecture]]\u000a* [[Software as a service]]\u000a* [[Lookeen]]\u000a* [[Lucene]]\u000a* [[Exalead]]\u000a{{col-end}}\u000a\u000a<!-- Categories -->\u000a[[Category:Enterprise application integration]]\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search engines| ]]\u000a[[Category:Internet terminology]]
p97
sg4
S'59'
p98
sg6
VSearch-based application
p99
ssI189
(dp100
g2
V{{other uses}}\u000a{{unreferenced|date=September 2013}}\u000a{{lowercase|title=find}} \u000aIn [[Unix-like]] and some other [[operating system]]s, <code>'''find'''</code> is a [[command-line utility]] that [[Search engine (computing)|searches]] through one or more [[directory tree]]s of a [[file system]], locates [[Computer file|file]]s based on some [[user (computing)|user]]-specified criteria and applies a user-specified action on each matched file. The possible search criteria include a [[pattern matching|pattern]] to match against the [[file name]] or a time range to match against the modification time or access time of the file. By default, <code>find</code> returns a list of all files below the current [[working directory]].\u000a\u000aThe related <code>[[locate (Unix)|locate]]</code> programs use a database of indexed files obtained through <code>find</code> (updated at regular intervals, typically by <code>[[cron]]</code> job) to provide a faster method of searching the entire filesystem for files by name.\u000a\u000a==History==\u000a<code>find</code> appeared in [[Version 5 Unix]] as part of the [[PWB/UNIX|Programmer's Workbench]] project.<ref name="reader">{{cite techreport |first1=M. D. |last1=McIlroy |authorlink1=Doug McIlroy |year=1987 |url=http://www.cs.dartmouth.edu/~doug/reader.pdf |title=A Research Unix reader: annotated excerpts from the Programmer's Manual, 1971\u20131986 |series=CSTR |number=139 |institution=Bell Labs}}</ref>\u000a\u000a== Find syntax ==\u000a{{expand section|date=August 2008}}\u000a\u000a<code>find [-H] [-L] [-P] path... [expression]</code>\u000a\u000aThe three options control how the <code>find</code> command should treat symbolic links. The default behaviour is never to follow symbolic links. This can be explicitly specified using the -P flag. The -L flag will cause the <code>find</code> command to follow symbolic links. The -H flag will only follow symbolic links while processing the command line arguments. These flags are not available with some older versions of <code>find</code>.\u000a\u000aAt least one path must precede the expression. <code>find</code> is capable of interpreting [[Wildcard character|wildcards]] internally and commands must be constructed carefully in order to control [[Glob (programming)|shell globbing]].\u000a\u000aExpression elements are whitespace-separated and evaluated from left to right.  They can contain logical elements such as AND (&#x2011;and or &#x2011;a) and OR (&#x2011;or &#x2011;o) as well as more complex predicates.\u000a\u000aThe [[GNU Find Utilities|GNU]] <code>find</code> has a large number of additional features not specified by POSIX.\u000a\u000a== POSIX protection from infinite output ==\u000a\u000aReal-world filesystems often contain looped structures created through the use of [[hard link|hard]] or [[symbolic link|soft links]].  The [[POSIX|POSIX standard]] requires that\u000a{{Quotation|\u000aThe <code>find</code> utility shall detect infinite loops; that is, entering a previously visited\u000adirectory that is an ancestor of the last file encountered. When it detects an infinite\u000aloop, <code>find</code> shall write a diagnostic message to standard error and shall either recover\u000aits position in the hierarchy or terminate.\u000a}}\u000a\u000a==Operators ==\u000aOperators can be used to enhance the expressions of the find command. Operators are listed in order of decreasing precedence:\u000a\u000a*'''( expr )''' Force precedence. \u000a*'''! expr''' True if expr is false.\u000a*'''expr1 expr2''' And (implied); expr2 is not evaluated if expr1 is false. \u000a*'''expr1 -a expr2''' Same as expr1 expr2.  \u000a*'''expr1 -o expr2''' Or; expr2 is not evaluated if expr1 is true.\u000a\u000a find . -name 'fileA_*' -o -name 'fileB_*'\u000a\u000aThis command searches files whose name has a prefix of "fileA_" or "fileB_" in the current directory.\u000a\u000a find . -name 'foo.cpp' '!' -path '.svn'\u000a\u000aThis command searches for files with the name "foo.cpp" in all subdirectories of the current directory (current directory itself included) other than ".svn".   We quote the ! so that it's not interpreted by the shell as the history substitution character.\u000a\u000a==Type filter explanation==\u000a\u000a'''-type''' ''option used to specify search for only file, link or directory.''\u000aVarious type filters are supported by find. They are activated using the\u000a\u000a find -type c\u000a\u000aconfiguration switch where c may be any of:\u000a* '''b '''[[Device file|block (buffered) special]]\u000a* '''c '''[[Device file|character (unbuffered special)]]\u000a* '''d [[Directory (computing)|directory]]'''\u000a* '''p '''[[Named pipe|named pipe (FIFO)]]\u000a* '''f [[regular file]]'''\u000a* '''l '''[[symbolic link]]; this is never true if the -L option or the -follow option is in effect, unless the symbolic link is broken. If you want to search for symbolic links when -L is in effect, use -xtype (though that is a GNU extension).\u000a* '''s '''[[Unix domain socket|socket]]\u000a* '''D '''[[Doors (computing)|door (Solaris)]]\u000a\u000aThe configuration switches listed in bold are most commonly used.\u000a\u000a==Examples==\u000a\u000a===From current directory===\u000a find . -name 'my*'\u000a\u000aThis searches in the current directory (represented by the dot character) and below it, for files and directories with names starting with ''my''. The quotes avoid the [[shell (computing)|shell]] expansion \u2014 without them the shell would replace ''my*'' with the list of files whose names begin with ''my'' in the current directory. In newer versions of the program, the directory may be omitted, and it will imply the current directory.\u000a\u000a===Files only===\u000a find . -name 'my*' -type f\u000aThis limits the results of the above search to only regular files, therefore excluding directories, special files, pipes, symbolic links, etc. ''my*'' is enclosed in single quotes (apostrophes) as otherwise the shell would replace it with the list of  files in the current directory starting with ''my''......\u000a\u000a===Commands===\u000aThe previous examples created listings of results because, by default, <code>find</code> executes the '-print' action.   (Note that early versions of the <code>find</code> command had no default action at all; therefore the resulting list of files would be discarded, to the bewilderment of users.)\u000a\u000a find . -name 'my*' -type f -ls\u000aThis prints extended file information.\u000a\u000a===Search all directories===\u000a find / -name myfile -type f -print\u000aThis searches every file on the computer for a file with the name ''myfile'' and prints it to the screen. It is generally not a good idea to look for data files this way.  This can take a considerable amount of time, so it is best to specify the directory more precisely.  Some operating systems may mount dynamic filesystems that are not congenial to <code>find</code>.   More complex filenames including characters special to the shell may need to be enclosed in single quotes.\u000a\u000a===Search all but one directory subtree===\u000a find / -path excluded_path -prune -o -type f -name myfile -print\u000aThis searches every folder on the computer except the subtree ''excluded_path'' (full path including the leading /), for a file with the name ''myfile''.  It will not detect directories, devices, links, doors, or other "special" filetypes.\u000a\u000a===Specify a directory===\u000a find /home/weedly -name 'myfile' -type f -print\u000aThis searches for files named ''myfile'' in the ''/home/weedly'' directory, the home directory for userid ''weedly''.  You should always specify the directory to the deepest level you can remember.  The quotes are optional in this example because "myfile" contains no characters special to the shell.\u000a\u000a===Search several directories===\u000a find local /tmp -name mydir -type d -print\u000aThis searches for directories named ''mydir'' in the ''local'' subdirectory of the current working directory and the ''/tmp'' directory.\u000a\u000a===Ignore errors===\u000aIf you're doing this as a user other than root, you might want to ignore permission denied (and any other) errors.  Since errors are printed to [[stderr]], they can be suppressed by redirecting the output to /dev/null.  The following example shows how to do this in the bash shell: \u000a find / -name 'myfile' -type f -print 2>/dev/null\u000a\u000aIf you are a [[C shell|csh]] or [[tcsh]] user, you cannot redirect [[stderr]] without redirecting [[stdout]] as well.  You can use sh to run the <code>find</code> command to get around this:\u000a sh -c find / -name 'myfile' -type f -print 2>/dev/null\u000a\u000aAn alternate method when using [[C shell|csh]] or [[tcsh]] is to pipe the output from [[stdout]] and [[stderr]] into a [[grep]] command. This example shows how to suppress lines that contain permission denied errors.\u000a find . -name 'myfile' |& grep -v 'Permission denied'\u000a\u000a===Find any one of differently named files===\u000a find . \u005c( -name '*jsp' -o -name '*java' \u005c) -type f -ls\u000a\u000aThe <code>-ls</code> option prints extended information, and the example finds any file whose name ends with either 'jsp' or 'java'. Note that the parentheses are required. Also note that the operator "or" can be abbreviated as "o". The "and" operator is assumed where no operator is given.  In many shells the parentheses must be escaped with a backslash, "\u005c(" and "\u005c)", to prevent them from being interpreted as special shell characters. The <code>-ls</code> option and the <code>-or</code> operator are not available on all versions of <code>find</code>.\u000a\u000a===Execute an action===\u000a find /var/ftp/mp3 -name '*.mp3' -type f -exec chmod 644 {} \u005c;\u000aThis command changes the [[File system permissions|permissions]] of all files with a name ending in ''.mp3'' in the directory ''/var/ftp/mp3''. The  action is carried out by specifying the option <code>-exec [[chmod]] 644 {} \u005c;</code> in the command. For every file whose name ends in <code>.mp3</code>, the command <code>chmod 644 {}</code> is executed replacing <code>{}</code> with the name of the file. The semicolon (backslashed to avoid the shell interpreting it as a command separator) indicates the end of the command. Permission <code>644</code>, usually shown as <code>rw-r--r--</code>, gives the file owner full permission to read and write the file, while other users have read-only access. In some shells, the <code>{}</code> must be quoted.  The trailing ";" is customarily quoted with a leading "\u005c", but could just as effectively be enclosed in single quotes.\u000a\u000aNote that the command itself should *not* be quoted; otherwise you get error messages like\u000a\u000a find: echo "mv ./3bfn rel071204": No such file or directory\u000a\u000awhich means that <code>find</code> is trying to run a file called 'echo "mv ./3bfn rel071204"' and failing.\u000a\u000aIf you will be executing over many results, it is more efficient to use a variant of the exec primary that collects filenames up to ARG_MAX and then executes COMMAND with a list of filenames.\u000a\u000a find . -exec COMMAND {} +\u000a\u000aThis will ensure that filenames with whitespaces are passed to the executed COMMAND without being split up by the shell.\u000a\u000a===Delete files and directories===\u000a'''Caveats''': the -delete action is a GNU extension, and using it turns on -depth.   So, if you are testing a find command with -print instead of -delete in order to figure out what will happen before going for it, you need to use -depth -print.\u000a\u000aDelete empty files and directories and print the names (note that -empty is a vendor unique extension from GNU find that may not be available in all find implementations)\u000a find /foo -empty -delete -print\u000a\u000aDelete empty files\u000a find /foo -type f -empty -delete\u000a\u000aDelete empty directories\u000a find /foo -type d -empty -delete\u000a\u000aDelete files and directories (if empty) named <code>bad</code> \u000a find /foo -name bad -empty -delete\u000a\u000a'''Warning''': <code>-delete</code> should be used with other operators such as\u000a<code>-empty</code> or <code>-name</code>.\u000a\u000a find /foo -delete  # this deletes '''all''' in /foo\u000a\u000a===Search for a string===\u000aThis command will search for a string in all files from the /tmp directory and below:\u000a<source lang="bash">\u000a $ find /tmp -type f -exec grep 'search string' '{}' /dev/null \u005c+\u000a</source>\u000aThe <tt>[[/dev/null]]</tt> argument is used to show the name of the file before the text that is found. Without it, only the text found is printed.  An equivalent mechanism is to use the "-H" or "--with-filename" option to grep:\u000a<source lang="bash">\u000a $ find /tmp -type f -exec grep -H 'search string' '{}' '+' \u000a</source>\u000aGNU grep can be used on its own to perform this task:\u000a\u000a $ grep -r 'search string' /tmp\u000a\u000aExample of search for "LOG" in jsmith's home directory\u000a<source lang="bash" highlight="1">\u000a $ find ~jsmith -exec grep LOG '{}' /dev/null \u005c; -print\u000a /home/jsmith/scripts/errpt.sh:cp $LOG $FIXEDLOGNAME\u000a /home/jsmith/scripts/errpt.sh:cat $LOG\u000a /home/jsmith/scripts/title:USER=$LOGNAME\u000a</source>\u000aExample of search for the string "ERROR" in all XML files in the current directory and all sub-directories\u000a<source lang="bash">\u000a\u000a $ find . -name "*.xml" -exec grep "ERROR" /dev/null '{}' \u005c+ \u000a</source>\u000aThe double quotes (" ") surrounding the search string and single quotes (<nowiki>' '</nowiki>) surrounding the braces are optional in this example, but needed to allow spaces and some other special characters in the string.  Note with more complex text (notably in most popular shells descended from `sh` and `csh`) single quotes are often the easier choice, since '''double quotes do not prevent all special interpretation'''. Quoting filenames which have English contractions demonstrates how this can get rather complicated, since a string with an apostrophe in it is easier to protect with double quotes.  Example:\u000a<source lang="bash">\u000a\u000a $ find . -name "file-containing-can't" -exec grep "can't" '{}' \u005c; -print\u000a</source>\u000a\u000a===Search for all files owned by a user===\u000a find . -user <userid>\u000a\u000a===Search in case insensitive mode===\u000aNote that -iname is not in the standard and may not be supported by all implementations.\u000a\u000a find . -iname ''''MyFile'''*'\u000a\u000aIf the <code>-iname</code> switch is not supported on your system then workaround techniques may be possible such as:\u000a\u000a find . -name '[m'''M''']['''y'''Y][f'''F''']['''i'''I]['''l'''L]['''e'''E]*'\u000a\u000aThis uses [[Perl]] to build the above command for you (though in general this kind of usage is dangerous, since special characters are not properly quoted before being fed into the standard input of `sh`):\u000a\u000a echo "''''MyFile'''*'" |perl -pe 's/([a-zA-Z])/[\u005cL\u005c1\u005cU\u005c1]/g;s/(.*)/find . -name \u005c1/'|sh\u000a\u000a===Search files by size===\u000aExample of searching files with size between 100 kilobytes and 500 kilobytes.\u000a find . -size +100k -a -size -500k\u000aExample of searching empty files.\u000a find . -size 0k\u000aExample of searching non-empty files.\u000a find . ! -size 0k\u000a\u000a===Search files by name and size ===\u000a '''find''' /usr/src {{abbr|!|the negation of the expression that follows}} {{abbr|\u005c(|the start of a complex expression.}} -name '*,v' {{abbr|-o|a logical or of a complex expression. In this case the complex expression is all files like '*,v' or '.*,v'}} -name '.*,v' {{abbr|\u005c)|the end of a complex expression.}} '{}' \u005c; -print\u000a\u000aThis command will search in the /usr/src directory and all sub directories. All files that are of the form '*,v' and '.*,v' are excluded. Important arguments to note are in the [[tooltip]] that is displayed on mouse-over.\u000a\u000a<source lang="bash" enclose="div">\u000afor file in `find /opt \u005c( -name error_log -o -name 'access_log' -o -name 'ssl_engine_log' -o -name 'rewrite_log' -o\u000a -name 'catalina.out' \u005c) -size +300000k -a -size -5000000k`; do \u000a    cat /dev/null > $file\u000adone\u000a</source>\u000aThe units should be one of [bckw], 'b' means 512-byte blocks, 'c' means byte, 'k' means kilobytes and 'w' means 2-byte words. The size does not count indirect blocks, but it does count blocks in sparse files that are not actually allocated.\u000a\u000a==Related utilities==\u000a* <code>[[locate (Unix)|locate]]</code> is a Unix search tool that searches through a prebuilt database of files instead of directory trees of a file system. This is faster than <code>find</code> but less accurate because the database may not be up-to-date.\u000a* <code>[[grep]]</code> is a command-line utility for searching plain-text data sets for lines matching a regular expression and by default reporting matching lines on [[standard output]].\u000a* <code>[[tree (Unix)|tree]]</code> is a command-line utility that recursively lists files found in a directory tree, indenting the file names according to their position in the file hierarchy.\u000a* [[GNU Find Utilities]] (also known as findutils) is a [[GNU package]] which contains implementations of the tools <code>find</code> and [[xargs]].\u000a* [[BusyBox]] is a utility that provides several stripped-down Unix tools in a single executable file, intended for embedded operating systems with very limited resources. It also provides a version of <code>find</code>.\u000a* <code>[[dir (command)|dir]]</code> has the /s option that recursively searches for files or folders.\u000a\u000a==See also==\u000a*[[mdfind]], a similar utility that utilizes metadata for [[Mac OS X]] and [[Darwin (operating system)|Darwin]]\u000a*[[List of Unix programs]]\u000a*[[List of DOS commands]]\u000a*[[List of duplicate file finders]]\u000a*[[Filter (higher-order function)]]\u000a*[[find (command)]], a DOS and Windows command that is very different from UNIX <code>find</code>\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a==External links==\u000a*{{man|cu|find|SUS|find files}}\u000a*[http://www.gnu.org/software/findutils/manual/html_mono/find.html Official webpage for GNU find]\u000a\u000a{{Unix commands}}\u000a\u000a[[Category:Searching]]\u000a[[Category:Standard Unix programs]]\u000a[[Category:Unix SUS2008 utilities]]
p101
sg4
S'189'
p102
sg6
VFind
p103
ssI64
(dp104
g2
V{{other uses2|Gain}}\u000a{{Unreferenced|date=August 2009}}\u000aThe '''gain''', also called '''improvement over random''' {{cn|date=March 2013}} can be specified for a [[classifier (mathematics)|classifier]] and is an important measure {{dubious|date=March 2013}} to describe the performance of it.\u000a\u000a== Definition ==\u000aIn the following a random classifier is defined such that it randomly predicts the same amount of either class.\u000a\u000aThe gain is defined as described in the following:\u000a\u000a=== Gain in Precision ===\u000a\u000aThe random [[positive predictive value|precision]] of a classifier is defined as\u000a\u000a<math>\u000ar = \u005cfrac{TP+FN}{TP+TN+FP+FN} = \u005cfrac{\u005ctextit{Positives}}{N}\u000a</math>\u000a\u000awhere TP, TN, FP and FN are the numbers of true positives, true negatives, false positives and false negatives respectively, positives is the number of positive instances in the target dataset and N is the size of the dataset.\u000a\u000aThe random precision defines the lowest baseline of a classifier.\u000a\u000aAnd '''Gain''' is defined as \u000a\u000a<math>\u000aG = \u005cfrac{\u005ctextit{precision}}{r}\u000a</math>\u000a\u000awhich gives a factor by which a classifier is better when compared to its random counterpart. A Gain of 1 would indicate a classifier that is not better than random. The larger the gain, the better.\u000a\u000a=== Gain in Overall Accuracy ===\u000a\u000aThe [[accuracy]] of a classifier in general is defined as\u000a\u000a<math>\u000aAcc = \u005cfrac{TP+TN}{TP+TN+FP+FN} = \u005cfrac{\u005ctextit{Corrects}}{N}\u000a</math>\u000a\u000aHere, the random accuracy of a classifier can be defined as\u000a\u000a<math>\u000ar = \u005cleft ( \u005cfrac{\u005ctextit{Positives}}{N} \u005cright ) ^2+ \u005cleft ( \u005cfrac{\u005ctextit{Negatives}}{N} \u005cright ) ^2=f(\u005ctextit{Positives})^2 + f(\u005ctextit{Negatives})^2\u000a</math>\u000a\u000af(Positives) and f(Negatives) is the fraction of positive and negative classes in the dataset.\u000a\u000aAnd again '''gain''' is\u000a\u000a<math>\u000aG = \u005cfrac{\u005ctextit{Acc}}{r}\u000a</math>\u000a\u000aThis time the gain is measured not only with respect to the prediction of a so-called positive class, but with respect to the overall classifier ability to distinguish the two equally important classes.\u000a\u000a== Application ==\u000aIn [[Bioinformatics]] as an example, the gain is measured for methods that predict residue contacts in proteins.\u000a\u000a== See also ==\u000a* [[Accuracy and precision]]\u000a* [[Binary classification]]\u000a* [[Brier score]]\u000a* [[Confusion matrix]]\u000a* [[Detection theory]]\u000a* [[F-score]]\u000a* [[Information retrieval]]\u000a* [[Matthews correlation coefficient]]\u000a* [[Receiver operating characteristic]] or ROC curve\u000a* [[Selectivity (electronic)|Selectivity]]\u000a* [[Sensitivity and specificity]]\u000a* [[Sensitivity index]]\u000a* [[Statistical significance]]\u000a* [[Youden's J statistic]]\u000a\u000a{{DEFAULTSORT:Gain (Information Retrieval)}}\u000a[[Category:Logic]]\u000a[[Category:Information retrieval]]
p105
sg4
S'64'
p106
sg6
VGain (information retrieval)
p107
ssI194
(dp108
g2
V{{lowercase}}\u000a'''<code>locate</code>''', a [[Unix]] utility first created in 1983,<ref>\u000aRef: [[Usenix]] ''';login:''', Vol 8, No 1, February/March, 1983, p. 8.\u000a</ref>\u000aserves to find [[computer file|file]]s on [[filesystem]]s. It searches through a prebuilt [[database]] of files generated by '''<code>updatedb</code>''' or by a [[Daemon (computing)|daemon]] and compressed using [[incremental encoding]]. It operates significantly faster than <code>[[find]]</code>, but requires regular updating of the database. This sacrifices overall efficiency (because of the regular interrogation of filesystems even when no user needs information) and absolute accuracy (since the database does not update in [[Real-time computing|real time]]) for significant speed improvements (particularly on very large filesystems).\u000a\u000aThe GNU version forms a part of [[GNU Findutils]].\u000a\u000aSome versions can also index network filesystems.\u000a\u000a==mlocate==\u000amlocate is a locate/updatedb implementation.\u000a\u000a[https://fedorahosted.org/mlocate/ mlocate site]\u000a\u000a==References==\u000a<references/>\u000a\u000a==External links==\u000a* {{man|1|locate|FreeBSD}}\u000a* [https://www.gnu.org/software/findutils/findutils.html GNU Findutils]\u000a\u000aVariants:\u000a* {{wayback|url=http://slocate.trakker.ca/|title=slocate (Secure Locate)|date=20090204031919}}\u000a** {{man|1|slocate|die.net}}\u000a* [http://carolina.mff.cuni.cz/~trmac/blog/mlocate/ <code>mlocate</code>] - faster updates\u000a** {{man|1|locate|die.net|mlocate}}\u000a* [http://rlocate.sourceforge.net/ rlocate] - always up-to-date\u000a* [http://www.kde-apps.org/content/show.php/KwickFind+(Locate+GUI+Frontend)?content=54817 KwickFind] - KDE GUI frontend for locate\u000a* [http://www.locate32.net/ Locate32 for Windows] Windows analog of GNU locate with GUI, released under GNU license\u000a\u000a{{unix commands}}\u000a\u000a[[Category:GNU Project software]]\u000a[[Category:Unix file system-related software]]\u000a[[Category:Searching]]\u000a\u000a{{Unix-stub}}
p109
sg4
S'194'
p110
sg6
VLocate (Unix)
p111
ssI69
(dp112
g2
V{{Cat main|Citation index}}\u000a{{cat see also|Bibliographic databases|Bibliographic indexes}}\u000a\u000a[[Category:Bibliometrics]]\u000a[[Category:Reference works]]\u000a[[Category:Indexes]]\u000a[[Category:Information retrieval]]\u000a[[Category:Bibliographic databases| ]]
p113
sg4
S'69'
p114
sg6
VCategory:Citation indices
p115
ssI199
(dp116
g2
V{| align="right"\u000a|-\u000a| [[Image:Hamming distance 3 bit binary.svg|thumb|140px|3-bit binary [[cube]] for finding Hamming distance]]\u000a| [[Image:Hamming distance 3 bit binary example.svg|thumb|140px|Two example distances: 100\u2192011 has distance 3 (red path); 010\u2192111 has distance 2 (blue path)]]\u000a|-\u000a|colspan=2 | [[Image:Hamming distance 4 bit binary.svg|thumb|280px|4-bit binary [[tesseract]] for finding Hamming distance]]\u000a|-\u000a|colspan=2 | [[Image:Hamming distance 4 bit binary example.svg|thumb|280px|Two example distances: 0100\u21921001 has distance 3 (red path); 0110\u21921110 has distance 1 (blue path)]]\u000a|}\u000a\u000aIn [[information theory]], the '''Hamming distance''' between two [[String (computer science)|string]]s of equal length is the number of positions at which the corresponding symbols are different. In another way, it measures the minimum number of ''substitutions'' required to change one string into the other, or the minimum number of ''errors'' that could have transformed one string into the other.\u000a\u000a==Examples==\u000aThe Hamming distance between:\u000a* "'''</span>ka<span style="color:#0082ff">rol</span>in</span>'''" and "'''</span>ka<span style="color:red;">thr</span>in</span>'''" is 3.\u000a* "'''</span>k<span style="color:#0082ff">a</span>r<span style="color:#0082ff">ol</span>in</span>'''" and "'''</span>k<span style="color:red;">e</span>r<span style="color:red;">st</span>in</span>'''" is 3.\u000a* '''10<span style="color:#0082ff">1</span>1<span style="color:#0082ff">1</span>01''' and '''10<span style="color:red;">0</span>1<span style="color:red;">0</span>01''' is 2.\u000a* '''2<span style="color:#0082ff">17</span>3<span style="color:#0082ff">8</span>96''' and '''2<span style="color:red;">23</span>3<span style="color:red;">7</span>96''' is 3.\u000a\u000a==Special properties==\u000aFor a fixed length ''n'', the Hamming distance is a [[Metric (mathematics)|metric]] on the vector space of the words of length n, as it fulfills the conditions of non-negativity, identity of indiscernibles and symmetry, and it can be shown by [[complete induction]] that it satisfies the [[triangle inequality]] as well. The Hamming distance between two words ''a'' and ''b'' can also be seen as the [[Hamming weight]] of ''a''&minus;''b'' for an appropriate choice of the &minus; operator.\u000a\u000aFor '''binary strings''' ''a'' and ''b'' the Hamming distance is equal to the number of ones ([[Hamming weight|population count]]) in ''a'' [[Exclusive or|XOR]] ''b''. The metric space of length-''n'' binary strings, with the Hamming distance, is known as the ''Hamming cube''; it is equivalent as a metric space to the set of distances between vertices in a [[hypercube graph]]. One can also view a binary string of length ''n'' as a vector in <math>R^n</math> by treating each symbol in the string as a real coordinate; with this embedding, the strings form the vertices of an ''n''-dimensional [[hypercube]], and the Hamming distance of the strings is equivalent to the [[Manhattan distance]] between the vertices.\u000a\u000a==History and applications==\u000a\u000aThe Hamming distance is named after [[Richard Hamming]], who introduced it in his fundamental paper on [[Hamming code]]s ''Error detecting and error correcting codes'' in 1950.<ref>{{harvtxt|Hamming|1950}}.</ref> It is used in [[telecommunication]] to count the number of flipped bits in a fixed-length binary word as an estimate of error, and therefore is sometimes called the '''signal distance'''. Hamming weight analysis of bits is used in several disciplines including [[information theory]], [[coding theory]], and [[cryptography]]. However, for comparing strings of different lengths, or strings where not just substitutions but also insertions or deletions have to be expected, a more sophisticated metric like the [[Levenshtein distance]] is more appropriate.\u000aFor ''q''-ary strings over an [[alphabet]] of size ''q''&nbsp;\u2265&nbsp;2 the Hamming distance is applied in case of orthogonal [[modulation]], while the [[Lee distance]] is used for phase modulation. If ''q''&nbsp;=&nbsp;2 or ''q''&nbsp;=&nbsp;3 both distances coincide.\u000a\u000aThe Hamming distance is also used in [[systematics]] as a measure of genetic distance.<ref name="pmid18351799">{{harvtxt|Pilcher|Wong|Pillai|2008}}.</ref>\u000a\u000aOn a grid such as a chessboard, the Hamming distance is the minimum number of moves it would take a [[Rook_(chess)|rook]] to move from one cell to the other.\u000a\u000a== Algorithm example ==\u000aThe [[Python (programming language)|Python]] function <code>hamming_distance()</code> computes the Hamming distance between\u000atwo strings (or other [[Iterator|iterable]] objects) of equal length, by creating a sequence of Boolean values indicating mismatches and matches between corresponding positions in the two inputs, and then summing the sequence with False and True values being interpreted as zero and one.\u000a{{-}}\u000a\u000a<syntaxhighlight lang="python">\u000adef hamming_distance(s1, s2):\u000a    """Return the Hamming distance between equal-length sequences"""\u000a    if len(s1) != len(s2):\u000a        raise ValueError("Undefined for sequences of unequal length")\u000a    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\u000a</syntaxhighlight>\u000a\u000aThe following [[C (programming language)|C]] function will compute the Hamming distance of two integers (considered as binary values, that is, as sequences of bits). The running time of this procedure is proportional to the Hamming distance rather than to the number of bits in the inputs. It computes the [[bitwise operation|bitwise]] [[exclusive or]] of the two inputs, and then finds the [[Hamming weight]] of the result (the number of nonzero bits) using an algorithm of {{harvtxt|Wegner|1960}} that repeatedly finds and clears the lowest-order nonzero bit.\u000a\u000a<syntaxhighlight lang="c">\u000aint hamming_distance(unsigned x, unsigned y)\u000a{\u000a    int       dist;\u000a    unsigned  val;\u000a\u000a    dist = 0;\u000a    val = x ^ y;    // XOR\u000a\u000a    // Count the number of bits set\u000a    while (val != 0)\u000a    {\u000a        // A bit is set, so increment the count and clear the bit\u000a        dist++;\u000a        val &= val - 1;\u000a    }\u000a\u000a    // Return the number of differing bits\u000a    return dist;\u000a}\u000a</syntaxhighlight>\u000a\u000a==See also==\u000a{{Portal|Mathematics}}\u000a* [[Closest string]]\u000a* [[Damerau\u2013Levenshtein distance]]\u000a* [[Euclidean distance]]\u000a* [[Mahalanobis distance]]\u000a* [[Jaccard index]]\u000a* [[String metric]]\u000a* [[Sørensen similarity index]]\u000a* [[Word ladder]]\u000a\u000a==Notes==\u000a{{Reflist}}\u000a\u000a==References==\u000a*{{FS1037C}}\u000a*{{citation\u000a | last = Hamming | first = Richard W. | author-link = Richard W. Hamming\u000a | mr = 0035935\u000a | issue = 2\u000a | journal = [[Bell System Technical Journal]]\u000a | pages = 147\u2013160\u000a | title = Error detecting and error correcting codes\u000a | url = http://wayback.archive.org/web/20060525060427/http://www.caip.rutgers.edu/~bushnell/dsdwebsite/hamming.pdf\u000a | volume = 29\u000a | year = 1950\u000a | doi=10.1002/j.1538-7305.1950.tb00463.x}}.\u000a*{{citation\u000a | last1 = Pilcher | first1 = C. D.\u000a | last2 = Wong | first2 = J. K.\u000a | last3 = Pillai | first3 = S. K.\u000a | date = March 2008\u000a | doi = 10.1371/journal.pmed.0050069\u000a | issue = 3\u000a | journal = PLoS Med.\u000a | page = e69\u000a | pmid = 18351799\u000a | title = Inferring HIV transmission dynamics from phylogenetic sequence relationships\u000a | volume = 5\u000a | pmc = 2267810}}.\u000a*{{citation\u000a | last = Wegner | first = Peter | author-link = Peter Wegner\u000a | doi = 10.1145/367236.367286\u000a | issue = 5\u000a | journal = [[Communications of the ACM]]\u000a | page = 322\u000a | title = A technique for counting ones in a binary computer\u000a | volume = 3\u000a | year = 1960}}.\u000a\u000a[[Category:String similarity measures]]\u000a[[Category:Coding theory]]\u000a[[Category:Articles with example Python code]]\u000a[[Category:Articles with example C++ code]]\u000a[[Category:Metric geometry]]\u000a[[Category:Cubes]]
p117
sg4
S'199'
p118
sg6
VHamming distance
p119
ssI74
(dp120
g2
V{{other uses}}\u000aThe '''MA'''trixware '''RE'''search '''C'''ollection ('''MAREC''') is a standardised patent data corpus available for research purposes. MAREC seeks to represent patent documents of several languages in order to answer specific research questions.<ref>Merz C., (2003) A Corpus Query Tool For Syntactically Annotated Corpora Licentiate Thesis, The University of Zurich, Department of Computation linguistic, Switzerland</ref><ref>Biber D., Conrad S., and Reppen R. (2000) Corpus Linguistics: Investigating Language Structure and Use. Cambridge University Press, 2nd edition</ref> It consists of 19 million patent documents in different languages, normalised to a highly specific [[XML]] schema.\u000a\u000aMAREC is intended as raw material for research in areas such as [[information retrieval]], [[natural language processing]] or [[machine translation]], which require large amounts of complex documents.<ref>Manning, C. D. and Schütze, H. (2002) Foundations of statistical natural language processing Cambridge, MA, Massachusetts Institute of Technology (MIT)  ISBN 0-262-13360-1.</ref> The collection contains documents in 19 languages, the majority being English, German and French, and about half of the documents include full text.\u000a\u000aIn MAREC, the documents from different countries and sources are normalised to a common XML format with a uniform patent numbering scheme and citation format. The standardised fields include dates, countries, languages, references, person names, and companies as well as subject classifications such as [[International Patent Classification|IPC]] codes.<ref>European Patent Office (2009) [http://documents.epo.org/projects/babylon/eponet.nsf/0/1AFC30805E91D074C125758A0051718A/$File/guidelines_2009_complete_en.pdf Guidelines for examination in the European Patent Office], Published by European Patent Office, Germany (April 2009)</ref>\u000a\u000aMAREC is a comparable corpus, where many documents are available in similar versions in other languages. A comparable corpus can be defined as consisting of texts that share similar topics \u2013 news text from the same time period in different countries, while a parallel corpus is defined as a collection of documents with aligned translations from the source to the target language.<ref>Järvelin A. , Talvensaari T. , Järvelin Anni, (2008) Data driven methods for improving mono- and cross-lingual IR performance in noisy environments, Proceedings of the second workshop on Analytics for noisy unstructured text data, (Singapore)</ref> Since the patent document refers to the same \u201cinvention\u201d or \u201cconcept of idea\u201d the text is a translation of the invention, but it does not have to be a direct translation of the text itself \u2013 text parts could have been removed or added for clarification reasons.\u000a\u000aThe 19,386,697 XML files measure a total of 621 GB and are hosted by the [[Information Retrieval Facility]]. Access and support are free of charge for research purposes.\u000a\u000a== Use Cases ==\u000a* MAREC is used in the [[Patent Language Translations Online (PLuTO)]] project.\u000a\u000a== References ==\u000a{{Reflist}}\u000a\u000a== External links ==\u000a* [http://www.ir-facility.org/prototypes/marec User guide and statistics]\u000a* [http://ir-facility.org Information Retrieval Facility]\u000a\u000a[[Category:Corpora]]\u000a[[Category:Information retrieval]]\u000a[[Category:Machine translation]]\u000a[[Category:Natural language processing]]\u000a[[Category:XML]]
p121
sg4
S'74'
p122
sg6
VMAREC
p123
ssI204
(dp124
g2
VThe '''Jaccard index''', also known as the '''Jaccard similarity coefficient''' (originally coined ''coefficient de communauté'' by [[Paul Jaccard]]), is a [[statistic]] used for comparing the [[Similarity measure|similarity]] and [[diversity index|diversity]] of [[Sample (statistics)|sample]] sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the [[intersection (set theory)|intersection]] divided by the size of the [[Union (set theory)|union]] of the sample sets:\u000a\u000a:<math> J(A,B) = {{|A \u005ccap B|}\u005cover{|A \u005ccup B|}}.</math>\u000a\u000a(If ''A'' and ''B'' are both empty, we define ''J''(''A'',''B'')&nbsp;=&nbsp;1.) Clearly, \u000a:<math> 0\u005cle J(A,B)\u005cle 1.</math>\u000a\u000aThe [[MinHash]] min-wise independent permutations [[locality sensitive hashing]] scheme may be used to efficiently compute an accurate estimate of the Jaccard similarity coefficient of pairs of sets, where each set is represented by a constant-sized signature derived from the minimum values of a [[hash function]].\u000a\u000aThe '''Jaccard distance''', which measures ''dis''similarity between sample sets, is complementary to the Jaccard coefficient and is obtained by subtracting the Jaccard coefficient from 1, or, equivalently, by dividing the difference of the sizes of the union and the intersection of two sets by the size of the union:\u000a\u000a:<math> d_J(A,B) = 1 - J(A,B) = { { |A \u005ccup B| - |A \u005ccap B| } \u005cover |A \u005ccup B| }.</math>\u000a\u000aAn alternate interpretation of the Jaccard distance is as the ratio of the size of the [[symmetric difference]] <math>A \u005ctriangle B = (A \u005ccup B) - (A \u005ccap B)</math> to the union. \u000a\u000aThis distance is a [[Distance function|metric]] on the collection of all finite sets.<ref name="lipkus">{{citation |last=Lipkus |first=Alan H\u000a|title=A proof of the triangle inequality for the Tanimoto distance\u000a|journal=J Math Chem |volume=26 |number=1-3 |year=1999 |pages=263\u2013265 }}</ref><ref>{{citation |last1=Levandowsky |first1=Michael |last2=Winter |first2=David |title=Distance between sets|journal=Nature |volume=234 |number=5 |year=1971 |pages=34\u201335 |doi=10.1038/234034a0}}</ref>\u000a\u000aThere is also a version of the Jaccard distance for [[measure (mathematics)|measures]], including [[probability measure]]s. If <math>\u005cmu</math> is a measure on a [[measurable space]] <math>X</math>, then we define the Jaccard coefficient by <math>J_\u005cmu(A,B) = {{\u005cmu(A \u005ccap B)} \u005cover {\u005cmu(A \u005ccup B)}}</math>, and the Jaccard distance by <math>d_\u005cmu(A,B) = 1 - J_\u005cmu(A,B) = {{\u005cmu(A \u005ctriangle B)} \u005cover {\u005cmu(A \u005ccup B)}}</math>. Care must be taken if <math>\u005cmu(A \u005ccup B) = 0</math> or <math>\u005cinfty</math>, since these formulas are not well defined in that case.\u000a\u000a== Similarity of asymmetric binary attributes ==\u000aGiven two objects, ''A'' and ''B'', each with ''n'' [[binary numeral system|binary]] attributes, the Jaccard coefficient is a useful measure of the overlap that ''A'' and ''B'' share with their attributes.  Each attribute of ''A'' and ''B'' can either be 0 or 1.  The total number of each combination of attributes for both ''A'' and ''B'' are specified as follows:\u000a:<math>M_{11}</math> represents the total number of attributes where ''A'' and ''B'' both have a value of 1.\u000a:<math>M_{01}</math> represents the total number of attributes where the attribute of ''A'' is 0 and the attribute of ''B'' is 1.\u000a:<math>M_{10}</math> represents the total number of attributes where the attribute of ''A'' is 1 and the attribute of ''B'' is 0.\u000a:<math>M_{00}</math> represents the total number of attributes where ''A'' and ''B'' both have a value of 0.\u000aEach attribute must fall into one of these four categories, meaning that\u000a:<math>M_{11} + M_{01} + M_{10} + M_{00} = n.</math>\u000a\u000aThe Jaccard similarity coefficient, ''J'', is given as\u000a:<math>J = {M_{11} \u005cover M_{01} + M_{10} + M_{11}}.</math>\u000a\u000aThe Jaccard distance, ''d''<sub>''J''</sub>, is given as\u000a:<math>d_J = {M_{01} + M_{10} \u005cover M_{01} + M_{10} + M_{11}}.</math>\u000a\u000a== Generalized Jaccard similarity and distance ==\u000a\u000aIf <math>\u005cmathbf{x} = (x_1, x_2, \u005cldots, x_n)</math> and <math>\u005cmathbf{y} = (y_1, y_2, \u005cldots, y_n)</math> are two vectors with all real <math>x_i, y_i \u005cgeq 0</math>, then their Jaccard similarity coefficient is defined as\u000a:<math>J(\u005cmathbf{x}, \u005cmathbf{y}) = \u005cfrac{\u005csum_i \u005cmin(x_i, y_i)}{\u005csum_i \u005cmax(x_i, y_i)},</math>\u000aand Jaccard distance\u000a:<math>d_J(\u005cmathbf{x}, \u005cmathbf{y}) = 1 - J(\u005cmathbf{x}, \u005cmathbf{y}).</math>\u000a\u000aWith even more generality, if <math>f</math> and <math>g</math> are two non-negative measurable functions on a measurable space <math>X</math> with measure <math>\u005cmu</math>, then we can define\u000a:<math>J(f, g) = \u005cfrac{\u005cint\u005cmin(f, g) d\u005cmu}{\u005cint \u005cmax(f, g)  d\u005cmu},</math>\u000awhere <math>\u005cmax</math> and <math>\u005cmin</math> are pointwise operators. Then Jaccard distance is\u000a:<math>d_J(f, g) = 1 - J(f, g).</math>\u000a\u000aThen, for example, for two measurable sets <math>A, B \u005csubseteq X</math>, we have <math>J_\u005cmu(A,B) = J(\u005cchi_A, \u005cchi_B),</math> where <math>\u005cchi_A</math> and <math>\u005cchi_B</math> are the characteristic functions of the corresponding set.\u000a\u000a== Tanimoto similarity and distance ==\u000a\u000a<!-- [[Tanimoto score]] redirects here, please change that redirect if you change this section title -->\u000a\u000aVarious forms of functions described as  Tanimoto similarity  and Tanimoto distance occur  in the literature and on the Internet. Most of these are synonyms for Jaccard similarity and Jaccard distance, but some are mathematically different. Many sources<ref>For example {{cite book |first=Huihuan |last=Qian |first2=Xinyu |last2=Wu |first3=Yangsheng |last3=Xu |title=Intelligent Surveillance Systems |publisher=Springer |year=2011 |page=161 |isbn=978-94-007-1137-2 }}</ref> cite an  unavailable IBM Technical Report<ref>{{cite journal |last=Tanimoto |first=T. |title=An Elementary Mathematical theory of Classification and Prediction |journal=Internal IBM Technical Report |date=17 Nov 1957 |issue=8? |volume=1957 }}</ref> as the seminal reference.\u000a\u000aIn "A Computer Program for Classifying Plants", published in October 1960,<ref>{{cite journal |first=David J. |last=Rogers |first2=Taffee T. |last2=Tanimoto |title=A Computer Program for Classifying Plants |journal=[[Science (journal)|Science]] |volume=132 |issue=3434 |pages=1115\u20131118 |year=1960 |doi=10.1126/science.132.3434.1115 }}</ref> a method of classification based on a similarity ratio, and a derived distance function, is given. It seems that this is  the most authoritative  source for the meaning of the terms "Tanimoto similarity" and "Tanimoto Distance". The similarity ratio is equivalent to Jaccard similarity, but the distance function is ''not'' the same as Jaccard distance.\u000a\u000a=== Tanimoto's definitions of similarity and distance ===\u000a\u000aIn that paper, a "similarity ratio" is  given over [[Bit array|bitmaps]], where each bit of a fixed-size array represents the presence or absence of a characteristic in the plant being modelled. The definition of the ratio is the number of common bits, divided by the number of bits set (i.e. nonzero) in either sample.\u000a\u000aPresented in mathematical terms, if samples ''X'' and ''Y'' are bitmaps, <math>X_i</math> is the ''i''th bit of ''X'', and <math> \u005cland , \u005clor </math> are [[bitwise operation|bitwise]] ''[[logical conjunction|and]]'', ''[[logical disjunction|or]]'' operators respectively, then the similarity ratio <math>T_s</math> is\u000a\u000a: <math> T_s(X,Y) =  \u005cfrac{\u005csum_i ( X_i \u005cland Y_i)}{\u005csum_i ( X_i \u005clor Y_i)}</math>\u000a\u000aIf each sample is modelled instead as a set of attributes, this value is  equal to the Jaccard coefficient of the two sets. Jaccard is not cited in the paper, and it seems likely that the authors were not aware of it.\u000a\u000aTanimoto goes on to define a "distance coefficient" based on this ratio, defined for bitmaps with non-zero similarity:\u000a\u000a: <math>T_d(X,Y) = -\u005clog_2 ( T_s(X,Y) ) </math>\u000a\u000aThis coefficient is, deliberately, not a distance metric. It is chosen to allow the possibility of two specimens, which are quite different from each other, to both be similar to a third. It is  easy to construct an example which disproves the property of [[Triangle inequality#Metric space|triangle inequality]].\u000a\u000a=== Other definitions of Tanimoto distance ===\u000a\u000aTanimoto distance is often referred to, erroneously, as a synonym for Jaccard distance <math> 1 - T_s</math>. This function is a proper distance metric. "Tanimoto Distance" is often stated as being a proper distance metric, probably because of its confusion with Jaccard distance.\u000a\u000aIf Jaccard or Tanimoto similarity is expressed over a bit vector, then it can be written as\u000a\u000a: <math>\u000af(A,B) =\u005cfrac{ A \u005ccdot B}{\u005cvert A\u005cvert^2 +\u005cvert B\u005cvert^2 -  A \u005ccdot B }\u000a</math>\u000a\u000awhere the same calculation is expressed in terms of vector scalar product and magnitude. This representation relies on the fact that, for a bit vector (where the value of each dimension is either 0 or 1) then <math>A \u005ccdot B = \u005csum_i A_iB_i = \u005csum_i ( A_i \u005cland B_i)</math> and <math>{\u005cvert A\u005cvert}^2 = \u005csum_i A_i^2 = \u005csum_i A_i </math>.\u000a\u000aThis is a potentially confusing representation, because the function as expressed over vectors is more general, unless its domain is explicitly restricted. Properties of <math> T_s </math> do not necessarily extend to <math>f</math>. In particular, the difference function <math>1 - f</math> does not preserve [[triangle inequality]], and is not therefore a proper distance metric, whereas <math>1 - T_s </math> is.\u000a\u000aThere is a real danger that the combination of "Tanimoto Distance" being defined using this formula, along with the statement "Tanimoto Distance is a proper distance metric" will lead to the false conclusion that the function <math>1 - f</math> is in fact a distance metric over vectors or multisets in general, whereas its use in similarity search or clustering algorithms may fail to produce correct results.\u000a\u000aLipkus<ref name="lipkus" /> uses a definition of Tanimoto similarity which is equivalent to <math>f</math>, and refers to Tanimoto distance as the function <math> 1 - f</math>. It is however made clear within the paper that the context is restricted by the use of a (positive) weighting vector <math>W</math> such that, for any vector ''A'' being considered, <math> A_i \u005cin \u005c{0,W_i\u005c} </math>. Under these circumstances, the  function  is a proper distance metric, and so a set of vectors governed by such a weighting vector forms a metric space under this function.\u000a\u000a== See also ==\u000a* [[Sørensen similarity index]]\u000a* [[simple matching coefficient]]\u000a* [[Mountford's index of similarity]]\u000a* [[Most frequent k characters]]\u000a* [[Hamming distance]]\u000a* [[Dice's coefficient]], which is equivalent: <math>J=D/(2-D)</math> and <math>D=2J/(1+J)</math>\u000a* [[Tversky index]]\u000a* [[Correlation]]\u000a* [[Mutual information]], a normalized [[Mutual information#Metric|metricated]] variant of which is an entropic Jaccard distance.\u000a\u000a==Notes==\u000a{{reflist}}\u000a\u000a{{More footnotes|date=March 2011}}\u000a\u000a== References ==\u000a*{{citation|first1=Pang-Ning|last1=Tan|first2=Michael|last2=Steinbach|first3=Vipin|last3=Kumar|title=Introduction to Data Mining|year=2005|isbn=0-321-32136-7}}.\u000a*{{citation|first=Paul|last=Jaccard|authorlink=Paul Jaccard|year=1901|title=Étude comparative de la distribution florale dans une portion des Alpes et des Jura|journal=Bulletin de la Société Vaudoise des Sciences Naturelles|volume=37|pages=547\u2013579}}.\u000a*{{citation|first=Paul|last=Jaccard|authorlink=Paul Jaccard|year=1912|title=The distribution of the flora in the alpine zone|journal=New Phytologist|volume=11|pages=37\u201350|doi=10.1111/j.1469-8137.1912.tb05611.x}}.\u000a\u000a== External links ==\u000a* [http://www-users.cs.umn.edu/~kumar/dmbook/dmslides/chap2_data.pdf Introduction to Data Mining lecture notes from Tan, Steinbach, Kumar]\u000a* [http://sourceforge.net/projects/simmetrics/ SimMetrics a sourceforge implementation of Jaccard index and many other similarity metrics]\u000a* [http://www.idea-miner.de/cgi-bin/INT_Tools/ver_vergleich_0_1/cmp_menu2.cgi Web based tool for comparing texts using Jaccard coefficient]\u000a* [http://www.gettingcirrius.com/2011/01/calculating-similarity-part-2-jaccard.html Tutorial on how to calculate different similarities]\u000a* Open Source [https://github.com/rockymadden/stringmetric/blob/master/core/src/main/scala/com/rockymadden/stringmetric/similarity/JaccardMetric.scala Jaccard] [[Scala programming language|Scala]] implementation as part of the larger [http://rockymadden.com/stringmetric/ stringmetric project]\u000a\u000a{{DEFAULTSORT:Jaccard Index}}\u000a[[Category:Index numbers]]\u000a[[Category:Measure theory]]\u000a[[Category:Clustering criteria]]\u000a[[Category:String similarity measures]]
p125
sg4
S'204'
p126
sg6
VJaccard index
p127
ssI79
(dp128
g2
V'''Query expansion''' ('''QE''') is the process of reformulating a seed query to improve retrieval performance in [[information retrieval]] operations.<ref>{{cite journal\u000a | last = Vectomova | first = Olga |author2=Wang, Ying  | year = 2006\u000a | title = A study of the effect of term proximity on query expansion | journal = [[Journal of Information Science]]\u000a | volume = 32 | issue = 4 | pages = 324&ndash;333\u000a | doi = 10.1177/0165551506065787 | id =  | url = http://jis.sagepub.com/cgi/content/abstract/32/4/324\u000a | format = Abstract | accessdate = 2006-12-09\u000a }}</ref>\u000aIn the context of web [[search engine]]s, query expansion involves evaluating a user's input (what words were typed into the search query area, and sometimes other types of [[data]]) and expanding the search query to match additional documents.  Query expansion involves techniques such as:\u000a\u000a* Finding [[synonym]]s of words, and searching for the synonyms as well\u000a* Finding all the various [[Morphology (linguistics)|morphological]] forms of words by [[stemming]] each word in the [[search query]]\u000a* Fixing [[Typographical error|spelling errors]] and automatically searching for the corrected form or suggesting it in the results\u000a* Re-weighting the terms in the original query\u000a\u000aQuery expansion is a methodology studied in the field of [[computer science]], particularly within the realm of [[natural language processing]] and [[information retrieval]].\u000a\u000a== Precision and recall tradeoffs ==\u000a\u000aSearch engines invoke query expansion to increase the quality of user search results.  It is assumed that users do not always formulate search queries using the best terms. Best in this case may be because the database does not contain the user entered terms.  \u000a\u000aBy [[stemming]] a user-entered term, more documents are matched, as the alternate word forms for a user entered term are matched as well, increasing the total [[recall (information retrieval)|recall]]. This comes at the expense of reducing the [[precision (information retrieval)|precision]].  By expanding a search query to search for the synonyms of a user entered term, the recall is also increased at the expense of precision.  This is due to the nature of the equation of how precision is calculated, in that a larger recall implicitly causes a decrease in precision, given that factors of recall are part of the denominator. It is also inferred that a larger recall negatively impacts overall search result quality, given that many users do not want more results to comb through, regardless of the precision.\u000a\u000aThe goal of query expansion in this regard is by increasing recall, precision can potentially increase (rather than decrease as mathematically equated), by including in the result set pages which are more relevant (of higher quality), or at least equally relevant. Pages which would not be included in the result set, which have the potential to be more relevant to the user's desired query, are included, and without query expansion would not have, regardless of relevance.  At the same time, many of the current commercial search engines use word frequency ([[Tf-idf]]) to assist in ranking.  By ranking the occurrences of both the user entered words and synonyms and alternate morphological forms, documents with a higher density (high frequency and close proximity) tend to migrate higher up in the search results, leading to a higher quality of the search results near the top of the results, despite the larger recall.\u000a\u000aThis tradeoff is one of the defining problems in query expansion, regarding whether it is worthwhile to perform given the questionable effects on precision and recall. Critics{{Who|date=March 2009}} state one of the problems is that the dictionaries and [[thesauri]], and the stemming algorithm, are driven by human bias and while this is implicitly handled by the query expansion algorithm, this explicitly affects the results in a non-automated manner (similar to how statisticians can 'lie' with statistics){{Citation needed|date=July 2013}}. Other critics{{Who|date=March 2009}} point out potential for corporate influence on the dictionaries, promoting advertising of online web pages in the case of [[web search engine]]s. {{Citation needed|date=December 2007}}\u000a\u000a==See also==\u000a\u000a* [[Search engine]]\u000a* [[Search engine indexing]]\u000a* [[Information retrieval]]\u000a* [[Document retrieval]]\u000a* [[Linguistics]]\u000a* [[Natural language processing]]\u000a* [[Stemming]]\u000a* [[Morphology (linguistics)]]\u000a\u000a== Software libraries ==\u000a*[http://qtanalyzer.codeplex.com/ QueryTermAnalyzer] open-source, C#. Machine learning based query term weight and synonym analyzer for query expansion.\u000a*[http://lucene-qe.sourceforge.net/ LucQE] - open-source, Java.  Provides a framework along with several implementations that allow to perform query expansion with the use of Apache [[Lucene]].\u000a*[[Xapian]] is an open-source search library which includes support for query expansion\u000a\u000a== References ==\u000a\u000a* D. Abberley, D. Kirby, S. Renals, and T. Robinson, The THISL broadcast news  retrieval system. In ''Proc. ESCA ETRW Workshop Accessing Information in Spoken Audio'', (Cambridge), pp.&nbsp;14\u201319, 1999. Section on [http://homepages.inf.ed.ac.uk/srenals/pubs/1999/esca99-thisl/node6.html Query Expansion] - Concise, mathematical overview.\u000a* R. Navigli, P. Velardi. [http://www.dcs.shef.ac.uk/~fabio/ATEM03/navigli-ecml03-atem.pdf An Analysis of Ontology-based Query Expansion Strategies]. ''Proc. of Workshop on Adaptive Text Extraction and Mining (ATEM 2003)'', in the ''14th European Conference on Machine Learning (ECML 2003)'', Cavtat-Dubrovnik, Croatia, September 22-26th, 2003, pp.&nbsp;42\u201349 - An analysis of query expansion methods relying on WordNet as the reference ontology.\u000a* Y. Qiu and H.P. Frei. [http://citeseer.ist.psu.edu/qiu93concept.html Concept Based Query Expansion]. In ''Proceedings of SIGIR-93, 16th ACM International Conference on Research and Development in Information Retrieval'', Pittsburgh, SIGIR Forum, ACM Press, June 1993 - Academic document on a specific method of query expansion\u000a* Efthimis N. Efthimiadis. [http://faculty.washington.edu/efthimis/pubs/Pubs/qe-arist/QE-arist.html Query Expansion]. In: Martha E. Williams (ed.), ''Annual Review of Information Systems and Technology (ARIST)'', v31, pp 121\u2013187, 1996 - An introduction for less-technical viewers.\u000a\u000a=== Notes ===\u000a{{reflist}}\u000a\u000a{{DEFAULTSORT:Query Expansion}}\u000a[[Category:Information retrieval]]\u000a[[Category:Searching]]
p129
sg4
S'79'
p130
sg6
VQuery expansion
p131
ssI209
(dp132
g2
VIn [[machine learning]] and [[data mining]], a '''string kernel''' is a [[Positive-definite kernel|kernel function]] that operates on [[String (computer science)|strings]], i.e. finite sequences of symbols that need not be of the same length. String kernels can be intuitively understood as functions measuring the similarity of pairs of strings: the more similar two strings ''a'' and ''b'' are, the higher the value of a string kernel ''K''(''a'', ''b'') will be.\u000a\u000aUsing string kernels with [[Kernel trick|kernelized]] learning algorithms such as [[support vector machine]]s allow such algorithms to work with strings, without having to translate these to fixed-length, real-valued [[feature vector]]s.<ref name="Lodhi"/> String kernels are used in domains where sequence data are to be [[Cluster analysis|clustered]] or [[statistical classification|classified]], e.g. in [[text mining]] and [[bioinformatics|gene analysis]].<ref>\u000a{{Citation\u000a  | title = The spectrum kernel: A string kernel for SVM protein classification\u000a  | last = Leslie\u000a  | first = C.\u000a  | last2 = Eskin\u000a  | first2 = E.\u000a  | last3 = Noble\u000a  | first3 = W.S.\u000a  | booktitle = Proceedings of the Pacific Symposium on Biocomputing\u000a  | volume = 7\u000a  | pages = 566\u2013575\u000a  | year = 2002\u000a}}</ref>\u000a\u000a==Informal introduction==\u000a\u000aSuppose one wants to compare some text passages automatically and indicate their relative similarity.\u000aFor many applications, it might be sufficient to find some keywords which match exactly.\u000aOne example where exact matching is not always enough is found in [[Spam (electronic)|spam]] detection.<ref>\u000a{{Citation\u000a  | title = Improved Online Support Vector Machines Spam Filtering Using String Kernels\u000a  | last = Amayri\u000a  | first = O.\u000a}}</ref>\u000aAnother would be in computational gene analysis, where [[Homology (biology)|homologous]] [[genes]] have [[mutated]], resulting in common subsequences along with deleted, inserted or replaced symbols.\u000a<!--- TODO insert a picture here --->\u000a\u000a==Motivation==\u000a\u000aSince several well-proven data clustering, classification and information retrieval\u000a<!--- and other ... see manifold learning --->\u000amethods (for example support vector machines) are designed to work on vectors\u000a(i.e. data are elements of a vector space), using a string kernel allows the extension of these methods to handle sequence data.\u000a\u000aThe string kernel method is to be contrasted with earlier approaches for text classification where feature vectors only indicated\u000athe presence or absence of a word.\u000aNot only does it improve on these approaches, but it is an example for a whole class of kernels adapted to data structures, which\u000abegan to appear at the turn of the 21st century. A survey of such methods has been compiled by Gärtner.<ref>\u000a{{Citation\u000a  | last = Gärtner\u000a  | first = T.\u000a  | title = A survey of kernels for structured data\u000a  | journal = CM SIGKDD Explorations Newsletter\u000a  | publisher = [[Association for Computing Machinery|ACM]]\u000a  | year = 2003\u000a  | volume = 5\u000a  | number = 1\u000a  | page = 58}}\u000a</ref>\u000a\u000a==Definition==\u000a\u000aA [[Kernel trick|kernel]] on a domain <math>D</math> is a function <math>K: D \u005ctimes D \u005crightarrow \u005cmathbb{R}</math>\u000asatisfying some conditions (being [[symmetric]] in the arguments, [[continuous function|continuous]] and [[Positive-semidefinite function|positive semidefinite]] in a certain sense).\u000a\u000a[[Mercer's theorem]] asserts that <math>K</math> can then be expressed as <math>K(x,y)=\u005cvarphi(x)\u005ccdot \u005cvarphi(y)</math> with <math>\u005cvarphi</math> mapping the arguments into an [[inner product space]].\u000a\u000aWe can now reproduce the definition of a '''string subsequence kernel'''<ref name="Lodhi">{{Cite journal\u000a  | last = Lodhi\u000a  | first = Huma\u000a  | last2 = Saunders\u000a  | first2 = Craig\u000a  | last3 = Shawe-Taylor\u000a  | first3 = John\u000a  | last4 = Cristianini\u000a  | first4 = Nello\u000a  | last5 = Watkins\u000a  | first5 = Chris\u000a  | title = Text classification using string kernels\u000a  | journal = [[Journal of Machine Learning Research]]\u000a  | year = 2002\u000a  | pages = 419\u2013444}}</ref>\u000aon strings over an [[Alphabet (computer science)|alphabet]] <math>\u005cSigma</math>. Coordinate-wise, the mapping is defined as follows:\u000a\u000a:<math>\u005cvarphi_u :\u000a\u005cleft\u005c{\u000a\u005cbegin{array}{l}\u000a\u005cSigma^n \u005crightarrow \u005cmathbb{R}^{\u005cSigma^n} \u005c\u005c\u000a s \u005cmapsto \u005csum_{\u005cmathbf{i} : u=s_{\u005cmathbf{i}}} \u005clambda^{l(\u005cmathbf{i})}\u000a\u005cend{array}\u000a\u005cright.\u000a</math>\u000a\u000aThe <math>\u005cmathbf{i}</math> are [[multiindices]] and <math>u</math> is a string of length <math>n</math>:\u000asubsequences can occur in a non-contiguous manner, but gaps are penalized.\u000aThe parameter <math>\u005clambda</math> may be set to any value between <math>0</math> (gaps are not allowed) and <math>1</math>\u000a(even widely-spread "occurrences" are weighted the same as appearances as a contiguous substring).\u000a\u000a<!--- TODO put an example here !!! --->\u000a\u000aFor several relevant algorithms, data enters into the algorithm only in expressions involving an inner product of feature vectors,\u000ahence the name [[kernel methods]]. A desirable consequence of this is that one does not need to explicitly calculate the transformation <math>\u005cphi(x)</math>, only the inner product via the kernel, which may be a lot quicker, especially when [[approximation|approximated]].<ref name=Lodhi/>\u000a<!--- ==Efficitent Computation== --->\u000a<!--- == See also == --->\u000a\u000a==References==\u000a<!--- cite "alignment kernels", precursor --->\u000a{{Reflist}}\u000a\u000a[[Category:Algorithms on strings]]\u000a[[Category:Kernel methods for machine learning]]\u000a[[Category:Natural language processing]]\u000a[[Category:String similarity measures]]
p133
sg4
S'209'
p134
sg6
VString kernel
p135
ssI84
(dp136
g2
V{{refimprove|date=February 2010}}\u000a'''Queries Per Second''' (QPS) is a common measure of the amount of search traffic an [[information retrieval]] system, such as a [[search engine]] or a [[database]], receives during one second.<ref>[http://www.microsoft.com/enterprisesearch/en/us/search-glossary.aspx#Q Microsoft's search glossary]</ref><ref>[http://www.answers.com/topic/qps QPS definition at answers.com]</ref>\u000a\u000aHigh-traffic systems must watch their QPS in order to know when to scale the system to handle more load.\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a[[Category:Units of measurement]]\u000a[[Category:Information retrieval]]\u000a\u000a{{computer-stub}}
p137
sg4
S'84'
p138
sg6
VQueries per second
p139
ssI214
(dp140
g2
V{{multiple issues|\u000a{{Third-party|date=March 2014}}\u000a{{Notability|date=March 2014}}\u000a}}\u000a\u000aIn [[information theory]], '''MostFreqKDistance''' is a [[string metric]] technique for quickly estimating how [[Similarity measure|similar]] two [[Order theory|ordered sets]] or [[String (computer science)|strings]] are. The scheme was invented by {{harvs|first=Sadi Evren|last=SEKER|authorlink=Sadi Evren SEKER|year=2014|txt}},<ref name="mfkc"/> and initially used in [[text mining]] applications like [[author recognition]].<ref name="mfkc">{{citation\u000a | last1 = SEKER | first1 = Sadi E. | author1-link = Sadi Evren SEKER\u000a | last2 = Altun | first2 = Oguz\u000a | last3 = Ayan | first3 = Ugur\u000a | last4 = Mert | first4 = Cihan\u000a | contribution = A Novel String Distance Function based on Most Frequent K Characters\u000a | volume = 4\u000a | issue = 2\u000a | pages = 177\u2013183\u000a | publisher = [[International Association of Computer Science and Information Technology Press (IACSIT Press)]]\u000a | title = [[International Journal of Machine Learning and Computing (IJMLC)]]\u000a | contribution-url = http://arxiv.org/abs/1401.6596\u000a | year = 2014}}</ref>\u000aMethod is originally based on a hashing function MaxFreqKChars <ref name="hashfunc">{{citation\u000a | last1 = Seker | first1 = Sadi E. | author1-link = Sadi Evren SEKER\u000a | last2 = Mert | first2 = Cihan\u000a | contribution = A Novel Feature Hashing For Text Mining\u000a | url = http://journal.ibsu.edu.ge/index.php/jtst/article/view/428\u000a | pages = 37\u201341\u000a | publisher = [[International Black Sea University]]\u000a | title = Journal of Technical Science and Technologies\u000a | ISSN = 2298-0032\u000a | volume = 2\u000a | issue = 1\u000a | year = 2013}}</ref> classical [[author recognition]] problem and idea first came out while studying on [[data stream mining]].<ref name="author">{{citation\u000a | last1 = Seker | first1 = Sadi E. | author1-link = Sadi Evren SEKER\u000a | last2 = Al-Naami | first2 = Khaled\u000a | last3 = Khan | first3 = Latifur\u000a | contribution = Author attribution on streaming data\u000a | doi = 10.1109/IRI.2013.6642511\u000a | url = http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6642511\u000a | pages = 497\u2013503\u000a | publisher = [[IEEE]]\u000a | title = Information Reuse and Integration (IRI), 2013 IEEE 14th International Conference on, San Francisco, USA, Aug 14-16, 2013\u000a | year = 2013}}</ref> Algorithm is suitable for coding in most of the programming languages like [[Java (programming language)|Java]], [[Tcl]], [[Python (programming language)|Python]] or [[J (programming language)|J]]. <ref>\u000a{{Citation |title=Rosetta Code: Most frequent k chars distance , code sources for Python, Java, Tcl and J |accessdate=16 Oct 2014 |url=http://rosettacode.org/wiki/Most_frequent_k_chars_distance}}\u000a</ref>\u000a\u000a\u000a==Definition==\u000aMethod has two steps.\u000a* [[Hash function|Hash]] input strings str1 and str2 separately using MostFreqKHashing and output hstr1 and hstr2 respectively\u000a* Calculate string distance (or string similarity coefficient) of two hash outputs, hstr1 and hstr2 and output an integer value\u000a\u000a===Most frequent K hashing===\u000aThe first step of algorithm is calculating the hashing based on the most frequent k characters. The hashing algorithm has below steps:\u000a<syntaxhighlight lang="Java">\u000aString function MostFreqKHashing (String inputString, int K)\u000a    def string outputString\u000a    for each distinct character\u000a        count occurrence of each character\u000a    for i := 0 to K\u000a        char c = next most freq ith character  (if two chars have same frequency than get the first occurrence in inputString)\u000a        int count = number of occurrence of the character\u000a        append to outputString, c and count\u000a    end for\u000a    return outputString\u000a</syntaxhighlight>\u000a\u000aAbove function, simply gets an input string and an integer K value and outputs the most frequent K characters from the input string. The only condition during the creation of output string is adding the first occurring character first, if the frequencies of two characters are equal. Similar to the most of [[hashing function]]s, ''Most Frequent K Hashing'' is also a [[one way function]].\u000a\u000a===Most frequent K distance===\u000aThe second step of algorithm works on two outputs from two different input strings and outputs the similarity coefficient (or distance metric).\u000a<syntaxhighlight lang="Java">\u000aint function MostFreqKSimilarity (String inputStr1, String inputStr2, int limit)\u000a    def int similarity\u000a    for each c = next character from inputStr1\u000a        lookup c in inputStr2\u000a        if c is null\u000a             continue\u000a             similarity += frequency of c in inputStr1\u000a    return limit-similarity\u000a</syntaxhighlight>\u000aAbove function, simply gets two input strings, previously outputted from the <code>MostFreqKHashing</code> function. From the most frequent k hashing function, the characters and their frequencies are returned. So, the similarity function calculates the similarity based on characters and their frequencies by checking if the same character appears on both strings. The limit is usually taken to be 10 and in the end the function returns the result of the subtraction of the sum of similarities from limit.\u000a\u000aIn some implementations, the distance metric is required instead of similarity coefficient. In order to convert the output of above similarity coefficient to distance metric, the output can be subtracted from any constant value (like the maximum possible output value). For the case, it is also possible to implement a [[wrapper function]] over above two functions.\u000a\u000a===String distance wrapper function===\u000aIn order to calculate the distance between two strings, below function can be implemented\u000a<syntaxhighlight lang="Java">\u000aint function MostFreqKSDF (String inputStr1, String inputStr2, int K, int maxDistance)\u000a    return maxDistance - MostFreqKSimilarity(MostFreqKHashing(inputStr1, K), MostFreqKHashing(inputStr2, K))\u000a</syntaxhighlight>\u000a\u000aAny call to above string distance function will supply two input strings and a maximum distance value. The function will calculate the similarity and subtract that value from the maximum possible distance. It can be considered as a simple [[additive inverse]] of similarity.\u000a\u000a==Examples==\u000aLet's consider maximum 2 frequent hashing over two strings \u2018research\u2019 and \u2018seeking\u2019.\u000aMostFreqKHashing('research', 2) = r2e2\u000abecause we have 2 'r' and 2 'e' characters with the highest frequency and we return in the order they appear in the string.\u000aMostFreqKHashing('seeking', 2) = e2s1\u000aAgain we have character 'e' with highest frequency and rest of the characters have same frequency of 1, so we return the first character of equal frequencies, which is 's'.\u000aFinally we make the comparison:\u000aMostFreqKSimilarity('r2e2', 'e2s1') = 2\u000aWe simply compared the outputs and only character occurring in both input is character 'e' and the occurrence in both input is 2.\u000aInstead running the sample step by step as above, we can simply run by using the string distance wrapper function as below:\u000aMostFreqKSDF('research', 'seeking', 2) = 2\u000a\u000aBelow table holds some sample runs between example inputs for K=2:\u000a{|class="wikitable"\u000a|-\u000a! Inputs\u000a! Hash Outputs\u000a! SDF Output (max from 10)\u000a|-\u000a|'night'\u000a'nacht'\u000a|n1i1\u000an1a1\u000a|9\u000a|-\u000a|'my'\u000a'a'\u000a|m1y1\u000aa1NULL0\u000a|10\u000a|-\u000a|\u2018research\u2019\u000a\u2018research\u2019	\u000a|r2e2\u000ar2e2	\u000a|6\u000a|-\u000a|\u2018aaaaabbbb\u2019\u000a\u2018ababababa\u2019	\u000a|a5b4\u000aa5b4	\u000a|1\u000a|-\u000a|\u2018significant\u2019\u000a\u2018capabilities\u2019	\u000a|i3n2\u000ai3a2	\u000a|7\u000a|}\u000a\u000aMethod is also suitable for bioinformatics to compare the genetic strings like in [[FASTA format]].\u000a\u000aStr1 = LCLYTHIGRNIYYGSYLYSETWNTGIMLLLITMATAFMGYVLPWGQMSFWGATVITNLFSAIPYIGTNLV\u000a\u000aStr2 = EWIWGGFSVDKATLNRFFAFHFILPFTMVALAGVHLTFLHETGSNNPLGLTSDSDKIPFHPYYTIKDFLG\u000a\u000aMostFreqKHashing(str1, 2) = L9T8\u000a\u000aMostFreqKHashing(str2, 2) = F9L8\u000a\u000aMostFreqKSDF(str1, str2, 2, 100) = 83\u000a\u000a==Algorithm complexity and comparison==\u000aThe motivation behind algorithm is calculating the similarity between two input strings. So, the hashing function should be able to reduce the size of input and at the same time keep the characteristics of the input. Other hashing algorithms like [[MD5]] or [[SHA-1]], the output is completely unrelated with the input and those hashing algorithms are not suitable for string similarity check.\u000a\u000aOn the other hand string similarity functions like [[Levenshtein distance]] have the algorithm complexity problem.\u000a\u000aAlso algorithms like [[Hamming distance]], [[Jaccard coefficient]] or [[Tanimoto coefficient]] have relatively low algorithm complexity but the success rate in [[text mining]] studies are also low.\u000a\u000a===Time complexity===\u000aThe calculation of time complexity of 'most frequent k char string similarity' is quite simple. In order to get the maximum frequent K characters from a string, the first step is sorting the string in a lexiconical manner. After this sort, the input with highest occurrence can be achieved with a simple pass in linear time complexity. Since major classical sorting algorithms are working in O(nlogn) complexity like [[merge sort]] or [[quick sort]], we can sort the first string in O(nlogn) and second string on O(mlogm) times. The total complexity would be O(nlog n ) + O (m log m) which is O(n log n) as the upper bound [[worst case analysis]].\u000a\u000a===Comparison===\u000aBelow table compares the complexity of algorithms:\u000a{|class="wikitable"\u000a|-\u000a! Algorithm\u000a! Time Complexity\u000a|-\u000a| [[Levenshtein distance]]\u000a| O(nm) = O(n^2)\u000a|-\u000a| [[Jaccard index]]\u000a| O(n+m) = O(n)\u000a|-\u000a| MostFreqKSDF\u000a| O(nlogn+mlogm) = O(n log n)\u000a|}\u000a\u000aFor the above table, n is the length of first string and m is the length of second string.\u000a\u000a==Success on text mining==\u000aThe success of string similarity algorithms are compared on a study. The study is based on IMDB62 dataset which is holding 1000 comment entries in [[Internet Movie Database]] from each 62 people. The data set is challenged for three string similarity functions and the success rates are as below:\u000a\u000a{|class="wikitable"\u000a|-\u000a! Algorithm\u000a! Running Time\u000a! Error (RMSE)\u000a! Error (RAE)\u000a|-\u000a|[[Levenshtein distance]]\u000a|3647286.54 sec\u000a|29\u000a|0.47\u000a|-\u000a|[[Jaccard index]]\u000a|228647.22 sec\u000a|45\u000a|0.68\u000a|-\u000a|MostFreqKSDF\u000a|2712323.51 sec\u000a|32\u000a|0.49\u000a|}\u000a\u000aThe running times for [[author recognition]] are in seconds and the error rates are [[root mean square error]] (RMSE) and [[relative absolute error]] (RAE).\u000a\u000aAbove table shows, the 'most frequent k similarity' is better than [[Levenshtein distance]] by time and [[Jaccard index]] by success rate.\u000a\u000aFor the time performance and the success rates, the bitwise similarity functions like [[Dice's coefficient|Sørensen\u2013Dice index]], [[Tversky index]] or [[Hamming Distance]] are all in the same category with similar success rates and running times. There are obviously slight differences but the idea behind bitwise operation, looses the string operations like deletion or addition. For example a single bit addition to the front of one of the input strings would yield a catastrophic result on the similarity for bitwise operators while Levenshtein distance is successfully catching.\u000a\u000aUnfortunately, [[big data]] studies requires a faster algorithm with still acceptable success. Here the 'max frequent k characters' is an easy and simple algorithm (as in [[Occams razor]]), which is straight forward to implement.\u000a\u000a==See also==\u000a[http://rosettacode.org/wiki/Most_frequent_k_chars_distance RosettaCode,Code reposistory of Most Frequent K Chars Distance Algorithm in Java, Python, TCL or J languages] (Retrieved Oct. 16 2014)\u000a<div class= style="-moz-column-count:2; column-count:2;">\u000a* [[agrep]]\u000a* [[Approximate string matching]]\u000a* [[Bitap algorithm]]\u000a* [[Damerau\u2013Levenshtein distance]]\u000a* [[diff]]\u000a* [[MinHash]]\u000a* [[Dynamic time warping]]\u000a* [[Euclidean distance]]\u000a* [[Fuzzy string searching]]\u000a* [[Hamming weight]]\u000a* [[Hirschberg's algorithm]]\u000a* [[Sequence homology|Homology of sequences in genetics]]\u000a* [[Hunt\u2013McIlroy algorithm]]\u000a* [[Jaccard index]]\u000a* [[Jaro\u2013Winkler distance]]\u000a* [[Levenshtein distance]]\u000a* [[Longest common subsequence problem]]\u000a* [[Lucene]] (an open source search engine that implements edit distance)\u000a* [[Manhattan distance]]\u000a* [[Metric space]]\u000a* [[Needleman\u2013Wunsch algorithm]]\u000a* [[Optimal matching]] algorithm\u000a* [[Sequence alignment]]\u000a* Similarity space on [[Numerical taxonomy]]\u000a* [[Smith\u2013Waterman algorithm]]\u000a* [[Sørensen similarity index]]\u000a* [[String distance metric]]\u000a* [[String similarity function]]\u000a* [[Wagner-Fischer algorithm]]\u000a* [[Locality-sensitive hashing]]\u000a</div>\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a[[Category:String similarity measures]]\u000a[[Category:Dynamic programming]]\u000a[[Category:Articles with example pseudocode]]\u000a[[Category:Quantitative linguistics]]\u000a[[Category:Hash functions]]\u000a[[Category:Hashing]]
p141
sg4
S'214'
p142
sg6
VMost frequent k characters
p143
ssI89
(dp144
g2
V{{linguistics}}\u000a'''Statistical semantics''' is the study of "how the statistical patterns of human word usage can be used to figure out what people mean, at least to a level sufficient for information access" {{citation needed|date=July 2012}}<!--([[George Furnas|Furnas]], 2006)--this page has been moved and the new version no longer contains this quotation-->. How can we figure out what words mean, simply by looking at patterns of words in huge collections of text? What are the limits to this approach to understanding words?\u000a\u000a==History==\u000a\u000aThe term ''Statistical Semantics'' was first used by [[Warren Weaver]] in his well-known paper on [[machine translation]].<ref>{{harvnb|Weaver|1955}}</ref> He argued that [[word sense disambiguation]] for machine translation should be based on the [[co-occurrence]] frequency of the context words near a given target word. The underlying assumption that "a word is characterized by the company it keeps" was advocated by [[J. R. Firth|J.R. Firth]].<ref>{{harvnb|Firth|1957}}</ref> This assumption is known in [[Linguistics]] as the [[Distributional hypothesis|Distributional Hypothesis]].<ref>{{harvnb|Sahlgren|2008}}</ref> Emile Delavenay defined ''Statistical Semantics'' as "Statistical study of meanings of words and their frequency and order of recurrence."<ref>{{harvnb|Delavenay|1960}}</ref> "[[George Furnas|Furnas]] ''et al.'' 1983" is frequently cited as a foundational contribution to Statistical Semantics.<ref>{{harvnb|Furnas|Landauer|Gomez|Dumais|1983}}</ref>  An early success in the field was [[Latent semantic analysis|Latent Semantic Analysis]].\u000a\u000a==Applications of statistical semantics==\u000a\u000aResearch in Statistical Semantics has resulted in a wide variety of algorithms that use the Distributional Hypothesis to discover many aspects of [[semantics]], by applying statistical techniques to [[Text corpus|large corpora]]:\u000a* Measuring the [[Semantic similarity|similarity in word meanings]] <ref>{{harvnb|Lund|Burgess|Atchley|1995}}</ref><ref>{{harvnb|Landauer|Dumais|1997}}</ref><ref>{{harvnb|McDonald|Ramscar|2001}}</ref><ref>{{harvnb|Terra|Clarke|2003}}</ref>\u000a* Measuring the similarity in word relations <ref>{{harvnb|Turney|2006}}</ref>\u000a* Modeling [[similarity-based generalization]] <ref>{{harvnb|Yarlett|2008}}</ref>\u000a* Discovering words with a given relation <ref>{{harvnb|Hearst|1992}}</ref>\u000a* Classifying relations between words <ref>{{harvnb|Turney|Littman|2005}}</ref>\u000a* Extracting keywords from documents <ref>{{harvnb|Frank|Paynter|Witten|Gutwin|1999}}</ref><ref>{{harvnb|Turney|2000}}</ref>\u000a* Measuring the cohesiveness of text <ref>{{harvnb|Turney|2003}}</ref>\u000a* Discovering the different senses of words <ref>{{harvnb|Pantel|Lin|2002}}</ref>\u000a* Distinguishing the different senses of words <ref>{{harvnb|Turney|2004}}</ref>\u000a* Subcognitive aspects of words <ref>{{harvnb|Turney|2001}}</ref>\u000a* Distinguishing praise from criticism <ref>{{harvnb|Turney|Littman|2003}}</ref>\u000a\u000a==Related fields==\u000a\u000aStatistical Semantics focuses on the meanings of common words and the relations between common words, unlike [[text mining]], which tends to focus on whole documents, document collections, or named entities (names of people, places, and organizations). Statistical Semantics is a subfield of [[computational semantics]], which is in turn a subfield of [[computational linguistics]] and [[natural language processing]].\u000a\u000aMany of the applications of Statistical Semantics (listed above) can also be addressed by [[lexicon]]-based algorithms, instead of the [[text corpus|corpus]]-based algorithms of Statistical Semantics. One advantage of corpus-based algorithms is that they are typically not as labour-intensive as lexicon-based algorithms. Another advantage is that they are usually easier to adapt to new languages than lexicon-based algorithms. However, the best performance on an application is often achieved by combining the two approaches.<ref>{{harvnb|Turney|Littman|Bigham|Shnayder|2003}}</ref>\u000a\u000a==See also==\u000a{{Portal|Linguistics}}\u000a*[[Latent semantic analysis]]\u000a*[[Latent semantic indexing]]\u000a*[[Text mining]]\u000a*[[Information retrieval]]\u000a*[[Natural language processing]]\u000a*[[Computational linguistics]]\u000a*[[Web mining]]\u000a*[[Semantic similarity]]\u000a*[[Co-occurrence]]\u000a*[[Text corpus]]\u000a*[[Semantic Analytics]]\u000a\u000a==References==\u000a{{reflist|2}}\u000a\u000a===Sources===\u000a{{refbegin}}\u000a* {{cite book | last = Delavenay | first = Emile | year = 1960 | title = An Introduction to Machine Translation | location = New York, NY | publisher = [[Thames and Hudson]] | oclc = 1001646 | ref = harv }}\u000a\u000a* {{cite journal | last = Firth | first = John R. | authorlink = John Rupert Firth | year = 1957 | title = A synopsis of linguistic theory 1930-1955 | journal = [[Studies in Linguistic Analysis]] | pages = 1\u201332 | location = Oxford | publisher = [[Philological Society]] | ref = harv }}\u000a*: Reprinted in {{cite book | editor1-first = F.R. | editor1-last = Palmer | title = Selected Papers of J.R. Firth 1952-1959 | location = London | publisher = Longman | year = 1968 | oclc = 123573912 }}\u000a\u000a* {{cite conference | last1 = Frank | first1 = Eibe | last2 = Paynter | first2 = Gordon W. | last3 = Witten | first3 = Ian H. | last4 = Gutwin | first4 = Carl | last5 = Nevill-Manning | first5 = Craig G. | year = 1999 | title = Domain-specific keyphrase extraction | booktitle = Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence | conference = [[International Joint Conference on Artificial Intelligence|IJCAI-99]] | volume = 2 | pages = 668\u2013673 | location = California | publisher = Morgan Kaufmann | isbn = 1-55860-613-0 | id = {{citeseerx|10.1.1.43.9100}} {{citeseerx|10.1.1.148.3598}} | ref = harv }}\u000a\u000a* {{cite journal | last1 = Furnas | first1 = George W. | authorlink = George Furnas | last2 = Landauer | first2 = T. K. | last3 = Gomez | first3 = L. M. | last4 = Dumais | first4 = S. T. | year = 1983 | title = Statistical semantics: Analysis of the potential performance of keyword information systems | url = http://furnas.people.si.umich.edu/Papers/FurnasEtAl1983_BSTJ_p1753.pdf | journal = [[Bell System Technical Journal]] | volume = 62 | issue = 6 | pages = 1753\u20131806 | ref = harv | doi=10.1002/j.1538-7305.1983.tb03513.x}}\u000a\u000a* {{cite conference | last = Hearst | first = Marti A. | year = 1992 | title = Automatic Acquisition of Hyponyms from Large Text Corpora | booktitle = Proceedings of the Fourteenth International Conference on Computational Linguistics | conference = [[COLING|COLING '92]] | pages = 539\u2013545 | location = Nantes, France | url = http://acl.ldc.upenn.edu/C/C92/C92-2082.pdf | doi = 10.3115/992133.992154 | id = {{citeseerx|10.1.1.36.701}} | ref = harv }}\u000a\u000a* {{cite journal | last1 = Landauer | first1 = Thomas K. | last2 = Dumais | first2 = Susan T. | year = 1997 | title = A solution to Plato's problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge | journal = [[Psychological Review]] | volume = 104 | issue = 2 | pages = 211\u2013240 | url = http://lsa.colorado.edu/papers/plato/plato.annote.html | id = {{citeseerx|10.1.1.184.4759}} | ref = harv | doi=10.1037/0033-295x.104.2.211}}\u000a\u000a* {{cite conference | last1 = Lund | first1 = Kevin | last2 = Burgess | first2 = Curt | last3 = Atchley | first3 = Ruth Ann | year = 1995 | title = Semantic and associative priming in high-dimensional semantic space | booktitle = Proceedings of the 17th Annual Conference of the Cognitive Science Society | publisher = [[Cognitive Science Society]] | pages = 660\u2013665 | url = http://locutus.ucr.edu/reprintPDFs/lba95csp.pdf | ref = harv }}\u000a\u000a* {{cite conference | last1 = McDonald | first1 = Scott | last2 = Ramscar | first2 = Michael | year = 2001 | title = Testing the distributional hypothesis: The influence of context on judgements of semantic similarity | booktitle = Proceedings of the 23rd Annual Conference of the Cognitive Science Society | pages = 611\u2013616 | url = http://homepages.inf.ed.ac.uk/smcdonal/cogsci2001.pdf | id = {{citeseerx|10.1.1.104.7535}} | ref = harv }}\u000a\u000a* {{cite conference | last1 = Pantel | first1 = Patrick | last2 = Lin | first2 = Dekang | year = 2002 | title = Discovering word senses from text | booktitle = Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining | isbn = 1-58113-567-X | conference = [[KDD Conference|KDD '02]] | pages = 613\u2013619 | id = {{citeseerx|10.1.1.12.6771}} | doi = 10.1145/775047.775138 | ref = harv }}\u000a\u000a* {{cite journal | last1 = Sahlgren | first1 = Magnus | year = 2008 | title = The Distributional Hypothesis | url = http://soda.swedish-ict.se/3941/1/sahlgren.distr-hypo.pdf | journal = Rivista di Linguistica | volume = 20 | issue = 1 | pages = 33\u201353 | ref = harv}}\u000a\u000a* {{cite conference | last1 = Terra | first1 = Egidio L. | last2 = Clarke | first2 = Charles L. A. | year = 2003 | title = Frequency estimates for statistical word similarity measures | booktitle = Proceedings of the Human Language Technology and North American Chapter of Association of Computational Linguistics Conference 2003 | conference = HLT/NAACL 2003 | pages = 244\u2013251 | url = http://acl.ldc.upenn.edu/N/N03/N03-1032.pdf | id = {{citeseerx|10.1.1.12.9041}} | doi = 10.3115/1073445.1073477 | ref = harv }}\u000a\u000a* {{cite journal | last = Turney | first = Peter D. |date=May 2000 | title = Learning algorithms for keyphrase extraction | journal = [[Information Retrieval (journal)|Information Retrieval]] | volume = 2 | issue = 4 | pages = 303\u2013336 | arxiv = cs/0212020 | id = {{citeseerx|10.1.1.11.1829}} | doi = 10.1023/A:1009976227802 | ref = harv }}\u000a\u000a* {{cite journal | last = Turney | first = Peter D. | year = 2001 | title = Answering subcognitive Turing Test questions: A reply to French | journal = [[Journal of Experimental and Theoretical Artificial Intelligence]] | volume = 13 | issue = 4 | pages = 409\u2013419 | arxiv = cs/0212015 | id = {{citeseerx|10.1.1.12.8734}} | ref = harv | doi=10.1080/09528130110100270}}\u000a\u000a* {{cite conference | last = Turney | first = Peter D. | year = 2003 | title = Coherent keyphrase extraction via Web mining | booktitle = Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence | conference = IJCAI-03 | location = Acapulco, Mexico | pages = 434\u2013439 | arxiv = cs/0308033 | id = {{citeseerx|10.1.1.100.3751}} | ref = harv }}\u000a\u000a* {{cite conference | last = Turney | first = Peter D. | year = 2004 | title = Word sense disambiguation by Web mining for word co-occurrence probabilities | booktitle = Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text | conference = SENSEVAL-3 | location = Barcelona, Spain | pages = 239\u2013242 | arxiv = cs/0407065 | url = http://cogprints.org/3732/ | ref = harv }}\u000a\u000a* {{cite journal | last = Turney | first = Peter D. | year = 2006 | title = Similarity of semantic relations |journal = [[Computational Linguistics (journal)|Computational Linguistics]] | volume = 32 | issue = 3 | pages = 379\u2013416 | arxiv = cs/0608100 | url = http://cogprints.org/5098/ | doi = 10.1162/coli.2006.32.3.379 | id = {{citeseerx|10.1.1.75.8007}} | ref = harv }}\u000a\u000a* {{cite journal | last1 = Turney | first1 = Peter D. | last2 = Littman | first2 = Michael L. |date=October 2003 | title = Measuring praise and criticism: Inference of semantic orientation from association | journal = [[ACM Transactions on Information Systems]] (TOIS) | volume = 21 | issue = 4 | pages = 315\u2013346 | arxiv = cs/0309034 | url = http://cogprints.org/3164/ | id = {{citeseerx|10.1.1.9.6425}} | doi = 10.1145/944012.944013 | ref = harv }}\u000a\u000a* {{cite journal | last1 = Turney | first1 = Peter D. | last2 = Littman | first2 = Michael L. | year = 2005 | title = Corpus-based Learning of Analogies and Semantic Relations | journal = [[Machine Learning (journal)|Machine Learning]] | volume = 60 | issue = 1\u20133 | pages = 251\u2013278 | arxiv = cs/0508103 | id = {{citeseerx|10.1.1.90.9819}} | doi = 10.1007/s10994-005-0913-1 | url = http://cogprints.org/4518/ | ref = harv }}\u000a\u000a* {{cite conference | last1 = Turney | first1 = Peter D. | last2 = Littman | first2 = Michael L. | last3 = Bigham | first3 = Jeffrey | last4 = Shnayder | first4 = Victor | year = 2003 | title = Combining Independent Modules to Solve Multiple-choice Synonym and Analogy Problems | booktitle = Proceedings of the International Conference on Recent Advances in Natural Language Processing | conference = RANLP-03 | location = [[Borovets]], Bulgaria | pages = 482\u2013489 | arxiv = cs/0309035 | id = {{citeseerx|10.1.1.5.2939}} | url = http://cogprints.org/3163/ | ref = harv }}\u000a\u000a* {{cite book | last = Weaver | first = Warren | authorlink = Warren Weaver | year = 1955 | chapter = Translation | chapter-url = http://www.mt-archive.info/Weaver-1949.pdf | editor1-first = W.N. | editor1-last = Locke | editor2-first = D.A. | editor2-last = Booth | title = Machine Translation of Languages | location = [[Cambridge, Massachusetts]] | publisher = [[MIT Press]] | isbn = 0-8371-8434-7 | pages = 15\u201323 | ref = harv }}\u000a\u000a* {{cite thesis | last = Yarlett | first = Daniel G. | year = 2008 | title = Language Learning Through Similarity-Based Generalization | url = http://psych.stanford.edu/~michael/papers/Draft_Yarlett_Similarity.pdf | degree = PhD | publisher = Stanford University | ref = harv }}\u000a{{refend}}\u000a\u000a==External links==\u000a* {{cite web | url = http://www.si.umich.edu/people/george-furnas | work = Faculty Profile | title = George Furnas | publisher = University of Michigan, School of Information | accessdate = 2010-07-12 }}\u000a*[http://research.microsoft.com/%7Esdumais/ Susan Dumais]\u000a*[http://www.pearsonkt.com/bioLandauer.shtml Thomas Landauer]\u000a*[http://www.apperceptual.com/ Peter Turney]\u000a*[http://waldron.stanford.edu/~michael/papers/ Michael Ramscar]\u000a*[http://www.cs.ualberta.ca/~lindek/demos.htm Dekang Lin's Demos]\u000a*[http://www.isi.edu/~pantel/Content/demos.htm Patrick Pantel's Demos]\u000a*[http://www.nzdl.org/Kea/ Kea keyphrase extraction]\u000a*[http://seokeywordanalysis.com/seotools/ Online keyphrase extractor]\u000a\u000a{{DEFAULTSORT:Statistical Semantics}}\u000a[[Category:Artificial intelligence applications]]\u000a[[Category:Computational linguistics]]\u000a[[Category:Information retrieval]]\u000a[[Category:Semantics]]\u000a[[Category:Statistical natural language processing]]\u000a[[Category:Fields of application of statistics]]
p145
sg4
S'89'
p146
sg6
VStatistical semantics
p147
ssI219
(dp148
g2
V{{incomplete|date=January 2014}}\u000a{{ infobox bibliographic database\u000a| title = Science Citation Index\u000a| image = \u000a| caption = \u000a| producer = [[Thomson Reuters]]\u000a| country = United States\u000a| history = 1964-present\u000a| languages = \u000a| providers = \u000a| cost = \u000a| disciplines = Science, medicine, and technology\u000a| depth = \u000a| formats = \u000a| temporal = \u000a| geospatial = \u000a| number = \u000a| updates = \u000a| p_title = \u000a| p_dates = \u000a| ISSN = 0036-827X\u000a| web = http://thomsonreuters.com/science-citation-index-expanded/\u000a| titles = \u000a}}\u000aThe '''Science Citation Index''' ('''SCI''') is a [[citation index]] originally produced by the [[Institute for Scientific Information]] (ISI) and created by [[Eugene Garfield]]. It was officially launched in 1964. It is now owned by [[Thomson Reuters]].<ref name=dimension>\u000a{{cite journal\u000a|doi=10.1126/science.122.3159.108\u000a|title=Citation Indexes for Science: A New Dimension in Documentation through Association of Ideas\u000a|url=http://ije.oxfordjournals.org/content/35/5/1123.full\u000a|format=Free web article download\u000a|year=1955\u000a|last1=Garfield\u000a|first1=E.\u000a|journal=Science\u000a|volume=122\u000a|issue=3159\u000a|pages=108\u201311\u000a|pmid=14385826|bibcode=1955Sci...122..108G\u000a}}</ref><ref name=evolve>\u000a{{cite journal\u000a |last = Garfield \u000a |first = Eugene\u000a |doi=10.2436/20.1501.01.10\u000a |url=http://garfield.library.upenn.edu/papers/barcelona2007a.pdf\u000a |format=Free PDF download\u000a |title=The evolution of the Science Citation Index|doi_brokendate = 2015-01-21\u000a }} International microbiology '''10.'''1 (2010): 65-69.</ref><ref name=gOverview>\u000a{{cite web\u000a | last = Garfield \u000a | first = Eugene\u000a | authorlink =\u000a | coauthors =\u000a | title = Science Citation Index\u000a | work = Science Citation Index 1961\u000a | publisher = Garfield Library - UPenn\u000a | date = 1963\u000a | url = http://garfield.library.upenn.edu/papers/80.pdf\u000a | format = Free PDF download\u000a | doi =\u000a | accessdate = 2013-05-27}} \u000a* Originally published by the Institute of Scientific Information in 1964\u000a* Other titles in this document are: What is a Citation Index? , How is the Citation Index Prepared? , How is the Citation Index Used? , Applications of the Science Citation Index , Source Coverage and Statistics , and a Glossary.</ref><ref name=history-cite-indexing>\u000a{{cite web\u000a | title =History of Citation Indexing \u000a | work =Needs of researchers create demand for citation indexing \u000a | publisher =Thomson Ruters \u000a | date =November 2010 \u000a | url =http://thomsonreuters.com/products_services/science/free/essays/history_of_citation_indexing/ \u000a | format =Free HTML download \u000a | accessdate =2010-11-04}}</ref> The larger version ('''Science Citation Index Expanded''') covers more than 6,500 notable and significant [[Scientific journal|journals]], across 150 disciplines, from 1900 to the present. These are alternately described as the world's leading journals of [[science]] and [[technology]], because of a rigorous selection process.{{citation needed|date=August 2013}}<ref name=Expanded>\u000a{{cite web \u000a|url=http://thomsonreuters.com/products_services/science/science_products/a-z/science_citation_index_expanded/ \u000a|title=Science Citation Index Expanded \u000a|work= |accessdate=2009-08-30}}</ref>\u000a<ref name=wetland>{{cite journal| doi= 10.1007/s12665-012-2193-y|title= The Top-cited Wetland Articles in Science Citation Index Expanded: characteristics and hotspots|url=http://dns2.asia.edu.tw/~ysho/YSHO-English/Publications/PDF/Env%20Ear%20Sci-Ma.pdf|date= December 2012| last1= Ma| first1= Jiupeng| last2= Fu| first2= Hui-Zhen| last3= Ho| first3= Yuh-Shan| journal= Environmental Earth Sciences|volume= 70|issue= 3|pages= 1039}} (Springer-Verlag)</ref><ref name=shan>\u000a{{cite journal \u000a| doi= 10.1007/s11192-012-0837-z \u000a|title= The top-cited research works in the Science Citation Index Expanded \u000a|url= http://trend.asia.edu.tw/Publications/PDF/Scientometrics94,%201297.pdf \u000a| year= 2012 \u000a| last1= Ho \u000a| first1= Yuh-Shan \u000a| journal= Scientometrics \u000a| volume= 94 \u000a| issue= 3 \u000a| page= 1297}}</ref>\u000a\u000aThe index is made available online through different platforms, such as the [[Web of Science]]<ref name=AtoZ>{{cite web |last=ISI Web of Knowledge platform |title =Available databases A to Z |publisher=Thomson Reuters |year=2010 |url=http://wokinfo.com/products_tools/products/ |format=Choose databases on method of discovery and analysis |accessdate=2010-06-24}}</ref><ref>[http://wokinfo.com/media/pdf/SSR1103443WoK5-2_web3.pdf Thomson Reuters Web of Knowledge. Thomson Reuters, 2013.]</ref> and SciSearch.<ref>{{cite web |url=http://library.dialog.com/bluesheets/html/bl0034.html |title=SCISEARCH - A CITED REFERENCE SCIENCE DATABASE |publisher=Library.dialog.com |date= |accessdate=2014-04-17}}</ref> (There are also CD and printed editions, covering a smaller number of journals). This database allows a researcher to identify which later articles have cited any particular earlier article, or have cited the articles of any particular author, or have been cited most frequently. Thomson Reuters also markets several subsets of this database, termed "Specialty Citation Indexes",<ref name=SpCI>\u000a{{cite web \u000a|url=http://thomsonreuters.com/products_services/science/science_products/a-z/specialty_citation_indexes/ \u000a|title=Specialty Citation Indexes \u000a|work= |accessdate=2009-08-30}}</ref> \u000asuch as the '''Neuroscience Citation Index'''<ref name=NCI>\u000a{{cite web \u000a|url=http://science.thomsonreuters.com/cgi-bin/jrnlst/jlresults.cgi?PC=MD \u000a|title=Journal Search - Science - |work= |accessdate=2009-08-30}}</ref> and the '''Chemistry Citation Index'''.<ref>{{cite web |url=http://science.thomsonreuters.com/cgi-bin/jrnlst/jloptions.cgi?PC=CD \u000a|title=Journal Search - Science - Thomson Reuters |accessdate=14 January 2011}}</ref>\u000a\u000a==Chemistry Citation Index==\u000a\u000aThe Chemistry Citation Index was first introduced by Eugene Garfield, a chemist. His original "search examples were based on [his] experience as a chemist".<ref name=Garcci/> In 1992 an electronic and print form of the index was derived from a core of 330 chemistry journals, within which all areas were covered. Additional information was provided from articles selected from 4,000 other journals. All chemistry subdisciplines were covered: organic, inorganic, analytical, physical chemistry, polymer, computational, organometallic, materials chemistry, and electrochemistry.<ref name=Garcci>Garfield, Eugene. "[http://garfield.library.upenn.edu/essays/v15p007y1992-93.pdf New Chemistry Citation Index On CD-ROM Comes With Abstracts, Related Records, and Key-Words-Plus]." Current Contents 3 (1992): 5-9.</ref>\u000a\u000aBy 2002 the core journal coverage increased to 500 and related article coverage increased to 8,000 other journals.<ref>\u000a[http://www.chinweb.com/cgi-bin/chemport/getfiler.cgi?ID=k4l7vyYF5FimYvScsOm3pxWVmEhBoH0ZuYgxjLdKBfqdmURDHLrjuVv78i16JLPX&VER=E Chemistry Citation Index]. Institute of Process Engineering of the Chinese Academy of Sciences. 2003.</ref>\u000a\u000aOne 1980 study reported the overall citation indexing benefits for chemistry, examining the use of citations as a tool for the study of the sociology of chemistry and illustrating the use of citation data to "observe" chemistry subfields over time.<ref>\u000a{{cite journal\u000a|doi=10.1007/BF02016348\u000a|title=Science citation index and chemistry\u000a|year=1980\u000a|last1=Dewitt\u000a|first1=T. W.\u000a|last2=Nicholson\u000a|first2=R. S.\u000a|last3=Wilson\u000a|first3=M. K.\u000a|journal=Scientometrics\u000a|volume=2\u000a|issue=4\u000a|page=265}}</ref>\u000a\u000a==See also==\u000a* [[Arts and Humanities Citation Index]], which covers 1130 journals, beginning with 1975.\u000a* [[Impact factor]]\u000a* [[List of academic databases and search engines]]\u000a* [[Social Sciences Citation Index]], which covers 1700 journals, beginning with 1956.\u000a\u000a== References ==\u000a{{Reflist|2}}\u000a\u000a==Further reading==\u000a*{{cite journal\u000a|doi= 10.1002/aris.1440360102\u000a|url= http://polaris.gseis.ucla.edu/cborgman/pubs/borgmanfurnerarist2002.pdf\u000a|title=Scholarly Communication and Bibliometrics\u000a|year= 2005\u000a|last1= Borgman\u000a|first1= Christine L.\u000a|last2= Furner\u000a|first2= Jonathan\u000a|journal= Annual Review of Information Science and Technology\u000a|volume= 36\u000a|issue= 1 \u000a|pages=3\u201372}}\u000a\u000a*{{cite journal\u000a|doi= 10.1002/asi.20677\u000a|url= http://staff.aub.edu.lb/~lmeho/meho-yang-impact-of-data-sources.pdf\u000a|format= Free PDF download\u000a|title= Impact of data sources on citation counts and rankings of LIS faculty: Web of science versus scopus and google scholar\u000a|year= 2007\u000a|last1= Meho\u000a|first1= Lokman I.\u000a|last2= Yang\u000a|first2= Kiduk\u000a|journal= Journal of the American Society for Information Science and Technology\u000a|volume= 58\u000a|issue= 13\u000a|page= 2105}}\u000a\u000a*{{cite journal\u000a|doi= 10.1002/asi.5090140304\u000a|url= http://www.garfield.library.upenn.edu/essays/v6p492y1983.pdf\u000a|format= Free PDF download\u000a|title= New factors in the evaluation of scientific literature through citation indexing\u000a|year= 1963\u000a|last1= Garfield\u000a|first1= E.\u000a|last2= Sher\u000a|first2= I. H.\u000a|journal= American Documentation\u000a|volume= 14\u000a|issue= 3\u000a|page= 195}}\u000a\u000a*{{cite journal\u000a|doi= 10.1038/227669a0\u000a|url= http://www.garfield.library.upenn.edu/essays/V1p133y1962-73.pdf\u000a|format= Free PDF download\u000a|title= Citation Indexing for Studying Science\u000a|year= 1970\u000a|last1= Garfield\u000a|first1= E.\u000a|journal= Nature\u000a|volume= 227\u000a|issue= 5259\u000a|pages= 669\u201371\u000a|pmid= 4914589|bibcode= 1970Natur.227..669G\u000a}}\u000a\u000a*{{cite book\u000a | last =Garfield\u000a | first =Eugene \u000a | authorlink =\u000a | title =Citation Indexing: Its Theory and Application in Science, Technology, and Humanities\u000a | publisher =Wiley-Interscience\u000a | series = Information Sciences Series\u000a | edition = 1st\u000a | origyear = 1979| year = 1983\u000a | location = New York\u000a | isbn =9780894950247}}\u000a\u000a==External links==\u000a* [http://scientific.thomson.com/products/wos/ Introduction to SCI]\u000a* [http://science.thomsonreuters.com/mjl/ Master journal list]\u000a* [https://en.wikibooks.org/wiki/Chemical_Information_Sources/Author_and_Citation_Searches Chemical Information Sources/ Author and Citation Searches]. on WikiBooks. \u000a* [http://scientific.thomson.com/tutorials/citedreference/crs1.htm Cited Reference Searching: An Introduction]. Thomson Reuters. \u000a* [http://www.chinweb.com/cgi-bin/chemport/getfiler.cgi?ID=k4l7vyYF5FimYvScsOm3pxWVmEhBoH0ZuYgxjLdKBfqdmURDHLrjuVv78i16JLPX&VER=E Chemistry Citation Index]. Chinweb.\u000a\u000a{{Thomson Reuters}}\u000a\u000a[[Category:Online databases]]\u000a[[Category:Citation indices]]\u000a[[Category:Thomson Reuters]]
p149
sg4
S'219'
p150
sg6
VScience Citation Index
p151
ssI94
(dp152
g2
V{{external links|date=November 2013}}\u000a{{Use dmy dates|date=June 2013}}\u000a{{Recommender systems}}\u000a[[File:Collaborative filtering.gif|600px|thumb|\u000a\u000aThis image shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about user's rating for an item, which the user hasn't rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in our case the system has made a prediction, that the active user won't like the video.\u000a\u000a]]\u000a\u000a'''Collaborative filtering''' ('''CF''') is a technique used by some [[recommender system]]s.<ref name="handbook">Francesco Ricci and Lior Rokach and Bracha Shapira, [http://www.inf.unibz.it/~ricci/papers/intro-rec-sys-handbook.pdf Introduction to Recommender Systems Handbook], Recommender Systems Handbook, Springer, 2011, pp. 1-35</ref> Collaborative filtering has two senses, a narrow one and a more general one.<ref name=recommender>{{cite web|title=Beyond Recommender Systems: Helping People Help Each Other|url=http://www.grouplens.org/papers/pdf/rec-sys-overview.pdf|publisher=Addison-Wesley|accessdate=16 January 2012|page=6|year=2001|last1=Terveen|first1=Loren|last2=Hill|first2=Will}}</ref>  In general, collaborative filtering is the process of filtering for information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc.<ref name="recommender" />  Applications of collaborative filtering typically involve very large data sets.   Collaborative filtering methods have been applied to many different kinds of data including: sensing and monitoring data, such as in mineral exploration, environmental sensing over large areas or multiple sensors; financial data, such as financial service institutions that integrate many financial sources; or in electronic commerce and web applications  where the focus is on user data, etc.  The remainder of this discussion focuses on collaborative filtering for user data, although some of the methods and approaches may apply to the other major applications as well.\u000a\u000aIn the newer, narrower sense, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or [[taste (sociology)|taste]] information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person ''A'' has the same opinion as a person ''B'' on an issue, A is more likely to have B's opinion on a different issue ''x'' than to have the opinion on x of a person chosen randomly. For example, a collaborative filtering recommendation system for [[television]] tastes could make predictions about which television show a user should like given a partial list of that user's tastes (likes or dislikes).<ref>[http://www.redbeemedia.com/insights/integrated-approach-tv-vod-recommendations An integrated approach to TV & VOD Recommendations]</ref> Note that these predictions are specific to the user, but use information gleaned from many users. This differs from the simpler approach of giving an [[average]] (non-specific) score for each item of interest, for example based on its number of [[vote]]s.\u000a\u000a==Introduction==\u000aThe growth of the Internet has made it much more difficult to effectively extract useful information from all the available online information. The overwhelming amount of data necessitates  mechanisms for efficient information filtering. One of the techniques used for dealing with this problem is called collaborative filtering.\u000a\u000aThe motivation for collaborative filtering comes from the idea that people often get the best recommendations from someone with similar tastes to themselves. Collaborative filtering explores techniques for matching people with similar interests and making recommendations on this basis.\u000a\u000aCollaborative filtering algorithms often require (1) users\u2019 active participation, (2) an easy way  to represent users\u2019 interests to the system, and (3) algorithms that are able to match people with similar interests.\u000a\u000aTypically, the workflow of a collaborative filtering system is:\u000a# A user expresses his or her preferences by rating items (e.g. books, movies or CDs) of the system. These ratings can be viewed as an approximate representation of the user's interest in the corresponding domain.\u000a# The system matches this user\u2019s ratings against other users\u2019  and finds the people with most \u201csimilar\u201d tastes.\u000a# With similar users, the system recommends items that the similar users have rated highly but not yet being rated by this user (presumably the absence of rating is often considered as the unfamiliarity of an item)\u000aA key problem of collaborative filtering is how to combine and weight the preferences of user neighbors. Sometimes, users can immediately rate the recommended items. As a result, the system gains an increasingly accurate representation of user preferences over time.\u000a\u000a==Methodology==\u000a\u000a[[File:Collaborative Filtering in Recommender Systems.jpg|thumb|Collaborative Filtering in Recommender Systems]]\u000a\u000aCollaborative filtering systems have many forms, but many common systems can be reduced to two steps:\u000a# Look for users who share the same rating patterns with the active user (the user whom the prediction is for).\u000a# Use the ratings from those like-minded users found in step 1 to calculate a prediction for the active user\u000aThis falls under the category of user-based collaborative filtering. A specific application of this is the user-based [[K-nearest neighbor algorithm|Nearest Neighbor algorithm]].\u000a\u000aAlternatively, [[item-item collaborative filtering|item-based collaborative filtering]] (users who bought x also bought y), proceeds in an item-centric manner:\u000a# Build an item-item matrix determining relationships between pairs of items\u000a# Infer the tastes of the current user by examining the matrix and matching that user's data\u000aSee, for example, the [[Slope One]] item-based collaborative filtering family.\u000a\u000aAnother form of collaborative filtering can be based on implicit observations of normal user behavior (as opposed to the artificial behavior imposed by a rating task). These systems observe what a user has done together with what all users have done (what music they have listened to, what items they have bought) and use that data to predict the user's behavior in the future, or to predict how a user might like to behave given the chance.  These predictions then have to be filtered through [[business logic]] to determine how they might affect the actions of a business system.  For example, it is not useful to offer to sell somebody a particular album of music if they already have demonstrated that they own that music.\u000a\u000aRelying on a scoring or rating system which is averaged across all users ignores specific demands of a user, and is particularly poor in tasks where there is large variation in interest (as in the recommendation of music). However, there are other methods to combat information explosion, such as [[WWW|web]] search and [[data clustering]].\u000a\u000a==Types==\u000a\u000a===Memory-based===\u000aThis mechanism uses user rating data to compute similarity between users or items. This is used for making recommendations. This was the earlier mechanism and is used in many commercial systems. It is easy to implement and is effective. Typical examples of this mechanism are neighbourhood based CF and item-based/user-based top-N recommendations.[3] For example, in user based approaches, the value of ratings user 'u' gives to item 'i' is calculated as an aggregation of some similar users rating to the item:\u000a:<math>r_{u,i} = \u005coperatorname{aggr}_{u^\u005cprime \u005cin U} r_{u^\u005cprime, i}</math>\u000a\u000awhere 'U' denotes the set of top 'N' users that are most similar to user 'u' who rated item 'i'. Some examples of the aggregation function includes:\u000a:<math>r_{u,i} = \u005cfrac{1}{N}\u005csum\u005climits_{u^\u005cprime \u005cin U}r_{u^\u005cprime, i}</math>\u000a:<math>r_{u,i} = k\u005csum\u005climits_{u^\u005cprime \u005cin U}\u005coperatorname{simil}(u,u^\u005cprime)r_{u^\u005cprime, i}</math>\u000a:<math>r_{u,i} = \u005cbar{r_u} +  k\u005csum\u005climits_{u^\u005cprime \u005cin U}\u005coperatorname{simil}(u,u^\u005cprime)(r_{u^\u005cprime, i}-\u005cbar{r_{u^\u005cprime}} )</math>\u000a\u000awhere k is a normalizing factor defined as <math>k =1/\u005csum_{u^\u005cprime \u005cin U}|\u005coperatorname{simil}(u,u^\u005cprime)| </math>. and <math>\u005cbar{r_u}</math> is the average rating of user u for all the items rated by that user.\u000a\u000aThe neighborhood-based algorithm calculates the similarity between two users or items, produces a prediction for the user taking the weighted average of all the ratings. Similarity computation between items or users is an important part of this approach. Multiple mechanisms such as [[Pearson product-moment correlation coefficient|Pearson correlation]] and [[Cosine similarity|vector cosine]] based similarity are used for this.\u000a\u000aThe Pearson correlation similarity of two users x, y is defined as \u000a:<math> \u005coperatorname{simil}(x,y) = \u005cfrac{\u005csum\u005climits_{i \u005cin I_{xy}}(r_{x,i}-\u005cbar{r_x})(r_{y,i}-\u005cbar{r_y})}{\u005csqrt{\u005csum\u005climits_{i \u005cin I_{xy}}(r_{x,i}-\u005cbar{r_x})^2\u005csum\u005climits_{i \u005cin I_{xy}}(r_{y,i}-\u005cbar{r_y})^2}} </math>\u000a\u000awhere I<sub>xy</sub> is the set of items rated by both user x and user y.\u000a\u000aThe cosine-based approach defines the cosine-similarity between two users x and y as:<ref name="Breese1999">John S. Breese, David Heckerman, and Carl Kadie, [http://uai.sis.pitt.edu/displayArticleDetails.jsp?mmnu=1&smnu=2&article_id=231&proceeding_id=14 Empirical Analysis of Predictive Algorithms for Collaborative Filtering], 1998</ref>\u000a:<math>\u005coperatorname{simil}(x,y) = \u005ccos(\u005cvec x,\u005cvec y) = \u005cfrac{\u005cvec x \u005ccdot \u005cvec y}{||\u005cvec x|| \u005ctimes ||\u005cvec y||} = \u005cfrac{\u005csum\u005climits_{i \u005cin I_{xy}}r_{x,i}r_{y,i}}{\u005csqrt{\u005csum\u005climits_{i \u005cin I_{x}}r_{x,i}^2}\u005csqrt{\u005csum\u005climits_{i \u005cin I_{y}}r_{y,i}^2}}</math>\u000a\u000aThe user based top-N recommendation algorithm identifies the k most similar users to an active user using similarity based vector model. After the k most similar users are found, their corresponding user-item matrices are aggregated to identify the set of items to be recommended. A popular method to find the similar users is the [[Locality-sensitive hashing]], which implements the [[Nearest neighbor search|nearest neighbor mechanism]] in linear time.\u000a\u000aThe advantages with this approach include:  the explainability of the results, which is an important aspect of recommendation systems; it is easy to create and use; new data can be added easily and incrementally; it need not consider the content of the items being recommended; and the mechanism scales well with co-rated items.\u000a\u000aThere are several disadvantages with this approach.  Its performance decreases when data gets sparse, which is frequent with web related items. This prevents the scalability of this approach and has problems with large datasets. Although it can efficiently handle new users because it relies on a data structure, adding new items becomes more complicated since that representation usually relies on a specific vector space. That would require to include the new item and re-insert all the elements in the structure.\u000a\u000a===Model-based===\u000aModels are developed using [[data mining]], [[machine learning]] algorithms to find patterns based on training data. These are used to make predictions for real data. There are many model-based CF algorithms. These include [[Bayesian networks]], [[Cluster Analysis|clustering models]], [[Latent Semantic Indexing|latent semantic models]] such as [[singular value decomposition]], [[probabilistic latent semantic analysis]], Multiple Multiplicative Factor, [[Latent Dirichlet allocation]] and [[markov decision process]] based models.<ref name="Suetal2009">Xiaoyuan Su, Taghi M. Khoshgoftaar, [http://www.hindawi.com/journals/aai/2009/421425/ A survey of collaborative filtering techniques], Advances in Artificial Intelligence archive, 2009.</ref>\u000a\u000aThis approach has a more holistic goal to uncover latent factors that explain observed ratings.<ref>[http://research.yahoo.com/pub/2435 Factor in the Neighbors: Scalable and Accurate Collaborative Filtering]</ref> Most of the models are based on creating a classification or clustering technique to identify the user based on the test set. The number of the parameters can be reduced based on types of [[Principal Component Analysis|principal component analysis]].\u000a\u000aThere are several advantages with this paradigm. It handles the sparsity better than memory based ones. This helps with scalability with large data sets. It improves the prediction performance. It gives an intuitive rationale for the recommendations.\u000a\u000aThe disadvantages with this approach are in the expensive model building. One needs to have a tradeoff between prediction performance and scalability. One can lose useful information due to reduction models. A number of models have difficulty explaining the predictions.\u000a\u000a===Hybrid===\u000aA number of applications combines the memory-based and the model-based CF algorithms. These overcome the limitations of native CF approaches. It improves the prediction performance. Importantly, it overcomes the CF problems such as sparsity and loss of information. However, they have increased complexity and are expensive to implement.<ref>Kernel Mapping Recommender System Algorithms, www.sciencedirect.com/science/article/pii/S0020025512002587\u000a</ref> Usually most of the commercial recommender systems are hybrid, for example, Google news recommender system.<ref>[http://dl.acm.org/citation.cfm?id=1242610 Google News Personalization: Scalable Online Collaborative Filtering]</ref>\u000a\u000a==Application on social web==\u000aUnlike the traditional model of mainstream media, in which there are few editors who set guidelines, collaboratively filtered social media can have a very large number of editors, and content improves as the number of participants increases. Services like [[Reddit]], [[YouTube]], and [[Last.fm]] are typical example of collaborative filtering based media.<ref>[http://www.readwriteweb.com/archives/collaborative_filtering_social_web.php Collaborative Filtering: Lifeblood of The Social Web]</ref>\u000a\u000aOne scenario of collaborative filtering application is to recommend interesting or popular information as judged by the community. As a typical example, stories appear in the front page of [[Digg]] as they are "voted up" (rated positively) by the community. As the community becomes larger and more diverse, the promoted stories can better reflect the average interest of the community members.\u000a\u000aAnother aspect of collaborative filtering systems is the ability to generate more personalized recommendations by analyzing information from the past activity of a specific user, or the history of other users deemed to be of similar taste to a given user. These resources are used as user profiling and helps the site recommend content on a user-by-user basis. The more a given user makes use of the system, the better the recommendations become, as the system gains data to improve its model of that user.\u000a\u000a===Problems===\u000aA collaborative filtering system does not necessarily succeed in automatically matching content to one's preferences. Unless the platform achieves unusually good diversity and independence of opinions, one point of view will always dominate another in a particular community. As in the personalized recommendation scenario, the introduction of new users or new items can cause the [[cold start]] problem, as there will be insufficient data on these new entries for the collaborative filtering to work accurately. In order to make appropriate recommendations for a new user, the system must first learn the user's preferences by analysing past voting or rating activities. The collaborative filtering system requires a substantial number of users to rate a new item before that item can be recommended.\u000a\u000a==Challenges of collaborative filtering==\u000a\u000a===Data sparsity===\u000aIn practice, many commercial recommender systems are based on large datasets. As a result, the user-item matrix used for collaborative filtering could be extremely large and sparse, which brings about the challenges in the performances of the recommendation.\u000a\u000aOne typical problem caused by the data sparsity is the [[cold start]] problem. As collaborative filtering methods recommend items based on users\u2019 past preferences,  new users will need to rate sufficient number of items to enable the system to capture their preferences accurately and thus provides reliable recommendations.\u000a\u000aSimilarly,  new items also have the same problem. When new items are added to system, they need to be rated by substantial number of users before they could be recommended to users who have similar tastes with the ones rated them. The new item problem does not limit the [[Recommender system#Content-based filtering|content-based recommendation]], because the recommendation of an item is based on its discrete set of descriptive qualities rather than its ratings.\u000a\u000a===Scalability===\u000aAs the numbers of users and items grow, traditional CF algorithms will suffer serious scalability problems{{Citation needed|date=April 2013}}. For example, with tens of millions of customers <math>O(M)</math> and millions of items <math>O(N)</math>, a CF algorithm with the complexity of <math>n</math> is already too large. As well, many systems need to react immediately to online requirements and make recommendations for all users regardless of their purchases and ratings history, which demands a higher scalability of a CF system. Large web companies such as Twitter use clusters of machines to scale recommendations for their millions of users, with most computations happening in very large memory machines.<ref name="twitterwtf">Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, and Reza Bosagh Zadeh [http://dl.acm.org/citation.cfm?id=2488433 WTF: The who-to-follow system at Twitter], Proceedings of the 22nd international conference on World Wide Web</ref>\u000a\u000a===Synonyms===\u000a[[Synonyms]] refers to the tendency of a number of the same or very similar items to have different names or entries. Most recommender systems are unable to discover this latent association and thus treat these products differently.\u000a\u000aFor example, the seemingly different items \u201cchildren movie\u201d and \u201cchildren film\u201d are actually referring to the same item. Indeed, the degree of variability in descriptive term usage is greater than commonly suspected.{{citation needed|date=September 2013}} The prevalence of synonyms decreases the recommendation performance of CF systems. Topic Modeling (like the Latent Dirichlet Allocation technique) could solve this by grouping different words belonging to the same topic.{{citation needed|date=September 2013}}\u000a\u000a===Grey sheep===\u000aGrey sheep refers to the users whose opinions do not consistently agree or disagree with any group of people and thus do not benefit from collaborative filtering. [[Black sheep]] are the opposite group whose idiosyncratic tastes make recommendations nearly impossible. Although this is a failure of the recommender system, non-electronic recommenders also have great problems in these cases, so black sheep is an acceptable failure.\u000a\u000a===Shilling attacks===\u000aIn a recommendation system where everyone can give the ratings, people may give lots of positive ratings  for their own items and negative ratings for their competitors. It is often necessary for the collaborative filtering systems to introduce precautions to discourage such kind of manipulations.\u000a\u000a===Diversity and the Long Tail===\u000aCollaborative filters are expected to increase diversity because they help us discover new products. Some algorithms, however, may unintentionally do the opposite. Because collaborative filters recommend products based on past sales or ratings, they cannot usually recommend products with limited historical data. This can create a rich-get-richer effect for popular products, akin to [[positive feedback]]. This bias toward popularity can prevent what are otherwise better consumer-product matches. A [[Wharton School of the University of Pennsylvania|Wharton]] study details this phenomenon along with several ideas that may promote diversity and the "[[long tail]]."<ref>{{cite journal| last1= Fleder | first1= Daniel | first2= Kartik |last2= Hosanagar | title=Blockbuster Culture's Next Rise or Fall: The Impact of Recommender Systems on Sales Diversity|journal=Management Science |date=May 2009|url=http://papers.ssrn.com/sol3/papers.cfm?abstract_id=955984}}</ref>\u000a\u000a==Innovations==\u000a{{Prose|date=May 2012}}\u000a* New algorithms have been developed for CF as a result of the [[Netflix prize]].\u000a* Cross-System Collaborative Filtering where user profiles across multiple [[recommender systems]] are combined in a privacy preserving manner.\u000a* Robust Collaborative Filtering, where recommendation is stable towards efforts of manipulation. This research area is still active and not completely solved.<ref>{{cite web|url=http://dl.acm.org/citation.cfm?id=1297240 |title=Robust collaborative filtering |doi=10.1145/1297231.1297240 |publisher=Portal.acm.org |date=19 October 2007 |accessdate=2012-05-15}}</ref>\u000a\u000a==See also==\u000a* [[Attention Profiling Mark-up Language|Attention Profiling Mark-up Language (APML)]]\u000a* [[Cold start]]\u000a* [[Collaborative model]]\u000a* [[Collaborative search engine]]\u000a* [[Collective intelligence]]\u000a* [[Customer engagement]]\u000a* [[Delegative Democracy]], the same principle applied to voting rather than filtering\u000a* [[Enterprise bookmarking]]\u000a* [[Firefly (website)]], a defunct website which was based on collaborative filtering\u000a* [[Long tail]]\u000a* [[Preference elicitation]]\u000a* [[Recommendation system]]\u000a* [[Relevance (information retrieval)]]\u000a* [[Reputation system]]\u000a* [[Robust collaborative filtering]]\u000a* [[Similarity search]]\u000a* [[Slope One]]\u000a* [[Social translucence]]\u000a\u000a==References==\u000a{{Reflist|30em}}\u000a\u000a==External links==\u000a*[http://www.grouplens.org/papers/pdf/rec-sys-overview.pdf ''Beyond Recommender Systems: Helping People Help Each Other''], page 12, 2001\u000a*[http://www.prem-melville.com/publications/recommender-systems-eml2010.pdf Recommender Systems.] Prem Melville and Vikas Sindhwani. In Encyclopedia of Machine Learning, Claude Sammut and Geoffrey Webb (Eds), Springer, 2010.\u000a*[http://arxiv.org/abs/1203.4487 Recommender Systems in industrial contexts - PHD thesis (2012) including a comprehensive overview of many collaborative recommender systems]\u000a*[http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1423975  Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions]. Adomavicius, G. and Tuzhilin, A. IEEE Transactions on Knowledge and Data Engineering 06.2005\u000a*[http://ectrl.itc.it/home/laboratory/meeting/download/p5-l_herlocker.pdf Evaluating collaborative filtering recommender systems]{{dead link|date=May 2012}} ([http://www.doi.org/ DOI]: [http://dx.doi.org/10.1145/963770.963772 10.1145/963770.963772])\u000a*[http://www.grouplens.org/publications.html GroupLens research papers].\u000a*[http://www.cs.utexas.edu/users/ml/papers/cbcf-aaai-02.pdf Content-Boosted Collaborative Filtering for Improved Recommendations.] Prem Melville, Raymond J. Mooney, and Ramadass Nagarajan. Proceedings of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002), pp.&nbsp;187\u2013192, Edmonton, Canada, July 2002.\u000a*[http://agents.media.mit.edu/projects.html A collection of past and present "information filtering" projects (including collaborative filtering) at MIT Media Lab]\u000a*[http://www.ieor.berkeley.edu/~goldberg/pubs/eigentaste.pdf Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information Retrieval, 4(2), 133-151. July 2001.]\u000a*[http://downloads.hindawi.com/journals/aai/2009/421425.pdf A Survey of Collaborative Filtering Techniques] Su, Xiaoyuan and Khoshgortaar, Taghi. M\u000a*[http://dl.acm.org/citation.cfm?id=1242610 Google News Personalization: Scalable Online Collaborative Filtering] Abhinandan Das, Mayur Datar, Ashutosh Garg, and Shyam Rajaram. International World Wide Web Conference, Proceedings of the 16th international conference on World Wide Web\u000a*[http://research.yahoo.com/pub/2435 Factor in the Neighbors: Scalable and Accurate Collaborative Filtering] Yehuda Koren, Transactions on Knowledge Discovery from Data (TKDD) (2009)\u000a*[http://webpages.uncc.edu/~asaric/ISMIS09.pdf Rating Prediction Using Collaborative Filtering]\u000a*[http://www.cis.upenn.edu/~ungar/CF/ Recommender Systems]\u000a*[http://www2.sims.berkeley.edu/resources/collab/ Berkeley Collaborative Filtering]\u000a\u000a{{DEFAULTSORT:Collaborative Filtering}}\u000a[[Category:Collaboration]]\u000a[[Category:Collaborative software| Collaborative filtering]]\u000a[[Category:Collective intelligence]]\u000a[[Category:Information retrieval]]\u000a[[Category:Recommender systems]]\u000a[[Category:Social information processing]]\u000a[[Category:Behavioral and social facets of systemic risk]]
p153
sg4
S'94'
p154
sg6
VCollaborative filtering
p155
ssI224
(dp156
g2
V{{Redirect|Global Health|other uses|Global health}}\u000a{{italic title}}\u000a{{Infobox Bibliographic Database\u000a|title =CAB Abstracts \u000a|image = \u000a|caption = \u000a|producer =[[CABI (organisation)|CABI]]\u000a|country =United Kingdom \u000a|history =1973 to present \u000a|languages =Fifty languages, English abstracts \u000a|providers =Datastar, Dialog bluesheets, STN International, CAB Direct (CABI's own platform), Thomson-Reuters [[Web of Knowledge]], EBSCO, OvidSP, Dimdi \u000a|cost = \u000a|disciplines =applied life sciences - agriculture, environment, veterinary sciences, applied economics, food science and nutrition \u000a|depth =bibliographic, abstracting and indexing \u000a|formats =journal articles, abstracts, proceedings, books, book chapters, monographs, annual reports, handbooks, bulletins, newsletters, discussion papers, field notes, technical information, thesis papers  \u000a|temporal =1973-Present \u000a|geospatial =Global - international \u000a|number =6 million + \u000a|updates =\u000a|p_title = \u000a|p_dates = \u000a|ISSN =\u000a|web = \u000a|titles =http://www.cabi.org/default.aspx?site=170&page=1028  \u000a}}\u000a{{Infobox Bibliographic Database\u000a|title =Global Health bibliographic database \u000a|image = \u000a|caption = \u000a|producer = \u000a|country = \u000a|history = \u000a|languages = 50 languages (158 countries)\u000a|providers =CAB Direct, SilverPlatter, Web of Knowledge, EBSCO, OvidSP, Dialog, Dimdi \u000a|cost = \u000a|disciplines =international health research (medical and public)\u000a|depth =bibliographic, abstracting and indexing \u000a|formats =scientific journals, reports, books and conferences \u000a|temporal =1973 to present \u000a|geospatial =global-international \u000a|number =1.2 million scientific records \u000a|updates = \u000a|p_title = \u000a|p_dates = \u000a|ISSN =\u000a|web = \u000a|titles =  \u000a}}\u000a\u000a'''CAB Direct''' is a source of references for the ''[[life sciences|applied life sciences]]'' It incorporates two  bibliographic databases: '''''CAB Abstracts''''' and '''''Global Health'''''. CAB Direct is an access point for multiple [[bibliographic databases]] produced by ''CABI''. This database contains 8.8 million [[bibliographic record]]s, which includes  85,000 full text articles. It also includes noteworthy literature reviews. News articles and reports are also part of this combined database.<ref name=direct>{{cite web\u000a  | title =CAB Direct \u000a  | work = \u000a  | publisher =CABI  \u000a  | date =July 2010 \u000a  | url =http://www.cabdirect.org/ \u000a  | accessdate =2010-07-18}}</ref>\u000a\u000aIn the U.K., in 1947, the ''Imperial Agricultural Bureaux'' became the ''Commonwealth Agricultural Bureaux'' or ''CAB''. In 1986 the ''Commonwealth Agricultural Bureaux'' became ''[[CAB International]]'' or ''CABI''  <ref name=history-cabi>{{cite web\u000a  | title =Our history \u000a  | work =Bulleted history \u000a  | publisher =CABI  \u000a  | date =July 2010 \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1388 \u000a  | accessdate =2010-07-18}}</ref>\u000a\u000a==CAB Abstracts==\u000a'''CAB Abstracts''' is an applied life sciences bibliographic database emphasising [[agricultural]] literature, which is international in scope. It contains 6 million records, with coverage from 1973 to present day, adding 300,000 abstracts per year. Subject coverage includes [[agriculture]], [[environmental science|environment]], [[veterinary]] sciences, [[applied economics]], [[food science]] and nutrition. Database covers international issues in agriculture, [[forestry]], and allied disciplines in the life sciences. Indexed publications are from 150 countries in 50 languages, including English abstracts for most articles. Literature coverage includes journals, proceedings,  books, and a large collection of agricultural serials. Other non-journal formats are also indexed.<ref name=cabAb>\u000a{{cite web\u000a  | title =CAB Abstracts \u000a  | work = \u000a  | publisher =CABI  \u000a  | date =July 2010 \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1016&pid=125 \u000a  | accessdate =2010-07-18}}</ref><ref name=TRcababse>{{cite web\u000a  | title =CAB Abstracts (Web of Knowledge) \u000a  | work = \u000a  | publisher =Thomson Reuters \u000a  | date =July 2010 \u000a  | url =http://science.thomsonreuters.com/training/cab/#overview \u000a  | accessdate =2010-07-18}}</ref><ref name=ovidCABabs>{{cite web\u000a  | title =CAB Abstracts \u000a  | work =Coverage is 1973-Present \u000a  | publisher =Ovid Technologies, Inc  \u000a  | date =December 2010 \u000a  | url =http://www.ovid.com/site/catalog/DataBase/31.jsp?top=2&mid=3&bottom=7&subsection=10  \u000a  | accessdate =2010-12-10}}</ref> \u000a===CAB Abstracts Archive===\u000a'''CAB Abstracts Archive''' is a searchable database produced by ''CABI''. It is created from 600 volumes of printed abstracts,  which are the collected and published [[scientific research]] from 1910 to 1972, and then digitized to form the archive. This archive database contains more than 1.8 million records which covers agriculture, [[veterinary]] science, nutrition and the environment. Subject coverage also includes [[biodiversity]], [[pest control]], [[environmental pollution]], [[animal disease]] (including [[zoonotic disease]]s), [[nutrition]], and [[food production]]. [[Natural resource management]] includes plant and [[animal breeding]]. CAB Abstracts Archive is also  indexed in other databases, which also serve as access points. These other databases are ''CAB Direct'', [[Web of Knowledge]], [[EBSCOhost]], [[Ovid Technologies|OvidSP]], and [[Dialog]].\u000a\u000aThe following print journals (digitized) comprise CAB Abstracts Archive:\u000a                                                \u000a:Animal Breeding Abstracts, Dairy Science Abstracts, Field Crop Abstracts, \u000a:Forestry Abstracts, Horticultural Science Abstracts, Nematological Abstracts, \u000a:Nutrition Abstracts and Reviews Series A: Human and Experimental, \u000a:Nutrition Abstracts and Reviews Series B: Livestock Feeds and Feeding,  \u000a:Plant Breeding Abstracts, Review of Agricultural Entomology, \u000a:Review of Medical and Veterinary Mycology, Review of Plant Pathology, \u000a:Review of Medical and Veterinary Entomology, Review of Plant Pathology, \u000a:Soils and Fertilizers, Tropical Veterinary Bulletin, Veterinary Bulletin  \u000a:and Weed Abstracts.\u000a\u000a===Weed Abstracts===\u000a'''''Weed Abstracts''''', derived from CAB Abstracts, is an abstracts database focused on [[scientific journal|published research]] regarding [[weed]]s and [[herbicides]]. This includes [[plant biology|weed biology]], encompassing [[research|research areas]] from [[genetics]] to [[ecology]], including [[parasitic]], [[poisonous]], [[allergenic]] and [[aquatic plant|aquatic]] weeds. Further coverage includes all topics related to [[weed control]], in both [[farming|crop]] and non-crop situations. Research on herbicides, includes formulations, [[herbicide resistance]] and the effects of [[herbicide residues]] in the environment. 10,000 records are add to this database per year. \u000a\u000a'''''Weed Abstracts''''' is updated weekly with summaries from notable English and foreign language journal articles, reports, conferences and books about weeds and herbicides. With the back-file, coverage is from 1990 to present day bringing the total of available research summaries to 130,000 records.<ref name=weedAb>{{cite web\u000a  | title =Weed Abstracts \u000a  | work = \u000a  | publisher =CABI  \u000a  | date =July 2010 \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1016&pid=2203\u000a  | accessdate =2010-07-20}}</ref>\u000a\u000a==Global Health database==\u000a'''''Global Health''''' is a bibliographic database which focuses on [[scientific literature|research literature]] in [[public health]] and [[Health science|medical health]] science sectors (including practice). Information (see infobox above) in indexed in more than 5000 [[academic journals]], and indexed from other sources such as reports, books and conferences.  Global Health contains over 1.2 million [[scientific]] records from 1973 to the present, with an addition of  90,000 indexed and abstracted records per year. Sources are abstracted from publications in 158 countries written in 50 languages. Any relevant non-English-language papers are translated into English. Proceedings, patents, thesis papers, electronic publications and relevant but difficult-to-find literature sources are also part of this database.<ref name=glbl-hlth-cabi>{{cite web\u000a  | title =Global Health overview \u000a  | work = \u000a  | publisher =CABI  \u000a  | date =July 2010 \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1016&pid=328 \u000a  | accessdate =2010-07-18}}</ref><ref name=TRglblhlth>{{cite web\u000a  | title =Global Health (Web of Knowledge) \u000a  | work = \u000a  | publisher =Thomson Reuters \u000a  | date =July 2010 \u000a  | url =http://thomsonreuters.com/content/PDF/scientific/globalhealth_fs.pdf \u000a  | format =Free PDF download \u000a  | accessdate =2010-07-18}}</ref><ref name=ovidGH>{{cite web\u000a  | title =Global Health (Ovid) \u000a  | work = \u000a  | publisher =Ovid Technologies Inc. \u000a  | date =July 2010 \u000a  | url =http://www.ovid.com/site/catalog/DataBase/30.jsp?top=2&mid=3&bottom=7&subsection=10 \u000a  | accessdate =2010-07-18}}</ref> \u000a\u000a===Global Health Archive===\u000a'''''Global Health Archive''''' is a searchable database produced by CABI. It is created from 800,000 records, from six printed abstract journals,  which are collected published scientific research from 1910 to 1972, digitized to form the archive. Global Health Archive is also  indexed in other databases, which also serve as access points. These other databases are ''CAB Direct'', [[Web of Knowledge]], [[EBSCOhost]], [[Ovid Technologies|OvidSP]], and [[Dialog]].<ref name=ghArchive/>\u000a\u000aWhen combined with the ''Global Health'' database indexing coverage can be from 1910 to present day. Hence, coverage is made up of past [[epidemics]], from rates and patterns of disease [[Transmission (medicine)|transmission]], duration of [[pandemics]], timing of epidemiological peaks, [[geographic distribution]] of diseases, and [[World Health Organization|government preparedness]] and [[quarantine]] provisions.  The following can also be taken  into account:  effects on different age and [[social groups]], severity in developing vs. developed countries, [[symptoms]], causes of [[Human|mortality]] - such as secondary problems like [[pneumonia]] - and mortality rates.<ref name=ghArchive>{{cite web\u000a  | title =Global Health Archive \u000a  | work = \u000a  | publisher =CABI \u000a  | date =March 2010  \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1016&pid=2221 \u000a  | accessdate =2010-07-18}}</ref><ref name=ovidGHA>{{cite web\u000a  | title =Global Health Archive (Ovid)\u000a  | work = \u000a  | publisher =Ovid Technologies Inc. \u000a  | date =July 2010 \u000a  | url =http://www.ovid.com/site/catalog/DataBase/1748.jsp?top=2&mid=3&bottom=7&subsection=10 \u000a  | accessdate =2010-07-18}}</ref> \u000a\u000a====Journal and topic coverage====\u000aRecords for this database are derived from the following journals throughout certain years:<ref name=ghArchive/><ref name=ovidGHA/>\u000a\u000a:Tropical Diseases Bulletin (1912-83),\u000a:Abstracts on Hygiene and Communicable Diseases (1926-83), \u000a:Review of Veterinary and Medical Entomology (1913-72), \u000a:Review of Veterinary and Medical Mycology (1943-72) \u000a:Nutrition Abstracts and Reviews (1931-72), and Helminthological Abstracts (1932-72).\u000a\u000aSubject coverage includes [[Public health]], [[tropical disease|Tropical]] and [[Communicable disease]]s, Nutrition, [[Parasitology]], [[Entomology]], and [[Mycology]].\u000a\u000a===Tropical Diseases Bulletin===\u000a'''''Tropical Diseases Bulletin''''' is a bibliographic and abstracts database which focuses on research published regarding [[infectious disease]]s and [[public health]] in [[developing countries]] and the [[tropics]] and [[subtropics]]. This includes research areas from [[epidemiology]] to [[diagnosis]], [[therapy]] to [[disease prevention]], [[tropical medicine]], and related aspects of [[travel medicine]]. Published research coverage on [[patients]] and populations encompasses the health of marginalized populations: [[immigrant]]s, [[refugee]]s, and [[indigenous peoples]].<ref name=tropical/>\u000a\u000aBack-file coverage is from 1990 to present day, with an accessible base of 195,000 abstracts and the addition of 11,000 records per year. As a monthly journal '''''Tropical Diseases Bulletin''''' is also available in print. This print journal has author, subject and serials cited indexes.  Coverage of the print back-file is to 1912. A searchable, electronic database version of this journal is part of the ''Global Health Archive'' (see above).<ref name=tropical>\u000a{{cite web\u000a  | title =Tropical Diseases Bulletin\u000a  | work = \u000a  | publisher =CABI \u000a  | year =2010  \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1016&pid=2201\u000a  | accessdate =2010-07-18}}</ref>\u000a\u000a==Organic Research Database==\u000aThis indexing database focuses on scientific literature pertaining to all topics in  [[organic farming]], in both the [[temperate zone|temperate]] and [[tropical zone]]s. This includes [[sustainability|sustainability issues]] and [[soil science|soil fertility]]. Coverage is global; literature is obtained from 125 countries. The temporal coverage spans 30 years, 180,000 organic research abstracts, along with the addition of 8000 records per year. Linking to full text articles, guided searches, broad subject categorization along with subject refinement are also provided. The editorial advisory board of this database also commission reviews pertaining to organic farming.<ref name=organic>\u000a{{cite web\u000a  | title =Organic Research Database\u000a  | work =Description and bibliographic information \u000a  | publisher =CABI \u000a  | year =2011  \u000a  | url =http://www.cabi.org/organicresearch/default.aspx?site=154&page=932\u000a  | accessdate =2011-01-03}}</ref><ref name=usda>\u000a{{cite web\u000a  | title =Primary Research and Literature Databases\u000a  | work = focus on sustainable and alternative agricultural topics\u000a  | publisher =[[USDA]] - [[National Agriculture Library]] - [[AFSIC]] \u000a  | year =2011  \u000a  | url =http://afsic.nal.usda.gov/nal_display/index.php?info_center=2&tax_level=2&tax_subject=288&level3_id=0&level4_id=0&level5_id=0&topic_id=1597&&placement_default=0\u000a  | accessdate =2011-01-03}}</ref>\u000a\u000a==CABI full text repository==\u000a'''''CABI full text repository''''' is integrated into all ''CABI databases'' including CAB Abstracts, and Global Health. Both of these are online and print journals. Coverage includes 70,000 full text articles, through agreements with third party publishers. Eighty percent of the content is exclusive to CABI.<ref name=full-text/>  \u000a\u000aThe full text repository is made up of fifty percent journal articles, and equal percentage of conference (proceeding) papers, and other accessible literature is also included. Eighty percent of the articles are in English and coverage includes 56 countries. Also included in this database are relevant but hard to find materials which crosses disciplines consisting of [[agriculture]], [[health sciences|health]] and the [[life sciences]]. Main stream literature and hard to find materials of equal relevance are given equal access.<ref name=full-text>{{cite web\u000a  | title =CABI full text \u000a  | work = \u000a  | publisher =CABI \u000a  | date =March 2010  \u000a  | url =http://www.cabi.org/default.aspx?site=170&page=1016&pid=2227 \u000a  | accessdate =2010-07-18}}</ref>\u000a\u000a''CABI full text repository'' is indexed in other databases, which also serve as access points, consisting of ''Web of Knowledge (Thomson Reuters)'', ''CAB Direct'', ''OvidSP, Dialog, Dimdi, and EBSCOhost''.\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a[[Category:Bibliographic database providers]]\u000a[[Category:Bibliographic indexes]]\u000a[[Category:Citation indices]]\u000a[[Category:Environmental science]]\u000a[[Category:Global health]]
p157
sg4
S'224'
p158
sg6
VCAB Direct (database)
p159
ssI99
(dp160
g2
VThe '''Conference and Labs of the Evaluation Forum''' (formerly '''Cross-Language Evaluation Forum'''), or '''CLEF''', is an organization promoting research  in multilingual [[information access]] (currently focusing on [[European Commissioner for Multilingualism|European languages]]). Its specific functions are to  maintain an underlying framework for testing [[information retrieval]] systems, and creating [[digital library|repositories]] of data for researchers to use in developing  comparable [[Technical standard|standards]].<ref name="Peters">{{cite conference | first1 = Carol | last1 = Peters| first2 = Martin | last2 = Braschler | first3 = Khalid | last3 = Choukri | first4 = Julio | last4 = Gonzalo | first5 = Michael | last5 = Kluck | title = The Future of Evaluation for Cross-Language Information Retrieval Systems | conference = Second Workshop of the Cross-Language Evaluation Forum, CLEF 2001 | id = {{citeseerx|10.1.1.109.7647}} }}</ref>\u000aThe organization holds a forum meeting   every September in Europe. Prior to each forum, participants receive a set of challenge tasks. The tasks  are designed to test various aspects of information retrieval systems and encourage their development. Groups of researchers propose and organize campaigns to satisfy those tasks. The results are used as [[benchmark (computing)|benchmarks]] for the state of the art  in the specific areas.,<ref>{{cite journal | url = http://www.springerlink.com/content/l7v0354471u53385/ | title = Special Issue on CLEF | journal = Information Retrieval | volume = 7 | issue = 1\u20132 | year = 2004 }}</ref><ref>Fredric C. Gey, Noriko Kando, and Carol Peters "Cross-Language Information Retrieval: the way ahead" in ''Information Processing & Management''\u000avol. 41, no. 3,  p.415-431 May 2005, {{doi|10.1016/j.ipm.2004.06.006}}</ref>  \u000a\u000aFor example, the 2010 medical retrieval task focuses on retrieval of computed tomography,  MRI, and radiographic images.<ref name="ImageCLEFmed">{{cite web | last = Mueller| first = Henning| authorlink = | coauthors = | title = Medical Retrieval Task| work = | publisher =ImageCLEF - Cross-language image retrieval evaluations | date = 20 May 2010| url =http://www.imageclef.org/2010/medical | format = | doi = | accessdate = 27 May 2010 }}</ref>\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a== External links ==\u000a* [http://www.clef-campaign.org CLEF homepage]\u000a\u000a[[Category:Information retrieval]]\u000a\u000a{{Compu-conference-stub}}
p161
sg4
S'99'
p162
sg6
VConference and Labs of the Evaluation Forum
p163
ssI229
(dp164
g2
V{{Mergeto|Web of Science|date=June 2014|discuss=Talk:Web of Science#Merge}}\u000a[[File:Web of Science Logo.png|thumb|The current Web of Science logo]]\u000a[[Image:ISI Web of Knowledge updated.png|thumb|400px|An example search result from Web of Knowledge version 3.0]]\u000a\u000a'''Web of Knowledge''' (formerly known as [[Institute for Scientific Information|ISI]] Web of Knowledge) is an academic [[citation index]]ing and search service, which is combined with web linking and is provided by [[Thomson Reuters]]. Web of Knowledge covers the sciences, [[social science]]s, arts and [[humanities]]. It provides [[bibliography|bibliographic]] content and tools to access, analyze, and manage research information. Multiple databases can be searched simultaneously.<ref name=describe/><ref name=tutor>[http://science.thomsonreuters.com/tutorials/wok4/wok4tut3.html Tutorial]. ISI Web of Knowledge. Thomson Reuters. 2010. Accessed on 2010-06-24</ref>\u000a\u000a==Overview==\u000aWeb of Knowledge is described as a unifying research tool which enables the user to acquire, analyze, and disseminate database information in a timely manner. This is accomplished because of the creation of a common vocabulary, called [[Ontology (information science)|ontology]], for varied search terms and varied data. Moreover, search terms generate related information across categories.\u000a\u000aAcceptable content for Web of Knowledge is determined by an evaluation and selection process based on the following criteria: impact, influence, timeliness, [[peer review]], and geographic representation.<ref name=describe/>\u000a\u000a===Search and analysis===\u000a<!-- Deleted image removed: [[File:ISI Web of knowledge logo.jpg|thumb||Former Web of Knowledge logo]] -->\u000a\u000aWeb of Knowledge employs various search and analysis capabilities. First, citation indexing is employed, which is enhanced by the capability to search for results across disciplines. The influence, impact, history, and [[methodology]] of an idea can be followed from its first instance, notice, or referral to the present day. This technology points to a deficiency with the [[Index term|keyword]]-only method of searching. \u000a\u000aSecond, subtle trends and patterns relevant to the literature or research of interest, become apparent. Broad trends indicate significant topics of the day, as well as the history relevant to both the work at hand, and particular areas of study. \u000a\u000aThird, trends can be [[mathematical modeling|graphically]] represented.<ref name=describe>[http://thomsonreuters.com/content/science/pdf/Web_of_Knowledge_factsheet.pdf Overview and Description]. ISI Web of Knowledge. Thomson Reuters. 2010. Accessed on 2010-06-24</ref><ref>{{cite web|url=http://wokinfo.com/realfacts/qualityandquantity/|title=Web of Knowledge > Real Facts > Quality and Quantity|accessdate = 2010-05-05}}</ref>\u000a\u000a=== Content ===\u000aThe combined databases includes the following:\u000a*23,000 [[Academic journal|academic]] and [[scientific journal]]s (including [[Web of Science]] journal listings)\u000a*23,000,000 [[patent]]s\u000a*110,000 conference [[proceedings]]\u000a*9,000 websites\u000a*Coverage from the year 1900 to present day (with Web of Science)\u000a*Over 40 million source items\u000a*Integrated and simultaneous searching across multiple databases<ref name=describe/>\u000a\u000a=== Included databases ===\u000aThe Web of Knowledge suite encompasses the following databases:<ref name=dbase-List>{{Cite web| last =''ISI Web of Knowledge''| title =Suite of databases| publisher =Thomson Reuters| year =2010| url = http://thomsonreuters.com/products_services/science/science_products/a-z/isi_web_of_knowledge?parentKey=555184 | format =List of databases that are part of the Web of Knowledge suite.| accessdate =2010-06-24}}</ref><ref name=AtoZ>{{Cite web| last = ISI Web of Knowledge platform| title =Available databases A to Z| publisher =Thomson Reuters| year =2010| url =http://wokinfo.com/products_tools/products/ | format =Choose databases on method of discovery and analysis| accessdate =2010-06-24}}</ref><ref>[http://wokinfo.com/media/pdf/SSR1103443WoK5-2_web3.pdf Thomson Reuters Web of Knowledge. Thomson Reuters, 2013.]</ref>\u000a{{columns-list|colwidth=30em|\u000a*[[Biological Abstracts]]\u000a*[[Biosis Previews]] \u000a*[[CAB Abstracts]]\u000a*[[CAB Direct|CAB Global Health]]\u000a*[[Chinese Science Citation Database]]\u000a*[[Conference Proceedings Citation Index]] \u000a*[[Current Contents|Current Contents Connect]]\u000a*[[Data Citation Index]]\u000a*[[Derwent Innovations Index]]\u000a*[[Essential Science Indicators]]\u000a*[[Food Science and Technology Abstracts]]\u000a*[[Inspec]] \u000a*[[ISI Highly Cited]]\u000a*[[Journal Citation Reports]]\u000a*[[MEDLINE]] \u000a*[[Web of Science]]\u000a**[[Arts & Humanities Citation Index]]\u000a**[[Book Citation Index]] \u000a**[[Current Chemical Reactions]]\u000a**[[Index Chemicus]]\u000a**[[Science Citation Index Expanded]]\u000a**[[Social Sciences Citation Index]]\u000a*[[The Zoological Record]]\u000a}}\u000a\u000a==See also==\u000a*[[List of academic journal search engines]]\u000a\u000a==References==\u000a{{Reflist|30em}}\u000a\u000a==External links==\u000a* {{Official website|http://wokinfo.com/}}\u000a\u000a{{Thomson Reuters}}\u000a\u000a[[Category:Bibliographic databases]]\u000a[[Category:Online databases]]\u000a[[Category:Thomson Reuters]]\u000a[[Category:Citation indices]]\u000a[[Category:Scholarly search services]]
p165
sg4
S'229'
p166
sg6
VWeb of Knowledge
p167
ssI104
(dp168
g2
VThe '''Extended Boolean model''' was described in a Communications of the ACM article appearing in 1983, by Gerard Salton, Edward A. Fox, and Harry Wu. The goal of the Extended Boolean model is to overcome the drawbacks of the Boolean model that has been used in [[information retrieval]]. The Boolean model doesn't consider term weights in queries, and the result set of a Boolean query is often either too small or too big. The idea of the extended model is to make use of partial matching and term weights as in the vector space model. It combines the characteristics of the [[Vector Space Model]] with the properties of [[Boolean algebra (logic)|Boolean algebra]] and ranks the similarity between queries and documents. This way a document may be somewhat relevant if it matches some of the queried terms and will be returned as a result, whereas in the [[Standard Boolean model]] it wasn't.<ref>	\u000a{{citation | url=http://portal.acm.org/citation.cfm?id=358466 | last=Salton | first=Gerard | coauthors=Edward A. Fox, Harry Wu | title=Extended Boolean information retrieval | publisher=Communications of the ACM, Volume 26,  Issue 11 | year=1983 }}</ref>\u000a\u000aThus, the extended Boolean model can be considered as a generalization of both the Boolean and vector space models; those two are special cases if suitable settings and definitions are employed. Further, research has shown effectiveness improves relative to that for Boolean query processing.  Other research has shown that [[relevance feedback]] and [[query expansion]] can be integrated with extended Boolean query processing.\u000a\u000a==Definitions==\u000aIn the '''Extended Boolean model''', a document is represented as a vector (similarly to in the vector model). Each ''i'' [[Dimension (vector space)|dimension]] corresponds to a separate term associated with the document.\u000a\u000aThe weight of term {{math|''K<sub>x</sub>''}} associated with document {{math|''d<sub>j</sub>''}} is measured by its normalized [[Term frequency]] and can be defined as:\u000a\u000a<math>\u000aw_{x,j}=f_{x,j}*\u005cfrac{Idf_{x}}{max_{i}Idf_{i}}\u000a</math>\u000a\u000awhere {{math|''Idf<sub>x</sub>''}} is [[inverse document frequency]].\u000a\u000aThe weight vector associated with document {{math|''d<sub>j</sub>''}} can be represented as:\u000a\u000a<math>\u005cmathbf{v}_{d_j} = [w_{1,j}, w_{2,j}, \u005cldots, w_{i,j}]</math>\u000a\u000a==The 2 Dimensions Example==\u000a{{multiple image\u000a | width     = 150\u000a | image1    = 2D_Extended_Boolean_model_OR_example.png\u000a | alt1      = Figure 1\u000a | caption1  = '''Figure 1:''' The similarities of {{math|''q'' {{=}} (''K<sub>x</sub>'' &or; ''K<sub>y</sub>'')}} with documents {{math|''d<sub>j</sub>''}} and {{math|''d''<sub>''j''+1</sub>}}.\u000a | image2    = 2D_Extended_Boolean_model_AND_example.png\u000a | alt2      = Figure 2\u000a | caption2  = '''Figure 2:''' The similarities of {{math|''q'' {{=}} (''K<sub>x</sub>'' &and; ''K<sub>y</sub>'')}} with documents {{math|''d<sub>j</sub>''}} and {{math|''d''<sub>''j''+1</sub>}}.\u000a}}\u000a\u000aConsidering the space composed of two terms {{math|''K<sub>x</sub>''}} and {{math|''K<sub>y</sub>''}} only, the corresponding term weights are {{math|''w''<sub>1</sub>}} and {{math|''w''<sub>2</sub>}}.<ref>[http://www.cs.cityu.edu.hk/~cs5286/Lectures/Lwang.ppt Lusheng Wang]</ref>  Thus, for query {{math|''q<sub>or</sub>'' {{=}} (''K<sub>x</sub>'' &or; ''K<sub>y</sub>'')}}, we can calculate the similarity with the following formula:\u000a \u000a<math>sim(q_{or},d)=\u005csqrt{\u005cfrac{w_1^2+w_2^2}{2}}</math>\u000a\u000aFor query {{math|''q<sub>and</sub>'' {{=}} (''K<sub>x</sub>'' &and; ''K<sub>y</sub>'')}}, we can use:\u000a\u000a<math>sim(q_{and},d)=1-\u005csqrt{\u005cfrac{(1-w_1)^2+(1-w_2)^2}{2}}</math>\u000a\u000a==Generalizing the idea and P-norms==\u000aWe can generalize the previous 2D extended Boolean model example to higher t-dimensional space using Euclidean distances.\u000a\u000aThis can be done using [[P-norm]]s which extends the notion of distance to include p-distances, where {{math|1 &le; ''p'' &le; &infin;}} is a new parameter.<ref>{{ citation | last=Garcia | first= Dr. E. | url=http://www.miislita.com/term-vector/term-vector-6-boolean-model.html | title=The Extended Boolean Model - Weighted Queries: Term Weights, p-Norm Queries and Multiconcept Types. Boolean OR Extended? AND that is the Query }}</ref>\u000a\u000a*A generalized conjunctive query is given by:\u000a:<math>q_{or}=k_1 \u005clor^p k_2 \u005clor^p .... \u005clor^p k_t  </math>\u000a\u000a*The similarity of <math>q_{or}</math> and <math>d_j</math> can be defined as:\u000a''':<math>sim(q_{or},d_j)=\u005csqrt[p]{\u005cfrac{w_1^p+w_2^p+....+w_t^p}{t}}</math>'''\u000a\u000a*A generalized disjunctive query is given by:\u000a:<math>q_{and}=k_1 \u005cland^p k_2 \u005cland^p .... \u005cland^p k_t  </math>\u000a\u000a*The similarity of <math>q_{and}</math> and <math>d_j</math> can be defined as:\u000a:<math>sim(q_{and},d_j)=1-\u005csqrt[p]{\u005cfrac{(1-w_1)^p+(1-w_2)^p+....+(1-w_t)^p}{t}}</math>\u000a\u000a==Examples==\u000aConsider the query {{math|''q'' {{=}} (''K''<sub>1</sub> &and; ''K''<sub>2</sub>) &or; ''K''<sub>3</sub>}}. The similarity between query {{math|''q''}} and document {{math|''d''}} can be computed using the formula:\u000a\u000a<math>sim(q,d)=\u005csqrt[p]{\u005cfrac{(1-\u005csqrt[p]{(\u005cfrac{(1-w_1)^p+(1-w_2)^p}{2}}))^p+w_3^p}{2}}</math>\u000a\u000a==Improvements over the Standard Boolean Model==\u000a\u000aLee and Fox<ref>{{citation | last=Lee | first=W. C. | coauthors=E. A. Fox | year=1988 | title=Experimental Comparison of Schemes for Interpreting Boolean Queries}}</ref> compared the Standard and Extended Boolean models with three test collections, CISI, CACM and INSPEC.\u000aUsing P-norms they obtained an average precision improvement of 79%, 106% and 210% over the Standard model, for the CISI, CACM and INSPEC collections, respectively.<br>\u000aThe P-norm model is computationally expensive because of the number of exponentiation operations that it requires but it achieves much better results than the Standard model and even [[Fuzzy retrieval]] techniques. The [[Standard Boolean model]] is still the most efficient.\u000a\u000a==Further reading==\u000a* [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.1997 Adaptive Feedback Methods in an Extended Boolean Model  by Dr.Jongpill Choi]\u000a* [http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6VC8-454T5MS-2&_user=513551&_rdoc=1&_fmt=&_orig=search&_sort=d&_docanchor=&view=c&_searchStrId=1117914301&_rerunOrigin=google&_acct=C000025338&_version=1&_urlVersion=0&_userid=513551&md5=4eab0da46bfe361afa883e48f2060feb Interpolation of the extended Boolean retrieval model ]\u000a* {{citation | title=Information Retrieval: Algorithms and Data structures; Extended Boolean model | last=Fox | first=E. | coauthors=S. Betrabet , M. Koushik , W. Lee | year=1992 | publisher=Prentice-Hall, Inc. | url=http://www.scribd.com/doc/13742235/Information-Retrieval-Data-Structures-Algorithms-William-B-Frakes}}\u000a* {{citation | title=Experiments with Automatic Query Formulation in the Extended Boolean Model | url=http://www.springerlink.com/content/tk1t141253257613/ | first= Lucie | last= Skorkovská | coauthors=Pavel Ircing | year=2009 | publisher= Springer Berlin / Heidelberg}}\u000a\u000a==See also==\u000a*[[Information retrieval]]\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a{{DEFAULTSORT:Extended Boolean Model}}\u000a[[Category:Information retrieval]]
p169
sg4
S'104'
p170
sg6
VExtended Boolean model
p171
ssI234
(dp172
g2
V{{Infobox Software\u000a| name                   = Rapid Evolution\u000a| screenshot             = <!--  Commented out: [[Image:RapidEvolutionScreenshot1.jpg|thumb|right|250px]] -->\u000a| caption                = Screenshot of Rapid Evolution 2.9.0\u000a| developer              = [[Jesse Bickmore]]\u000a| frequently_updated     = yes\u000a| operating system       = Any OS that supports Java\u000a| genre                  = Music Software\u000a| website                = [http://www.mixshare.com/ Mixshare]\u000a}}\u000a'''Rapid Evolution''' (also known as RE) is an [[open source]] [[software]] tool for [[DJs]], providing filtering and searching features suitable for musicians.  It can analyze audio files and automatically determine properties such as the musical key, [[beats per minute]] (BPM), beat intensity and [[ReplayGain]]. \u000a\u000aIt supports file types [[MP3]], [[MP4]], [[WAV]], [[FLAC]], [[Ogg|OGG]], [[Advanced Audio Coding|AAC]] and [[APE tag|APE]].  It helps [[DJs]] to organize and profile their music, and assists in the process of mixing music by utilizing song metadata to be able to show harmonically compatible songs and songs of a similar style.  It allows DJs to save and remember which songs are good matches (like a personal, digital mixing journal) and to plan entire mix sets.\u000a\u000aOne of its uses is to assist in a [[DJ]] technique called [[harmonic mixing]]. Once the musical key and BPM is known for a set of songs, [[DJs]] can use [[music theory]] (such as the [[Circle of Fifths]]) to identify songs that are harmonically compatible.  The act of mixing harmonically can help eliminate [[consonance and dissonance|dissonant]] tones while mixing songs together.  Since identifying whether songs can be made harmonically compatible can be quite complex (once features such as pitch lock are introduced), the software assists DJs by being able to show them which songs in their collection can be made harmonically compatible with any particular song.  It can also assist DJs in the act of [[beatmatching]] by showing which songs are in a compatible BPM range, and the percent of BPM difference.\u000a\u000aRapid Evolution is created and released through Mixshare.com.  The metadata generated by Rapid Evolution is shared through the central servers at Mixshare.com, which can be browsed online.  There are 1 million songs added to the database sharing information such as key, BPM, styles and ratings.\u000a\u000a==History==\u000aRapid Evolution was developed for the [[Microsoft Windows|Windows]] environment and released in 2003.  Starting in version 2.0 it was switched to run on the Java platform, allowing it to run in virtually any environment.  It is still actively developed.\u000a\u000aSeveral improvements to the key detection algorithm have been introduced over the years.  Rapid Evolution is the only program which can detect advanced key modes, such as aeolian, ionian, dorian, phrygian, lydian and mixolydian.  To date, there has only been one serious comparison of key detection accuracy (including programs such as [[Mixed In Key]] and Mixmeister).  It was shown that Rapid Evolution is the most accurate.<ref>{{cite web|title=Key Detection Software Comparison|url=http://www.mixingonbeat.com/phpbb/viewtopic.php?t=2268|date=2006-04-26|accessdate=2008-03-21|publisher=MixingOnBeat}}</ref>\u000a\u000aThe program was open-sourced on November 2013. <ref>{{cite web |url=http://www.mixshare.com/cgi-bin/yabb2/YaBB.pl?num=1381954407|title=Open-sourcing forum thread |date=2013-10-13 |accessdate=2014-04-17 |publisher=Mixshare}}</ref>\u000a\u000a==Community interest==\u000aRapid Evolution was originally a freeware program.<ref>{{cite web |url=http://www.mixshare.com/wiki/doku.php?id=testimonials|title=DJ Testimonials |date=2007-01-01 |accessdate=2008-03-21 |publisher=Mixshare}}</ref>Due to its vast feature set, Rapid Evolution tends to be suited more for experienced DJs versus beginners.  \u000a\u000a== See also ==\u000a*[[Harmonic mixing]]\u000a*[[Music Theory]]\u000a*[[DJing]]\u000a\u000a== External links ==\u000a*[http://www.mixshare.com/software Download Rapid Evolution]\u000a*[http://www.mixshare.com Mixshare's Official website]\u000a*[http://www.harmonic-mixing.com Harmonic-Mixing.com]\u000a*[https://github.com/djqualia/RapidEvolution2 Source code for version 2]\u000a*[https://github.com/djqualia/RapidEvolution3 Source code for version 3]\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a[[Category:Music search engines]]\u000a[[Category:OS X multimedia software]]\u000a[[Category:Windows multimedia software]]\u000a[[Category:Audio mixing software]]
p173
sg4
S'234'
p174
sg6
VRapid Evolution
p175
ssI109
(dp176
g2
V{{Expert-subject|date=October 2010}}\u000a{{for|the skiing technique|Stem (skiing)}}\u000a'''Stemming''' is the term used in [[linguistic morphology]] and [[information retrieval]] to describe the process for reducing inflected (or sometimes derived) words to their [[word stem]], base or [[root (linguistics)|root]] form\u2014generally a written word form. The stem needs not to be identical to the [[morphological root]] of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. [[Algorithm]]s for stemming have been studied in [[computer science]] since the 1960s. Many [[search engine]]s treat words with the same stem as [[synonym]]s as a kind of [[query expansion]], a process called conflation.\u000a\u000aStemming programs are commonly referred to as stemming algorithms or stemmers.\u000a\u000a==Examples==\u000aA stemmer for English, for example, should identify the [[string literal|string]] "cats" (and possibly "catlike", "catty" etc.) as based on the root "cat", and "stemmer", "stemming", "stemmed" as based on "stem". A stemming algorithm reduces the words "fishing", "fished", and "fisher" to the root word, "fish". On the other hand, "argue", "argued", "argues", "arguing", and "argus" reduce to the stem "argu" (illustrating the case where the stem is not itself a word or root) but "argument" and "arguments" reduce to the stem "argument".<!-- using the Porter algorithm -->\u000a\u000a==History==\u000aThe first published stemmer was written by [[Julie Beth Lovins]] in 1968.<ref>{{cite journal |first=Julie Beth |last=Lovins |year=1968 |title=Development of a Stemming Algorithm |journal=Mechanical Translation and Computational Linguistics |volume=11 |pages=22\u201331 }}</ref> This paper was remarkable for its early date and had great influence on later work in this area.\u000a\u000aA later stemmer was written by [[Martin Porter]] and was published in the July 1980 issue of the journal ''Program''. This stemmer was very widely used and became the de facto standard algorithm used for English stemming. Dr. Porter received the [[Tony Kent Strix award]] in 2000 for his work on stemming and information retrieval.\u000a\u000aMany implementations of the Porter stemming algorithm were written and freely distributed; however, many of these implementations contained subtle flaws. As a result, these stemmers did not match their potential. To eliminate this source of error, Martin Porter released an official [http://tartarus.org/~martin/PorterStemmer/ free-software implementation] of the algorithm around the year 2000. He extended this work over the next few years by building [[Snowball programming language|Snowball]], a framework for writing stemming algorithms, and implemented an improved English stemmer together with stemmers for several other languages.\u000a\u000a==Algorithms==\u000aThere are several types of stemming algorithms which differ in respect to performance and accuracy and how certain stemming obstacles are overcome.\u000a\u000a===Lookup algorithms===\u000aA simple stemmer looks up the inflected form in a [[lookup table]]. The advantages of this approach is that it is simple, fast, and easily handles exceptions. The disadvantages are that all inflected forms must be explicitly listed in the table: new or unfamiliar words are not handled, even if they are perfectly regular (e.g. iPads ~ iPad), and the table may be large. For languages with simple morphology, like English, table sizes are modest, but highly inflected languages like Turkish may have hundreds of potential inflected forms for each root.\u000a\u000aA lookup approach may use preliminary part-of-speech tagging to avoid overstemming.<ref>Yatsko, V. A.; [http://yatsko.zohosites.com/y-stemmer.html ''Y-stemmer'']</ref>\u000a\u000a====The production technique====\u000aThe lookup table used by a stemmer is generally produced semi-automatically. For example, if the word is "run", then the inverted algorithm might automatically generate the forms "running", "runs", "runned", and "runly". The last two forms are valid constructions, but they are unlikely.\u000a\u000a===Suffix-stripping algorithms===\u000aSuffix stripping algorithms do not rely on a lookup table that consists of inflected forms and root form relations. Instead, a typically smaller list of "rules" is stored which provides a path for the algorithm, given an input word form, to find its root form. Some examples of the rules include:\u000a* if the word ends in 'ed', remove the 'ed'\u000a* if the word ends in 'ing', remove the 'ing'\u000a* if the word ends in 'ly', remove the 'ly'\u000a\u000aSuffix stripping approaches enjoy the benefit of being much simpler to maintain than brute force algorithms, assuming the maintainer is sufficiently knowledgeable in the challenges of linguistics and morphology and encoding suffix stripping rules. Suffix stripping algorithms are sometimes regarded as crude given the poor performance when dealing with exceptional relations (like 'ran' and 'run'). The solutions produced by suffix stripping algorithms are limited to those [[lexical category|lexical categories]] which have well known suffixes with few exceptions. This, however, is a problem, as not all parts of speech have such a well formulated set of rules. Lemmatisation attempts to improve upon this challenge.\u000a\u000aPrefix stripping may also be implemented. Of course, not all languages use prefixing or suffixing.\u000a\u000a====Additional algorithm criteria====\u000aSuffix stripping algorithms may differ in results for a variety of reasons. One such reason is whether the algorithm constrains whether the output word must be a real word in the given language. Some approaches do not require the word to actually exist in the language lexicon (the set of all words in the language). Alternatively, some suffix stripping approaches maintain a database (a large list) of all known morphological word roots that exist as real words. These approaches check the list for the existence of the term prior to making a decision. Typically, if the term does not exist, alternate action is taken. This alternate action may involve several other criteria. The non-existence of an output term may serve to cause the algorithm to try alternate suffix stripping rules.\u000a\u000aIt can be the case that two or more suffix stripping rules apply to the same input term, which creates an ambiguity as to which rule to apply. The algorithm may assign (by human hand or stochastically) a priority to one rule or another. Or the algorithm may reject one rule application because it results in a non-existent term whereas the other overlapping rule does not. For example, given the English term ''friendlies'', the algorithm may identify the ''ies'' suffix and apply the appropriate rule and achieve the result of ''friendl''. ''friendl'' is likely not found in the lexicon, and therefore the rule is rejected.\u000a\u000aOne improvement upon basic suffix stripping is the use of suffix substitution. Similar to a stripping rule, a substitution rule replaces a suffix with an alternate suffix. For example, there could exist a rule that replaces ''ies'' with ''y''. How this affects the algorithm varies on the algorithm's design. To illustrate, the algorithm may identify that both the ''ies'' suffix stripping rule as well as the suffix substitution rule apply. Since the stripping rule results in a non-existent term in the lexicon, but the substitution rule does not, the substitution rule is applied instead. In this example, ''friendlies'' becomes ''friendly'' instead of ''friendl''.\u000a\u000aDiving further into the details, a common technique is to apply rules in a cyclical fashion (recursively, as computer scientists would say). After applying the suffix substitution rule in this example scenario, a second pass is made to identify matching rules on the term ''friendly'', where the ''ly'' stripping rule is likely identified and accepted. In summary, ''friendlies'' becomes (via substitution) ''friendly'' which becomes (via stripping) ''friend''.\u000a\u000aThis example also helps illustrate the difference between a rule-based approach and a brute force approach. In a brute force approach, the algorithm would search for ''friendlies'' in the set of hundreds of thousands of inflected word forms and ideally find the corresponding root form ''friend''. In the rule-based approach, the three rules mentioned above would be applied in succession to converge on the same solution. Chances are that the rule-based approach would be slower, as lookup algorithms have a direct access to the solution, while rule-based should try several options, and combinations of them, and then choose which result seems to be the best.\u000a\u000a===Lemmatisation algorithms===\u000aA more complex approach to the problem of determining a stem of a word is [[lemmatisation]]. This process involves first determining the [[part of speech]] of a word, and applying different normalization rules for each part of speech. The part of speech is first detected prior to attempting to find the root since for some languages, the stemming rules change depending on a word's part of speech.\u000a\u000aThis approach is highly conditional upon obtaining the correct lexical category (part of speech). While there is overlap between the normalization rules for certain categories, identifying the wrong category or being unable to produce the right category limits the added benefit of this approach over suffix stripping algorithms. The basic idea is that, if the stemmer is able to grasp more information about the word being stemmed, then it can apply more accurate normalization rules (which unlike suffix stripping rules can also modify the stem).\u000a\u000a===Stochastic algorithms===\u000a[[Stochastic]] algorithms involve using probability to identify the root form of a word. Stochastic algorithms are trained (they "learn") on a table of root form to inflected form relations to develop a probabilistic model. This model is typically expressed in the form of complex linguistic rules, similar in nature to those in suffix stripping or lemmatisation. Stemming is performed by inputting an inflected form to the trained model and having the model produce the root form according to its internal ruleset, which again is similar to suffix stripping and lemmatisation, except that the decisions involved in applying the most appropriate rule, or whether or not to stem the word and just return the same word, or whether to apply two different rules sequentially, are applied on the grounds that the output word will have the highest probability of being correct (which is to say, the smallest probability of being incorrect, which is how it is typically measured).\u000a\u000aSome lemmatisation algorithms are stochastic in that, given a word which may belong to multiple parts of speech, a probability is assigned to each possible part. This may take into account the surrounding words, called the context, or not. Context-free grammars do not take into account any additional information. In either case, after assigning the probabilities to each possible part of speech, the most likely part of speech is chosen, and from there the appropriate normalization rules are applied to the input word to produce the normalized (root) form.\u000a\u000a===''n''-gram analysis===\u000aSome stemming techniques use the [[n-gram]] context of a word to choose the correct stem for a word.<ref name="Workshop2006">{{cite book|author=Cross-Language Evaluation Forum. Workshop|title=Accessing Multilingual Information Repositories: 6th Workshop of the Cross-Language Evaluation Forum, CLEF 2005, Vienna, Austria, 21-23 September, 2005, Revised Selected Papers|url=http://books.google.com/books?id=jWKzNGr1H0AC&pg=PA159|date=20 September 2006|publisher=Springer|isbn=978-3-540-45697-1|pages=159\u2013}}</ref>\u000a\u000a===Hybrid approaches===\u000aHybrid approaches use two or more of the approaches described above in unison. A simple example is a [[probabilistic suffix tree|suffix tree]] algorithm which first consults a lookup table using brute force. However, instead of trying to store the entire set of relations between words in a given language, the lookup table is kept small and is only used to store a minute amount of "frequent exceptions" like "ran => run". If the word is not in the exception list, apply suffix stripping or lemmatisation and output the result.\u000a\u000a===Affix stemmers===\u000aIn [[linguistics]], the term [[affix]] refers to either a [[prefix]] or a [[suffix]]. In addition to dealing with suffixes, several approaches also attempt to remove common prefixes. For example, given the word ''indefinitely'', identify that the leading "in" is a prefix that can be removed. Many of the same approaches mentioned earlier apply, but go by the name '''affix stripping'''. A study of affix stemming for several European languages can be found here.<ref>Jongejan, B.; and Dalianis, H.; ''Automatic Training of Lemmatization Rules that Handle Morphological Changes in pre-, in- and Suffixes Alike'', in the ''Proceeding of the ACL-2009, Joint conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, Singapore, August 2\u20137, 2009'', pp. 145-153\u000a[http://www.aclweb.org/anthology/P/P09/P09-1017.pdf]</ref>\u000a\u000a===Matching algorithms===\u000aSuch algorithms use a stem database (for example a set of documents that contain stem words). These stems, as mentioned above, are not necessarily valid words themselves (but rather common sub-strings, as the "brows" in "browse" and in "browsing"). In order to stem a word the algorithm tries to match it with stems from the database, applying various constraints, such as on the relative length of the candidate stem within the word (so that, for example, the short prefix "be", which is the stem of such words as "be", "been" and "being", would not be considered as the stem of the word "beside").\u000a\u000a==Language challenges==\u000aWhile much of the early academic work in this area was focused on the English language (with significant use of the Porter Stemmer algorithm), many other languages have been investigated.<ref>Dolamic, Ljiljana; and Savoy, Jacques; [http://clef.isti.cnr.it/2007/working_notes/DolamicCLEF2007.pdf ''Stemming Approaches for East European Languages (CLEF 2007)'']</ref><ref>Savoy, Jacques; [http://portal.acm.org/citation.cfm?doid=1141277.1141523 ''Light Stemming Approaches for the French, Portuguese, German and Hungarian Languages''], ACM Symposium on Applied Computing, SAC 2006, ISBN 1-59593-108-2</ref><ref>Popovi\u010d, Mirko; and Willett, Peter (1992); [http://onlinelibrary.wiley.com/doi/10.1002/%28SICI%291097-4571%28199206%2943:5%3C384::AID-ASI6%3E3.0.CO;2-L/abstract ''The Effectiveness of Stemming for Natural-Language Access to Slovene Textual Data''], Journal of the [[American Society for Information Science]], Volume 43, Issue 5 (June), pp. 384\u2013390</ref><ref>[http://staff.science.uva.nl/~mdr/Publications/Files/clef2005-proc-adhoc.pdf ''Stemming in Hungarian at CLEF 2005'']</ref><ref>Viera, A. F. G. & Virgil, J. (2007); [http://InformationR.net/ir/12-3/paper315.html ''Uma revisão dos algoritmos de radicalização em língua portuguesa''], Information Research, 12(3), paper 315</ref>\u000a\u000aHebrew and Arabic are still considered difficult research languages for stemming. English stemmers are fairly trivial (with only occasional problems, such as "dries" being the third-person singular present form of the verb "dry", "axes" being the plural of "axe" as well as "axis"); but stemmers become harder to design as the morphology, orthography, and character encoding of the target language becomes more complex. For example, an Italian stemmer is more complex than an English one (because of a greater number of verb inflections), a Russian one is more complex (more noun [[declension]]s), a Hebrew one is even more complex (due to [[nonconcatenative morphology]], a writing system without vowels, and the requirement of prefix stripping: Hebrew stems can be two, three or four characters, but not more), and so on.\u000a\u000a===Multilingual stemming===\u000aMultilingual stemming applies morphological rules of two or more languages simultaneously instead of rules for only a single language when interpreting a search query. Commercial systems using multilingual stemming exist{{CN|date=October 2013}}.\u000a\u000a==Error metrics==\u000aThere are two error measurements in stemming algorithms, overstemming and understemming. Overstemming is an error where two separate inflected words are stemmed to the same root, but should not have been\u2014a [[false positive]]. Understemming is an error where two separate inflected words should be stemmed to the same root, but are not\u2014a [[false negative]]. Stemming algorithms attempt to minimize each type of error, although reducing one type can lead to increasing the other.\u000a\u000aFor example, the widely used Porter stemmer stems "universal", "university", and "universe" to "univers". This is a case of overstemming: though these three words are etymologically related, their modern meanings are in widely different domains, so treating them as synonyms in a search engine will likely reduce the relevance of the search results.\u000a\u000aAn example of understemming in the Porter stemmer is "alumnus" \u2192 "alumnu", "alumni" \u2192 "alumni", "alumna"/"alumnae" \u2192 "alumna".  This English word keeps Latin morphology, and so these near-synonyms are not conflated.\u000a\u000a==Applications==\u000aStemming is used as an approximate method for grouping words with a similar basic meaning together. For example, a text mentioning "daffodils" is probably closely related to a text mentioning "daffodil" (without the s). But in some cases, words with the same morphological stem have [[idiom]]atic meanings which are not closely related: a user searching for "marketing" will not be satisfied by most documents mentioning "markets" but not "marketing".\u000a\u000a===Information retrieval===\u000aStemmers are common elements in [[Information Retrieval|query systems]] such as [[World Wide Web|Web]] [[search engine]]s. The effectiveness of stemming for English query systems were soon found to be rather limited, however, and this has led early [[information retrieval]] researchers to deem stemming irrelevant in general.<ref>Baeza-Yates, Ricardo; and Ribeiro-Neto, Berthier (1999); ''Modern Information Retrieval'', ACM Press/Addison Wesley</ref> An alternative approach, based on searching for [[n-gram]]s rather than stems, may be used instead. Also, recent research has shown greater benefits for retrieval in other languages.<ref>Kamps, Jaap; Monz, Christof; de Rijke, Maarten; and Sigurbjörnsson, Börkur (2004); ''Language-Dependent and Language-Independent Approaches to Cross-Lingual Text Retrieval'', in Peters, C.; Gonzalo, J.; Braschler, M.; and Kluck, M. (eds.); ''Comparative Evaluation of Multilingual Information Access Systems'', Springer Verlag, pp. 152\u2013165</ref><ref>Airio, Eija (2006); ''Word Normalization and Decompounding in Mono- and Bilingual IR'', Information Retrieval '''9''':249\u2013271</ref>\u000a\u000a===Domain Analysis===\u000aStemming is used to determine domain vocabularies in [[domain analysis]].\u000a<ref>Frakes, W.; Prieto-Diaz, R.; & Fox, C. (1998); ''DARE: Domain Analysis and Reuse Environment'', Annals of Software Engineering (5), pp. 125-141</ref>\u000a\u000a===Use in commercial products===\u000aMany commercial companies have been using stemming since at least the 1980s and have produced algorithmic and lexical stemmers in many languages.<ref>[http://www.dtsearch.co.uk/language.htm ''Language Extension Packs''], dtSearch</ref><ref>[http://technet2.microsoft.com/Office/en-us/library/87065c9d-d39d-479d-909b-02160ec6d7791033.mspx?mfr=true ''Building Multilingual Solutions by using Sharepoint Products and Technologies''], Microsoft Technet</ref>\u000a\u000aThe Snowball stemmers have been compared with commercial lexical stemmers with varying results.<ref>[http://clef.isti.cnr.it/2003/WN_web/19.pdf CLEF 2003: Stephen Tomlinson compared the Snowball stemmers with the Hummingbird lexical stemming (lemmatization) system]</ref><ref>[http://clef.isti.cnr.it/2004/working_notes/WorkingNotes2004/21.pdf CLEF 2004: Stephen Tomlinson "Finnish, Portuguese and Russian Retrieval with Hummingbird SearchServer"]</ref>\u000a\u000a[[Google search]] adopted word stemming in 2003.<ref>[http://www.google.com/support/bin/static.py?page=searchguides.html&ctx=basics#stemming ''The Essentials of Google Search''], Web Search Help Center, [[Google|Google Inc.]]</ref> Previously a search for "fish" would not have returned "fishing". Other software search algorithms vary in their use of word stemming. Programs that simply search for substrings obviously will find "fish" in "fishing" but when searching for "fishes" will not find occurrences of the word "fish".\u000a\u000a==See also==\u000a* [[Root (linguistics)]] - linguistic definition of the term "root"\u000a* [[Stem (linguistics)]] - linguistic definition of the term "stem"\u000a* [[Morphology (linguistics)]]\u000a* [[Lemma (morphology)]] - linguistic definition\u000a* [[Lemmatization]]\u000a* [[Lexeme]]\u000a* [[Inflection]]\u000a* [[Derivation (linguistics)|Derivation]] - stemming is a form of reverse derivation\u000a* [[Natural language processing]] - stemming is generally regarded as a form of NLP\u000a* [[Text mining]] - stemming algorithms play a major role in commercial NLP software\u000a* [[Computational linguistics]]\u000a\u000a{{Natural Language Processing}}\u000a\u000a==References==\u000a{{reflist|2}}\u000a\u000a==Further reading==\u000a{{refbegin|2}}\u000a* Dawson, J. L. (1974); ''Suffix Removal for Word Conflation'', Bulletin of the Association for Literary and Linguistic Computing, 2(3): 33\u201346\u000a* Frakes, W. B. (1984); ''Term Conflation for Information Retrieval'', Cambridge University Press\u000a* Frakes, W. B. & Fox, C. J. (2003); ''Strength and Similarity of Affix Removal Stemming Algorithms'', SIGIR Forum, 37: 26\u201330\u000a* Frakes, W. B. (1992); ''Stemming algorithms, Information retrieval: data structures and algorithms'', Upper Saddle River, NJ: Prentice-Hall, Inc.\u000a* Hafer, M. A. & Weiss, S. F. (1974); ''Word segmentation by letter successor varieties'', Information Processing & Management 10 (11/12), 371\u2013386\u000a* Harman, D. (1991); ''How Effective is Suffixing?'', Journal of the American Society for Information Science 42 (1), 7\u201315\u000a* Hull, D. A. (1996); ''Stemming Algorithms&nbsp;\u2013 A Case Study for Detailed Evaluation'', JASIS, 47(1): 70\u201384\u000a* Hull, D. A. & Grefenstette, G. (1996); ''A Detailed Analysis of English Stemming Algorithms'', Xerox Technical Report\u000a* Kraaij, W. & Pohlmann, R. (1996); ''Viewing Stemming as Recall Enhancement'', in Frei, H.-P.; Harman, D.; Schauble, P.; and Wilkinson, R. (eds.); ''Proceedings of the 17th ACM SIGIR conference held at Zurich, August 18\u201322'', pp.&nbsp;40\u201348\u000a* Krovetz, R. (1993); ''Viewing Morphology as an Inference Process'', in ''Proceedings of ACM-SIGIR93'', pp.&nbsp;191\u2013203\u000a* Lennon, M.; Pierce, D. S.; Tarry, B. D.; & Willett, P. (1981); ''An Evaluation of some Conflation Algorithms for Information Retrieval'', Journal of Information Science, 3: 177\u2013183\u000a* Lovins, J. (1971); ''[http://www.eric.ed.gov/sitemap/html_0900000b800c571a.html Error Evaluation for Stemming Algorithms as Clustering Algorithms]'', JASIS, 22: 28\u201340\u000a* Lovins, J. B. (1968); ''Development of a Stemming Algorithm'', Mechanical Translation and Computational Linguistics, 11, 22\u201431\u000a* Jenkins, Marie-Claire; and Smith, Dan (2005); [http://www.uea.ac.uk/polopoly_fs/1.85493!stemmer25feb.pdf ''Conservative Stemming for Search and Indexing'']\u000a* Paice, C. D. (1990); ''[http://www.comp.lancs.ac.uk/computing/research/stemming/paice/article.htm Another Stemmer]'', SIGIR Forum, 24: 56\u201361\u000a* Paice, C. D. (1996) ''[http://www3.interscience.wiley.com/cgi-bin/abstract/57804/ABSTRACT Method for Evaluation of Stemming Algorithms based on Error Counting]'', JASIS, 47(8): 632\u2013649\u000a* Popovi\u010d, Mirko; and Willett, Peter (1992); [http://onlinelibrary.wiley.com/doi/10.1002/%28SICI%291097-4571%28199206%2943:5%3C384::AID-ASI6%3E3.0.CO;2-L/abstract ''The Effectiveness of Stemming for Natural-Language Access to Slovene Textual Data''], Journal of the [[American Society for Information Science]], Volume 43, Issue 5 (June), pp.&nbsp;384\u2013390\u000a* Porter, Martin F. (1980); ''[http://telemat.det.unifi.it/book/2001/wchange/download/stem_porter.html An Algorithm for Suffix Stripping]'', Program, 14(3): 130\u2013137\u000a* Savoy, J. (1993); ''[http://www3.interscience.wiley.com/cgi-bin/abstract/10049824/ABSTRACT?CRETRY=1&SRETRY=0 Stemming of French Words Based on Grammatical Categories]'' Journal of the American Society for Information Science, 44(1), 1\u20139\u000a* Ulmschneider, John E.; & Doszkocs, Tamas (1983); ''[http://www.eric.ed.gov/sitemap/html_0900000b8007ea83.html A Practical Stemming Algorithm for Online Search Assistance]'', Online Review, 7(4), 301\u2013318\u000a* Xu, J.; & Croft, W. B. (1998); ''[http://portal.acm.org/citation.cfm?doid=267954.267957 Corpus-Based Stemming Using Coocurrence of Word Variants]'', ACM Transactions on Information Systems, 16(1), 61\u201381\u000a{{refend}}\u000a\u000a==External links==\u000a*[http://opennlp.apache.org/index.html Apache OpenNLP] includes Porter and Snowball stemmers\u000a* [http://smile-stemmer.appspot.com SMILE Stemmer] - free online service, includes Porter and Paice/Husk' Lancaster stemmers (Java API)\u000a* [http://code.google.com/p/ir-themis/ Themis] - open source IR framework, includes Porter stemmer implementation (PostgreSQL, Java API)\u000a* [http://snowball.tartarus.org Snowball] - free stemming algorithms for many languages, includes source code, including stemmers for five romance languages\u000a* [http://www.iveonik.com/blog/2011/08/snowball-stemmers-on-csharp-free-download/ Snowball on C#] - port of Snowball stemmers for C# (14 languages)\u000a* [http://snowball.tartarus.org/wrappers/guide.html Python bindings to Snowball API]\u000a* [http://locknet.ro/archive/2009-10-29-ann-ruby-stemmer.html Ruby-Stemmer] - Ruby extension to Snowball API\u000a* [http://pecl.php.net/package/stem/ PECL] - PHP extension to the Snowball API\u000a* [http://www.oleandersolutions.com/stemming.html Oleander Porter's algorithm] - stemming library in C++ released under BSD\u000a* [http://www.cs.waikato.ac.nz/~eibe/stemmers/index.html Unofficial home page of the Lovins stemming algorithm] - with source code in a couple of languages\u000a* [http://www.tartarus.org/~martin/PorterStemmer/index.html Official home page of the Porter stemming algorithm] - including source code in several languages\u000a* [http://www.comp.lancs.ac.uk/computing/research/stemming/index.htm Official home page of the Lancaster stemming algorithm] - Lancaster University, UK\u000a* [http://www.cmp.uea.ac.uk/Research/stemmer/ Official home page of the UEA-Lite Stemmer ] - University of East Anglia, UK\u000a* [http://www.comp.lancs.ac.uk/computing/research/stemming/general/index.htm Overview of stemming algorithms]\u000a* [http://code.google.com/p/ptstemmer/ PTStemmer] - A Java/Python/.Net stemming toolkit for the Portuguese language\u000a* [http://mazko.github.com/jssnowball/ jsSnowball] - open source JavaScript implementation of Snowball stemming algorithms for many languages\u000a* [http://trimc-nlp.blogspot.com/2013/08/snowball-stemmer-for-java.html Snowball Stemmer] - implementation for Java\u000a* [http://hlt.di.fct.unl.pt/luis/hindi_stemmer/ hindi_stemmer] - open source stemmer for Hindi\u000a* [http://hlt.di.fct.unl.pt/luis/czech_stemmer/ czech_stemmer] - open source stemmer for Czech\u000a* [http://www.comp.leeds.ac.uk/eric/sawalha08coling.pdf Comparative Evaluation of Arabic Language Morphological Analysers and Stemmers]\u000a* [https://github.com/rdamodharan/tamil-stemmer Tamil Stemmer]\u000a\u000a{{FOLDOC}}\u000a\u000a[[Category:Linguistic morphology]]\u000a[[Category:Natural language processing]]\u000a[[Category:Tasks of natural language processing]]\u000a[[Category:Computational linguistics]]\u000a[[Category:Information retrieval]]
p177
sg4
S'109'
p178
sg6
VStemming
p179
ssI239
(dp180
g2
V{{use mdy dates|date=July 2014}}\u000a{{use American English|date=July 2014}}\u000a{{Infobox website\u000a|name           = Songza\u000a|logo           = [[File:Songza Logo.jpg|frameless|150px]]\u000a|screenshot     = \u000a|caption        = \u000a|url            = {{URL|songza.com}}\u000a|alexa          = {{Loss}} 9,279 ({{as of|2014|4|1|alt=April 2014}})<ref name="alexa">{{cite web|url= http://www.alexa.com/siteinfo/songza.com |title= Songza.com Site Info | publisher= [[Alexa Internet]] |accessdate= April 1, 2014 }}</ref><!--Updated monthly by OKBot.-->\u000a|commercial     = \u000a|type           = Free [[internet radio]]\u000a|language       = [[English language|English]]\u000a|location       = [[Long Island City, New York|Long Island City]], [[Queens]], [[New York City]], [[New York]], United States\u000a|registration   = \u000a|owner          = [[Google Inc.]]\u000a|author         = [[Aza Raskin]] and Scott Robbin\u000a|launch date    = {{start date and age|2007|11|08|paren=yes}}\u000a|current status = Active\u000a|revenue        = \u000a|slogan         = Good music makes good times.<ref>{{cite web|url= http://songza.com |title= Songza.com Site Info | publisher= Songza Media, Inc. |accessdate= August 15, 2012 }}</ref>\u000a}}\u000a\u000a'''Songza''' is a free [[music streaming]] and [[Recommender system|recommendation]] service for Internet users in the United States and Canada. \u000a\u000aStating that its playlists are made by music experts, the service recommends various playlists based on time of day and mood or activity.<ref name="The New York Times">{{cite news| first= Ben| last= Sisaro| work = [[The New York Times]] |title= Pandora Faces Rivals for Ears and Ads| accessdate = June 20, 2012| url= http://www.nytimes.com/2012/06/21/business/songza-and-spotify-challenge-pandora-for-ears-and-ads.html?_r=3| date= June 20, 2012}}</ref><ref name=PandoDaily>{{cite web| first= Erin|last= Griffith| publisher= [[PandoDaily]]|title= Songza's Founders Realized They Weren't Thinking Radically Enough{{spaced ndash}} Here's How They Changed That| accessdate = August 15, 2012|url= http://pandodaily.com/2012/08/15/songzas-founders-realized-they-werent-thinking-radically-enough-heres-how-they-changed-that/}}</ref> Songza offers playlists for activities such as waking up, working out, commuting, concentrating, unwinding, entertaining, and sleeping.<ref name="The Washington Post" >{{cite news| first= Hayley| last= Tsukayama| work = [[The Washington Post]] |title=TechBits: Songza adapts the music to your mood| accessdate = June 23, 2012| url = http://www.washingtonpost.com/techbits-songza-adapts-the-music-to-your-mood/2012/06/23/gJQAYRzKyV_story.html| date= June 25, 2012}}</ref>  Users can vote songs up or down, and the service will adapt to the user's personal music preferences.<ref name="The Washington Post" /> Users can find playlists not just based on artists, songs, or genres, but also based on themes, interests, and eras, such as "[[List of 1990s one-hit wonders in the United States|90s One-Hit Wonders]]", or "Music of [[Fashion Week]]".<ref name=SongzaAbout>{{cite web| publisher= Songza|title= About Us| accessdate = March 25, 2011| url = http://songza.com/page/about/}}</ref>\u000a\u000aSongza is headquartered in the [[Long Island City]] neighborhood of the [[Queens]] [[borough (New York City)|borough]] of [[New York City]], [[New York]].<ref name="NY Daily News">{{cite news| first= Clare | last= Trapasso| work = [[Daily News (New York)|Daily News]] |title= Songza music service streams for success| accessdate = July 27, 2012| url= http://articles.nydailynews.com/2012-07-27/news/32874462_1_spotify-apps-music-download}}</ref>\u000a\u000a== History ==\u000a[[Amie Street]] acquired Songza, a product created by [[Aza Raskin]] and Scott Robbin, in October 2008.<ref>{{cite web| first= Kristen| last=Nicole| publisher= bub.blicio.us |title= Interview with Amie Street: Why Keep Acquisition of Songza a Secret?| accessdate = March 25, 2011| url = http://bub.blicio.us/interview-with-amie-street-why-keep-acquisition-of-songza-a-secret/}}</ref> In August 2010, Amie Street was sold to Amazon for an undisclosed amount.<ref>{{cite web| first= Michael | last= Arrington| publisher= [[TechCrunch]]|title= Amazon Acquires Amie Street, But Not in a Good Way| accessdate = September 8, 2010| url= http://techcrunch.com/2010/09/08/amazon-acquires-amie-street-but-not-in-a-good-way/}}</ref>  Shortly after this the co-founders{{spaced ndash}} CEO Elias Roman, COO Peter Asbill, CPO Elliott Breece and CCO Eric Davich{{spaced ndash}} refocused their efforts on Songza.<ref name="The New York Times" /><ref>{{cite web| publisher= [[Internships.com]]|title= 5 in 5! with Eric Davich, Chief Content Officer and Co-Founder of Songza| accessdate = August 6, 2012| url= http://www.internships.com/eyeoftheintern/applying-2/employers-applying-2/5-5-eric-davichchief-content-officer-cofounder-songza/?cid=SO_ST_TW_080612_5IN5_SONGZA}}</ref>  The team discontinued the original version and relaunched a new alpha version of Songza, keeping nothing of the original product but the name.<ref name=Upstart>{{cite news| first= Michael| last= del Castillo| work =  [[American City Business Journals|Upstart Business Journal]] |title= Downtime: The birth of Songza| accessdate = June 15, 2012| url= http://upstart.bizjournals.com/entrepreneurs/hot-shots/2012/06/15/songza-minigolfs-to-no-1-app.html?page=2}}</ref>\u000a\u000aOver the next year the founders experimented with various iterations, when the app originally launched in 2010 "it was like a pre-Turntable.fm.  A function called Social Radio allowed users to be DJs for their friends" stated PandoDaily.<ref name="PandoDaily" />  This version of the app allowed it to be social and crowdsourced; the problem with it was that the service as it stood was not sufficiently differentiated from other services on the market and the quality of the crowd sourced playlists was low.<ref name=PandoDaily/>  Following a year of testing various iterations of the alpha version of the app, Songza relaunched in beta on iPhone and Android apps on September 13, 2011, armed with a team of 25 expert music curators.<ref name="The New York Times" /><ref name="PandoDaily" /><ref name=TechCrunch>{{cite web| first= Rip| last= Empson| publisher= [[TechCrunch]]|title= Songza Raises Seven Figure Round; Launches Mobile, Sharable Music Collections in the Cloud| accessdate = September 13, 2011| url= http://techcrunch.com/2011/09/13/songza-raises-seven-figure-round-launches-mobile-sharable-music-collections-in-the-cloud/}}</ref><ref>[http://www.ad60.com/2011/09/19/songza-launches-iphone-android-apps-digitize-mix-tape/ "Songza launches iPhone and Android apps to digitize the mix tape"].</ref>\u000a\u000aIn March 2012, Songza released its Music Concierge feature, on iPhone and the web.<ref name="The New York Times" /><ref name = TechCrunch>{{cite web| first= Jordan| last= Crook| publisher= [[TechCrunch.com]]|title= Songza, the Music Streaming Service That Does All Work for You, Launches an iPad App| accessdate = June 7, 2012| url= http://techcrunch.com/2012/06/07/songza-the-music-streaming-service-that-does-all-work-for-you-launches-an-ipad-app/}}</ref>  The concierge presents users with up to six situations based on time of day, with filters for whatever mood they might be in.  For example, on a Wednesday morning a user might be presented with situations for "Waking Up", "Singing in the Shower", "Working Out" and so on.  This feature was rolled out to iPad on June 7, 2012; during the first ten days following the iPad app launch, Songza saw over 1.15 million downloads.<ref>{{cite news| first= Stephanie| last= Mlot| work = [[PC Magazine]]|title= Songza Hits 1.15 Million iOS Downloads in 10 Days| accessdate = June 18, 2012| url= http://www.pcmag.com/article2/0,2817,2405952,00.asp}}</ref>\u000a\u000aOn June 12, 2012, Songza was listed as the top free app on iTunes for the iPad and the number two free app for the iPhone.<ref>{{cite web| first= Glenn| last= Peoples| publisher= [[Billboard.biz]]|title= Songza Reaches One Million iOs Downloads in Ten Days, But Is It the Next Big Thing?| accessdate = June 19, 2012| url= http://www.billboard.biz/bbbiz/others/songza-reaches-one-million-ios-downloads-1007360352.story}}</ref>  Concierge was released on Android on July 10, 2012, and for Android tablets on August 14, 2012.<ref>{{cite web| first= Andrew| last= Kameka| publisher= Androinica.com |title= Songza re-ups with expert Music Concierge playlists, lockscreen controls, and new Holo-like design| accessdate = July 10, 2012| url= http://androinica.com/2012/07/songza-android-app/}}</ref><ref>{{cite news| first= Stephanie| last= Mlot| work = [[PC Magazine]]|title= Songza App Now Available on Android Tablets| accessdate = August 14, 2012| url= http://www.pcmag.com/article2/0,2817,2408435,00.asp}}</ref>  The app expanded to Canada on August 7, 2012, and became the number-one overall free app in Canada on August 13, 2012.<ref name=PandoDaily/><ref>{{cite web| first= Anand| last= Ram| publisher= o.canada.com |title= Songza's Elias Roman wants to provide the music for every mood | accessdate = August 7, 2012| url= http://o.canada.com/2012/08/05/songzas-elias-roman-wants-to-provide-the-music-for-every-mood/}}</ref> Within the week of Microsoft's Build developer event in June 2013, Songza snuck in its official Windows 8 App.<ref>[http://www.wpcentral.com/songza-sneaks-windows-store-wins-our-hearts]. WP Central. June 27, 2013.</ref>\u000a\u000aSongza launched in Canada on August 7, 2012, and reached the one million download mark after 70 days.<ref>Dobby, Christine (August 23, 2012).  [http://business.financialpost.com/2012/08/23/songza-startup-singing-a-canadian-tune/ "Songza startup singing a Canadian tune"].  ''[[Financial Post]]''. August 23, 2012.</ref><ref>Crook, Jordan (October 18, 2012). [http://techcrunch.com/2012/10/18/songzas-canada-launch-nabs-1-million-new-users-in-70-days/ "Songza's Canada Launch Nabs 1 Million New Users in 70 Days"]. [[TechCrunch]].</ref>\u000a\u000aStarting October 2013, Songza began inserting pop-up audio/video ads when initiating a playlist so it is no longer "audio-ad free". Songza reported having 5.5 million regular users at the end of 2013.<ref>{{Cite news|url = http://www.nytimes.com/2014/07/02/business/media/google-buys-songza-a-playlist-app-for-any-occasion.html|title = Google in Deal for Songza, a Music Playlist Service|last = Sisario|first = Ben|date = July 1, 2014|work = New York Times|accessdate = }}</ref>\u000a\u000aSongza was acquired by Google on July 1, 2014.<ref>{{cite web | url=http://techcrunch.com/2014/07/01/google-buys-songza/ | title=Google Buys Songza | publisher= [[TechCrunch]] | accessdate= July 1, 2014}}</ref> No terms were disclosed but speculation put the price at somewhere between $15 million and $39 million. Both companies issued statements saying they were "thrilled" to be doing the deal.<ref name="GoogleSongza">{{cite news|title=Google acquires music app start-up Songza|url=http://www.businesssun.com/index.php/sid/223470673/scat/3a8a80d6f705f8cc/ht/Google-acquires-music-app-start-up-Songza|accessdate= July 3, 2014|publisher=''Business Sun''}}</ref> In October 2014, following the acquisition, the [[Google Play Music|Google Play Music All Access]] service was updated to include functionality adapted from Songza's Concierge system.<ref name=verge-songzagpm>{{cite web|title=Google brings Songza's best feature to Play Music|url=http://www.theverge.com/2014/10/21/7027707/google-brings-best-songza-feature-to-play-music|website=The Verge|accessdate=21 October 2014}}</ref>\u000a\u000a==Similar organizations==\u000a{{div col|colwidth=30em}}\u000a* [[8tracks]]\u000a* [[AccuRadio]]\u000a* [[Deezer]]\u000a* [[Digitally Imported]]\u000a* [[FIT Radio]]\u000a* [[Google Play Music]]\u000a* [[Grooveshark]]\u000a* [[Guvera]]\u000a* [[iHeartRadio]]\u000a* [[Live365]]\u000a* [[MOG (online music)|MOG]]\u000a* [[Musicovery]]\u000a* [[Pandora Radio]]\u000a* [[Rara.com]]\u000a* [[Rdio]]\u000a* [[Rhapsody (online music service)|Rhapsody]]\u000a* [[Slacker Radio]]\u000a* [[Spotify]]\u000a* [[Soundtracker (music streaming)]]\u000a* [[WiMP]]\u000a* [[Xbox Music]]\u000a{{div col end}}\u000a\u000a\u000a{{portal|Companies|Music}}\u000a\u000a==References==\u000a{{reflist|30em}}\u000a==External links==\u000a*{{official website|songza.com}}\u000a\u000a{{Digital distribution platforms}}\u000a{{Google Inc.}}\u000a\u000a[[Category:American companies established in 2007]]\u000a[[Category:Community websites]]\u000a[[Category:Companies based in Queens, New York]]\u000a[[Category:Domain-specific search engines]]\u000a[[Category:Free music]]\u000a[[Category:Google acquisitions]]\u000a[[Category:Internet advertising]]\u000a[[Category:Internet companies of the United States]]\u000a[[Category:Internet properties established in 2007]]\u000a[[Category:Internet radio in the United States]]\u000a[[Category:Long Island City]]\u000a[[Category:Media companies based in New York City]]\u000a[[Category:Music companies of the United States]]\u000a[[Category:Music search engines]]\u000a[[Category:Recommender systems]]\u000a[[Category:Technology companies established in 2007]]
p181
sg4
S'239'
p182
sg6
VSongza
p183
ssI114
(dp184
g2
V'''Nearest neighbor search''' ('''NNS'''), also known as '''proximity search''', '''similarity search''' or '''[[Closest pair of points problem|closest point search]]''',  is an [[optimization problem]] for finding closest (or most similar) points. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set ''S'' of points in a space ''M'' and a query point ''q''&nbsp;\u2208&nbsp;''M'', find the closest point in ''S'' to ''q''. [[Donald Knuth]] in vol. 3 of ''[[The Art of Computer Programming]]'' (1973) called it the '''post-office problem''', referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a ''k''-NN search, where we need to find the ''k'' closest points.\u000a\u000aMost commonly ''M'' is a  [[metric space]] and dissimilarity is expressed as a [[distance metric]], which is symmetric and satisfies the [[triangle inequality]]. Even more common, ''M'' is taken to be the ''d''-dimensional [[vector space]] where dissimilarity is measured using the [[Euclidean distance]], [[Taxicab geometry|Manhattan distance]] or other [[Statistical distance|distance metric]]. However, the dissimilarity function can be arbitrary. One example are asymmetric [[Bregman divergence]]s, for which the triangle inequality does not hold.<ref name=Cayton2008>{{Cite journal\u000a | last1 = Cayton | first1 = Lawerence\u000a | year = 2008\u000a | title =  Fast nearest neighbor retrieval for bregman divergences.\u000a | journal = Proceedings of the 25th international conference on Machine learning\u000a | pages = 112\u2013119\u000a}}</ref>\u000a\u000a==Applications==\u000a\u000aThe nearest neighbor search problem arises in numerous fields of application, including:\u000a*[[Pattern recognition]] - in particular for [[optical character recognition]]\u000a*[[Statistical classification]]- see [[k-nearest neighbor algorithm]]\u000a*[[Computer vision]]\u000a*[[Computational Geometry]] - see [[Closest pair of points problem]]\u000a*[[Database]]s - e.g. [[content-based image retrieval]]\u000a*[[Coding theory]] - see [[Decoding methods|maximum likelihood decoding]]\u000a*[[Data compression]] - see [[MPEG-2]] standard\u000a*[[Recommender system|Recommendation systems]], e.g. see [[Collaborative filtering]]\u000a*[[Internet marketing]] - see [[contextual advertising]] and [[behavioral targeting]]\u000a*[[DNA sequencing]]\u000a*[[Spell checking]] - suggesting correct spelling\u000a*[[Plagiarism detection]]\u000a*[[Contact searching algorithms in FEA]]\u000a*[[Similarity score]]s for predicting career paths of professional athletes.\u000a*[[Cluster analysis]] - assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense, usually based on [[Euclidean distance]]\u000a*[[Chemical similarity]]\u000a*[[Motion planning#Sampling-Based Algorithms|Sampling-Based Motion Planning]]\u000a\u000a==Methods==\u000a\u000aVarious solutions to the NNS problem have been proposed.  The quality and usefulness of the algorithms are determined by the time complexity of queries as well as the space complexity of any search data structures that must be maintained. The informal observation usually referred to as the [[curse of dimensionality]] states that there is no general-purpose exact solution for NNS in high-dimensional Euclidean space using polynomial preprocessing and polylogarithmic search time.\u000a\u000a===Linear search===\u000aThe simplest solution to the NNS problem is to compute the distance from the query point to every other point in the database, keeping track of the "best so far".  This algorithm, sometimes referred to as the naive approach, has a [[running time]] of ''O''(''dN'') where ''N'' is the [[cardinality]] of ''S'' and ''d'' is the dimensionality of ''M''.  There are no search data structures to maintain, so linear search has no space complexity beyond the storage of the database. Naive search can, on average, outperform space partitioning approaches on higher dimensional spaces.<ref>{{cite web|title=A quantitative analysis and performance study for similarity search methods in high dimensional spaces|author=Weber, Schek, Blott | url=http://www.vldb.org/conf/1998/p194.pdf}}</ref>\u000a\u000a===Space partitioning===\u000aSince the 1970s, [[branch and bound]] methodology has been applied to the problem. In the case of Euclidean space this approach is known as [[spatial index]] or spatial access methods. Several [[Space partitioning|space-partitioning]] methods have been developed for solving the NNS problem.  Perhaps the simplest is the [[k-d tree]], which iteratively bisects the search space into two regions containing half of the points of the parent region.  Queries are performed via traversal of the tree from the root to a leaf by evaluating the query point at each split. Depending on the distance specified in the query, neighboring branches that might contain hits may also need to be evaluated. For constant dimension query time, average complexity is ''O''(log&nbsp;''N'') <ref>{{cite web|title=An introductory tutorial on KD trees|author=Andrew Moore | url=http://www.autonlab.com/autonweb/14665/version/2/part/5/data/moore-tutorial.pdf?branch=main&language=en}}</ref> in the case of randomly distributed points, worst case complexity analyses have been performed.<ref name=Lee1977>{{Cite journal\u000a | last1 = Lee | first1 = D. T. | author1-link = Der-Tsai Lee\u000a | last2 = Wong | first2 = C. K.\u000a | year = 1977\u000a | title = Worst-case analysis for region and partial region searches in multidimensional binary search trees and balanced quad trees\u000a | journal = Acta Informatica\u000a | volume = 9\u000a | issue = 1\u000a | pages = 23\u201329\u000a | doi = 10.1007/BF00263763\u000a | postscript = .\u000a}}</ref>\u000aAlternatively the [[R-tree]] data structure was designed to support nearest neighbor search in dynamic context, as it has efficient algorithms for insertions and deletions such as the [[R* tree]].<ref>{{cite doi|10.1145.2F223784.223794}}</ref> R-trees can yield nearest neighbors not only for Euclidean distance, but can also be used with other distances.\u000a\u000aIn case of general metric space branch and bound approach is known under the name of [[metric trees]]. Particular examples include [[vp-tree]] and [[BK-tree]].\u000a\u000aUsing a set of points taken from a 3-dimensional space and put into a [[Binary space partitioning|BSP tree]], and given a query point taken from the same space, a possible solution to the problem of finding the nearest point-cloud point to the query point is given in the following description of an algorithm.  (Strictly speaking, no such point may exist, because it may not be unique.  But in practice, usually we only care about finding any one of the subset of all point-cloud points that exist at the shortest distance to a given query point.)  The idea is, for each branching of the tree, guess that the closest point in the cloud resides in the half-space containing the query point.  This may not be the case, but it is a good heuristic.  After having recursively gone through all the trouble of solving the problem for the guessed half-space, now compare the distance returned by this result with the shortest distance from the query point to the partitioning plane.  This latter distance is that between the query point and the closest possible point that could exist in the half-space not searched.  If this distance is greater than that returned in the earlier result, then clearly there is no need to search the other half-space.  If there is such a need, then you must go through the trouble of solving the problem for the other half space, and then compare its result to the former result, and then return the proper result.  The performance of this algorithm is nearer to logarithmic time than linear time when the query point is near the cloud, because as the distance between the query point and the closest point-cloud point nears zero, the algorithm needs only perform a look-up using the query point as a key to get the correct result.\u000a\u000a===Locality sensitive hashing===\u000a\u000a[[Locality sensitive hashing]] (LSH) is a technique for grouping points in space into 'buckets' based on some distance metric operating on the points. Points that are close to each other under the chosen metric are mapped to the same bucket with high probability.<ref>{{cite web|author=A. Rajaraman and J. Ullman| url=http://infolab.stanford.edu/~ullman/mmds.html |title=Mining of Massive Datasets, Ch. 3. |year=2010}}</ref>\u000a\u000a===Nearest neighbor search in spaces with small intrinsic dimension===\u000a\u000aThe [[cover tree]] has a theoretical bound that is based on the dataset's [[doubling constant]]. The bound on search time is ''O''(''c''<sup>12</sup>&nbsp;log&nbsp;''n'') where ''c''  is the [[Expansivity constant|expansion constant]] of the dataset.\u000a\u000a===Vector approximation files===\u000a\u000aIn high dimensional spaces, tree indexing structures become useless because an increasing percentage of the nodes need to be examined anyway. To speed up linear search, a compressed version of the feature vectors stored in RAM is used to prefilter the datasets in a first run. The final candidates are determined in a second stage using the uncompressed data from the disk for distance calculation.<ref>{{cite web|title=An Approximation-Based Data Structure for Similarity Search|author=Weber, Blott}}</ref>\u000a\u000a===Compression/clustering based search===\u000aThe VA-file approach is a special case of a compression based search, where each feature component is compressed uniformly and independently. The optimal compression technique in multidimensional spaces is Vector Quantization (VQ), implemented through clustering. The database is clustered and the most "promising" clusters are retrieved. Huge gains over VA-File, tree-based indexes and sequential scan have been observed.<ref>{{cite web|title=Adaptive cluster-distance bounding for similarity search in image databases|author=Ramaswamy, Rose, ICIP 2007}}</ref><ref>{{cite web|title=Adaptive cluster-distance bounding for high-dimensional indexing|author=Ramaswamy, Rose, TKDE 2010}}</ref> Also note the parallels between clustering and LSH.\u000a\u000a===Greedy walks===\u000aOne possible way to solve NNS is to construct a graph <math>G(V,E)</math>, where every point <math>x_i \u005cin S </math> is uniquely associated with vertex <math>v_i \u005cin V </math>. The search of the point in the set ''S'' closest to the query ''q'' takes the form of the search of vertex in the graph <math>G(V,E)</math>.\u000aOne of the basic vertex search algorithms in graphs with metric objects is the greedy search algorithm. It starts from the random vertex <math>v_i \u005cin V </math>. The algorithm computes a distance value from the query q to each vertex from the neighborhood <math>\u005c{v_j:(v_i,v_j) \u005cin E\u005c}</math> of  the current vertex <math>v_i</math>, and then selects a vertex with the minimal distance value. If the distance value between the query and the selected vertex is smaller than the one between the query and the current element, then the algorithm moves to the selected vertex, and it becomes new current vertex. The algorithm stops when it reaches a local minimum: a vertex whose neighborhood does not contain a vertex that is closer to the query than the vertex itself.\u000aThis idea was exploited in VoroNet system <ref name=voroNet>{{Cite journal\u000a | last1 = Olivier | first1 = Beaumont  \u000a | last2 = Kermarrec | first2 = Anne-Marie\u000a | last3 = Marchal | first3 = Loris \u000a | last4 = Rivière | first4 = Etienne   \u000a | year = 2006\u000a | title = VoroNet: A scalable object network based on Voronoi tessellations\u000a | journal = INRIA\u000a | volume = RR-5833\u000a | issue = 1\u000a | pages = 23\u201329\u000a | doi = 10.1007/BF00263763\u000a | postscript = .\u000a}}</ref> for the plane, in RayNet system <ref name=rayNet>{{Cite journal\u000a | last1 = Olivier | first1 = Beaumont  \u000a | last2 = Kermarrec | first2 = Anne-Marie\u000a | last4 = Rivière | first4 = Etienne   \u000a | year = 2007\u000a | title = Peer to Peer Multidimensional Overlays: Approximating Complex Structures\u000a | journal = Principles of Distributed Systems\u000a | volume =  4878\u000a | issue = .\u000a | pages = 315\u2013328\u000a | doi = 10.1007/978-3-540-77096-1_23\u000a | isbn = 978-3-540-77095-4\u000a | postscript = .\u000a}}</ref> for the <math>\u005cmathbb{E}^n</math> and for the general metric space in Metrized Small World algorithm <ref name=msw2014>{{Cite journal\u000a | last1 = Malkov | first1 = Yury  \u000a | last2 = Ponomarenko | first2 = Alexander\u000a | last3 = Krylov | first3 = Vladimir \u000a | last4 = Logvinov | first4 = Andrey   \u000a | year = 2014\u000a | title = Approximate nearest neighbor algorithm based on navigable small world graphs\u000a | journal = Information Systems\u000a | volume = 45\u000a | pages = 61\u201368\u000a | doi = 10.1016/j.is.2013.10.006\u000a | postscript = .\u000a}}</ref>\u000a\u000a==Variants==\u000a\u000aThere are numerous variants of the NNS problem and the two most well-known are the [[K-nearest neighbor algorithm|''k''-nearest neighbor search]] and the [[&epsilon;-approximate nearest neighbor search]].\u000a\u000a===<span id="K-nearest neighbor"> ''k''-nearest neighbor </span>===\u000a\u000a[[K-nearest neighbor algorithm|''k''-nearest neighbor search]] identifies the top ''k'' nearest neighbors to the query.  This technique is commonly used in predictive analytics to estimate or classify a point based on the consensus of its neighbors. ''k''-nearest neighbor graphs are graphs in which every point is connected to its ''k'' nearest neighbors.\u000a\u000a===Approximate nearest neighbor===\u000aIn some applications it may be acceptable to retrieve a "good guess" of the nearest neighbor. In those cases, we can use an algorithm which doesn't guarantee to return the actual nearest neighbor in every case, in return for improved speed or memory savings. Often such an algorithm will find the nearest neighbor in a majority of cases, but this depends strongly on the dataset being queried.\u000a\u000aAlgorithms that support the approximate nearest neighbor search include [[Locality-sensitive hashing#LSH algorithm for nearest neighbor search|locality-sensitive hashing]], [[best bin first]] and [[balanced box-decomposition tree]] based search.<ref>S. Arya, [[David Mount|D. M. Mount]], [[Nathan Netanyahu|N. S. Netanyahu]], R. Silverman and A. Wu, An optimal algorithm for approximate nearest neighbor searching, Journal of the ACM, 45(6):891-923, 1998. [http://www.cse.ust.hk/faculty/arya/pub/JACM.pdf]</ref>\u000a\u000a===Nearest neighbor distance ratio===\u000a\u000a[[Nearest neighbor distance ratio]] do not apply the threshold on the direct distance from the original point to the challenger neighbor but on a ratio of it depending on the distance to the previous neighbor. It is used in [[Content-based image retrieval|CBIR]] to retrieve pictures through a "query by example" using the similarity between local features. More generally it is involved in several [[Pattern matching|matching]] problems.\u000a\u000a===Fixed-radius near neighbors===\u000a\u000a[[Fixed-radius near neighbors]] is the problem where one wants to efficiently find all points given in [[Euclidean space]] within a given fixed distance from a specified point. The data structure should work on a distance which is fixed however the query point is arbitrary.\u000a\u000a===All nearest neighbors===\u000a\u000aFor some applications (e.g. [[entropy estimation]]), we may have ''N'' data-points and wish to know which is the nearest neighbor ''for every one of those N points''. This could of course be achieved by running a nearest-neighbor search once for every point, but an improved strategy would be an algorithm that exploits the information redundancy between these ''N'' queries to produce a more efficient search. As a simple example: when we find the distance from point ''X'' to point ''Y'', that also tells us the distance from point ''Y'' to point ''X'', so the same calculation can be reused in two different queries.\u000a\u000aGiven a fixed dimension, a semi-definite positive norm (thereby including every  [[lp space|L<sup>p</sup> norm]]), and ''n'' points in this space, the nearest neighbour of every point can be found in ''O''(''n''&nbsp;log&nbsp;''n'') time and the ''m'' nearest neighbours of every point can be found in ''O''(''mn''&nbsp;log&nbsp;''n'') time.<ref>{{citation\u000a | last = Clarkson | first = Kenneth L. | author-link = Kenneth L. Clarkson\u000a | contribution = Fast algorithms for the all nearest neighbors problem\u000a | doi = 10.1109/SFCS.1983.16\u000a | pages = 226\u2013232\u000a | title = 24th IEEE Symp. Foundations of Computer Science, (FOCS '83)\u000a | year = 1983| isbn = 0-8186-0508-1 }}.</ref><ref name=Vaidya>{{Cite journal\u000a | doi = 10.1007/BF02187718\u000a | last1 = Vaidya | first1 = P. M.\u000a | year = 1989\u000a | title = An ''O''(''n''&nbsp;log&nbsp;''n'') Algorithm for the All-Nearest-Neighbors Problem \u000a | journal = [[Discrete and Computational Geometry]]\u000a | volume = 4\u000a | issue = 1\u000a | pages = 101\u2013115\u000a | url = http://www.springerlink.com/content/p4mk2608787r7281/?p=09da9252d36e4a1b8396833710ef08cc&pi=8\u000a | postscript = .\u000a}}</ref>\u000a\u000a==See also==\u000a{{div col|colwidth=20em}}\u000a* [[Range search]]\u000a* [[Set cover problem]]\u000a*[[Statistical distance]]\u000a*[[Closest pair of points problem]]\u000a*[[Ball tree]]\u000a*[[Cluster analysis]]\u000a*[[Neighbor joining]]\u000a*[[Content-based image retrieval]]\u000a*[[Curse of dimensionality]]\u000a*[[Digital signal processing]]\u000a*[[Dimension reduction]]\u000a*[[Fixed-radius near neighbors]]\u000a*[[Fourier analysis]]\u000a*[[Instance-based learning]]\u000a*[[k-nearest neighbor algorithm|''k''-nearest neighbor algorithm]]\u000a*[[Linear least squares (mathematics)|Linear least squares]]\u000a*[[Locality sensitive hashing]]\u000a*[[Multidimensional analysis]]\u000a*[[Nearest-neighbor interpolation]]\u000a*[[Principal component analysis]]\u000a*[[Singular value decomposition]]\u000a*[[Time series]]\u000a*[[Voronoi diagram]]\u000a*[[Wavelet]]\u000a*[[MinHash]]\u000a{{div col end}}\u000a\u000a==Notes==\u000a<references/>\u000a\u000a==References==\u000a*Andrews, L.. A template for the nearest neighbor problem.  ''C/C++ Users Journal'', vol. 19, no 11 (November 2001), 40 - 49, 2001, ISSN:1075-2838, [http://www.ddj.com/architect/184401449 www.ddj.com/architect/184401449]\u000a*Arya, S., D. M. Mount, N. S. Netanyahu, R. Silverman, and A. Y. Wu.  An Optimal Algorithm for Approximate Nearest Neighbor Searching in Fixed Dimensions.  ''Journal of the ACM'', vol. 45, no. 6, pp.&nbsp;891\u2013923\u000a*Beyer, K., Goldstein, J., Ramakrishnan, R., and Shaft, U. 1999. When is nearest neighbor meaningful? In Proceedings of the 7th ICDT, Jerusalem, Israel.\u000a*Chung-Min Chen and Yibei Ling - A Sampling-Based Estimator for Top-k Query. ICDE 2002: 617-627\u000a*Samet, H. 2006. Foundations of Multidimensional and Metric Data Structures. Morgan Kaufmann. ISBN 0-12-369446-9\u000a*Zezula, P., Amato, G., Dohnal, V., and Batko, M. Similarity Search - The Metric Space Approach. Springer, 2006. ISBN 0-387-29146-6\u000a\u000a==Further reading==\u000a*{{cite book | last = Shasha | first = Dennis | title = High Performance Discovery in Time Series | publisher = Springer | location = Berlin | year = 2004 | isbn = 0-387-00857-8 }}\u000a\u000a==External links==\u000a*[http://simsearch.yury.name/tutorial.html Nearest Neighbors and Similarity Search] \u2013 a website dedicated to educational materials, software, literature, researchers, open problems and events related to NN searching. Maintained by Yury Lifshits\u000a*[http://sswiki.tierra-aoi.net Similarity Search Wiki] \u2013 a collection of links, people, ideas, keywords, papers, slides, code and data sets on nearest neighbours\u000a*[http://www.kgraph.org KGraph] \u2013 a C++ library for fast approximate nearest neighbor search with user-provided distance metric by Wei Dong.\u000a*[http://www.cs.ubc.ca/research/flann/ FLANN] \u2013 a library for performing fast approximate nearest neighbor searches in high dimensional spaces  by Marius Muja and David G. Low\u000a*[http://sisap.org/?f=library Metric Spaces Library] \u2013 An open-source C-based library for metric space indexing by Karina Figueroa, Gonzalo Navarro, Edgar Chávez\u000a*[https://github.com/searchivarius/NonMetricSpaceLib  Non-Metric Space Library] \u2013 An open-source C++ library for exact and approximate searching in non-metric and metric spaces\u000a*[http://www.cs.umd.edu/~mount/ANN/ ANN] \u2013 A library for Approximate Nearest Neighbor searching by David M. Mount and Sunil Arya\u000a*[http://www.irisa.fr/texmex/people/jegou/ann.php Product Quantization] \u2013 Matlab implementation of approximate nearest neighbor search in the compressed domain by Herve Jegou\u000a*[http://lsd.fi.muni.cz/trac/messif MESSIF] \u2013 Metric Similarity Search Implementation Framework by Michal Batko and David Novak\u000a*[http://www.obsearch.net/ OBSearch] \u2013 Similarity Search engine for Java (GPL); implementation by Arnoldo Muller, developed during Google Summer of Code 2007\u000a*[http://mrim.imag.fr/georges.quenot/freesoft/knnlsb/ KNNLSB] \u2013 K Nearest Neighbors Linear Scan Baseline (distributed, LGPL); implementation by Georges Quénot (LIG-CNRS)\u000a*[http://neartree.sourceforge.net/ NearTree] \u2013 An API for finding nearest neighbors among points in spaces of arbitrary dimensions by Lawrence C. Andrews and Herbert J. Bernstein\u000a*[http://nearpy.io/ NearPy] \u2013 Python framework for fast approximated nearest neighbor search by Ole Krause-Sparmann\u000a*[http://www.cgal.org/Pkg/SpatialSearchingD dD Spatial Searching] in [[CGAL]] \u2013 the Computational Geometry Algorithms Library\u000a*[https://github.com/ryanrhymes/panns Panns] \u2013 A Python library for searching approximate nearest neighbors, optimized for large dataset with high dimensional features, developed by Liang Wang\u000a\u000a{{DEFAULTSORT:Nearest Neighbor Search}}\u000a[[Category:Approximation algorithms]]\u000a[[Category:Classification algorithms]]\u000a[[Category:Data mining]]\u000a[[Category:Discrete geometry]]\u000a[[Category:Geometric algorithms]]\u000a[[Category:Information retrieval]]\u000a[[Category:Machine learning]]\u000a[[Category:Numerical analysis]]\u000a[[Category:Mathematical optimization]]\u000a[[Category:Searching]]\u000a[[Category:Search algorithms]]
p185
sg4
S'114'
p186
sg6
VNearest neighbor search
p187
ssI119
(dp188
g2
V{{cleanup-reorganize|date=June 2008}}\u000a\u000a'''Personalization''', also known as '''customization''', involves using technology to accommodate the differences between individuals.\u000a\u000a==Web pages==\u000a{{see also|Web pages|Adaptive hypermedia}}  \u000a[[Web page]]s are personalized based on the characteristics (interests, social category, context, ...) of an individual. Personalization implies that the changes are based on implicit data, such as items purchased or pages viewed. The term ''customization'' is used instead when the site only uses explicit data such as ratings or preferences. \u000a\u000aOn an [[intranet]] or [[B2E]] [[Web portal#Enterprise Web portals|Enterprise Web portals]], personalization is often based on user attributes such as department, functional area, or role.  The term '''customization''' in this context refers to the ability of users to modify the page layout or specify what content should be displayed.\u000a\u000aThere are three categories of personalization:\u000a# Profile / Group based\u000a# Behaviour based (also known as Wisdom of the Crowds)\u000a# Collaboration based\u000a\u000a\u000a\u000aThere are three broad methods of personalization:\u000a# Implicit\u000a# Explicit\u000a# Hybrid\u000a\u000aWith implicit personalization the personalization is performed by the web page (or information system) based on the different categories mentioned above. It can also be learned from interactions with the user directly.<ref>{{cite web|last1=Flynn|first1=Lawrence|title=5 Things To Know About Siri And Google Now's Growing Intelligence|url=http://www.forbes.com/sites/parmyolson/2014/07/08/5-things-to-know-about-siri-and-google-nows-growing-intelligence/|website=Forbes}}</ref> With explicit personalization, the web page (or information system) is changed by the user using the features provided by the system.\u000aHybrid personalization combines the above two approaches to leverage the ''best of both worlds''.\u000a\u000aMany companies offer services for web recommendation and email recommendation that are based on personalization or anonymously collected user behaviors.<ref name=behaviors>[http://online.wsj.com/article/SB10001424052748703294904575385532109190198.html?mod=googlenews_wsj ''Wall Street Journal'', \u201cOn the Web's Cutting Edge, Anonymity in Name Only\u201d], August 4, 2010</ref>  \u000a\u000aWeb personalization is closely linked to the notion of '''[[Adaptive hypermedia]]''' (AH). The main difference is that the former would usually work on what is considered an Open Corpus Hypermedia, whilst the latter would traditionally work on Closed Corpus Hypermedia. However, recent research directions in the AH domain take both closed and open corpus into account. Thus, the two fields are closely inter-related.\u000a\u000aPersonalization is also being considered for use in less overtly commercial applications to improve the user experience online.<ref>[[Jonathan Bowen|Bowen, J.P.]] and Filippini-Fantoni, S., [http://www.archimuse.com/mw2004/papers/bowen/bowen.html Personalization and the Web from a Museum Perspective]. In [[David Bearman]] and Jennifer Trant (eds.), ''[[Museums and the Web]] 2004: Selected Papers from an International Conference'', Arlington, Virginia, USA, 31 March \u2013 3 April 2004. Archives & Museum Informatics, pages 63\u201378, 2004.</ref> [[Remote control]] manufacturer [[Ruwido]] developed an [[interactive]] [[IPTV]] platform in 2010 called Voco Media, which controls [[digital media]] in the [[living room]] using web personalization. It uses personalization as a tool that supports modern forms of [[TV]] usage, by allowing users to create different profiles for each family member, personalized menu structures and [[fingerprint recognition]].<ref>[http://www.digitaltveurope.net/news_articles/mar_10/23_mar_10/ruwido_wins_virgin_media_contract,_announces_new_voco_apps Ruwido Wins Virgin Media Contract, Announces New Voco App]{{dead link|date=January 2013}}</ref>\u000a\u000aInternet activist [[Eli Pariser]] has documented that search engines like Google and Yahoo News give different results to different people (even when logged out).  He also points out social media site Facebook changes user's friend feeds based on what it thinks they want to see.  Pariser warns that these algorithms can create a "[[filter bubble]]" that prevents people from encountering a diversity of viewpoints beyond their own, or which only presents facts which confirm their existing views.\u000a\u000a==Digital media==\u000aAnother aspect of personalization is the increasing prevalence of [[open data]] on the Web. Many companies make their data available on the Web via [[API]]s, web services, and [[open data]] standards.<ref>{{cite news| url=http://www.guardian.co.uk/news/datablog/2010/apr/02/ordnance-survey-open-data | location=London | work=The Guardian | first1=Chris | last1=Thorpe | first2=Simon | last2=Rogers | title=Ordnance Survey opendata maps: what does it actually include? | date=2 April 2010}}</ref> Ordnance Survey Open Data This data is structured to allow it to be inter-connected and re-used by third parties.<ref>{{cite web|url=http://www.cio.com/article/372363/Google_Opens_Up_Data_Center_For_Third_Party_Web_Applications |title=Google Opens Up Data Centre for Third Party Web Applications |publisher=Cio.com |date=2008-05-28 |accessdate=2013-01-16}}</ref>\u000a\u000aData available from a user\u2019s personal [[social graph]] can be accessed by third-party [[application software]] to be suited to fit the personalized [[web page]] or [[information appliance]].\u000a\u000aCurrent [[open data]] standards on the Web include:\u000a# [[Attention Profiling Mark-up Language]] (APML)\u000a# [[DataPortability]]\u000a# [[OpenID]]\u000a# [[OpenSocial]]\u000a\u000a== Mobile phones ==\u000a\u000aOver time mobile phones have seen an increased emphasis placed on user personalization. Far from the black and white screens and monophonic ringtones of the past, phones now offer interactive wallpapers and MP3 TruTones. In the UK and Asia, WeeMees have become popular. WeeMees are three-dimensional characters that are used as wallpaper and respond to the tendencies of the user. Video Graphics Array (VGA) picture quality allows people to change their background with ease without sacrificing quality. All of these services are downloaded through the provider with the goal to make the user feel connected to the phone.<ref>May, Harvey, and Greg Hearn. "The Mobile Phone as Media." International Journal of Cultural Studies 8.2 (2005): 195-211. Print.</ref>\u000a\u000a==Print media==\u000a{{main|Mail merge}}\u000a\u000aIn print media, ranging from [[magazine]]s to [[admail|promotional publication]]s, personalization uses databases of individual recipients\u2019 information. Not only does the written document address itself by name to the reader, but the advertising is targeted to the recipient\u2019s demographics or interests using fields within the database, such as "first name", "last name", "company", etc. \u000a\u000aThe term "personalization" should not be confused with variable data, which is a much more granular method of marketing that leverages both images and text with the medium, not just fields within a database. Although personalized children's books are created by companies who are using and leveraging all the strengths of [[variable data printing| variable data printing (VDP)]]. This allows for full image and text variability within a printed book.\u000aWith the advent of online 3D printing services such as Shapeways and Ponoko we are seeing personalization enter into the realms of product design.\u000a\u000a== Promotional merchandise ==\u000aPromotional items ([[mug]]s, [[T-shirt]]s, [[keychain]]s, [[ball]]s etc.) are regularly personalized. Personalized children\u2019s storybooks \u2014 wherein the child becomes the [[protagonist]], with the name and image of the child personalized \u2014 are also popular. Personalized CDs for children also exist. With the advent of [[digital printing]], personalized calendars that start in any month, birthday cards, cards, e-cards, posters and photo books can also be obtained. In addition, with the advent of [[3D printing]], personalised apparel and accessories, such as jewellery made by [[StyleRocks]], is also increasing in popularity.<ref>{{cite web|url=http://www.jewellermagazine.com/Article.aspx?id=2167&h=New-jewellery-website-targets-|title=New jewellery website targets 'customisers'|last=Weinman|first=Aaron|date=21 February 2012|publisher=Jeweller Magazine|language=|accessdate=6 January 2015|quote=StyleRocks founder and CEO, Pascale Helyar-Moray, said the site offers women\u2019s and men\u2019s rings, necklaces, bracelets, earrings and cufflinks. Working alongside an Australian jewellery wholesaler, Helyar-Moray said customers have access to a variety of different styles and designs in an attempt to widen the site\u2019s ability to personalise pieces.}}</ref><ref>{{cite web|url=http://www.ragtrader.com.au/news/style-first|title=Style first|date=15 August 2014|publisher=Ragtrader|language=|accessdate=6 January 2015|quote=Online retailer StyleRocks is about to introduce an Australian first for the jewellery sector. The customisable fine jewellery retailer has introduced 3D printing in conjunction with the launch of a new website.}}</ref>\u000a\u000a== Mass personalization ==\u000a\u000a{{tone|section|date=January 2011}}\u000a\u000aMass personalization is defined as custom tailoring by a company in accordance with its end users tastes and preferences.<ref>{{cite web|url=http://www.answers.com/personalization&r=67 |title=personalize: Definition, Synonyms from |publisher=Answers.com |date= |accessdate=2013-01-16}}</ref> From collaborative engineering perspective, mass customization can be viewed as collaborative efforts between customers and manufacturers, who have different sets of priorities and need to jointly search for solutions that best match customers\u2019 individual specific needs with manufacturers\u2019 customization capabilities. <ref>	Chen, S., Y. Wang and M. M. Tseng. 2009. Mass Customization as a Collaborative Engineering Effort. International Journal of Collaborative Engineering, 1(2): 152-167</ref> The main difference between mass customization and mass personalization is that customization is the ability for a company to give its customers an opportunity to create and choose product to certain specifications, but does have limits.<ref>Haag et al., ''Management Information Systems for the Information Age'', 3rd edition, 2006, page 331.</ref> Clothing industry has also adopted the mass customization paradigm and some footwear retailers are producing mass customized shoes.<ref>{{cite web|url=http://www.botisto.com/how.php?language=EN |title=Botisto |publisher=Botisto |date= |accessdate=2013-01-16}}</ref><ref>[http://www.promoline1.com/Custom-T-Shirts-s/1814.htm Clothing ]</ref> The gaming market is seeing personalization in the new custom controller industry. A new, and notable, company called "Experience Custom" gives customers the opportunity to order personalized gaming controllers.<ref>{{cite web|url=http://www.experiencecustom.com/|title=Custom Controllers |publisher=ExperienceCustom.com |date= |accessdate=2014-11-20}}</ref> \u000a\u000aA website knowing a user's location, and buying habits, will present offers and suggestions tailored to the user's demographics; this is an example of mass personalization. The personalization is not individual but rather the user is first classified and then the personalization is based on the group they belong to.<ref>{{cite news| url=http://www.telegraph.co.uk/foodanddrink/9808015/How-supermarkets-prop-up-our-class-system.html | location=London | work=The Daily Telegraph | first=Harry | last=Wallop | title=How supermarkets prop up our class system | date=2013-01-18}}</ref>\u000a\u000a[[Behavioral targeting]] represents a concept that is similar to mass personalization.\u000a\u000a== Predictive personalization ==\u000a\u000aPredictive personalization is defined as the ability to predict customer behavior, needs or wants - and tailor offers and communications very precisely.<ref>{{cite web|url=http://www.slideshare.net/jwtintelligence/jwt-10-trends-for-2013-executive-summary|title=10 Trends for 2013 Executive Summary: Definition, Projected Trends |publisher=JWTIntelligence.com |date= |accessdate=2012-12-04}}</ref>  Social data is one source of providing this predictive analysis, particularly social data that is structured.  Predictive personalization is a much more recent means of personalization and can be used well to augment current personalization offerings.\u000a\u000a==See also==\u000a* [[Adaptation (computer science)]]\u000a* [[Mass customization]]\u000a* [[Adaptive hypermedia]]\u000a* [[Behavioral targeting]]\u000a* [[Bespoke]]\u000a* [[Collaborative filtering]]\u000a* [[Configurator]]\u000a* [[Personalized learning]]\u000a* [[Preorder economy]]\u000a* [[Real-time marketing]]\u000a* [[Recommendation system]]\u000a* [[User modeling]]\u000a\u000a==References==\u000a{{reflist|2}}\u000a\u000a==External links==\u000a* [http://www.iimcp.org International Institute on Mass Customization & Personalization which organizes MCP, a biannual conference on customization and personalization]\u000a* [http://www.umuai.org/ User Modeling and User-Adapted Interaction (UMUAI)] ''The Journal of Personalization Research''\u000a\u000a[[Category:Human\u2013computer interaction]]\u000a[[Category:World Wide Web]]\u000a[[Category:User interface techniques]]\u000a[[Category:Usability|Personas]]\u000a[[Category:Types of marketing]]\u000a[[Category:Information retrieval]]
p189
sg4
S'119'
p190
sg6
VPersonalization
p191
ssI124
(dp192
g2
V{{Multiple issues|\u000a{{citation style|date=December 2011}}\u000a{{technical|date=October 2012}}\u000a{{abbreviations|date=October 2012}}\u000a}}\u000a'''Automatic Content Extraction (ACE)''' is a program for developing advanced [[Information extraction]] [[technologies]]. Given a text in [[natural language]], the ACE challenge is to detect:\u000a# '''entities''' mentioned in the text, such as: persons, organizations, locations, facilities, weapons, vehicles, and geo-political entities.\u000a# '''relations''' between entities, such as: person A is the manager of company B. Relation types include: role, part, located, near, and social.\u000a# '''events''' mentioned in the text, such as: interaction, movement, transfer, creation and destruction.\u000a\u000aThis program began with a [[pilot study]] in 1999.\u000a\u000aWhile the ACE program is directed toward extraction of information from [[Sound|audio]] and [[image]] sources in addition to pure text, the research effort is restricted to information extraction from text. The actual [[transduction (machine learning)|transduction]] of audio and image data into text is not part of the ACE research effort, although the processing of ASR and OCR output from such transducers is.\u000a\u000aThe program relates to [[English language|English]], [[Arabic language|Arabic]] and [[Chinese language|Chinese]] texts.\u000a\u000aThe effort involves:\u000a* defining the research tasks in detail,\u000a* collecting and annotating data needed for training, development, and evaluation,\u000a* supporting the research with evaluation tools and [[research workshop]]s.\u000a\u000aIn general objective, the ACE program is motivated by and addresses the same issues as the MUC program that preceded it. The ACE program, however, defines the research objectives in terms of the target objects (i.e., the entities, the relations, and the events) rather than in terms of the words in the text. For example, the so-called \u201cnamed entity\u201d task, as defined in MUC, is to identify those words (on the page) that are names of entities. In ACE, on the other hand, the corresponding task is to identify the entity so named. This is a different task, one that is more abstract and that involves inference more explicitly in producing an\u000aanswer. In a real sense, the task is to detect things that \u201caren\u2019t there\u201d.\u000a\u000aThe ACE corpus is one of the standard benchmarks for testing new information extraction [[algorithm]]s.\u000a\u000a==References==\u000a* [http://www.citeulike.org/user/erelsegal-halevi/article/10003935 George Doddington@NIS T, Alexis Mitchell@LD C, Mark Przybocki@NIS T, Lance Ramshaw@BB N, Stephanie Strassel@LD C, Ralph Weischedel@BB N. The automatic content extraction (ACE) program\u2013tasks, data, and evaluation. 2004]\u000a\u000a==External links==\u000a* [http://www.itl.nist.gov/iaui/894.02/related_projects/muc/ MUC] - ACE's predecessor.\u000a* [http://projects.ldc.upenn.edu/ace/ ACE] (LDC)\u000a* [http://www.itl.nist.gov/iad/894.01/tests/ace/ ACE] (NIST)\u000a\u000a[[Category:Information retrieval]]
p193
sg4
S'124'
p194
sg6
VAutomatic Content Extraction
p195
ss.