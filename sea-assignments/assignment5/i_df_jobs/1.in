(dp0
I1
(dp1
S'docBody'
p2
VIn [[natural language processing|text processing]], a '''proximity search''' looks for documents where two or more separately matching term occurrences are within a specified [[string distance|distance]], where distance is the number of intermediate words or characters. In addition to proximity, some implementations may also impose a constraint on the word order, in that the order in the searched text must be identical to the order of the search query. Proximity searching goes beyond the simple matching of words by adding the constraint of proximity and is generally regarded as a form of advanced search.\u000a\u000aFor example, a search could be used to find "red brick house", and match phrases such as "red house of brick" or "house made of red brick". By limiting the proximity, these phrases can be matched while avoiding documents where the words are scattered or spread across a page or in unrelated articles in an anthology.\u000a\u000a== Rationale ==\u000aThe basic linguistic assumption of proximity searching is that the proximity of the words in a document implies a [[semantic relation|relationship]] between the words. Given that authors of documents try to formulate sentences which contain a single idea, or cluster of related ideas within neighboring sentences or organized into paragraphs, there is an inherent, relatively high, probability within the document structure that words used together are related. On the other hand, when two words are on the opposite ends of a book, the probability of a relationship between the words is relatively weak. By limiting search results to only include matches where the words are within the specified maximum proximity, or distance, the search results are assumed to be of higher relevance than the matches where the words are scattered.\u000a\u000aCommercial internet search engines tend to produce too many matches (known as recall) for the average search query. Proximity searching is one method of reducing the number of pages matches, and to improve the relevance of the matched pages by using word proximity to assist in ranking. As an added benefit, proximity searching helps combat [[spamdexing]] by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward [[word frequency]].\u000a\u000a== Boolean syntax and operators ==\u000aNote that a proximity search can designate that only some keywords must be within a specified distance. Proximity searching can be used with other search syntax and/or controls to allow more articulate search queries. Sometimes query operators like NEAR, NOT NEAR, FOLLOWED BY, NOT FOLLOWED BY, SENTENCE or FAR are used to indicate a proximity-search limit between specified keywords: for example, "brick NEAR house".\u000a\u000a== Usage in commercial search engines ==\u000aIn regards to implicit/automatic versus explicit proximity search, as of November 2008, most Internet [[search engine]]s only implement an implicit proximity search functionality. That is, they automatically rank those search results higher where the user keywords have a good "overall proximity score" in such results. If only two keywords are in the search query, this has no difference from an explicit proximity search which puts a NEAR operator between the two keywords. However, if three or more than three keywords are present, it is often important for the user to specify which subsets of these keywords expect a proximity in search results. This is useful if the user wants to do a [[prior art]] search (e.g. finding an existing approach to complete a specific task, finding a document that discloses a system that exhibits a procedural behavior collaboratively conducted by several components and links between these components).\u000a\u000a[[Web search engine]]s which support proximity search via an explicit proximity operator in their query language include  [[Walhello]], [[Exalead]], [[Yandex]], [[Yahoo!]] and [[Altavista]]:\u000a* When using the [[Walhello]] search-engine, the proximity can be defined by the number of characters between the keywords.<ref>[http://www.walhello.com/aboutgl.html "About Walhello"], visited 23 December 2009</ref>\u000a* The search engine Exalead allows the user to specify the required proximity, as the maximum number of words between keywords. The syntax is <tt>(keyword1 NEAR/n keyword2)</tt> where n is the number of words.<ref>[http://www.exalead.com/search/web/search-syntax/#proximity_search "Web Search Syntax"], visited 23 December 2009</ref>\u000a* [[Yandex]] uses the syntax <tt>keyword1 /n keyword2</tt> to search for two keywords separated by at most <math>n - 1</math> words, and supports a few other variations of this syntax.<ref>[http://help.yandex.ru/search/?id=481939 Yandex help page on query language] (in Russian)</ref>\u000a* [[Yahoo!]] and [[Altavista]] both support an undocumented NEAR operator.<ref>[http://search.yahoo.com/search?p=site%3Awww.rfc-editor.org+inurl%3Arfc2606+guidance+NEAR+additional "Successful Yahoo! proximity query"] (22 Feb 2010)</ref><ref>[http://search.yahoo.com/search?p=site%3Awww.rfc-editor.org+inurl%3Arfc2606+guidance+NEAR+unused "Unsuccessful Yahoo! proximity query"] (22 Feb 2010)</ref> The syntax is <tt>keyword1 NEAR keyword2</tt>.\u000a* Google supports AROUND(#).<ref>[http://www.guidingtech.com/16116/google-search-little-known-around-operator/ "GuidingTech: Meet Google Search's Little Known AROUND Operator"]</ref>\u000a\u000aOrdered search within the [[Google]] and [[Yahoo!]] search engines is possible using the asterisk (*) full-word [[Wildcard character|wildcard]]s: in Google this matches one or more words,<ref>[http://www.google.com/support/websearch/bin/answer.py?answer=136861 "More Google Search Help" visited 23 December 2009]</ref> and an in Yahoo! Search this matches exactly one word.<ref>[http://www.searchengineshowdown.com/features/yahoo/review.html "Review of Yahoo! Search", by Search Engine Showdown, visited 23 December 2009]</ref>  (This is easily verified by searching for the following phrase in both Google and Yahoo!: "addictive * of biblioscopy".)\u000a\u000aTo emulate unordered search of the NEAR operator can be done using a combination of ordered searches.  For example, to specify a close co-occurrence of "house" and "dog", the following search-expression could be specified: "house dog" OR "dog house" OR "house * dog" OR "dog * house" OR "house * * dog" OR "dog * * house".\u000a\u000a== See also ==\u000a* [[Compound term processing]]\u000a* [[Edit distance]]\u000a* [[Information retrieval]]\u000a* [[Search engine]]\u000a* [[Search engine indexing]] - how texts are indexed to support proximity search\u000a* [[Semantic proximity]]\u000a\u000a== Notes ==\u000a{{Reflist}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search algorithms]]
p3
sS'docID'
p4
S'1'
p5
sS'title'
p6
VProximity search (text)
p7
ssI131
(dp8
g2
V'''Natural Language User Interfaces''' (LUI or NLUI) are a type of [[User interface|computer human interface]] where linguistic phenomena such as verbs, phrases and clauses act as UI controls for creating, selecting and modifying data in software applications.\u000a\u000aIn [[interface design]] natural language interfaces are sought after for their speed and ease of use, but most suffer the challenges to [[natural language understanding|understanding]] wide varieties of ambiguous input.<ref>Hill, I. (1983). "Natural language versus computer language." In M. Sime and M. Coombs (Eds.) Designing for Human-Computer Communication. Academic Press.</ref>\u000aNatural language interfaces are an active area of study in the field of [[natural language processing]] and [[computational linguistics]]. An intuitive general Natural language interface is one of the active goals of the [[Semantic Web]].\u000a\u000aText interfaces are 'natural' to varying degrees. Many formal (un-natural) programming languages incorporate idioms of natural human language. Likewise, a traditional [[keyword search]] engine could be described as a 'shallow' Natural language user interface.\u000a\u000a==Overview==\u000aA natural language search engine would in theory find targeted answers to user questions (as opposed to keyword search). For example, when confronted with a question of the form 'which [[United States|U.S.]] state has the highest [[income tax]]?', conventional search engines ignore the question and instead search on the [[index term|keywords]] 'state', 'income' and 'tax'. Natural language search, on the other hand, attempts to use natural language processing to understand the nature of the question and then to search and return a subset of the web that contains the answer to the question. If it works, results would have a higher relevance than results from a keyword search engine.\u000a\u000a==History==\u000a\u000aPrototype Nl interfaces had already appeared in the late sixties and early seventies.<ref name="edin">Natural Language Interfaces to Databases \u2013 An Introduction,\u000aI. Androutsopoulos,\u000aG.D. Ritchie,\u000aP. Thanisch,\u000aDepartment of Artificial Intelligence, University of Edinburgh</ref>\u000a\u000a*[[SHRDLU]], a natural language interface that manipulates blocks in a virtual "blocks world"\u000a*''Lunar'', a natural language interface to a database containing chemical analyses of Apollo-11 moon rocks by [http://parsecraft.com/ William A. Woods].\u000a*''Chat-80'' transformed English questions into [[Prolog]] expressions, which were evaluated against the Prolog database.  The code of Chat-80 was circulated widely, and formed the basis of several other experimental Nl interfaces. An online demo is available on the LPA website.<ref>[http://www.lpa.co.uk/pws_dem5.htm Chat-80 demo]</ref>\u000a*[[ELIZA]], written at MIT by Joseph Weizenbaum between 1964 and 1966, mimicked a psychotherapist and was operated by processing users' responses to scripts. Using almost no information about human thought or emotion, the DOCTOR script sometimes provided a startlingly human-like interaction. An online demo is available on the LPA website.<ref>[http://www.lpa.co.uk/pws_dem4.htm ELIZA demo]</ref>\u000a* ''Janus'' is also one of the few systems to support temporal questions.\u000a* ''Intellect'' from [[Trinzic]] (formed by the merger of AICorp and Aion).\u000a* BBN\u2019s ''Parlance'' built on experience from the development of the ''Rus''  and ''Irus'' systems.\u000a* [[IBM]] ''Languageaccess''\u000a* [[Q&A (software)|Q&A]] from [[Symantec]].\u000a* ''Datatalker'' from Natural Language Inc.\u000a* ''Loqui''  from [[Bim]].\u000a* ''English Wizard'' from [[Linguistic Technology Corporation]].\u000a* ''iAskWeb'' from Anserity Inc. fully implemented in [[Prolog]] was providing interactive recommendations in NL to users in tax and investment domains in 1999-2001<ref>{{cite book | last = Galitsky\u000a | first = Boris\u000a | title = Natural Language Question Answering: technique of semantic headers\u000a | publisher = Advance Knowledge International\u000a | date = 2003\u000a | location = Adelaide, Australia\u000a | url = http://www.amazon.com/Natural-Language-Question-Answering-system/dp/0868039799\u000a | isbn = 0868039799\u000a  }}</ref>\u000a\u000a==Challenges==\u000aNatural language interfaces have in the past led users to anthropomorphize the computer, or at least to attribute more intelligence to machines than is warranted. On the part of the user, this has led to unrealistic expectations of the capabilities of the system. Such expectations will make it difficult to learn the restrictions of the system if users attribute too much capability to it, and will ultimately lead to disappointment when the system fails to perform as expected as was the case in the [[AI winter]] of the 1970s and 80s.\u000a\u000aA [http://arxiv.org/abs/cmp-lg/9503016 1995 paper] titled 'Natural Language Interfaces to Databases \u2013 An Introduction', describes some challenges:<ref name="edin"/>\u000a* ''Modifier attachment''\u000aThe request \u201cList all employees in the company with a driving licence\u201d is ambiguous unless you know companies can't have drivers licences.\u000a\u000a* ''Conjunction and disjunction''\u000a\u201cList all applicants who live in California and Arizona\u201d is ambiguous unless you know that a person can't live in two places at once.\u000a* ''[[Anaphora resolution]]''\u000a- resolve what a user means by 'he', 'she' or 'it', in a self-referential query.\u000a\u000aOther goals to consider more generally are the speed and efficiency of the interface, in all algorithms these two points are the main point that will determine if some methods are better than others and therefore have greater success in the market.\u000a\u000aFinally, regarding the methods used, the main problem to be solved is creating a general algorithm that can recognize the entire spectrum of different voices, while disregarding nationality, gender or age. The significant differences between the extracted features - even from speakers who says the same word or phrase - must be successfully overcome.\u000a\u000a==Uses and applications==\u000a\u000aThe natural language interface gives rise to technology used for many different applications. \u000a\u000aSome of the main uses are:\u000a\u000a* ''Dictation'', is the most common use for [[automated speech recognition]] (ASR) systems today. This includes medical transcriptions, legal and business dictation, and general word processing. In some cases special vocabularies are used to increase the accuracy of the system.\u000a* ''Command and control'', ASR systems that are designed to perform functions and actions on the system are defined as command and control systems. Utterances like "Open Netscape" and "Start a new xterm" will do just that.\u000a* ''Telephony'', some PBX/[[Voice Mail]] systems allow callers to speak commands instead of pressing buttons to send specific tones.\u000a* ''Wearables'', because inputs are limited for wearable devices, speaking is a natural possibility.\u000a* ''Medical, disabilities'', many people have difficulty typing due to physical limitations such as repetitive strain injuries (RSI), muscular dystrophy, and many others. For example, people with difficulty hearing could use a system connected to their telephone to convert a caller's speech to text.\u000a* ''Embedded applications'', some new cellular phones include C&C speech recognition that allow utterances such as "call home". This may be a major factor in the future of automatic speech recognition and [[Linux]].\u000a\u000aBelow are named and defined some of the applications that use natural language recognition, and so have integrated utilities listed above.\u000a\u000a===Ubiquity===\u000a{{main|Ubiquity (Firefox)}}\u000aUbiquity, an [[add-on (Mozilla)|add-on]] for [[Mozilla Firefox]], is a collection of quick and easy natural-language-derived commands that act as [[mashup (web application hybrid)|mashups]] of web services, thus allowing users to get information and relate it to current and other webpages.\u000a\u000a===Wolfram Alpha===\u000a{{main|Wolfram Alpha}}\u000aWolfram Alpha is an online service that answers factual queries directly by computing the answer from structured data, rather than providing a list of documents or web pages that might contain the answer as a [[search engine]] would.<ref>{{cite news |url=http://www.guardian.co.uk/technology/2009/mar/09/search-engine-google |title=British search engine 'could rival Google' |last=Johnson |first=Bobbie |date=2009-03-09 |work=[[The Guardian]] |accessdate=2009-03-09}}</ref> It was announced in March 2009 by [[Stephen Wolfram]], and was released to the public on May 15, 2009.<ref name="launch date">{{cite web|url=http://blog.wolframalpha.com/2009/05/08/so-much-for-a-quiet-launch/ |title=So Much for A Quiet Launch |publisher=Wolfram Alpha Blog |date=2009-05-08 |accessdate=2009-10-20}}</ref>\u000a\u000a===Siri===\u000a{{main|Siri (software)}}\u000aSiri is a [[personal assistant]] application for the operating system [[iOS]]. The application uses [[natural language processing]] to answer questions and make recommendations. The iPhone app is the first public product by its makers, who are focused on [[artificial intelligence]] applications.\u000a\u000aSiri's marketing claims include that it adapts to a user's individual preferences over time and personalizes results, and performs tasks such as making dinner reservations while trying to catch a cab.<ref>[http://www.apple.com/iphone/features/siri.html Siri webpage]</ref>\u000a\u000a===Others===\u000a* [[Anboto Group]] provides Web customer service and e-commerce technology based on semantics and natural language processing. The main offer of [http://www.anbotogroup.com/en/index.php Anboto Group] are the virtual sales agent and intelligent chat.\u000a* [[Ask.com]] - The original idea behind Ask Jeeves (Ask.com) was traditional keyword searching with an ability to get answers to questions posed in everyday, natural language. The current Ask.com still supports this, with added support for math, dictionary, and conversion questions.\u000a* [[Braina]]<ref>[http://www.brainasoft.com/braina/ Braina]</ref> - Braina is a natural language interface for [[Windows OS]] that allows to type or speak English language sentences to perform a certain action or find information.\u000a* [http://www.cmantik.com/ CMANTIK] - CMANTIK is a semantic information search engine which is trying to answer user's questions by looking up relevant information in Wikipedia and some news sources.\u000a* C-Phrase<ref>[http://code.google.com/p/c-phrase/ C-Phrase]</ref> - is a web-based natural language front end to relational databases. C-Phrase runs under Linux, connects with PostgreSQL databases via ODBC and supports both select queries and updates. Currently there is only support for English. C-Phrase is hosted on [[Google Code]] site.\u000a* [http://devtools.korzh.com/easyquery/ EasyQuery] - is a component library (for .NET framework first of all) which allows you to implement natural language query builder in your application. Works both with relational databases or ORM solutions like Entity Framework.\u000a[[File:GNOME Do Classic.png|thumb|Screenshot of GNOME DO classic interface.]]\u000a* [[GNOME Do]] - Allows for quick finding miscellaneous artifacts of GNOME environment (applications, Evolution and Pidgin contacts, Firefox bookmarks, Rhythmbox artists and albums, and so on) and execute the basic actions on them (launch, open, email, chat, play, etc.).<ref>Ubuntu 10.04 Add/Remove Applications description for GNOME Do</ref>\u000a* [[Invention Machine]] Goldfire - powered by a semantic research engine that has the capability to transform unstructured documents from various electronic sources into an index that, when searched, delivers answers to research questions. Goldfire\u2019s Natural Language query interface enables the user to put a question in a free text format, which would be the same format as if the question were given to another person. And, once knowledge has been retrieved, Goldfire presents the results in a way that makes their meaning readily apparent.\u000a* [[hakia]] - hakia is an Internet search engine. The company has invented an alternative new infrastructure to indexing that uses SemanticRank algorithm, a solution mix from the disciplines of ontological semantics, fuzzy logic, computational linguistics, and mathematics.\u000a* [[Lexxe]] - Lexxe is an Internet search engine that uses natural language processing for queries (semantic search). Searches can be made with keywords, phrases, and questions, such as "How old is Wikipedia?" When it comes to facts, Lexxe is quite effective, though needs much improvement in natural language analysis in the area of facts and in other areas.\u000a* [http://www.mnemoo.com/ Mnemoo] - Mnemoo is an answer engine that aimed to directly answer questions posed in plain text (Natural Language), which is accomplished using a database of facts and an inference engine.\u000a* [http://www.naturaldateandtime.com/ Natural Date and Time] - Natural language date and time zone engine. It allows you to ask questions about time, daylight saving information and to do time zone conversions via plain English questions such as 'What is the time in São Paulo when it is 6pm on the 2nd of June in Detroit'.\u000a* [http://www.linguasys.com/web_production/server-item/NLUI%20Server NLUI Server] - an enterprise-oriented multilingual application server by LinguaSys for natural language user interface scripts, supporting English, Spanish, Portuguese, German, Japanese, Chinese, Pashto, Thai, Russian, Vietnamese, Malay, with Arabic, French, and more languages in development.\u000a* [[Pikimal]] - Pikimal uses natural language tied to user preference to make search recommendations by template.\u000a* [[Powerset (company)|Powerset]] \u2014 On May 11, 2008, the company unveiled a tool for searching a fixed subset of [[Wikipedia]] using conversational phrases rather than keywords.<ref>{{cite news |url=http://bits.blogs.nytimes.com/2008/05/12/powerset-debuts-with-search-of-wikipedia/ |title=Powerset Debuts With Search of Wikipedia |publisher=The New York Times |first=Miguel |last=Helft |date=May 12, 2008}}</ref> On July 1, 2008, it was purchased by [[Microsoft]].<ref>{{cite web |url=http://www.powerset.com/blog/articles/2008/07/01/microsoft-to-acquire-powerset |archiveurl=http://web.archive.org/web/20090225064356/http://www.powerset.com/blog/articles/2008/07/01/microsoft-to-acquire-powerset |archivedate=February 25, 2009 |title=Microsoft to Acquire Powerset |publisher=Powerset Blog |first=Mark |last=Johnson |date=July 1, 2008}}</ref>\u000a* [[Q-go]] - The Q-go technology provides relevant answers to users in response to queries on a company\u2019s internet website or corporate intranet, formulated in natural sentences or keyword input alike. Q-go was acquired by [[RightNow Technologies]] in 2011\u000a* [[START (MIT project)]] - [http://start.csail.mit.edu/ START], Web-based question answering system. Unlike information retrieval systems such as search engines, START aims to supply users with "just the right information," instead of merely providing a list of hits. Currently, the system can answer millions of English questions about places, movies, people and dictionary definitions.\u000a* [http://swingly.com/ Swingly] - Swingly is an answer engine designed to find exact answers to factual questions. Just ask a question in plain English - and Swingly will find you the answer (or answers) you're looking for (according to their site).\u000a* [[Yebol]] - Yebol is a vertical "decision" search engine that had developed a knowledge-based, semantic search platform. Yebol's artificial intelligence human intelligence-infused algorithms automatically cluster and categorize search results, web sites, pages and content that it presents in a visually indexed format that is more aligned with initial human intent. Yebol uses association, ranking and clustering algorithms to analyze related keywords or web pages. Yebol integrates natural language processing, metasynthetic-engineered open complex systems, and machine algorithms with human knowledge for each query to establish a web directory that actually 'learns', using correlation, clustering and classification algorithms to automatically generate the knowledge query, which is retained and regenerated forward.<ref>Humphries, Matthew. [http://www.geek.com/articles/news/yebolcom-steps-into-the-search-market-20090731/ "Yebol.com steps into the search market"] ''Geek.com''. 31 July 2009.</ref>\u000a\u000a==See also==\u000a*[[Natural language programming]]\u000a**[[xTalk]], a family of English-like programming languages\u000a*[[Chatterbot]], a computer program that simulates human conversations\u000a*[[Noisy text]]\u000a*[[Question answering]]\u000a*[[Selection-based search]]\u000a*[[Semantic search]]\u000a*[[Semantic Web]]\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a{{Internet search}}\u000a{{Computable knowledge}}\u000a\u000a{{DEFAULTSORT:Natural language user interface}}\u000a[[Category:User interfaces]]\u000a[[Category:Artificial intelligence applications]]\u000a[[Category:Natural language processing]]\u000a[[Category:Computational linguistics]]\u000a[[Category:Information retrieval]]
p9
sg4
S'131'
p10
sg6
VNatural language user interface
p11
ssI6
(dp12
g2
V'''IFACnet''', the KnowledgeNet for Professional Accountants, is the global, multilingual search engine developed by the [[International Federation of Accountants]] (IFAC) and its members to provide professional accountants worldwide with one-stop access to [[good practice guidance]], articles, management tools and other resources. This enterprise search engine was launched on October 2, 2006 by INDEZ. Originally marketed to professional accountants in business, IFACnet was expanded in March 2007 to provide resources and information relevant to small and medium accounting practices. It now includes resources and information for accountants in all sectors of the profession.\u000a\u000aThe following 31 organizations participate in IFACnet:\u000a\u000a*[[American Institute of Certified Public Accountants]] (AICPA)\u000a*[[Association of Chartered Certified Accountants]] (ACCA)\u000a*[[Canadian Institute of Chartered Accountants]]\u000a*[[Certified General Accountants Association of Canada]]\u000a*[[Chartered Institute of Management Accountants]] (CIMA)\u000a*[[Chartered Institute of Public Finance and Accountancy]]\u000a*[[CMA Canada]]\u000a*[[Compagnie Nationale des Commissaires aux Comptes]]\u000a*[[Conseil Supérieur de l'Ordre des Experts-Comptables]]\u000a*[[Consiglio Nazionale Dottori Commercialisti]]\u000a*[[CPA Australia]]\u000a*[[Délégation Internationale Pour l'Audit et la Comptabilité]]\u000a*[[Hong Kong Institute of Certified Public Accountants]] (HKICPA)\u000a*[[International Federation of Accountants]]  (IFAC)\u000a*[[Institut der Wirtschaftspruefer in Deutschland]] e.V. (IDW)\u000a*[[Institute of Certified Public Accountants in Ireland]]\u000a*[[Institute of Certified Public Accountants of Singapore]]\u000a*[[Institute of Chartered Accountants of Australia]]\u000a*[[Institute of Chartered Accountants in England & Wales]] (ICAEW)\u000a*[[Institute of Chartered Accountants in Ireland]]\u000a*[[Institute of Chartered Accountants of India]]\u000a*[[Institute of Chartered Accountants of Pakistan]]\u000a*[[Institute of Chartered Accountants of Scotland]] (ICAS)\u000a*[[Institute of Management Accountants]]\u000a*[[Japanese Institute of Certified Public Accountants]] (JICPA)\u000a*[[Koninklijk Nederlands Instituut van Registeraccountants]] (Royal NIVRA)\u000a*[[Malaysian Institute of Accountants]]\u000a*[[Malta Institute of Accountants]]\u000a*[[National Association of State Boards of Accountancy]] (NASBA)\u000a*[[South African Institute of Chartered Accountants]] (SAICA)\u000a*[[Union of Chambers of Certified Public Accountants of Turkey]] (TÜRMOB)\u000a\u000a==External links==\u000a*[http://www.ifacnet.com/ IFACnet - A KnowledgeNet for Professional Accountants]\u000a*[http://www.ifac.org/ International Federation of Accountants Homepage]\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search engines]]\u000a[[Category:Accounting organizations]]
p13
sg4
S'6'
p14
sg6
VIFACnet
p15
ssI136
(dp16
g2
V{{Infobox software\u000a| name                   = Pleade-infoxbox\u000a| title                  = Pleade\u000a| logo                   = [[File:Pleade-logo.png]]\u000a| logo caption           = Logo de Pleade\u000a| screenshot             = <!-- [[File: ]] -->\u000a| caption                = \u000a| collapsible            = \u000a| author                 = AJLSM\u000a| developer              = AJLSM\u000a| released               = <!-- {{Start date|YYYY|MM|DD|df=yes/no}} -->\u000a| discontinued           = \u000a| latest release version = 3.4\u000a| latest release date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\u000a| latest preview version = <!-- 3.5 -->\u000a| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} -->\u000a| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\u000a| programming language   = [[Java]], [[XSLT]], [[Apache Cocoon|Cocoon]]\u000a| operating system       = [[Unix-like]], [[Microsoft Windows]]\u000a| platform               = \u000a| size                   = \u000a| language               = French, English, German, Chinese\u000a| language count         = <!-- DO NOT include this parameter unless you know what it does -->\u000a| language footnote      = \u000a| status                 = Active\u000a| genre                  = Digital Library\u000a| license                = GNU General Public License\u000a| alexa                  = \u000a| website                = {{URL|http://www.pleade.com/}}\u000a}}\u000a\u000a'''Pleade''' is an open source [[search engine]] and browser for [[Finding aid|archival finding aids]] encoded in [[Encoded Archival Description|EAD]] (an XML standard for encoding archival finding aids). Based on the [[SDX]] platform, it is a very flexible web application.\u000a\u000a== History ==\u000aThe software was jointly started by the companies AJLSM and Anaphore and was originally intended for publication and dissemination only of archival research tools like EAD finding aids, but it has become a library portal and a medium for digital libraries.<ref>[http://www.digicult.info/downloads/dc_info_issue6_december_20031.pdf DigiCult.Info issue #6, page 16]</ref>\u000a\u000a==Technologies==\u000aPleade is published in GPL 3. It is based on the [[Apache Cocoon|Apache Cocoon framework]] and it works with the search engine SDX.\u000a\u000aIt is able to publish and distribute the following format : [[Encoded Archival Description|EAD]], [[Comma-separated values|CSV]] (internally converted to XML), [[XMLMarc]], [[Text Encoding Initiative|TEI]], [[Dublin Core]]. Support for [[METS]] and [[ALTO (XML)|ALTO]] is under active development.<ref>[http://pleade.com/ Pleade 2012 : les imprimés numérisés et les formats XML METS / ALTO]</ref>\u000a\u000a== Features ==\u000a* Customizable publication ;\u000a* Customizable index creation ;\u000a* Customizable search form ;\u000a* Simple and advanced search among publish documents ;\u000a* Federate search among different bases (e.g. EAD, METS) ;\u000a* basket (for database and for images), a search history, printing, etc. ;\u000a* document viewer supporting : [[JPEG]], [[TIFF]] and for high resolution TIFF and [[JPEG2000]] it use [http://iipimage.sourceforge.net/ IIPImage image server] ;\u000a* [[OAI-PMH]] repositories and expose them, by default, the format EAD, Dublin Core and [[Dublin Core#Qualified Dublin Core|Qualified DC]] ;\u000a* The viewer has a Pleade indexing module (paleographic) that can be used to permit correction of the OCR. This tool is a TEI export of data input. A workflow management allows annotators and validation records seized ;\u000a* Printing resulting and finding aids as PDF documents (with embedded images) ;\u000a* Compatible with standard archival format : [[Text Encoding Initiative|TEI]], [[BiblioML]] ;\u000a* Ability to import metadata from an [[Integrated library system|ILS]].\u000a\u000a=== Pleade-Entreprise ===\u000a* Pleade-Entreprise extended features to others XML format, such as [[METS]] and [[ALTO (XML)|ALTO]].\u000a\u000a== Examples ==\u000aThese are examples of websites based on Pleade:\u000a{{columns-list|2|\u000a* Archival portals\u000a** [http://archives-inventaires.loire-atlantique.fr/ Departmental records of Loire-Atlantique (AD 44) (AD 44)]\u000a** [http://gael.gironde.fr/ GAEL : GAEL: Gironde archives online]\u000a** [http://odysseo.org/ Odysseo: Resources for the history of immigration]\u000a** [http://taubira.anaphore.org/ Parliamentary work of Christiane Taubira]\u000a** [http://archivesetmanuscrits.bnf.fr/ Archives and manuscrits of the BNF French National Library]\u000a** [http://jubilotheque.upmc.fr/ Jubilothèque, UPMC's scientific digital library]\u000a** [http://lbf-ehess.ens-lyon.fr/pages/fonds.html Michel Foucault's Library "les Mots et les Choses" ENS]\u000a\u000a* Portals documentary\u000a** [http://www.michael-culture.org/fr/home Michael]\u000a** [http://www.numerique.culture.fr/mpf/pub-fr/index.html Digital Heritage]\u000a\u000a* Digital Libraries\u000a** Digital Library of Lille\u000a** Lille III\u000a** [http://archivesetmanuscrits.bnf.fr/ BNF: Archives and manuscripts (French National Library)]\u000a}}\u000a\u000a== Related resources ==\u000a* {{Official website|http://pleade.com}}\u000a* [http://demo.pleade.com Official demo]\u000a* [http://www.pleadeenpratique.org/ Pleade in practice]\u000a* [http://www.ajlsm.com/produits/sdx SDX]\u000a* [http://www.ajlsm.com AJLSM company]\u000a\u000a== References ==\u000a<references/>\u000a\u000a[[Category:Digital library software]]\u000a[[Category:Free software]]\u000a[[Category:Information retrieval]]\u000a[[Category:Archival science]]
p17
sg4
S'136'
p18
sg6
VPleade
p19
ssI11
(dp20
g2
V{{Orphan|date=February 2009}}\u000a{{Infobox website\u000a| name = Chemrefer\u000a| logo = [[Image:Chemrefer.png]]\u000a| screenshot = \u000a| caption = \u000a| url = http://www.chemrefer.com\u000a| commercial = Yes\u000a| type = [[Search engine]]\u000a| language = English\u000a| registration = Not Applicable\u000a| owner = ChemRefer Limited\u000a| author = William James Griffiths\u000a| launch date = 2006\u000a| current status = Offline\u000a| revenue = \u000a}}\u000a'''ChemRefer''' is a service that allows searching of freely-available and full-text chemical and pharmaceutical literature that is published by authoritative sources.<ref>{{citation|journal=Science Articles |title= Science News Forum|publisher= SciScoop |date=May 19, 2006|url= http://www.sciscoop.com/story/2006/5/19/95844/6293}}</ref>\u000a\u000aFeatures include basic and advanced search options, [[mouseover]] detailed view, an integrated chemical structure drawing and search tool, downloadable [[toolbar]], customized [[RSS]] feeds, and newsletter.\u000a\u000aChemRefer is primarily of use to readers who do not have subscriptions for accessing restricted chemical literature, and to publishers who offer either [[Open access (publishing)|open access]] or [[hybrid open access journal]]s and seek to attract further subscriptions by publicly releasing part of their archive.\u000a\u000a==See also==\u000a*[[Google Scholar]]\u000a*[[Windows Live Academic]]\u000a*[[BASE (search engine)|BASE]]\u000a*[[PubMed]]\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a==External links==\u000a===Recommendations & reviews===\u000a*[http://www.rowland.harvard.edu/resources/library/lnn_archive/031706.php Cited as an "Internet Site of the Week"] by the library of the [[Rowland Institute for Science]] at [[Harvard University]]\u000a*[http://infoweb.nrl.navy.mil/index.cfm?i=156 Recommended in the list of chemical literature databases] by the library of the [[United States Naval Research Laboratory]]\u000a*[http://www.mta.ca/library/subject_chemistry.html Recommended in the list of chemical literature databases] by the library of [[Mount Allison University]]\u000a*[http://depth-first.com/articles/2007/01/15/chemrefer-free-direct-access-to-the-primary-literature Review of ChemRefer] at Depth-First chemoinformatics magazine\u000a*[http://recherche-technologie.wallonie.be/fr/particulier/menu/revue-athena/l-annuaire-de-liens/internet/moteurs-de-recherche/www-chemrefer-com.html?PROFIL=PART Recommended in the list of chemical literature databases] by the Technology Research Portal, Belgium\u000a*[http://www.certh.gr/0E9BF53C.en.aspx Recommended in the list of chemical literature databases] by the Centre for Research and Technology, Thessaloniki\u000a\u000a===Background===\u000a*[http://www.reactivereports.com/56/56_0.html Interview with William James Griffiths] at Reactive Reports chemistry magazine\u000a*[http://www.earlham.edu/~peters/fos/overview.htm Open access overview] by Professor Peter Suber, Earlham College\u000a\u000a[[Category:Scholarly search services]]\u000a[[Category:Chemistry literature]]\u000a[[Category:Information retrieval]]\u000a[[Category:Open access projects]]\u000a\u000a{{searchengine-website-stub}}
p21
sg4
S'11'
p22
sg6
VChemRefer
p23
ssI141
(dp24
g2
V'''Human\u2013computer information retrieval''' ('''HCIR''') is the study of [[information retrieval]] techniques that bring human intelligence into the [[search engine|search]] process. The fields of [[human\u2013computer interaction]] (HCI) and information retrieval (IR) have both developed innovative techniques to address the challenge of navigating complex information spaces, but their insights have often failed to cross disciplinary borders. Human\u2013computer information retrieval has emerged in academic research and industry practice to bring together research in the fields of IR and HCI, in order to create new kinds of search systems that depend on continuous human control of the search process.\u000a\u000a== History ==\u000a\u000aThis term ''human\u2013computer information retrieval'' was coined by Gary Marchionini in a series of lectures delivered between 2004 and 2006.<ref name=march2006>Marchionini, G. (2006). Toward Human-Computer Information Retrieval Bulletin, in June/July 2006 Bulletin of the American Society for Information Science. Available online at http://www.asis.org/Bulletin/Jun-06/marchionini.html.</ref> Marchionini\u2019s main thesis is that "HCIR aims to empower people to explore large-scale information bases but demands that people also take responsibility for this control by expending cognitive and physical energy."\u000a\u000aIn 1996 and 1998, a pair of workshops at the [[University of Glasgow]] on [[information retrieval]] and [[human\u2013computer interaction]] sought to address the overlap between these two fields. Marchionini notes the impact of the [[World Wide Web]] and the sudden increase in [[information literacy]] \u2013 changes that were only embryonic in the late 1990s.\u000a\u000aA few workshops have focused on the intersection of IR and HCI. The Workshop on Exploratory Search, initiated by the [[University of Maryland Human-Computer Interaction Lab]] in 2005, alternates between the [[Association for Computing Machinery]] [[Special Interest Group on Information Retrieval]] (SIGIR) and [[CHI (conference)|Special Interest Group on Computer-Human Interaction]] (CHI) conferences. Also in 2005, the [[European Science Foundation]] held an Exploratory Workshop on Information Retrieval in Context. Then, the first Workshop on Human Computer Information Retrieval was held in 2007 at the [[Massachusetts Institute of Technology]].\u000a\u000a== What is HCIR? ==\u000a\u000aHCIR includes various aspects of IR and HCI. These include [[exploratory search]], in which users generally combine querying and browsing strategies to foster learning and investigation; information retrieval in context (i.e., taking into account aspects of the user or environment that are typically not reflected in a query); and interactive information retrieval, which Peter Ingwersen defines as "the interactive communication processes that occur during the retrieval of information by involving all the major participants in information retrieval (IR), i.e. the user, the intermediary, and the IR system."<ref name=ingwer1992>Ingwersen, P. (1992). Information Retrieval Interaction. London: Taylor Graham. Available online at http://vip.db.dk/pi/iri/index.htm.</ref>\u000a\u000aA key concern of HCIR is that IR systems intended for human users be implemented and evaluated in a way that reflects the needs of those users.<ref>{{cite web|title=Mira working group (1996). Evaluation Frameworks for Interactive Multimedia Information Retrieval Applications|url=http://www.dcs.gla.ac.uk/mira/}}</ref>\u000a\u000aMost modern IR systems employ a [[ranking|ranked]] retrieval model, in which the documents are scored based on the [[probability]] of the document\u2019s [[relevance]] to the query.<ref>Grossman, D. and Frieder, O. (2004). Information Retrieval Algorithms and Heuristics. </ref> In this model, the system only presents the top-ranked documents to the user. This systems are typically evaluated based on their [[Information_retrieval#Average precision of precision and recall|mean average precision]] over a set of benchmark queries from organizations like the [[Text Retrieval Conference]] (TREC).\u000a\u000aBecause of its emphasis in using human intelligence in the information retrieval process, HCIR requires different evaluation models \u2013 one that combines evaluation of the IR and HCI components of the system. A key area of research in HCIR involves evaluation of these systems. Early work on interactive information retrieval, such as Juergen Koenemann and [[Nicholas J. Belkin]]\u2019s 1996 study of different levels of interaction for automatic query reformulation, leverage the standard IR measures of [[Information_retrieval#Precision|precision]] and [[Information_retrieval#Recall|recall]] but apply them to the results of multiple iterations of user interaction, rather than to a single query response.<ref name=koene1996>Koenemann, J. and Belkin, N. J. (1996). A case for interaction: a study of interactive information retrieval behavior and effectiveness. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems: Common Ground (Vancouver, British Columbia, Canada, April 13\u201318, 1996). M. J. Tauber, Ed. CHI \u201896. ACM Press, New York, NY, 205-212. Available online at http://sigchi.org/chi96/proceedings/papers/Koenemann/jk1_txt.htm.\u000a</ref> Other HCIR research, such as Pia Borlund\u2019s IIR evaluation model, applies a methodology more reminiscent of HCI, focusing on the characteristics of users, the details of experimental design, etc.<ref name=borlund2003>Borlund, P. (2003). The IIR evaluation model: a framework for evaluation of interactive information retrieval systems. Information Research, 8(3), Paper 152. Available online at http://informationr.net/ir/8-3/paper152.html.</ref>\u000a\u000a== Goals ==\u000a\u000aMarchionini put forth the following goals towards a system where the user has more control in determining relevant results.<ref name=march2006/>\u000a\u000aSystems should\u000a*no longer only deliver the relevant documents, but must also provide semantic information along with those documents\u000a*increase user responsibility as well as control; that is, information systems require human intellectual effort\u000a*have flexible architectures so they may evolve and adapt to increasingly more demanding and knowledgeable user bases\u000a*aim to be part of information ecology of personal and [[Collective memory|shared memories]] and tools rather than discrete standalone services\u000a*support the entire [[information life cycle]] (from creation to preservation) rather than only the dissemination or use phase\u000a*support tuning by end users and especially by information professionals who add value to information resources\u000a*be engaging and fun to use\u000a\u000aIn short, information retrieval systems are expected to operate in the way that good libraries do. Systems should help users to bridge the gap between data or information (in the very narrow, granular sense of these terms) and knowledge (processed data or information that provides the context necessary to inform the next iteration of an information seeking process). That is, good libraries provide both the information a patron needs as well as a partner in the learning process \u2014 the [[information professional]] \u2014 to navigate that information, make sense of it, preserve it, and turn it into knowledge (which in turn creates new, more informed information needs).\u000a\u000a== Techniques ==\u000a\u000aThe techniques associated with HCIR emphasize representations of information that use human intelligence to lead the user to relevant results. These techniques also strive to allow users to explore and digest the dataset without penalty, i.e., without expending unnecessary costs of time, mouse clicks, or context shift.\u000a\u000aMany [[search engines]] have features that incorporate HCIR techniques. [[Spelling suggestion]]s and [[query expansion|automatic query reformulation]] provide mechanisms for suggesting potential search paths that can lead the user to relevant results. These suggestions are presented to the user, putting control of selection and interpretation in the user\u2019s hands.\u000a\u000a[[Faceted search]] enables users to navigate information [[hierarchy|hierarchically]], going from a category to its sub-categories, but choosing the order in which the categories are presented. This contrasts with traditional [[Taxonomy (general)|taxonomies]] in which the hierarchy of categories is fixed and unchanging. [[Faceted classification|Faceted navigation]], like taxonomic navigation, guides users by showing them available categories (or facets), but does not require them to browse through a hierarchy that may not precisely suit their needs or way of thinking.<ref>Hearst, M. (1999). User Interfaces and Visualization, Chapter 10 of Baeza-Yates, R. and Ribeiro-Neto, B., Modern Information Retrieval.</ref>\u000a\u000a[[Lookahead]] provides a general approach to penalty-free exploration. For example, various [[web applications]] employ [[Ajax (programming)|AJAX]] to automatically complete query terms and suggest popular searches. Another common example of lookahead is the way in which search engines annotate results with summary information about those results, including both static information (e.g., [[metadata]] about the objects) and "snippets" of document text that are most pertinent to the words in the search query.\u000a\u000a[[Relevance feedback]] allows users to guide an IR system by indicating whether particular results are more or less relevant.<ref>Rocchio, J. (1971). Relevance feedback in information retrieval. In: Salton, G (ed), The SMART Retrieval System.</ref>\u000a\u000aSummarization and [[analytics]] help users digest the results that come back from the query. Summarization here is intended to encompass any means of [[aggregate data|aggregating]] or [[data compression|compressing]] the query results into a more human-consumable form. Faceted search, described above, is one such form of summarization. Another is [[cluster analysis|clustering]], which analyzes a set of documents by grouping similar or co-occurring documents or terms. Clustering allows the results to be partitioned into groups of related documents. For example, a search for "java" might return clusters for [[Java (programming language)]], [[Java|Java (island)]], or [[Java (coffee)]].\u000a\u000a[[information visualization|Visual representation of data]] is also considered a key aspect of HCIR. The representation of summarization or analytics may be displayed as tables, charts, or summaries of aggregated data. Other kinds of [[information visualization]] that allow users access to summary views of search results include [[tag clouds]] and [[treemapping]].\u000a\u000a== References ==\u000a\u000a<References/>\u000a\u000a==External links==\u000a*{{cite web|url=https://sites.google.com/site/hcirworkshop/ |title=Workshops on Human Computer Information Retrieval}}\u000a*{{cite web|url=http://www.chiir.org/ |title=ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR)}}\u000a\u000a{{DEFAULTSORT:Human-computer information retrieval}}\u000a[[Category:Information retrieval]]\u000a[[Category:Human\u2013computer interaction]]
p25
sg4
S'141'
p26
sg6
VHuman\u2013computer information retrieval
p27
ssI16
(dp28
g2
V{{catdiffuse}}\u000a\u000a'''[[Data management]]''' comprises all the disciplines related to managing data as a valuable resource.\u000a\u000a\u000a{{Commons cat|Data management}}\u000a\u000a[[Category:Computer data|Management]]\u000a[[Category:Data|Management]]\u000a[[Category:Project management]]\u000a[[Category:Information retrieval]]\u000a[[Category:Information technology management]]
p29
sg4
S'16'
p30
sg6
VCategory:Data management
p31
ssI146
(dp32
g2
V{{hatnote|Not to be confused with [[Markup language]] or [[HTML element]] tags.}}\u000a[[File:Web 2.0 Map.svg|thumb|right|250px|A [[tag cloud]] with terms related to [[Web 2.0]]]]\u000a\u000aIn [[information system]]s, a '''tag''' is a non-hierarchical [[index term|keyword or term]] assigned to a piece of information (such as an [[Bookmark (World Wide Web)|Internet bookmark]], digital image, or [[computer file]]). This kind of [[metadata]] helps describe an item and allows it to be found again by browsing or searching. Tags are generally chosen informally and personally by the item's creator or by its viewer, depending on the system.\u000a\u000aTagging was popularized by websites associated with [[Web 2.0]] and is an important feature of many Web 2.0 services. It is now also part of some desktop software.\u000a\u000a==History==\u000a\u000aLabeling and tagging are carried out to perform functions such as aiding in [[Classification (machine learning)|classification]], marking ownership, noting boundaries, and indicating [[online identity]]. They may take the form of words, images, or other identifying marks. An analogous example of tags in the physical world is museum object tagging. In the organization of information and objects, the use of textual keywords as part of identification and classification long  predates computers. However, computer based searching made the use of keywords a rapid way of exploring records.\u000a\u000a[[File:A Description of the Equator and Some Otherlands, collaborative hypercinema portal Upload page.jpg|thumb|A Description of the Equator and Some Otherlands, collaborative hypercinema portal, produced by documenta X, 1997. User upload page associating user contributed media with the term ''Tag''.]] Online and Internet databases and early websites deployed them as a way for publishers to help users find content. In 1997, the collaborative portal "A Description of the Equator and Some Other Lands" produced by [[documenta]] X, Germany, coined the folksonomic term ''Tag'' for its co-authors and guest authors on its Upload page. In "The Equator" the term ''Tag'' for user-input was described as an ''abstract literal or keyword'' to aid the user. Turned out in Web 1.0 days, all "Otherlands" users defined singular ''Tags'', and did not share ''Tags'' at that point.\u000a\u000aIn 2003, the [[social bookmarking]] website [[Delicious (website)|Delicious]] provided a way for its users to add "tags" to their bookmarks (as a way to help find them later); Delicious also provided browseable aggregated views of the bookmarks of all users featuring a particular tag.<ref>[http://flickr.com/photos/joshu/765809051/in/set-72157600740166824/ Screenshot of tags on del.icio.us] in 2004 and [http://flickr.com/photos/joshu/765817375/in/set-72157600740166824/ Screenshot of a tag page on del.icio.us], also in 2004, both published by [[Joshua Schachter]] on July 9, 2007.</ref> [[Flickr]] allowed its users to add their own text tags to each of their pictures, constructing flexible and easy metadata that made the pictures highly searchable.<ref>[http://www.adaptivepath.com/ideas/essays/archives/000519.php "An Interview with Flickr's Eric Costello"] by Jesse James Garrett, published on August 4, 2005. Quote: "Tags were not in the initial version of Flickr. Stewart Butterfield...liked the way they worked on del.icio.us, the social bookmarking application. We added very simple tagging functionality, so you could tag your photos, and then look at all your photos with a particular tag, or any one person\u2019s photos with a particular tag."</ref> The success of Flickr and the influence of Delicious popularized the concept,<ref>An example is [http://www.adammathes.com/academic/computer-mediated-communication/folksonomies.html "Folksonomies - Cooperative Classification and Communication Through Shared Metadata"] by Adam Mathes, December 2004. It focuses on tagging in Delicious and Flickr.</ref> and other [[social software]] websites&nbsp;\u2013 such as [[YouTube]], [[Technorati]], and [[Last.fm]]&nbsp;\u2013 also implemented tagging. Other traditional and web applications have incorporated the concept such as "Labels" in [[Gmail]] and the ability to add and edit tags in [[iTunes]] or [[Winamp]].\u000a\u000aTagging has gained wide popularity due to the growth of social networking, photography sharing and bookmarking sites. These sites allow users to create and manage labels (or \u201ctags\u201d) that categorize content using simple keywords. The use of keywords as part of an identification and classification system long predates computers. In the early days of the web keywords meta tags were used by web page designers to tell search engines what the web page was about. Today's tagging takes the meta keywords concept and re-uses it. The users add the tags. The tags are clearly visible, and are themselves links to other items that share that keyword tag.\u000a\u000aKnowledge tags are an extension of [[Index term|keyword]] tags. They were first used by [[Jumper 2.0]], an [[open source]] [[Web 2.0]] software platform released by Jumper Networks on 29 September 2008.<ref>{{Citation|url=http://www.jumpernetworks.com/ NEWS-Jumper_Networks_Releases_Jumper_2.0_Platform.pdf|title=Jumper Networks Press Release for Jumper 2.0|publisher=Jumper Networks, Inc.|date=29 September 2008}}</ref> Jumper 2.0 was the first [[collaborative search engine]] platform to use a method of expanded tagging for [[knowledge capture]].\u000a\u000aWebsites that include tags often display collections of tags as [[tag cloud]]s. A user's tags are useful both to them and to the larger community of the website's users.\u000a\u000aTags may be a "bottom-up" type of classification, compared to [[hierarchy|hierarchies]], which are "top-down". In a traditional hierarchical system ([[Taxonomy (general)|taxonomy]]), the designer sets out a limited number of terms to use for classification, and there is one correct way to classify each item. In a tagging system, there are an unlimited number of ways to classify an item, and there is no "wrong" choice. Instead of belonging to one category, an item may have several different tags. Some researchers and applications have experimented with combining structured hierarchy and "flat" tagging to aid in information retrieval.<ref>[http://infolab.stanford.edu/~heymann/taghierarchy.html Tag Hierarchies], research notes by Paul Heymann.</ref>\u000a\u000a==Examples==\u000a=== Within a Blog ===\u000aMany [[blog]] systems allow authors to add free-form tags to a post, along with (or instead of) placing the post into categories. For example, a post may display that it has been tagged with ''baseball'' and ''tickets''. Each of those tags is usually a [[web link]] leading to an index page listing all of the posts associated with that tag. The blog may have a sidebar listing all the tags in use on that blog, with each tag leading to an index page. To reclassify a post, an author edits its list of tags. All connections between posts are automatically tracked and updated by the blog software; there is no need to relocate the page within a complex hierarchy of categories.\u000a\u000a===For an event===\u000aAn official tag is a keyword adopted by events and conferences for participants to use in their web publications, such as blog entries, photos of the event, and presentation slides. Search engines can then index them to make relevant materials related to the event searchable in a uniform way. In this case, the tag is part of a [[controlled vocabulary]].\u000a\u000a===In research===\u000aA researcher may work with a large collection of items (e.g. press quotes, a bibliography, images) in digital form. If he/she wishes to associate each with a small number of themes (e.g. to chapters of a book, or to sub-themes of the overall subject), then a group of tags for these themes can be attached to each of the items in the larger collection. In this way, free form [[categorization|classification]] allows the author to manage what would otherwise be unwieldy amounts of information. Commercial, as well as some free computer applications are readily available to do this.\u000a\u000a==Special types==\u000a===Triple tags===\u000a{{see also|Microformat}}\u000aA '''triple tag''' or '''machine tag''' uses a special [[syntax]] to define extra [[semantic]] information about the tag, making it easier or more meaningful for interpretation by a computer program. Triple tags comprise three parts: a [[namespace]], a [[wikt:predicate|predicate]], and a value. For example, "geo:long=50.123456" is a tag for the geographical [[longitude]] coordinate whose value is 50.123456. This triple structure is similar to the [[Resource Description Framework]] model for information.\u000a\u000aThe triple tag format was first devised for geolicious<ref>[http://brainoff.com/weblog/2004/11/05/124 geo.lici.us : geotagging hosted services] by Mikel Maron, November 5, 2004.</ref> in November 2004, to map [[Delicious (website)|Delicious]] bookmarks, and gained wider acceptance after its adoption by [http://stamen.com/projects/mappr Mappr] and GeoBloggers<ref>[http://web.archive.org/web/20071011024028/http://geobloggers.com/archives/2006/01/11/advanced-tagging-and-tripletags/ Advanced Tagging and TripleTags] by Reverend Dan Catt, ''Geobloggers'', January 11, 2006.</ref> to map [[Flickr]] photos. In January 2007, [[Aaron Straup Cope]] at [[Flickr]] introduced the term ''machine tag'' as an alternative name for the triple tag, adding some questions and answers on purpose, syntax, and use.<ref>[http://www.flickr.com/groups/api/discuss/72157594497877875/ Machine tags], a post by Aaron Straup Cope in the Flickr API group, January 24, 2007.</ref>\u000a\u000aSpecialized metadata for geographical identification is known as ''[[geotagging]]''; machine tags are also used for other purposes, such as identifying photos taken at a specific event or naming species using [[binomial nomenclature]].<ref>[http://www.flickr.com/groups/encyclopedia_of_life/rules/ Encyclopedia of Life use of machine tag], The Encyclopedia of Life project rules including the required use of a taxonomy machine tag, September 19, 2009.</ref>\u000a\u000a===Hashtags===\u000a{{main|Hashtag}}\u000aA hashtag is a kind of metadata tag marked by the prefix <code>#</code>, sometimes known as a "hash" symbol. This form of tagging is used on [[microblogging]] and [[social networking service]]s such as [[Twitter]], [[Facebook]], [[Google+]], [[VK (social network)|VK]] and [[Instagram]].\u000a\u000a===Knowledge tags===\u000aA knowledge tag is a type of [[metadata|meta-information]] that describes or defines some aspect of an information resource (such as a [[document]], [[digital image]], [[database table|relational table]], or [[web page]]). Knowledge tags are more than traditional non-hierarchical [[index term|keywords or terms]]. They are a type of [[metadata]] that captures knowledge in the form of descriptions, categorizations, classifications, [[semantics]], comments, notes, annotations, [[hyperdata]], [[hyperlinks]], or references that are collected in tag profiles. These tag profiles reference an information resource that resides in a distributed, and often heterogeneous, storage repository. Knowledge tags are a [[knowledge management]] discipline that leverages [[Enterprise 2.0]] methodologies for users to capture insights, expertise, attributes, dependencies, or relationships associated with a data resource. It generally allows greater flexibility than other [[knowledge management]] classification systems.\u000a\u000aCapturing knowledge in tags takes many different forms, there is factual knowledge (that found in books and data), conceptual knowledge (found in perspectives and concepts), expectational knowledge (needed to make judgments and hypothesis), and methodological knowledge (derived from reasoning and strategies).<ref>\u000a{{Citation\u000a | last=Wiig | first=K. M.\u000a | year= 1997\u000a | title=Knowledge Management: An Introduction and Perspective\u000a | journal=Journal of Knowledge Management\u000a | volume=1 | issue=1\u000a | pages=6\u201314\u000a | url=http://www.mendeley.com/c/67997727/Wiig-1997-Knowledge-Management-An-Introduction-and-Perspective/\u000a | doi=10.1108/13673279710800682\u000a}}\u000a</ref> These forms of [[knowledge]] often exist outside the data itself and are derived from personal experience, insight, or expertise. \u000a\u000aKnowledge tags, in fact, manifest themselves in any number of ways \u2013 conceptual knowledge tags describe procedures, lessons learned, and facts that are related to the information resource. [[Tacit knowledge]] tags, manifests itself through skills, habits or learning by doing and represent experience or organizational intelligence. Anecdotal knowledge, is a memory of a particular case or event that may not surface without context.<ref>\u000a{{citation\u000a | last=Getting | first=Brian\u000a | year= 2007\u000a | title=What Are \u201cTags\u201d And What Is \u201cTagging?\u000a | publisher=Practical eCommerce\u000a | url=http://www.practicalecommerce.com/articles/589\u000a}}\u000a</ref> \u000a\u000aKnowledge can best be defined as information possessed in the mind of an individual: it is personalized or subjective information related to facts, procedures, concepts, interpretations, ideas, observations and judgments (which may or may not be unique, useful, accurate, or structurable). Knowledge tags are considered an expansion of the information itself that adds additional value, context, and meaning to the information.<ref>{{citation\u000a| author=Cambria, Erik and Hussain, Amir | title=Sentic album: Content-, concept-, and context-based online personal photo management system | journal=Cognitive Computation | volume=4 | issue=4 | pages=477-496 | year=2012 | doi=10.1007/s12559-012-9145-4}}</ref> Knowledge tags are valuable for preserving organizational intelligence that is often lost due to turn-over, for sharing knowledge stored in the minds of individuals that is typically isolated and unharnessed by the organization, and for connecting knowledge that is often lost or disconnected from an information resource.<ref>\u000a{{Citation\u000a | last=Alavi | first=Maryam\u000a | last2=Leidner\u000a | year= 1999\u000a | title=Knowledge Management Systems: Issues, Challenges, and Benefits\u000a | journal=Communications of the Association for Information Systems\u000a | volume=1 | issue=7\u000a | url=http://www.belkcollege.uncc.edu/jpfoley/Readings/artic07.pdf\u000a}}\u000a</ref>\u000a\u000a== Advantages and disadvantages ==\u000a{{procon|date=November 2012}}\u000a\u000aIn a typical tagging system, there is no explicit information about the meaning or [[semantics]] of each tag, and a user can apply new tags to an item as easily as applying older tags. Hierarchical classification systems can be slow to change, and are rooted in the culture and era that created them.<ref name="Smith2008">Smith, Gene (2008). Tagging: People-Powered Metadata for the Social Web. Berkeley, CA: New Riders. ISBN 0-321-52917-0</ref> The flexibility of tagging allows users to classify their collections of items in the ways that they find useful, but the personalized variety of terms can present challenges when searching and browsing.\u000a\u000aWhen users can freely choose tags (creating a [[folksonomy]], as opposed to selecting terms from a [[controlled vocabulary]]), the resulting metadata can include [[homonym]]s (the same tags used with different meanings) and [[synonym]]s (multiple tags for the same concept), which may lead to inappropriate connections between items and inefficient searches for information about a subject.<ref>Golder, Scott A. Huberman, Bernardo A. (2005).\u000a"[http://arxiv.org/abs/cs.DL/0508082 The Structure of Collaborative Tagging Systems]." Information Dynamics Lab, HP Labs. Visited November 24, 2005.</ref> For example, the tag "orange" may refer to the [[Orange (fruit)|fruit]] or the [[Orange (colour)|color]], and items related to a version of the [[Linux kernel]] may be tagged "Linux", "kernel", "Penguin", "software", or a variety of other terms. Users can also choose tags that are different [[inflection]]s of words (such as singular and plural),<ref>[http://keithdevens.com/weblog/archive/2004/Dec/24/SvP.tags Singular vs. plural tags in a tag-based categorization system] by Keith Devens, December 24, 2004.</ref> which can contribute to navigation difficulties if the system does not include [[stemming]] of tags when searching or browsing. Larger-scale folksonomies address some of the problems of tagging, in that users of tagging systems tend to notice the current use of "tag terms" within these systems, and thus use existing tags in order to easily form connections to related items. In this way, folksonomies collectively develop a partial set of tagging conventions.\u000a\u000a===Complex system dynamics===\u000a\u000aDespite the apparent lack of control, research has shown that a simple form of shared vocabularies emerges in social bookmarking systems. Collaborative tagging exhibits a form of [[complex system]]s dynamics,<ref name="WWW07-ref">Harry Halpin, Valentin Robu, Hana Shepherd [http://portal.acm.org/citation.cfm?id=1242572.1242602 The Complex Dynamics of Collaborative Tagging], Proceedings of the 16th International Conference on the World Wide Web (WWW'07), Banff, Canada, pp. 211-220, ACM Press, 2007. Downloadable on [http://www2007.org/papers/paper635.pdf the conference's website]</ref> (or [[Self-organization|self organizing]] dynamics). Thus, even if no central controlled vocabulary constrains the actions of individual users, the distribution of tags that describe different resources (e.g., websites) converges over time to stable [[power law]] distributions.<ref name="WWW07-ref"/> Once such stable distributions form, simple vocabularies can be extracted by examining the [[correlation]]s that form between different tags.  This informal collaborative system of tag creation and management has been called a [[folksonomy]].\u000a\u000a===Spamming===\u000a\u000aTagging systems open to the public are also open to tag spam, in which people apply an excessive number of tags or unrelated tags to an item (such as a [[YouTube]] video) in order to attract viewers. This abuse can be mitigated using human or statistical identification of spam items.<ref>[http://heymann.stanford.edu/tagspam.html Tag Spam], research notes by Paul Heymann.</ref> The number of tags allowed may also be limited to reduce spam.\u000a\u000a==Syntax==\u000aSome tagging systems provide a single [[text box]] to enter tags, so to be able to [[tokenize]] the string, a [[Wiktionary:separator|separator]] must be used. Two popular separators are the [[Space (punctuation)|space character]] and the [[comma]]. To enable the use of separators in the tags, a system may allow for higher-level separators (such as [[quotation mark]]s) or [[escape character]]s. Systems can avoid the use of separators by allowing only one tag to be added to each input [[Web widget|widget]] at a time, although this makes adding multiple tags more time-consuming.\u000a\u000aA syntax for use within [[HTML]] is to use the '''rel-tag''' [[microformat]] which uses the [[Rel attribute|''rel'' attribute]] with value "tag" (i.e., <code>rel="tag"</code>) to indicate that the linked-to page acts as a tag for the current context.<ref>[http://microformats.org/wiki/rel-tag rel tag microformat specification], Microformats Wiki, January 10, 2005.</ref>\u000a\u000a==See also==\u000a{{colbegin||27em}}\u000a* [[Collective intelligence]]\u000a* [[Concept map]]\u000a* [[Enterprise 2.0]]\u000a* [[Enterprise bookmarking]]\u000a* [[Explicit knowledge]]\u000a* [[Faceted classification]]\u000a* [[Folksonomy]]\u000a* [[Information ecology]]\u000a* [[Knowledge representation]]\u000a* [[Knowledge transfer]]\u000a* [[Metaknowledge]]\u000a* [[Ontology (information science)]]\u000a* [[Organisational memory]]\u000a* [[Semantic web]]\u000a* [[Tag cloud]]\u000a* [[Web 2.0]]\u000a{{colend}}\u000a'''Others'''\u000a{{colbegin||27em}}\u000a* [[Collective unconscious]]\u000a* [[Human-computer interaction]]\u000a* [[Social network aggregation]]\u000a* [[Enterprise social software]]\u000a* [[Expert system]]\u000a* [[Knowledge]]\u000a* [[Knowledge base]]\u000a* [[Knowledge worker]]\u000a* [[Management information system]]\u000a* [[Microformats]]\u000a* [[Social network]]\u000a* [[Social software]]\u000a* [[Sociology of knowledge]]\u000a* [[Tacit Knowledge]]\u000a{{colend}}\u000a\u000a==References==\u000a{{reflist|30em}}\u000a\u000a'''General'''\u000a{{refbegin}}\u000a*{{Citation\u000a | surname1=Nonaka | given1=Ikujiro\u000a | year=1994\u000a | title= A dynamic theory of organizational knowledge creation\u000a | journal= ORGANIZATION SCIENCE/ Vol. 5, No. 1, February 1994\u000a | pages=14\u201337\u000a | url=http://papers.ssrn.com/sol3/papers.cfm?abstract_id=889992\u000a}}\u000a*{{Citation\u000a | surname1=Wigg | given1=Karl M  \u000a | year=1993  \u000a | title= Knowledge Management Foundations: Thinking About Thinking: How People and Organizations Create, Represent and Use Knowledge \u000a | journal= Arlington: Schema Press  \u000a | pages=153\u000a | url=http://papers.ssrn.com/sol3/papers.cfm?abstract_id=889992 \u000a}} \u000a*{{Citation\u000a | surname1=Alavi | given1=Maryam\u000a | surname2=Leidner | given2=Dorothy E.\u000a | year=1999\u000a | title=Knowledge management systems: issues, challenges, and benefits\u000a | journal=Communications of the AIS\u000a | volume=1| issue=2 | url=http://portal.acm.org/citation.cfm?id=374117\u000a}}\u000a*{{Citation\u000a | surname1=Sandy | given1=Kemsley\u000a | year=2009\u000a | title=Models, Social Tagging and Knowledge Management #BPM2009 #BPMS2\u201909\u000a | journal=BPM, Enterprise 2.0 and technology trends in business\u000a | url=http://www.column2.com/2009/09/models-social-tagging-and-knowledge-management-bpm2009-bpms209/\u000a}}\u000a{{refend}}\u000a\u000a==External links==\u000a* [http://www.inc.com/tech-blog/twitter-hashtag-techniques-for-businesses.html Hashtag Techniques for Businesses], Curt Finch. Inc Magazine. May 26, 2011.\u000a* [http://www.tbray.org/tmp/tag-urn.html A Uniform Resource Name (URN) Namespace for Tag Metadata].  Tim Bray.  Internet draft, expired August 5, 2007.\u000a\u000a{{Web syndication}}\u000a\u000a{{DEFAULTSORT:Tag (Metadata)}}\u000a[[Category:Collective intelligence]]\u000a[[Category:Computer jargon]]\u000a[[Category:Information retrieval]]\u000a[[Category:Knowledge representation]]\u000a[[Category:Metadata]]\u000a[[Category:Reference]]\u000a[[Category:Web 2.0]]
p33
sg4
S'146'
p34
sg6
VTag (metadata)
p35
ssI21
(dp36
g2
V'''KWIC''' is an acronym for '''Key Word In Context''', the most common format for [[concordance (publishing)|concordance]] lines. The term KWIC was first coined by [[Hans Peter Luhn]].<ref>Manning, C. D., Schütze, H.: "Foundations of Statistical Natural Language Processing", p.35. The MIT Press, 1999</ref> The system was based on a concept called ''keyword in titles'' which was first proposed for Manchester libraries in 1864 by [[Andrea Crestadoro]].<ref name="index">{{cite book|title=Advanced Indexing and Abstracting Practices|url=http://books.google.co.uk/books?id=nIUkl7bLzYUC&pg=PA41&dq=Andrea+Crestadoro#v=onepage&q=Andrea%20Crestadoro&f=false}}</ref>\u000a\u000aA '''KWIC''' index is formed by sorting and aligning the words within an article title to allow each word (except the [[stop words]]) in titles to be searchable alphabetically in the index. It was a useful indexing method for technical manuals before computerized [[full text search]] became common.\u000a\u000aFor example, a search query including all of the words in the title statement of this article ("KWIC is an acronym for Key Word In Context, the most common format for concordance lines") and the [[Wikipedia:Slogans|Wikipedia slogan]] in English ("the free encyclopedia"), searched against this very webpages, might yield a KWIC index as follows. A KWIC index usually uses a wide layout to allow the display of maximum 'in context' information (not shown in the following example).\u000a\u000a{| nowrap\u000a|-\u000a|align=right|KWIC is an\u000a|'''acronym''' for Key Word In Context, ...\u000a|page 1\u000a|-\u000a|align=right|... Key Word In Context, the most \u000a|'''common''' format for concordance lines.\u000a|page 1\u000a|-\u000a|align=right|... the most common format for \u000a|'''concordance''' lines.\u000a|page 1\u000a|-\u000a|align=right|... is an acronym for Key Word In \u000a|'''Context''', the most common format ...\u000a|page 1\u000a|-\u000a|align=right|Wikipedia, The Free \u000a|'''Encyclopedia'''\u000a|page 0\u000a|-\u000a|align=right|... In Context, the most common \u000a|'''format''' for concordance lines.\u000a|page 1\u000a|-\u000a|align=right|Wikipedia, The \u000a|'''Free''' Encyclopedia\u000a|page 0\u000a|-\u000a|align=right|KWIC is an acronym for \u000a|'''Key''' Word In Context, the most ...\u000a|page 1\u000a|-\u000a|&nbsp;\u000a|'''KWIC''' is an acronym for Key Word ...\u000a|page 1\u000a|-\u000a|align=right|... common format for concordance \u000a|'''lines'''.\u000a|page 1\u000a|-\u000a|align=right|... for Key Word In Context, the \u000a|'''most''' common format for concordance ...\u000a|page 1\u000a|-\u000a|&nbsp;\u000a|'''Wikipedia''', The Free Encyclopedia\u000a|page 0\u000a|-\u000a|align=right|KWIC is an acronym for Key\u000a|'''Word''' In Context, the most common ...\u000a|page 1\u000a|}\u000a\u000aA KWIC index is a special case of a '''permuted index'''. This term refers to the fact that it indexes all [[cyclic permutation]]s of the headings. Books composed of many short sections with their own descriptive headings, most notably collections of [[Manual page (Unix)|manual pages]], often ended with a '''permuted index''' section, allowing the reader to easily find a section by any word from its heading. This practice, also known as '''KWOC''' (\u201c'''Key Word Out of Context'''\u201d), is no longer common.\u000a\u000a==References in Literature==\u000a\u000a''Note: The first reference does not show the KWIC index unless you pay to view the paper. The second reference does not even list the paper at all.''\u000a\u000a* [[David Parnas|David L. Parnas]] uses a KWIC Index as an example on how to perform modular design in his paper [http://portal.acm.org/citation.cfm?id=361623&coll=ACM&dl=ACM&CFID=9516243&CFTOKEN=98251202 ''On the Criteria To Be Used in Decomposing Systems into Modules''], available as an [http://www.acm.org/classics/may96/ ACM Classic Paper]\u000a* Christopher D. Manning and Hinrich Schütze describe a KWIC index and computer concordancing in section 1.4.5 of their book ''Foundations of Statistical Natural Language Processing''\u000a\u000a==References==\u000a{{reflist|2}}\u000a\u000a==See also==\u000a* <tt>[[Ptx (Unix)|ptx]]</tt>, a Unix command-line utility producing a [[permuted index]]\u000a*[[Concordancer]]\u000a*[[Concordance (publishing)]]\u000a*[[Burrows\u2013Wheeler transform]]\u000a*[[Hans Peter Luhn]]\u000a*[[Suffix tree]]\u000a\u000a[[Category:Indexing]]\u000a[[Category:Information retrieval]]\u000a[[Category:Reference]]\u000a[[Category:Searching]]
p37
sg4
S'21'
p38
sg6
VKey Word in Context
p39
ssI151
(dp40
g2
V'''Latent semantic indexing''' ('''LSI''') is an indexing and retrieval method that uses a mathematical technique called [[singular value decomposition]] (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text.  LSI is based on the principle that words that are used in the same contexts tend to have similar meanings.  A key feature of LSI is its ability to extract the conceptual content of a body of text by establishing associations between those terms that occur in similar contexts.<ref>Deerwester, S., et al, Improving Information Retrieval with Latent Semantic Indexing, Proceedings of the 51st Annual Meeting of the American Society for Information Science 25, 1988, pp. 36\u201340.</ref>\u000a\u000aLSI is also an application of [[correspondence analysis]], a multivariate statistical technique developed by [[Jean-Paul Benzécri]]<ref>{{ cite book\u000a | author = Benzécri, J.-P.\u000a | publisher=Dunod |location= Paris, France\u000a | year = 1973\u000a | title = L'Analyse des Données. Volume II. L'Analyse des Correspondences\u000a }}</ref> in the early 1970s, to a [[contingency table]] built from word counts in documents.\u000a\u000aCalled Latent Semantic Indexing because of its ability to correlate semantically related terms that are latent in a collection of text, it was first applied to text at Bellcore in the late 1980s.   The method, also called [[latent semantic analysis]] (LSA), uncovers the underlying latent semantic structure in the usage of words in a body of text and how it can be used to extract the meaning of the text in response to user queries, commonly referred to as concept searches.  Queries, or concept searches, against a set of documents that have undergone LSI will return results that are conceptually similar in meaning to the search criteria even if the results don\u2019t share a specific word or words with the search criteria.\u000a\u000a__TOC__\u000a\u000a== Benefits of LSI ==\u000a\u000aLSI overcomes two of the most problematic constraints of Boolean keyword queries:  multiple words that have similar meanings ([[synonymy]]) and words that have more than one meaning ([[polysemy]]).  Synonymy is often the cause of [[vocabulary mismatch|mismatches in the vocabulary]] used by the authors of documents and the users of information retrieval systems.<ref>{{cite doi|10.1145/32206.32212}}</ref><ref>{{cite doi|10.1145/1871437.1871474}}</ref>   As a result, Boolean or keyword queries often return irrelevant results and miss information that is relevant.\u000a\u000aLSI is also used to perform automated document categorization.  In fact, several experiments have demonstrated that there are a number of correlations between the way LSI and humans process and categorize text.<ref>Landauer, T., et al., Learning Human-like Knowledge by Singular Value Decomposition: A Progress Report, M. I. Jordan, M. J. Kearns & S. A. Solla (Eds.), Advances in Neural Information Processing Systems 10, Cambridge: MIT Press, 1998, pp. 45\u201351.</ref>    Document categorization is the assignment of documents to one or more predefined categories based on their similarity to the conceptual content of the categories.<ref>{{cite doi|10.1145/288627.288651}}</ref>   LSI uses ''example'' documents to establish the conceptual basis for each category.  During categorization processing, the concepts contained in the documents being categorized are compared to the concepts contained in the example items, and a category (or categories) is assigned to the documents based on the similarities between the concepts they contain and the concepts that are contained in the example documents.\u000a\u000aDynamic clustering based on the conceptual content of documents can also be accomplished using LSI.  Clustering is a way to group documents based on their conceptual similarity to each other without using example documents to establish the conceptual basis for each cluster.  This is very useful when dealing with an unknown collection of unstructured text.\u000a\u000aBecause it uses a strictly mathematical approach, LSI is inherently independent of language.  This enables LSI to elicit the semantic content of information written in any language without requiring the use of auxiliary structures, such as dictionaries and thesauri.  LSI can also perform cross-linguistic concept searching and example-based categorization.  For example, queries can be made in one language, such as English, and conceptually similar results will be returned even if they are composed of an entirely different language or of multiple languages.\u000a\u000aLSI is not restricted to working only with words.  It can also process arbitrary character strings.  Any object that can be expressed as text can be represented in an LSI vector space.<ref>Zukas, Anthony, Price, Robert J., Document Categorization Using Latent Semantic Indexing, White Paper, [[Content Analyst Company]], LLC</ref>   For example, tests with MEDLINE abstracts have shown that LSI is able to effectively classify genes based on conceptual modeling of the biological information contained in the titles and abstracts of the MEDLINE citations.<ref>{{cite doi|10.1093/bioinformatics/bth464}}</ref>\u000a\u000aLSI automatically adapts to new and changing terminology, and has been shown to be very tolerant of noise (i.e., misspelled words, typographical errors, unreadable characters, etc.).<ref>{{cite doi|10.1007/11427995_68}}</ref>   This is especially important for applications using text derived from Optical Character Recognition (OCR) and speech-to-text conversion.  LSI also deals effectively with sparse, ambiguous, and contradictory data.\u000a\u000aText does not need to be in sentence form for LSI to be effective.  It can work with lists, free-form notes, email, Web-based content, etc.  As long as a collection of text contains multiple terms, LSI can be used to identify patterns in the relationships between the important terms and concepts contained in the text.\u000a\u000aLSI has proven to be a useful solution to a number of conceptual matching problems.<ref>Ding, C., A Similarity-based Probability Model for Latent Semantic Indexing, Proceedings of the 22nd International ACM SIGIR Conference on Research and Development in Information Retrieval, 1999, pp. 59\u201365.</ref><ref>Bartell, B., Cottrell, G., and Belew, R., Latent Semantic Indexing is an Optimal Special Case of Multidimensional Scaling, Proceedings, ACM SIGIR Conference on Research and Development in Information Retrieval, 1992, pp. 161\u2013167.</ref>  The technique has been shown to capture key relationship information, including causal, goal-oriented, and taxonomic information.<ref>Graesser, A., and Karnavat, A., Latent Semantic Analysis Captures Causal, Goal-oriented, and Taxonomic Structures, Proceedings of CogSci 2000, pp. 184\u2013189.</ref>\u000a\u000a== LSI timeline ==\u000a\u000a'''Mid-1960s''' \u2013 Factor analysis technique first described and tested (H. Borko and M. Bernick)\u000a\u000a'''1988''' \u2013 Seminal paper on LSI technique published (Deerwester et al.)\u000a\u000a'''1989''' \u2013 Original patent granted (Deerwester et al.)\u000a\u000a'''1992''' \u2013 First use of LSI to assign articles to reviewers<ref>Dumais, S., and Nielsen, J., Automating the Assignment of Submitted Manuscripts to Reviewers, Proceedings of the Fifteenth Annual International Conference on Research and Development in Information Retrieval, 1992, pp. 233\u2013244.</ref>  (Dumais and Nielsen)\u000a\u000a'''1994''' \u2013 Patent granted for the cross-lingual application of LSI (Landauer et al.)\u000a\u000a'''1995''' \u2013 First use of LSI for grading essays (Foltz, et al., Landauer et al.)\u000a\u000a'''1999''' \u2013 First implementation of LSI technology for intelligence community for analyzing unstructured text (SAIC).\u000a\u000a'''2002''' \u2013 LSI-based product offering to intelligence-based government agencies (SAIC)\u000a\u000a'''2005''' \u2013 First vertical-specific application \u2013 publishing \u2013 EDB (EBSCO, [[Content Analyst Company]])\u000a\u000a== Mathematics of LSI ==\u000a\u000aLSI uses common linear algebra techniques to learn the conceptual correlations in a collection of text.  In general, the process involves constructing a weighted term-document matrix, performing a '''Singular Value Decomposition''' on the matrix, and using the matrix to identify the concepts contained in the text.\u000a\u000a=== Term-document matrix ===\u000a\u000aLSI begins by constructing a term-document matrix, <math>A</math>, to identify the occurrences of the <math>m</math> unique terms within a collection of <math>n</math> documents.  In a term-document matrix, each term is represented by a row, and each document is represented by a column, with each matrix cell, <math>a_{ij}</math>, initially representing the number of times the associated term appears in the indicated document, <math>\u005cmathrm{tf_{ij}}</math>.  This matrix is usually very large and very sparse.\u000a\u000aOnce a term-document matrix is constructed, local and global weighting functions can be applied to it to condition the data.  The weighting functions transform each cell, <math>a_{ij}</math> of <math>A</math>, to be the product of a local term weight, <math>l_{ij}</math>, which describes the relative frequency of a term in a document, and a global weight, <math>g_i</math>, which describes the relative frequency of the term within the entire collection of documents.\u000a\u000aSome common local weighting functions <ref>\u000aBerry, M. W., and Browne, M., Understanding Search Engines: Mathematical Modeling and Text Retrieval, Society for Industrial and Applied Mathematics, Philadelphia, (2005).</ref> are defined in the following table.\u000a\u000a{| style="width:60%" cellpadding="25" cellspacing="5" align="center"\u000a|-\u000a|  style="width:22%" | '''Binary''' ||\u000a| <math>l_{ij} = 1</math> if the term exists in the document, or else <math>0</math>\u000a|-\u000a|  style="width:22%" | '''TermFrequency''' ||\u000a| <math>l_{ij} = \u005cmathrm{tf}_{ij}</math>, the number of occurrences of term <math>i</math> in document <math>j</math>\u000a|-\u000a|  style="width:22%" | '''Log''' ||\u000a| <math>l_{ij} = \u005clog(\u005cmathrm{tf}_{ij} + 1)</math>\u000a|-\u000a|  style="width:22%" | '''Augnorm''' ||\u000a| <math>l_{ij} = \u005cfrac{\u005cBig(\u005cfrac{\u005cmathrm{tf}_{ij}}{\u005cmax_i(\u005cmathrm{tf}_{ij})}\u005cBig) + 1}{2}</math>\u000a|}\u000a\u000aSome common global weighting functions are defined in the following table.\u000a\u000a{| style="width:60%" cellpadding="25" cellspacing="5" align="center"\u000a|-\u000a| style="width:22%" | '''Binary''' ||\u000a| <math>g_i = 1</math>\u000a|-\u000a| style="width:22%" | '''Normal''' ||\u000a| <math>g_i = \u005cfrac{1}{\u005csqrt{\u005csum_j \u005cmathrm{tf}_{ij}^2}}</math>\u000a|-\u000a| style="width:22%" | '''GfIdf''' ||\u000a| <math>g_i = \u005cmathrm{gf}_i / \u005cmathrm{df}_i</math>, where <math>\u005cmathrm{gf}_i</math> is the total number of times term <math>i</math> occurs in the whole collection, and <math>\u005cmathrm{df}_i</math> is the number of documents in which term <math>i</math> occurs.\u000a|-\u000a| style="width:22%" | '''Idf''' ||\u000a| <math>g_i = \u005clog_2 \u005cfrac{n}{1+ \u005cmathrm{df}_i}</math>\u000a|-\u000a| style="width:22%" | '''Entropy''' ||\u000a| <math>g_i = 1 + \u005csum_j \u005cfrac{p_{ij} \u005clog p_{ij}}{\u005clog n}</math>, where <math>p_{ij} = \u005cfrac{\u005cmathrm{tf}_{ij}}{\u005cmathrm{gf}_i}</math>\u000a|}\u000a\u000aEmpirical studies with LSI report that the Log Entropy weighting functions work well, in practice, with many data sets.<ref>Landauer, T., et al., Handbook of Latent Semantic Analysis, Lawrence Erlbaum Associates, 2007.</ref>  In other words, each entry <math>a_{ij}</math> of <math>A</math> is computed as:\u000a\u000a:<math>g_i = 1 + \u005csum_j \u005cfrac{p_{ij} \u005clog p_{ij}}{\u005clog n}</math>\u000a\u000a:<math>a_{ij} = g_i \u005c \u005clog (\u005cmathrm{tf}_{ij} + 1)</math>\u000a\u000a=== Rank-reduced singular value decomposition ===\u000a\u000aA rank-reduced, [[singular value decomposition]] is performed on the matrix to determine patterns in the relationships between the terms and concepts contained in the text.  The SVD forms the foundation for LSI.<ref>Berry, Michael W., Dumais, Susan T., O'Brien, Gavin W., Using Linear Algebra for Intelligent Information Retrieval, December 1994, SIAM Review 37:4 (1995), pp. 573\u2013595.</ref>   It computes the term and document vector spaces by approximating the single term-frequency matrix, <math>A</math>, into three other matrices\u2014 an '''''m''''' by '''''r'''''  term-concept vector matrix <math>T</math>, an '''''r''''' by '''''r''''' singular values matrix <math>S</math>, and a '''''n''''' by '''''r''''' concept-document vector matrix, <math>D</math>, which satisfy the following relations:\u000a\u000a<math>A \u005capprox TSD^T</math>\u000a\u000a<math>T^T T = I_r \u005cquad D^T D = I_r </math>\u000a\u000a<math>S_{1,1} \u005cgeq S_{2,2} \u005cgeq \u005cldots \u005cgeq  S_{r,r} > 0 \u005cquad S_{i,j} = 0 \u005c; \u005ctext{where} \u005c; i \u005cneq j</math>\u000a\u000aIn the formula, '''A''' is the supplied '''''m''''' by '''''n''''' weighted matrix of term frequencies in a collection of text where '''''m''''' is the number of unique terms, and '''''n''''' is the number of documents.  '''T''' is a computed '''''m''''' by '''''r''''' matrix of term vectors where '''''r''''' is the rank of '''A'''\u2014a measure of its unique dimensions '''\u2264 min(''m,n'')'''.  '''S''' is a computed '''''r''''' by '''''r''''' diagonal matrix of decreasing singular values, and '''D''' is a computed '''''n''''' by '''''r''''' matrix of document vectors.\u000a\u000aThe LSI modification to a standard SVD is to reduce the rank or truncate the singular value matrix '''S''' to size '''''k''''' « '''''r''''', typically on the order of a '''''k''''' in the range of 100 to 300 dimensions, effectively reducing the term and document vector matrix sizes to '''''m''''' by '''''k''''' and '''''n''''' by '''''k''''' respectively.  The SVD operation, along with this reduction, has the effect of preserving the most important semantic information in the text while reducing noise and other undesirable artifacts of the original space of '''A'''.  This reduced set of matrices is often denoted with a modified formula such as:\u000a\u000a:::::::'''A \u2248 A''<sub>k''</sub> = T''<sub>k''</sub> S''<sub>k''</sub> D''<sub>k''</sub><sup>T</sup>'''\u000a\u000aEfficient LSI algorithms only compute the first '''''k''''' singular values and term and document vectors as opposed to computing a full SVD and then truncating it.\u000a\u000aNote that this rank reduction is essentially the same as doing [[Principal Component Analysis]] (PCA) on the matrix '''A''', except that PCA subtracts off the means.  PCA loses the sparseness of the '''A''' matrix, which can make it infeasible for large lexicons.\u000a\u000a== Querying and augmenting LSI vector spaces ==\u000a\u000aThe computed '''T''<sub>k''</sub>''' and '''D''<sub>k''</sub>''' matrices define the term and document vector spaces, which with the computed singular values, '''S''<sub>k''</sub>''', embody the conceptual information derived from the document collection.  The similarity of terms or documents within these spaces is a factor of how close they are to each other in these spaces, typically computed as a function of the angle between the corresponding vectors.\u000a\u000aThe same steps are used to locate the vectors representing the text of queries and new documents within the document space of an existing LSI index.  By a simple transformation of the '''A = T S D<sup>T</sup>''' equation into the equivalent '''D = A<sup>T</sup> T S<sup>\u22121</sup>''' equation, a new vector, '''''d''''', for a query or for a new document can be created by computing a new column in '''A''' and then multiplying the new column by '''T S<sup>\u22121</sup>'''.  The new column in '''A''' is computed using the originally derived global term weights and applying the same local weighting function to the terms in the query or in the new document.\u000a\u000aA drawback to computing vectors in this way, when adding new searchable documents, is that terms that were not known during the SVD phase for the original index are ignored.  These terms will have no impact on the global weights and learned correlations derived from the original collection of text.  However, the computed vectors for the new text are still very relevant for similarity comparisons with all other document vectors.\u000a\u000aThe process of augmenting the document vector spaces for an LSI index with new documents in this manner is called ''folding in''.  Although the folding-in process does not account for the new semantic content of the new text, adding a substantial number of documents in this way will still provide good results for queries as long as the terms and concepts they contain are well represented within the LSI index to which they are being added.  When the terms and concepts of a new set of documents need to be included in an LSI index, either the term-document matrix, and the SVD, must be recomputed or an incremental update method (such as the one described in <ref name="brand2006">{{cite journal | url=http://www.merl.com/reports/docs/TR2006-059.pdf |format=PDF| title=Fast Low-Rank Modifications of the Thin Singular Value Decomposition | author=Matthew Brand | journal=Linear Algebra and Its Applications | volume=415 | pages=20\u201330 | year=2006 | doi=10.1016/j.laa.2005.07.021 }}</ref>) be used.\u000a\u000a== Additional uses of LSI ==\u000a\u000aIt is generally acknowledged that the ability to work with text on a semantic basis is essential to modern information retrieval systems.  As a result, the use of LSI has significantly expanded in recent years as earlier challenges in scalability and performance have been overcome.\u000a\u000aLSI is being used in a variety of information retrieval and text processing applications, although its primary application has been for concept searching and automated document categorization.<ref>Dumais, S., Latent Semantic Analysis, ARIST Review of Information Science and Technology, vol. 38, 2004, Chapter 4.</ref>   Below are some other ways in which LSI is being used:\u000a\u000a* Information discovery<ref>Best Practices Commentary on the Use of Search and Information Retrieval Methods in E-Discovery, the Sedona Conference, 2007, pp. 189\u2013223.</ref>  (eDiscovery, Government/Intelligence community, Publishing)\u000a* Automated document classification (eDiscovery, Government/Intelligence community, Publishing)<ref>Foltz, P. W. and Dumais, S. T. Personalized Information Delivery:  An analysis of information filtering methods, Communications of the ACM, 1992, 34(12), 51-60.</ref>\u000a* Text summarization<ref>Gong, Y., and Liu, X., Creating Generic Text Summaries, Proceedings, Sixth International Conference on Document Analysis and Recognition, 2001, pp. 903\u2013907.</ref>  (eDiscovery, Publishing)\u000a* Relationship discovery<ref>Bradford, R., Efficient Discovery of New Information in Large Text Databases, Proceedings, IEEE International Conference on Intelligence and Security Informatics, Atlanta, Georgia, LNCS Vol. 3495, Springer, 2005, pp. 374\u2013380.</ref>  (Government, Intelligence community, Social Networking)\u000a* Automatic generation of link charts of individuals and organizations<ref>Bradford, R., Application of Latent Semantic Indexing in Generating Graphs of Terrorist Networks, in: Proceedings, IEEE International Conference on Intelligence and Security Informatics, ISI 2006, San Diego, CA, USA, May 23\u201324, 2006, Springer, LNCS vol. 3975, pp. 674\u2013675.</ref>  (Government, Intelligence community)\u000a* Matching technical papers and grants with reviewers<ref>Yarowsky, D., and Florian, R., Taking the Load off the Conference Chairs: Towards a Digital Paper-routing Assistant, Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in NLP and Very-Large Corpora, 1999, pp. 220\u2013230.</ref>  (Government)\u000a* Online customer support<ref>Caron, J., Applying LSA to Online Customer Support: A Trial Study, Unpublished Master's Thesis, May 2000.</ref>  (Customer Management)\u000a* Determining document authorship<ref>Soboroff, I., et al, Visualizing Document Authorship Using N-grams and Latent Semantic Indexing,   Workshop on New Paradigms in Information Visualization and Manipulation, 1997, pp. 43\u201348.</ref>  (Education)\u000a* Automatic keyword annotation of images<ref>Monay, F., and Gatica-Perez, D., On Image Auto-annotation with Latent Space Models, Proceedings of the 11th ACM international conference on Multimedia, Berkeley, CA, 2003, pp. 275\u2013278.</ref>\u000a* Understanding software source code<ref>Maletic, J., and Marcus, A., Using Latent Semantic Analysis to Identify Similarities in Source Code to Support Program Understanding, Proceedings of 12th IEEE International Conference on Tools with Artificial Intelligence, Vancouver, British Columbia, November 13\u201315, 2000, pp. 46\u201353.</ref>  (Software Engineering)\u000a* Filtering [[Spam (electronic)|spam]]<ref>Gee, K., Using Latent Semantic Indexing to Filter Spam, in: Proceedings, 2003 ACM Symposium on Applied Computing, Melbourne, Florida, pp. 460\u2013464.</ref>  (System Administration)\u000a* Information visualization<ref>Landauer, T., Laham, D., and Derr, M., From Paragraph to Graph: Latent Semantic Analysis for Information Visualization, Proceedings of the National Academy of Science, 101, 2004, pp. 5214\u20135219.</ref>\u000a* [[Automated essay scoring|Essay scoring]]<ref>Foltz, Peter W., Laham, Darrell, and Landauer, Thomas K., Automated Essay Scoring: Applications to Educational Technology, Proceedings of EdMedia,  1999.</ref>  (Education)\u000a* [[Literature-based discovery]]<ref>Gordon, M., and Dumais, S., Using Latent Semantic Indexing for Literature Based Discovery, Journal of the American Society for Information Science, 49(8), 1998, pp. 674\u2013685.</ref>\u000a\u000aLSI is increasingly being used for electronic document discovery (eDiscovery) to help enterprises prepare for litigation.  In eDiscovery, the ability to cluster, categorize, and search large collections of unstructured text on a conceptual basis is essential.  Concept-based searching using LSI has been applied to the eDiscovery process by leading providers as early as 2003.<ref>There Has to be a Better Way to Search, 2008, White Paper, Fios, Inc.</ref>\u000a\u000a== Challenges to LSI ==\u000a\u000aEarly challenges to LSI focused on scalability and performance.  LSI requires relatively high computational performance and memory in comparison to other information retrieval techniques.<ref>Karypis, G., Han, E., Fast Supervised Dimensionality Reduction Algorithm with Applications to Document Categorization and Retrieval, Proceedings of CIKM-00, 9th ACM Conference on Information and Knowledge Management.</ref>  However, with the implementation of modern high-speed processors and the availability of inexpensive memory, these considerations have been largely overcome.  Real-world applications involving more than 30 million documents that were fully processed through the matrix and SVD computations are not uncommon in some LSI applications. A fully scalable (unlimited number of documents, online training) implementation of LSI is contained in the open source [[gensim]] software package.<ref name="rehurek2011">{{cite journal | url=http://dx.doi.org/10.1007/978-3-642-20161-5_29 |format=PDF| title=Subspace Tracking for Latent Semantic Analysis | author=Radim \u0158eh\u016f\u0159ek | journal=Advances in Information Retrieval - 33rd European Conference on IR Research, ECIR 2011 | volume=6611 | pages=289\u2013300 | year=2011 | doi=10.1007/978-3-642-20161-5_29 }}</ref>\u000a\u000aAnother challenge to LSI has been the alleged difficulty in determining the optimal number of dimensions to use for performing the SVD.  As a general rule, fewer dimensions allow for broader comparisons of the concepts contained in a collection of text, while a higher number of dimensions enable more specific (or more relevant) comparisons of concepts.  The actual number of dimensions that can be used is limited by the number of documents in the collection.  Research has demonstrated that around 300 dimensions will usually provide the best results with moderate-sized document collections (hundreds of thousands of documents) and perhaps 400 dimensions for larger document collections (millions of documents).<ref>Bradford, R., An Empirical Study of Required Dimensionality for Large-scale Latent Semantic Indexing Applications, Proceedings of the 17th ACM Conference on Information and Knowledge Management, Napa Valley, California, USA, 2008, pp. 153\u2013162.</ref>   However, recent studies indicate that 50-1000 dimensions are suitable depending on the size and nature of the document collection.<ref>Landauer, Thomas K., and Dumais, Susan T., Latent Semantic Analysis, Scholarpedia, 3(11):4356, 2008.</ref>\u000a\u000aChecking the amount of variance in the data after computing the SVD can be used to determine the optimal number of dimensions to retain.  The variance contained in the data can be viewed by plotting the singular values (S) in a [[scree plot]].  Some LSI practitioners select the dimensionality associated with the knee of the curve as the cut-off point for the number of dimensions to retain.  Others argue that some quantity of the variance must be retained, and the amount of variance in the data should dictate the proper dimensionality to retain.  Seventy percent is often mentioned as the amount of variance in the data that should be used to select the optimal dimensionality for recomputing the SVD.<ref>Cangelosi, R., Goriely A., Component Retention In Principal Component Analysis With Application to Cdna Microarray Data, BMC Biology Direct 2(2) (2007).</ref><ref>Jolliffe, L. T., Principal Component Analysis, Springer-Verlag, New York, (1986).</ref><ref>Hu, X., Z. Cai, et al., LSA: First Dimension and Dimensional Weighting, 25th Annual Meeting of the Cognitive Science Society, Boston, MA.</ref>\u000a\u000a==See also==\u000a* [[Latent semantic analysis]]\u000a* [[Latent Semantic Structure Indexing]]\u000a* [[Principal component analysis]]\u000a* [[Correspondence analysis]]\u000a* [[Probabilistic latent semantic analysis]]\u000a\u000a{{Natural Language Processing}}\u000a\u000a== References ==\u000a{{Reflist}}\u000a\u000a== Further reading ==\u000a*{{cite book|authors=Berry, M. W., Browne M.|title=Understanding Search Engines: Mathematical Modeling and Text Retrieval|location=Philadelphia|publisher=Society for Industrial and Applied Mathematics|year=2005|isbn=978-0898715811|url=http://www.mblazquez.es/blog-ccdoc-recuperacion/documentos/book_understanding-search-engines.pdf}}\u000a*{{cite book|editors=Berry, M. W.|title=Survey of Text Mining: Clustering, Classification, and Retrieval|location=New York|publisher=Springer|year=2004|url=https://perso.uclouvain.be/vincent.blondel/publications/08-textmining.pdf|isbn=978-0387955636}}\u000a*{{cite book|authors=Landauer, T., et al.|title=Handbook of Latent Semantic Analysis|publisher=Lawrence Erlbaum Associates|year=2007|isbn= 978-0805854183|url=http://books.google.de/books/about/Handbook_of_latent_semantic_analysis.html?id=jgVWCuFXePEC&redir_esc=y}}\u000a*{{cite book|authors=Manning, C. D., Schutze H.|title=Foundations of Statistical Natural Language Processing|location=Cambridge, MA|publisher=The MIT Press|year=1999|url=http://nlp.stanford.edu/fsnlp/promo/contents.ps|isbn=9780262133609 }} [http://nlp.stanford.edu/fsnlp/ Companion webpage]\u000a\u000a==External links==\u000a* [http://www.cs.utk.edu/~lsi/ Michael Berry\u2019s site]\u000a* [http://radimrehurek.com/gensim Gensim] contains a scalable Python+[[NumPy]] implementation of LSI, even for datasets larger than the available RAM.\u000a* [http://scgroup.hpclab.ceid.upatras.gr/scgroup/Projects/TMG/ Text to Matrix Generator (TMG)]  MATLAB toolbox that can be used for various tasks in text mining (TM) specifically  i) indexing, ii) retrieval, iii) dimensionality reduction, iv) clustering, v) classification. Most of TMG is written in MATLAB and parts in Perl. It contains implementations of LSI, clustered LSI, NMF and other methods.\u000a* [http://www.youtube.com/watch?v=QGd06MTRMHs Stanford University Andrew Ng Video on LSI]\u000a\u000a{{DEFAULTSORT:Latent semantic indexing}}\u000a[[Category:Information retrieval]]\u000a[[Category:Semantic Web]]
p41
sg4
S'151'
p42
sg6
VLatent semantic indexing
p43
ssI26
(dp44
g2
V{{advert|date=April 2012}}\u000a{{Infobox company |\u000a  name   = ZyLAB |\u000a  logo   = <!--  Commented out because image was deleted: [[Image:zylab logo.jpg|center]] --> |\u000a  slogan = "eDiscovery & Information Risk Management" |\u000a  type   = Private |\u000a  foundation     = 1983 |\u000a  location       = [[McLean, Virginia]]<br>[[Amsterdam]] |\u000a  key_people     = [[Pieter Varkevisser]], president & CEO<br>[[Dr. Johannes C. Scholtes]], chairman & chief strategy officer | Mary Mack, Enterprise Technology Counsel\u000a  num_employees  = 140 |\u000a  industry       = [[Software]], eDiscovery and Information Risk Management, Records Management, Email Archiving, SharePoint Archiving |\u000a  products       = ZyLAB Information Management Platform and various bundles for eDiscovery, email & SharePoint archiving, text-analytics, visualization, contract management, and workflow. |\u000a\u000a  homepage       = [http://www.zylab.com/ www.zylab.com]\u000a}}\u000a\u000a'''ZyLAB''' is a developer of software for [[Electronic discovery|e-discovery]], information risk management, email management, records, contract, and document management, knowledge management, and workflow. The company is headquartered in [[McLean, Virginia]] and in [[Amsterdam]], [[Netherlands]]. ZyLAB\u2019s most important products are ZyLAB eDiscovery & Production System, the ZyLAB Information Management Platform and bundles that build systems for deployments.\u000a\u000a== History ==\u000aIn 1983 ZyLAB was the first company providing a [[Full text search|full-text]] search program for electronic files stored in the file system of [[IBM PC compatible|IBM-compatible PCs]]. The program was called ZyINDEX. The first version of ZyINDEX was written in [[Pascal (programming language)|Pascal]] and worked on [[MS-DOS]]. Subsequent programs were written in [[C (programming language)|C]], [[C++]] and [[C Sharp (programming language)|C#]] and work on a variety of Microsoft operating systems.\u000a\u000aIn 1991, ZyLAB integrated ZyINDEX with an optical character recognition ([[Optical character recognition|OCR]]) program, Calera Wordscan, which was a spin-off from [[Raymond Kurzweil]]\u2019s first OCR implementation. This integration was called ZyIMAGE. ZyIMAGE was the first PC program to include a [[Fuzzy string searching|fuzzy string search]] algorithm to overcome scanning and OCR errors.\u000a\u000aIn 1998, the company developed support to full-text search email, including attachments.\u000a\u000aIn 2000, ZyLAB embraced the new [[XML]] standard and created a full content management and records management system based on the XML standard and build a full solution for e-discovery, historical archives, records management, document management, email archiving, contract management, and professional back-office solutions.\u000a\u000aIn 2003, the company invested in expanding the ZyIMAGE product suite with advanced [[text analytics]], [[text mining]], [[data visualization]], [[computational linguistics]], and [[Machine translation|automatic translation]].\u000a\u000a2005: ZyIMAGE Information Access Platform was released, an integrated solution to address information access problems.\u000a\u000aPlatforms for ZyIMAGE e-Discovery and legal production, historical archiving, compliance, back-office records management and [[COMINT#COMINT|COMINT]] were launched in 2007.\u000a\u000a2010: ZyLAB Information Management Platform was released, an integrated solution to address e-Discovery and information management problems.\u000a\u000a==Customers==\u000aInitial customers of ZyINDEX were organizations such as the [[FBI]] and other law enforcement agencies to investigate electronic data from seized PCs, the [[United States Navy|U.S. Navy]] for on-board manuals, and law firms around the world for [[Electronic discovery|e-Discovery]]. Over the years, ZyLAB received grants from the European Union (DG13).\u000a\u000aOther well-known ZyLAB customers were [[O. J. Simpson murder case|O.J. Simpson's defense team]], war crime tribunals such as the [[trial of Slobodan Milo\u0161evi\u0107]], the [[Special Court for Sierra Leone]], the [[Extraordinary Chambers in the Courts of Cambodia|UN-AKRT-ECCC Cambodia Khmer Rouge trials]] and the [[International Criminal Tribunal for Rwanda|Rwanda tribunal]]. In 2007, the U.S. [[Executive Office of the President of the United States|Executive Office of the President]] selected ZyLAB for email archiving, basically for its open XML structures, which is endorsed by organizations such as the [[National Archives and Records Administration]]. ZyLAB\u2019s software was used for many other high-profile investigations such as the [[Oklahoma City bombing]].\u000a\u000aPublic websites also use the ZyLAB Webserver.\u000a\u000a[[Gartner]] positioned ZyLAB in the "Leaders" quadrant in its 2007, 2008 and 2009 Magic Quadrant for Information Access Solutions, gave it a strong positive rating in its 2007, 2008 and 2009 e-Discovery Marketscope and a Positive Rating in its 2007 and 2008 Records Management MarketScope.\u000a\u000aZyLAB\u2019s chief strategy officer, Dr. Johannes C. Scholtes, is professor in [[text mining]] at [[Maastricht University|the University of Maastricht]] faculty of Humanities and Sciences and director in the board of AIIM.\u000a\u000a==System overview and compatibility==\u000aAccording to the company\u2019s website it delivers systems for deployments, product bundles and the core components is the ZyLAB Information Management platform include:\u000a\u000aSystems:\u000a*ZyLAB eDiscovery and Production\u000a*ZyLAB Compliance and Litigation readiness\u000a*ZyLAB Law Enforcement and Investigations\u000a*ZyLAB Communications Intelligence\u000a*ZyLAB Digital Print and Media Archiving\u000a*ZyLAB Enterprise Information Management\u000a\u000aBundles:\u000a*E-Mail Archiving Bundle\u000a*Microsoft SharePoint Bundle\u000a*Analytics Bundle\u000a*eDiscovery EDRM Processing bundle\u000a*DoD and Sox Compliant RMA Bundle\u000a*TIFF Archiving and Production Bundle\u000a*WebPublishing Bundle\u000a*Commercial Publishing Bundle\u000a*Business Process Automation Bundle\u000a*Development and Integrators Bundle\u000a*Scanning Bundle\u000a*Digital Copier Bundle\u000a*Professional Text Mining\u000a*Machine translation\u000a\u000a===Supported configurations===\u000a*'''Server OS''': Windows 2003, Windows 2008\u000a*'''Databases''': XML, MS SQL Server 2005, MS SQL Server 2008, Oracle 10g, Oracle 11g, mySQL\u000a*'''Web Servers''': IIS\u000a*'''Client OS''': Windows XP, Windows Vista, Windows 7\u000a*'''Clustering''': Support for Active/Passive Failover.\u000a*'''Authentication''': Active Directory, LDAP, XML, NTFS, IBM Tripoli.\u000a*'''Virtualization''': VMware Infrastructure, VMware Workstation, VMware Server, VMware Fusion.\u000a\u000a===Languages supported===\u000a*'''Unicode'''. Support for documents in all languages.\u000a*'''Internationalization'''. ZyLAB offers translated products for English, German, French, Dutch, Spanish, Italian, Danish, Swedish, Norwegian, Finnish, Portuguese, Arabic and [[Persian language|Persian]]. In addition to these languages, over 400 languages are supported by ZyLAB's recognition and full-text indexing technology, including all Western-European, Eastern European, Baltic, African, Asian and South American languages. ZyLAB's technical ability for broad language and character recognition enhances the accuracy of stored information searches and helps diminish the costs incurred by incorrect searches or text correction.\u000a\u000a==Zy-IMAGE-nation Annual Conference==\u000aThe annual Zy-IMAGE-nation Conference is sponsored by ZyLAB. During this conference, seminars and interactive sessions from leading professionals about the advanced technologies and procedural enhancements that are driving new levels of operational efficiency in private and public sectors. The focus of the conference is on technologies that provide integrated capabilities for managing the accumulated knowledge of an organization, especially records and e-mail, as well as other business-critical processes. Related topics to be covered include best practices for e-discovery preparation and implementation, records management, email archiving, and knowledge management.\u000a\u000a==See also==\u000a* [[Electronic discovery|e-Discovery]]\u000a* [[Optical character recognition|Optical Character Recognition (OCR)]]\u000a* [[Document Imaging]]\u000a* [[E-mail archiving|E-mail Archiving]]\u000a* [[Knowledge Management]]\u000a* [[Document management system|Document Management (System)]]\u000a* [[Enterprise content management|Enterprise Content Management]]\u000a* [[Records management|Records Management]]\u000a* [[Contract management|Contract Management]]\u000a* [[Workflow]]\u000a* [[Text mining|Text Mining]]\u000a* [[Text analytics|Text Analytics]]\u000a* [[Machine translation|Automatic Machine Translation]]\u000a* [[Data visualization|Data Visualization]]\u000a\u000a==References==\u000a{{Reflist}}\u000a*[http://www.pcmag.com/encyclopedia_term/0,,t=zyindex&i=55248,00.asp Definition of ZyINDEX] in [[PC Magazine|''PCMAG.com'']]'s encyclopedia\u000a*[http://www.pcmag.com/encyclopedia_term/0,2542,t=ZyIMAGE&i=55247,00.asp Definition of ZyIMAGE] in [[PC Magazine|''PCMAG.com'']]'s encyclopedia\u000a*[http://www.informationweek.com/777/knowledge.htm Review] of ZyImage 3.0 in ''[[InformationWeek]]''\u000a*[http://www.accessmylibrary.com/coms2/summary_0286-9201794_ITM Mac version of ZyINDEX made its debut on Comdex]\u000a*[http://query.nytimes.com/gst/fullpage.html?res=940DE6DA1730F93AA35751C0A96E948260 Review] of ZyINDEX in the ''[[New York Times]]''\u000a*[http://www.computerwoche.de/heftarchiv/1988/26/1155611/ Review] of ZyINDEX on ''Computerwoche.de'' (article in German)\u000a*[http://www.computerwoche.de/index.cfm?pid=2123&pk=1096333 Review] of ZyIMAGE's webserver on ''Computerwoche.de'' (article in German)\u000a*[http://nl.newsbank.com/nl-search/we/Archives?p_product=MH&s_site=miami&p_multi=MH&p_theme=realcities&p_action=search&p_maxdocs=200&p_topdoc=1&p_text_direct-0=0EB367D56736E685&p_field_direct-0=document_id&p_perpage=10&p_sort=YMD_date: Review] of ZyINDEX in the ''[[Miami Herald]]''\u000a*[http://www.usdoj.gov/oig/special/0203/chapter3.htm ZyINDEX used in the Investigation of the Belated Production of Documents in the Oklahoma City Bombing Case]\u000a*[http://www.fcw.com/print/6_31/news/70014-1.html Review] of ZyIMAGE on ''Federal Computer Week (FCW.com)''\u000a*Zylab retrieval engine optimized for CD-ROM; Zylab, Progressive Technologies merge," Seybold Report on Desktop Publishing. vol. 8, No. 10, Jun. 6, 1994, p. 40.\u000a*Knibbe, "ZyImage 2 boosts, OCR, batch duties," InfoWorld, vol. 15, Issue 51, Dec. 20, 1993, p.&nbsp;20.\u000a*Knibbe, "ZyImage 3.0 will facilitate distribution on CD-ROMs; Boasts integration with WordScan OCR software," InfoWorld, vol. 16, No. 38, Sep. 19, 1994, p.&nbsp;22.\u000a*Marshall, "Text retrieval alternatives: 10 more ways to pinpoint important information," Infoworld, vol. 14, No. 12, Mar. 23, 1992, pp.&nbsp;88\u201389.\u000a*Marshall, "ZyImage adds scanning access to ZyIndex," InfoWorld, vol. 16, No. 15, Apr. 11, 1994, pp.&nbsp;73, 76, and 77.\u000a*Marshall, "ZyImage is ZyIndex plus a scan interface integrated," InfoWorld. vol. 15, Issue 10, Mar. 8, 1993, p.&nbsp;100.\u000a*Marshall et al., "ZyIndex for Windows, Version 5.0," InfoWorld, v. 15, n. 21, May 1993, pp.&nbsp;127, 129, 133 and 137.\u000a*Simon, "ZyImage: A Winning Combination of OCR And Text Indexing," PC Magazine. vol. 12, No. 6, Mar. 30, 1993, p.&nbsp;56.\u000a*Rooney, "Text-retrieval veterans prepare Windows attack," PC Week, v. 9, n. 24, Jun. 1992, p.&nbsp;46.\u000a*Rooney, "ZyLab partners with Calera: firms roll out document-image system," PC Week, vol. 10, No. 3, Jan. 25, 1993, p.&nbsp;22.\u000a*Torgan, "ZyImage: Document Imaging and Retrieval System," PC Magazine. vol. 12, No. 3, Feb. 9, 1993, p.&nbsp;62.\u000a\u000a===Gartner reports===\u000a*Introduction to Investigative Case Management Products (18 April 2007)\u000a*Hype Cycle for Legal and Regulatory Information Governance, 2007 (16 July 2007)\u000a*MarketScope for Contract Management, 2007 (16 July 2007)\u000a*Choosing an E-Discovery Solution in 2007 and 2008 (18 July 2007)\u000a*Magic Quadrant for Information Access Technology, 2007 (5 September 2007)\u000a*Magic Quadrant for Information Access Technology, 2008\u000a*Magic Quadrant for Information Access Technology, 2009\u000a*The Expanding Enterprise E-Discovery Marketplace (12 November 2007)\u000a*MarketScope for E-Discovery and Litigation Support Vendors, 2007 (14 December 2007)\u000a*MarketScope for E-Discovery Product Vendors, 2008\u000a*MarketScope for E-Discovery Product Vendors, 2009\u000a*MarketScope for Records Management (20 May 2008)\u000a*Hype Cycle for Content Management, 2008 (8 July 2008)\u000a*Using the Electronic Discovery Reference Model to Identify, Collect and Preserve Digital Evidence (11 July 2008)\u000a*Using the Electronic Discovery Reference Model to Process, Review and Analyze Digital Evidence (11 July 2008)\u000a*Hype Cycle for Governance, Risk and Compliance Technologies, 2009 (17 July 2009)\u000a\u000a==External links==\u000a*[http://www.zylab.com/ ZyLAB official website]\u000a*[http://www.edrm.net/ The Electronic Discovery Reference Model (EDRM)]\u000a*[http://www.aiim.org/ AIIM]\u000a\u000a[[Category:Companies established in 1983]]\u000a[[Category:Software companies of the United States]]\u000a[[Category:Information retrieval]]
p45
sg4
S'26'
p46
sg6
VZyLAB Technologies
p47
ssI156
(dp48
g2
VA directory maintains a list for reference or commercial purposes.  This category contains articles about directories.\u000a{{Cat main|Directories}}\u000a{{Commons cat|Directories}}\u000a\u000a[[Category:Telephony]]\u000a[[Category:Reference works]]\u000a[[Category:Data management]]\u000a[[Category:Information retrieval]]
p49
sg4
S'156'
p50
sg6
VCategory:Directories
p51
ssI31
(dp52
g2
V'''Term Discrimination''' is a way to rank keywords in how useful they are for [[Information Retrieval]].\u000a\u000a== Overview ==\u000a\u000aThis is a method similar to [[tf-idf]] but it deals with finding keywords suitable for [[information retrieval]] and ones that are not.  Please refer to [[Vector Space Model]] first.\u000a\u000aThis method uses the concept of ''Vector Space Density'' that the less dense an [[occurrence matrix]] is, the better an information retrieval query will be.\u000a\u000aAn optimal index term is one that can distinguish two different documents from each other and relate two similar documents.  On the other hand, a sub-optimal index term can not distinguish two different document from two similar documents.  \u000a\u000aThe discrimination value is the difference in the occurrence matrix's vector-space density versus the same matrix's vector-space without the index term's density.\u000a\u000a Let:\u000a <math>A</math> be the occurrence matrix\u000a <math>A_k</math> be the occurrence matrix without the index term <math>k</math>\u000a and <math>Q(A)</math> be density of <math>A</math>.\u000a Then:\u000a The discrimination value of the index term <math>k</math> is: \u000a <math>DV_k = Q(A) - Q(A_k)</math>\u000a\u000a== How to compute ==\u000a\u000aGiven an [[occurrency matrix]]: <math>A</math> and one keyword: <math>k</math>\u000a* Find the global document [[centroid]]: <math>C</math> (this is just the average document vector)\u000a* Find the average [[euclidean distance]] from every document vector, <math>D_i</math> to <math>C</math>\u000a* Find the average euclidean distance from every document vector, <math>D_i</math> to <math>C</math> ''IGNORING'' <math>k</math>\u000a* The difference between the two values in the above step is the ''discrimination value'' for keyword <math>K</math>\u000a\u000aA higher value is better because including the keyword will result in better information retrieval.\u000a\u000a== Qualitative Observations ==\u000aKeywords that are ''[[Sparse matrix|sparse]]'' should be poor discriminators because they have poor ''[[Precision and recall|recall]],''\u000awhereas\u000akeywords that are ''frequent'' should be poor discriminators because they have poor ''[[Precision and recall|precision]].''\u000a\u000a== References ==\u000a* [[Gerard Salton|G. Salton]], A. Wong, and C. S. Yang (1975), "[http://www.cs.uiuc.edu/class/fa05/cs511/Spring05/other_papers/p613-salton.pdf A Vector Space Model for Automatic Indexing]," ''Communications of the ACM'', vol. 18, nr. 11, pages 613\u2013620. ''(The article in which the vector space model was first presented)''\u000a\u000a* Can, F., Ozkarahan, E. A (1987), "Computation of term/document discrimination values by use of the cover coefficient concept." ''Journal of the American Society for Information Science'', vol. 38, nr. 3, pages 171-183.\u000a\u000a[[Category:Information retrieval]]
p53
sg4
S'31'
p54
sg6
VTerm Discrimination
p55
ssI161
(dp56
g2
V{{Redirect|Search engine}}\u000a{{selfref|For a tutorial on using search engines for researching Wikipedia articles, see [[Wikipedia:Search engine test]].}}\u000a[[File:Internet Key Layers.png|thumb|400px|right|Finding information on the World Wide Web had been a difficult and frustrating task, but became much more usable with breakthroughs in search engine technology in the late 1990s.]]\u000aA '''web search engine''' is a software system that is designed to search for information on the [[World Wide Web]].  The search results are generally presented in a line of results often referred to as [[search engine results pages]] (SERPs). The information may be a mix of [[web page]]s, images, and other types of files. Some search engines also [[data mining|mine data]] available in [[database]]s or [[web directory|open directories]].  Unlike [[web directories]], which are maintained only by human editors, search engines also maintain [[real-time computing|real-time]] information by running an [[algorithm]] on a [[web crawler]].\u000a\u000a== History ==\u000a{{further|Timeline of web search engines}}\u000a<!-- Keep this list limited to notable engines (i.e. those that already have Wikipedia articles) to avoid link spam -->\u000a{| class="bordered infobox"\u000a|-\u000a! colspan="3" | Timeline ([[List of search engines|full list]]) <!--Note:  "Launch" refers only to web availability of original crawl-based web search engine results.-->\u000a|-\u000a!Year\u000a!Engine\u000a!Current status\u000a|-\u000a| rowspan="4" |1993\u000a||[[W3Catalog]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Aliweb]]\u000a|{{Site inactive}}\u000a|-\u000a||[[JumpStation]]\u000a|{{Site inactive}}\u000a|-\u000a||[[World-Wide Web Worm|WWW Worm]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="4" |1994\u000a||[[WebCrawler]]\u000a|{{Site active}}, Aggregator\u000a|-\u000a||[[Go.com]]\u000a|{{Site active}}, Yahoo Search\u000a|-\u000a||[[Lycos]]\u000a|{{Site active}}\u000a|-\u000a||[[Infoseek]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="6" |1995\u000a||[[AltaVista]]\u000a|{{Site inactive}}, redirected to Yahoo!\u000a|-\u000a|[[Daum Communications|Daum]]\u000a|{{Site active}}\u000a|-\u000a||[[Magellan (search engine)|Magellan]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Excite]]\u000a|{{Site active}}\u000a|-\u000a||[[SAPO (company)|SAPO]]\u000a|{{Site active}}\u000a|-\u000a||[[Yahoo!]]\u000a|{{Site active}}, Launched as a directory\u000a|-\u000a| rowspan="4" |1996\u000a||[[Dogpile]]\u000a|{{Site active}}, Aggregator\u000a|-\u000a||[[Inktomi (company)|Inktomi]]\u000a|{{Site inactive}}, acquired by Yahoo!\u000a|-\u000a||[[HotBot]]\u000a|{{Site active}}  (lycos.com)\u000a|-\u000a||[[Ask.com|Ask Jeeves]]\u000a|{{Site active}}  (rebranded ask.com)\u000a|-\u000a| rowspan="2" |1997\u000a||[[Northern Light Group|Northern Light]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Yandex]]\u000a|{{Site active}}\u000a|-\u000a| rowspan="4" |1998\u000a||[[Google Search|Google]]\u000a|{{Site active}}\u000a|-\u000a||[[Ixquick]]\u000a|{{Site active}}  also as Startpage\u000a|-\u000a||[[MSN Search]]\u000a|{{Site active}}  as Bing\u000a|-\u000a||[[empas]]\u000a|{{Site inactive}}  (merged with NATE)\u000a|-\u000a| rowspan="5" |1999\u000a||[[AlltheWeb]]\u000a|{{Site inactive}}  (URL redirected to Yahoo!)\u000a|-\u000a||[[GenieKnows]]\u000a|{{Site active}}, rebranded Yellowee.com\u000a|-\u000a||[[Naver]]\u000a|{{Site active}}\u000a|-\u000a||[[Teoma]]\u000a|{{Site inactive}}, redirects to Ask.com\u000a|-\u000a||[[Vivisimo]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="3" |2000\u000a||[[Baidu]]\u000a|{{Site active}}\u000a|-\u000a||[[Exalead]]\u000a|{{Site active}}\u000a|-\u000a||[[Gigablast]]\u000a|{{Site active}}\u000a|-\u000a| rowspan="2" |2003\u000a||[[Info.com]]\u000a|{{Site active}}\u000a|-\u000a||[[Scroogle]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="3" |2004\u000a||[[Yahoo! Search]]\u000a|{{Site active}}, Launched own web search<br />(see Yahoo! Directory, 1995)\u000a|-\u000a||[[A9.com]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Sogou.com|Sogou]]\u000a|{{Site active}}\u000a|-\u000a| rowspan="3" |2005\u000a||[[AOL Search]]\u000a|{{Site active}}\u000a|-\u000a||[[GoodSearch]]\u000a|{{Site active}}\u000a|-\u000a||[[SearchMe]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="6" |2006\u000a||[[Soso (search engine)]]\u000a|{{Site active}}\u000a|-\u000a||[[Quaero]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Ask.com]]\u000a|{{Site active}}\u000a|-\u000a||[[Live Search]]\u000a|{{Site active}} as Bing, Launched as<br />rebranded MSN Search\u000a|-\u000a||[[ChaCha (search engine)|ChaCha]]\u000a|{{Site active}}\u000a|-\u000a||[[Guruji.com]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="4" |2007\u000a||[[wikiseek]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Sproose]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Wikia Search]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Blackle.com]]\u000a|{{Site active}}, Google Search\u000a|-\u000a| rowspan="7" |2008\u000a||[[Powerset (company)|Powerset]]\u000a|{{Site inactive}} (redirects to Bing)\u000a|-\u000a||[[Picollator]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Viewzi]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Boogami]]\u000a|{{Site inactive}}\u000a|-\u000a||[[LeapFish]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Forestle]]\u000a|{{Site inactive}} (redirects to Ecosia)\u000a|-\u000a||[[DuckDuckGo]]\u000a|{{Site active}}\u000a|-\u000a| rowspan="5" |2009\u000a||[[Bing]]\u000a|{{Site active}}, Launched as<br />rebranded Live Search\u000a|-\u000a||[[Yebol]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Mugurdy]]\u000a|{{Site inactive}}  due to a lack of funding\u000a|-\u000a||[[Goby Inc.|Scout (Goby)]]\u000a|{{Site active}}\u000a|-\u000a||[[Nate (web portal)|NATE]]\u000a|{{Site active}}\u000a|-\u000a| rowspan="3" |2010\u000a||[[Blekko]]\u000a|{{Site active}}\u000a|-\u000a||[[Cuil]]\u000a|{{Site inactive}}\u000a|-\u000a||[[Yandex]]\u000a|{{Site active}}, Launched global<br />(English) search\u000a|-\u000a||2011\u000a||[[YaCy]]\u000a|{{Site active}}, [[Peer-to-peer|P2P]] web search engine\u000a|-\u000a| rowspan="1" |2012\u000a||[[Volunia]]\u000a|{{Site inactive}}\u000a|-\u000a| rowspan="1" |2013\u000a||[[Halalgoogling]]\u000a|{{Site active}}, Islamic / Halal<br />filter Search\u000a|}\u000a\u000aDuring early development of the web, there was a list of [[webserver]]s edited by [[Tim Berners-Lee]] and hosted on the [[CERN]] webserver. One historical snapshot of the list in 1992 remains,<ref>{{cite web|url=http://www.w3.org/History/19921103-hypertext/hypertext/DataSources/WWW/Servers.html |title=World-Wide Web Servers |publisher=W3.org |accessdate=2012-05-14}}</ref> but as more and more webservers went online the central list could no longer keep up. On the [[National Center for Supercomputing Applications|NCSA]]  site, new servers were announced under the title "What's New!"<ref>{{cite web|url=http://home.mcom.com/home/whatsnew/whats_new_0294.html |title=What's New! February 1994 |publisher=Home.mcom.com |accessdate=2012-05-14}}</ref>\u000a\u000aThe first tool used for searching on the [[Internet]] was [[Archie search engine|Archie]].<ref name=LeidenUnivSE>\u000a     "Internet History - Search Engines" (from [[Search Engine Watch]]),\u000a     Universiteit Leiden, Netherlands, September 2001, web:\u000a     [http://www.internethistory.leidenuniv.nl/index.php3?c=7 LeidenU-Archie].\u000a</ref>\u000aThe name stands for "archive" without the "v".  It was created in 1990 by [[Alan Emtage]], Bill Heelan and J. Peter Deutsch, computer science students at [[McGill University]]  in [[Montreal]]. The program downloaded the directory listings of all the files located on public anonymous FTP ([[File Transfer Protocol]]) sites, creating a searchable database of file names; however, Archie did not index the contents of these sites since the amount of data was so limited it could be readily searched manually.\u000a\u000aThe rise of [[Gopher (protocol)|Gopher]] (created in 1991 by [[Mark McCahill]]  at the [[University of Minnesota]]) led to two new search programs, [[Veronica (computer)|Veronica]]  and [[Jughead (computer)|Jughead]]. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (''V''ery ''E''asy ''R''odent-''O''riented ''N''et-wide ''I''ndex to ''C''omputerized ''A''rchives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (''J''onzy's ''U''niversal ''G''opher ''H''ierarchy ''E''xcavation ''A''nd ''D''isplay) was a tool for obtaining menu information from specific Gopher servers.  While the name of the search engine "Archie" was not a reference to the [[Archie Comics|Archie comic book]] series, "[[Veronica Lodge|Veronica]]" and "[[Jughead Jones|Jughead]]" are characters in the series, thus referencing their predecessor.\u000a\u000aIn the summer of 1993, no search engine existed for the web, though numerous specialized catalogues were maintained by hand. [[Oscar Nierstrasz]] at the [[University of Geneva]] wrote a series of [[Perl]] scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for [[W3Catalog]], the web's first primitive search engine, released on September 2, 1993.<ref name="Announcement html">{{cite web |url= http://groups.google.com/group/comp.infosystems.www/browse_thread/thread/2176526a36dc8bd3/2718fd17812937ac?hl=en&lnk=gst&q=Oscar+Nierstrasz#2718fd17812937ac|title=Searchable Catalog of WWW Resources (experimental)|author=[[Oscar Nierstrasz]]|date=2 September 1993}}</ref>\u000a\u000aIn June 1993, Matthew Gray, then at [[Massachusetts Institute of Technology|MIT]], produced what was probably the first [[web robot]], the [[Perl]]-based [[World Wide Web Wanderer]], and used it to generate an index called 'Wandex'.  The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995.  The web's second search engine [[Aliweb]] appeared in November 1993.  Aliweb did not use a [[web robot]], but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format.\u000a\u000a[[JumpStation]] (created in December 1993<ref>{{cite web|url=http://archive.ncsa.uiuc.edu/SDG/Software/Mosaic/Docs/old-whats-new/whats-new-1293.html |archiveurl=//web.archive.org/web/20010620073530/http://archive.ncsa.uiuc.edu/SDG/Software/Mosaic/Docs/old-whats-new/whats-new-1293.html |archivedate=2001-06-20 |title=Archive of NCSA what's new in December 1993 page |publisher=Web.archive.org |date=2001-06-20 |accessdate=2012-05-14}}</ref> by [[Jonathon Fletcher]]) used a [[web crawler|web robot]] to find web pages and to build its index, and used a [[web form]] as the interface to its query program.  It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below.  Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered.\u000a\u000aOne of the first "all text" crawler-based search engines was [[WebCrawler]], which came out in 1994.  Unlike its predecessors, it allowed users to search for any word in any webpage, which has become the standard for all major search engines since. It was also the first one widely known by the public.  Also in 1994, [[Lycos]] (which started at [[Carnegie Mellon University]]) was launched and became a major commercial endeavor.\u000a\u000aSoon after, many search engines appeared and vied for popularity. These included [[Magellan (search engine)|Magellan]], [[Excite]], [[Infoseek]], [[Inktomi (company)|Inktomi]], [[Northern Light Group|Northern Light]], and [[AltaVista]]. [[Yahoo!]] was among the most popular ways for people to find web pages of interest, but its search function operated on its [[web directory]], rather than its full-text copies of web pages. Information seekers could also browse the directory instead of doing a keyword-based search.\u000a\u000aGoogle adopted the idea of selling search terms in 1998, from a small search engine company named [[goto.com]]. This move had a significant effect on the SE business, which went from struggling to one of the most profitable businesses in the internet.<ref>http://www.udacity.com/view#Course/cs101/CourseRev/apr2012/Unit/616074/Nugget/671097</ref>\u000a\u000aIn 1996, [[Netscape]] was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page.  The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.<ref>{{cite web|title=Yahoo! And Netscape Ink International Distribution Deal|url=http://files.shareholder.com/downloads/YHOO/701084386x0x27155/9a3b5ed8-9e84-4cba-a1e5-77a3dc606566/YHOO_News_1997_7_8_General.pdf|postscript=<!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. -->{{inconsistent citations}}}}</ref><ref>{{Cite journal |date=1 April 1996|title=Browser Deals Push Netscape Stock Up 7.8% |publisher=Los Angeles Times |url=http://articles.latimes.com/1996-04-01/business/fi-53780_1_netscape-home |postscript=<!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. -->{{inconsistent citations}}}}</ref>\u000a\u000aSearch engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s.<ref>{{cite journal |last=Gandal |first=Neil |authorlink= |year=2001 |title=The dynamics of competition in the internet search engine market |journal=International Journal of Industrial Organization |volume=19 |issue=7 |pages=1103\u20131117 |doi=10.1016/S0167-7187(01)00065-0  |url= |accessdate=|quote= }}</ref> Several companies entered the market spectacularly, receiving record gains during their [[initial public offering]]s. Some have taken down their public search engine, and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the [[dot-com bubble]], a speculation-driven market boom that peaked in 1999 and ended in 2001.\u000a\u000aAround 2000, [[Google Search|Google's search engine]] rose to prominence.<ref>{{cite web|url=http://www.google.com/about/company/history/ |title=Our History in depth |publisher=W3.org |accessdate=2012-10-31}}</ref>  The company achieved better results for many searches with an innovation called [[PageRank]], as was explained in the paper ''Anatomy of a Search Engine'' written by [[Sergey Brin]] and [[Larry Page]], the later founders of Google.<ref>{{cite web|url=http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf|title=The Anatomy of a Large-Scale Hypertextual Web Search Engine|last1=Brin|first1=Sergey|last2=Page|first2=Larry}}</ref> This [[iterative algorithm]] ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a [[web portal]]. In fact, Google search engine became so popular that spoof engines emerged such as [[Mystery Seeker]].\u000a\u000aBy 2000, [[Yahoo!]] was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and [[Overture]] (which owned [[AlltheWeb]] and AltaVista) in 2003.  Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions.\u000a\u000a[[Microsoft]] first launched MSN Search in the fall of 1998 using search results from Inktomi.  In early 1999 the site began to display listings from [[Looksmart]], blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista were instead.  In 2004, [[Microsoft]] began a transition to its own search technology, powered by its own [[web crawler]] (called [[msnbot]]).\u000a\u000aMicrosoft's rebranded search engine, [[Bing]], was launched on June 1, 2009.  On July 29, 2009, Yahoo! and Microsoft finalized a deal in which [[Yahoo! Search]] would be powered by Microsoft Bing technology.\u000a\u000a== How web search engines work ==\u000a{{Original research|section|date=October 2013\u000a}}\u000a{{Refimprove|date=July 2013}}\u000aA search engine operates in the following order:\u000a# [[Web crawling]]\u000a# [[Index (search engine)|Indexing]]\u000a# [[Web search query|Searching]]<ref name=Jawadekar2011>{{citation |year=2011 |author=Jawadekar, Waman S |title=Knowledge Management: Text & Cases |url=http://books.google.com/books?id=XmGx4J9daUMC&printsec=frontcover&dq=knowledge+management:+text&hl=en&sa=X&ei=ou6uUP-cNqWTiAe2oICoAw&sqi=2&ved=0CDIQ6AEwAA |chapter=8. Knowledge Management: Tools and Technology |chapter-url=http://books.google.com/books?id=XmGx4J9daUMC&pg=PA278&dq=%22search+engine+operates%22&hl=en&sa=X&ei=a-muUJ6UC4aeiAfI24GYAw&sqi=2&ved=0CDgQ6AEwBA |page=278 |place=New Delhi |publisher=Tata McGraw-Hill Education Private Ltd |isbn=978-0-07-07-0086-4 |accessdate=November 23, 2012 }}</ref>\u000a\u000aWeb search engines work by storing information about many web pages, which they retrieve from the [[HTML]] markup of the pages. These pages are retrieved by a [[Web crawler]] (sometimes also known as a spider) \u2014 an automated Web crawler which follows every link on the site. The site owner can exclude specific pages by using [[robots.txt]].\u000a\u000aThe search engine then analyzes the contents of each page to determine how it should be [[Search engine indexing|indexed]] (for example, words can be extracted from the titles, page content, headings, or special fields called [[meta tags]]). Data about web pages are stored in an index database for use in later queries. A query from a user can be a single word. The index helps find information relating to the query as quickly as possible.<ref name=Jawadekar2011/> Some search engines, such as [[Google]], store all or part of the source page (referred to as a [[web cache|cache]]) as well as information about the web pages, whereas others, such as [[AltaVista]], store every word of every page they find.{{Citation needed|date=November 2012}} This cached page always holds the actual search text since it is the one that was actually indexed, so it can be very useful when the content of the current page has been updated and the search terms are no longer in it.<ref name=Jawadekar2011/> This problem might be considered a mild form of [[linkrot]], and Google's handling of it increases [[usability]] by satisfying [[user expectations]] that the search terms will be on the returned webpage. This satisfies the [[principle of least astonishment]], since the user normally expects that the search terms will be on the returned pages. Increased search relevance makes these cached pages very useful as they may contain data that may no longer be available elsewhere.{{Citation needed|date=November 2012}}\u000a[[File:WebCrawlerArchitecture.svg|thumb|High-level architecture of a standard Web crawler]]\u000aWhen a user enters a [[web search query|query]] into a search engine (typically by using [[Keyword (Internet search)|keywords]]), the engine examines its [[inverted index|index]] and provides a listing of best-matching web pages according to its criteria, usually with a short summary containing the document's title and sometimes parts of the text. The index is built from the information stored with the data and the method by which the information is indexed.<ref name=Jawadekar2011/> From 2007 the Google.com search engine has allowed one to search by date by clicking "Show search tools" in the leftmost column of the initial search results page, and then selecting the desired date range.{{Citation needed|date=November 2012}} Most search engines support the use of the [[boolean operators]] AND, OR and NOT to further specify the [[web search query|search query]]. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered.  Some search engines provide an advanced feature called [[Proximity search (text)|proximity search]], which allows users to define the distance between keywords.<ref name=Jawadekar2011/>  There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases you search for. As well, natural language queries allow the user to type a question in the same form one would ask it to a human. A site like this would be ask.com.{{Citation needed|date=November 2012}}\u000a\u000aThe usefulness of a search engine depends on the [[relevance (information retrieval)|relevance]] of the '''result set''' it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to [[rank order|rank]] the results to provide the "best" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another.<ref name=Jawadekar2011/> The methods also change over time as Internet usage changes and new techniques evolve.  There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an "[[inverted index]]" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work.\u000a\u000aMost Web search engines are commercial ventures supported by [[advertising]] revenue and thus some of them allow advertisers to [[paid inclusion|have their listings ranked higher]] in search results for a fee. Search engines that do not accept money for their search results make money by running [[contextual advertising|search related ads]] alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.<ref>{{cite web|title=FAQ|url=http://www.rankstar.de/hilfe.html|publisher=RankStar|accessdate=19 June 2013}}</ref>\u000a\u000a== Market share ==\u000a\u000a[[Google Search|Google]] is the world's most popular search engine, with a marketshare of 66.44 percent as of December, 2014.<ref name="NMS">{{cite web|url=http://marketshare.hitslink.com/search-engine-market-share.aspx?qprid=4&qpcustomd=0&qpcustom=|title=Desktop Search Engine Market Share|publisher=NetMarketShare|accessdate=2014-06-04}}</ref> [[Baidu]] comes in at second place.<ref name="NMS" />\u000a\u000aThe world's most popular search engines are:<ref>{{cite web|title=FAQ|url=https://www.netmarketshare.com/search-engine-market-share.aspx?qprid=4&qpcustomd=0|publisher=NetMarketShare|accessdate=23 November 2014}}</ref>\u000a\u000a{| class="wikitable sortable"\u000a! Search engine !! colspan="2" |Market share in December 2014\u000a|-\u000a| [[Google Search|Google]] || style="text-align:right;"|{{bartable|66.44|%|2}}\u000a|-\u000a| [[Baidu]]  || style="text-align:right;"|{{bartable| 11.15|%|2}}\u000a|-\u000a| [[Bing]]   || style="text-align:right;"|{{bartable| 10.29|%|2}}\u000a|-\u000a| [[Yahoo!]]  || style="text-align:right;"|{{bartable| 9.31|%|2}}\u000a|-\u000a| [[AOL]]    || style="text-align:right;"|{{bartable| 0.53|%|2}}\u000a|-\u000a| [[Ask.com|Ask]]    || style="text-align:right;"|{{bartable| 0.21|%|2}}\u000a|-\u000a| [[Lycos]]   || style="text-align:right;"|{{bartable| 0.01|%|2}}\u000a|}\u000a\u000a{| class="wikitable sortable"\u000a! Search engine !! colspan="2" |Market share in October 2014\u000a|-\u000a| [[Google Search|Google]] || style="text-align:right;"|{{bartable|58.01|%|2}}\u000a|-\u000a| [[Baidu]]  || style="text-align:right;"|{{bartable| 29.06|%|2}}\u000a|-\u000a| [[Bing]]   || style="text-align:right;"|{{bartable| 8.01|%|2}}\u000a|-\u000a| [[Yahoo!]]  || style="text-align:right;"|{{bartable| 4.01|%|2}}\u000a|-\u000a| [[AOL]]    || style="text-align:right;"|{{bartable| 0.21|%|2}}\u000a|-\u000a| [[Ask.com|Ask]]    || style="text-align:right;"|{{bartable| 0.10|%|2}}\u000a|-\u000a| [[Excite]]   || style="text-align:right;"|{{bartable| 0.00|%|2}}\u000a|}\u000a\u000a{| class="wikitable sortable"\u000a! Search engine !! colspan="2" |Market share in July 2014<ref name="NMS" />\u000a|-\u000a| [[Google Search|Google]] || style="text-align:right;"|{{bartable|68.69|%|2}}\u000a|-\u000a| [[Baidu]]  || style="text-align:right;"|{{bartable| 17.17|%|2}}\u000a|-\u000a| [[Yahoo!]]  || style="text-align:right;"|{{bartable| 6.74|%|2}}\u000a|-\u000a| [[Bing]]   || style="text-align:right;"|{{bartable| 6.22|%|2}}\u000a|-\u000a| [[Excite]]   || style="text-align:right;"|{{bartable| 0.22|%|2}}\u000a|-\u000a| [[Ask.com|Ask]]    || style="text-align:right;"|{{bartable| 0.13|%|2}}\u000a|-\u000a| [[AOL]]    || style="text-align:right;"|{{bartable| 0.13|%|2}}\u000a|}\u000a\u000a=== East Asia and Russia ===\u000a\u000aEast Asian countries and Russia constitute a few places where Google is not the most popular search engine.\u000a\u000a[[Yandex]] commands a marketshare of 61.9 per cent in Russia, compared to Google's 28.3 percent.<ref>{{cite web|url=http://www.liveinternet.ru/stat/ru/searches.html?slice=ru;period=week|title=Live Internet - Site Statistics|publisher=Live Internet|accessdate=2014-06-04}}</ref> In China, Baidu is the most popular search engine.<ref>{{cite news|url=http://www.theguardian.com/world/2014/jun/03/chinese-technology-companies-huawei-dominate-world|title=The Chinese technology companies poised to dominate the world|publisher=The Guardian|author=Arthur, Charles|date=2014-06-03|accessdate=2014-06-04}}</ref>  South Korea's homegrown search portal, [[Naver]], is used for 70 per cent online searches in the country.<ref>{{cite web|url=http://blogs.wsj.com/korearealtime/2014/05/21/how-naver-hurts-companies-productivity/|title=How Naver Hurts Companies\u2019 Productivity|publisher=The Wall Street Journal|date=2014-05-21|accessdate=2014-06-04}}</ref> [[Yahoo! Japan]] and [[Yahoo! Search|Yahoo! Taiwan]] are the most popular avenues for internet search in Japan and Taiwan, respectively.<ref>{{cite web|url=http://geography.oii.ox.ac.uk/?page=age-of-internet-empires|title=Age of Internet Empires|publisher=Oxford Internet Institute|accessdate=2014-06-04}}</ref>\u000a\u000a== Search engine bias ==\u000aAlthough search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide.<ref>Segev, El (2010). Google and the Digital Divide: The Biases of Online Knowledge, Oxford: Chandos Publishing.</ref><ref name=vaughan-thelwall>{{cite journal|last=Vaughan|first=Liwen|author2=Mike Thelwall |title=Search engine coverage bias: evidence and possible causes|journal=Information Processing & Management|year=2004|volume=40|issue=4|pages=693\u2013707|doi=10.1016/S0306-4573(03)00063-3}}</ref> These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its [[organic search]] results), and political processes (e.g., the removal of search results to comply with local laws).<ref>Berkman Center for Internet & Society (2002), [http://cyber.law.harvard.edu/filtering/china/google-replacements/ \u201cReplacement of Google with Alternative Search Systems in China: Documentation and Screen Shots\u201d], Harvard Law School.</ref> For example, Google will not surface certain Neo-Nazi websites in France and Germany, where Holocaust denial is illegal.\u000a\u000aBiases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more "popular" results.<ref>{{cite journal|last=Introna|first=Lucas|author2=[[Helen Nissenbaum]] |title=Shaping the Web: Why the Politics of Search Engines Matters|journal=The Information Society: An International Journal|year=2000|volume=16|issue=3|doi=10.1080/01972240050133634}}</ref> Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.<ref name=vaughan-thelwall />\u000a\u000a[[Google Bombing]] is one example of an attempt to manipulate search results for political, social or commercial reasons.\u000a\u000a== Customized results and filter bubbles ==\u000a\u000aMany search engines such as Google and Bing provide customized results based on the user's activity history. This leads to an effect that has been called a [[filter bubble]]. The term describes a phenomenon in which websites use [[algorithm]]s to selectively guess what information a user would like to see, based on information about the user (such as location, past click behaviour and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint, effectively isolating the user in a bubble that tends to exclude contrary information. Prime examples are Google's personalized search results and [[Facebook]]'s personalized news stream. According to [[Eli Pariser]], who coined the term, users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Pariser related an example in which one user searched Google for "BP" and got investment news about [[British Petroleum]] while another searcher got information about the [[Deepwater Horizon oil spill]] and that the two search results pages were "strikingly different".<ref name=twsT43>{{cite news\u000a |first1= Lynn | last1= Parramore\u000a |title= The Filter Bubble\u000a |work= The Atlantic\u000a |quote= Since Dec. 4, 2009, Google has been personalized for everyone. So when I had two friends this spring Google "BP," one of them got a set of links that was about investment opportunities in BP. The other one got information about the oil spill....\u000a |date=  10 October 2010\u000a |url= http://www.theatlantic.com/daily-dish/archive/2010/10/the-filter-bubble/181427/\u000a |accessdate= 2011-04-20\u000a}}</ref><ref name=twsO11>{{cite news\u000a |first= Jacob | last= Weisberg\u000a |title= Bubble Trouble: Is Web personalization turning us into solipsistic twits?\u000a |work= Slate\u000a |date= 10 June 2011\u000a |url= http://www.slate.com/id/2296633/\u000a |accessdate= 2011-08-15\u000a}}</ref><ref name=twsO14>{{cite news\u000a |first= Doug | last= Gross\u000a |title= What the Internet is hiding from you\u000a |publisher= ''CNN''\u000a |quote= I had friends Google BP when the oil spill was happening. These are two women who were quite similar in a lot of ways. One got a lot of results about the environmental consequences of what was happening and the spill. The other one just got investment information and nothing about the spill at all.\u000a |date= May 19, 2011\u000a |url= http://edition.cnn.com/2011/TECH/web/05/19/online.privacy.pariser/\u000a |accessdate= 2011-08-15\u000a}}</ref> The bubble effect may have negative implications for civic discourse, according to Pariser.<ref>{{cite journal| last1= Zhang | first1= Yuan Cao | first2= Diarmuid Ó |last2= Séaghdha | first3= Daniele | last3= Quercia | first4 =Tamas | last4 = Jambor |title=Auralist: Introducing Serendipity into Music Recommendation|journal=ACM WSDM |date=February 2012|url=http://www-typo3.cs.ucl.ac.uk/fileadmin/UCL-CS/research/Research_Notes/RN_11_21.pdf}}</ref>\u000a\u000aSince this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or "bubbling" users.\u000a\u000a== Faith-based search engines ==\u000a\u000aThe global growth of the Internet and popularity of electronic contents in the [[Arab]] and [[Muslim]] World during the last decade has encouraged faith adherents, notably in [[Middle East|the Middle East]] and [[Indian subcontinent|Asian sub-continent]], to "dream" of their own faith-based i.e. "[[Islamic]]" search engines or filtered search portals filters that would enable users to avoid accessing forbidden websites such as pornography and would only allow them to access sites that are compatible to the Islamic faith. Shortly before the Muslim only month of [[Ramadan]], [[Halalgoogling]] which collects results from other search engines like [[Google]] and [[Bing]] was introduced to the world July 2013 to presents the [[halal]] results to its users,<ref>{{cite web|url=http://news.msn.com/science-technology/new-islam-approved-search-engine-for-muslims |title=New Islam-approved search engine for Muslims |publisher=News.msn.com |date= |accessdate=2013-07-11}}</ref> nearly two years after I\u2019mHalal, another search engine initially (launched on September 2011) to serve Middle East Internet had to close its search service due to what its owner blamed on lack of funding.<ref>[http://blog.imhalal.com/ I\u2019mHalal - Islamic compliant search project launched September 2009 and shut down late 2011]</ref>\u000a\u000aWhile lack of investment and slow pace in technologies in the Muslim World as the main consumers or targeted end users has hindered progress and thwarted success of serious Islamic search engine, the spectacular failure of heavily invested Muslim lifestyle web projects like [[Muxlim]], which received millions of dollars from investors like Rite Internet Ventures, has - according to I\u2019mHalal shutdown notice - made almost laughable the idea that the next [[Facebook]] or [[Google]] can only come from [[Middle East|the Middle East]] if you support your bright youth.<ref>[http://imhalal.com/ I'mHalal Blog]</ref> Yet Muslim internet experts have been determining for years what is or is not allowed according to [[Shariah|the "Law of Islam"]] and have been categorizing websites and such into being either "[[halal]]" or "[[haram]]". All the existing and past Islamic search engines are merely custom search indexed or monetized by web major search giants like [[Google]], [[Yahoo]] and [[Bing]] with only certain filtering systems applied to ensure that their users can't access Haram sites, which include such sites as nudity, gay, gambling or anything that is deemed to be anti-Islamic.<ref>[http://blog.imhalal.com/ I'mHalal Blog]</ref>\u000a\u000aAnother religiously-oriented search engine is Jewogle, which is the Jewish version of Google and yet another is SeekFind.org, which is a Christian website that includes filters preventing users from seeing anything on the internet that attacks or degrades their faith.<ref>[http://allchristiannews.com/halalgoogling-muslims-get-their-own-sin-free-google-should-christians-have-christian-google/ AllChristianNews]</ref>\u000a\u000a== See also ==\u000a*[[Most popular Internet search engines]]\u000a* [[Comparison of web search engines]]\u000a* [[List of search engines]]\u000a* Answer engine ([[question answering]]) <!-- examples necessary here until article comprehensible to normal reader-->\u000a** [[Quora]]\u000a** [[True Knowledge]]\u000a** [[Wolfram Alpha]]\u000a* [[Google effect]]\u000a* [[Internet Search Engines and Libraries]]\u000a* [[Semantic Web]]\u000a* [[Spell checker]]\u000a* [[Web development tools]]\u000a\u000a== References ==\u000a{{Reflist|33em}}\u000a\u000a== Further reading ==\u000a* For a more detailed history of early search engines, see [http://searchenginewatch.com/showPage.html?page=3071951 Search Engine Birthdays] (from [[Search Engine Watch]]), Chris Sherman, September 2003.\u000a* {{cite journal | quotes =| author =Steve Lawrence; C. Lee Giles | year =1999| title =Accessibility of information on the web | journal =[[Nature (journal)|Nature]] | volume =400 | issue =6740| doi =10.1038/21987 | pmid =10428673 | pages =107\u20139 }}\u000a* Bing Liu (2007), ''[http://www.cs.uic.edu/~liub/WebMiningBook.html Web Data Mining: Exploring Hyperlinks, Contents and Usage Data].'' Springer,ISBN 3-540-37881-2\u000a* Bar-Ilan, J. (2004). The use of Web search engines in information science research. ARIST, 38, 231-288.\u000a* {{cite book | first =Mark | last =Levene | year =2005 | title =An Introduction to Search Engines and Web Navigation | publisher =Pearson | location =| isbn =}}\u000a* {{cite book | first =Randolph | last =Hock | year =2007 | title =The Extreme Searcher's Handbook}}ISBN 978-0-910965-76-7\u000a* {{cite journal | quotes =| author =Javed Mostafa |date= February 2005 | title =Seeking Better Web Searches | journal =[[Scientific American]] | volume =| issue =| pages =| publisher =| pmid =| doi =| bibcode =| url =http://www.sciam.com/article.cfm?articleID=0006304A-37F4-11E8-B7F483414B7F0000 | language =}}<sup class="noprint Inline-Template"><span title="&nbsp;since September 2010" style="white-space: nowrap;">&#91;''&#93;</span></sup>\u000a* {{cite journal |last=Ross |first=Nancy |authorlink=|author2=Wolfram, Dietmar  |year=2000 |title=End user searching on the Internet: An analysis of term pair topics submitted to the Excite search engine |journal=Journal of the American Society for Information Science |volume=51 |issue=10 |pages=949\u2013958 |doi=10.1002/1097-4571(2000)51:10<949::AID-ASI70>3.0.CO;2-5|url=|accessdate=|quote=}}\u000a* {{cite journal |last=Xie |first=M. |authorlink=|year=1998 |title=Quality dimensions of Internet search engines |journal=Journal of Information Science |volume=24 |issue=5 |pages=365\u2013372 |doi=10.1177/016555159802400509 |url=|accessdate=|quote=|display-authors=1 |last2=Wang |first2=H. |last3=Goh |first3=T. N. }}\u000a*{{cite book|title=Information Retrieval: Implementing and Evaluating Search Engines|url= http://www.ir.uwaterloo.ca/book/ | year=2010|publisher=MIT Press|author8=Stefan Büttcher, Charles L. A. Clarke, and Gordon V. Cormack}}\u000a\u000a== External links ==\u000a{{commons category|Internet search engines}}\u000a* {{Dmoz|Computers/Internet/Searching/Search_Engines/|Search Engines}}\u000a\u000a{{Internet search}}\u000a\u000a{{DEFAULTSORT:Web Search Engine}}\u000a[[Category:Internet search engines| ]]\u000a[[Category:History of the Internet]]\u000a[[Category:Information retrieval]]\u000a[[Category:Internet terminology]]
p57
sg4
S'161'
p58
sg6
VWeb search engine
p59
ssI36
(dp60
g2
V{{Refimprove|date=June 2007}}\u000a'''Mean reciprocal rank''' is a [[statistic]] measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. The reciprocal rank of a query response is the [[multiplicative inverse]] of the rank of the first correct answer. The mean reciprocal rank is the average of the reciprocal ranks of results for a sample of queries Q:<ref>{{cite conference | title=Proceedings of the 8th Text Retrieval Conference | booktitle=TREC-8 Question Answering Track Report | author=E.M. Voorhees |year=1999 | pages=77&ndash;82}}</ref>\u000a\u000a:<math> \u005ctext{MRR} = \u005cfrac{1}{|Q|} \u005csum_{i=1}^{|Q|} \u005cfrac{1}{\u005ctext{rank}_i}. \u005c!</math>\u000a\u000aThe reciprocal value of the mean reciprocal rank corresponds to the [[harmonic mean]] of the ranks.\u000a\u000a== Example ==\u000aFor example, suppose we have the following three sample queries for a system that tries to translate English words to their plurals.  In each case, the system makes three guesses, with the first one being the one it thinks is most likely correct:\u000a\u000a{| class="wikitable"\u000a|-\u000a! Query\u000a! Results\u000a! Correct response\u000a! Rank\u000a! Reciprocal rank\u000a|-\u000a| cat\u000a| catten, cati, '''cats'''\u000a| cats\u000a| 3\u000a| 1/3\u000a|-\u000a| torus\u000a| torii, '''tori''', toruses\u000a| tori\u000a| 2\u000a| 1/2\u000a|-\u000a| virus\u000a| '''viruses''', virii, viri\u000a| viruses\u000a| 1\u000a| 1\u000a|}\u000a\u000aGiven those three samples, we could calculate the mean reciprocal rank as (1/3&nbsp;+&nbsp;1/2&nbsp;+&nbsp;1)/3 = 11/18 or about 0.61.\u000a\u000aThis basic definition does not specify what to do if...\u000a# none of the proposed results are correct (use reciprocal rank 0), or if\u000a# there are multiple correct answers in the list. Consider using [[Information_retrieval#Mean_average_precision|mean average precision (MAP)]].\u000a\u000aSee also [[Information retrieval]] and [[Question answering]].<ref>{{cite conference | title=Evaluating web-based question answering systems | booktitle=Proceedings of LREC | author=D. R. Radev, H. Qi, H. Wu, W. Fan |year=2002 }}</ref>\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a[[Category:Summary statistics]]\u000a[[Category:Information retrieval]]
p61
sg4
S'36'
p62
sg6
VMean reciprocal rank
p63
ssI166
(dp64
g2
V{{Confusing|date=January 2010}}\u000aThe '''Generalized vector space model''' is a generalization of the [[vector space model]] used in [[information retrieval]].  Many classifiers, especially those which are related to document or text classification, use the TFIDF basis of VSM.  However, this is where the similarity between the models ends - the generalized model uses the results of the TFIDF dictionary to generate similarity metrics based on distance or angle difference, rather than centroid based classification.  '''Wong et al.'''<ref name="wong">{{cite | title=Generalized vector spaces model in information retrieval | url=http://doi.acm.org/10.1145/253495.253506 | first=S. K. M. | last=Wong | coauthors=Wojciech Ziarko, Patrick C. N. Wong | publisher=[[Association for Computing Machinery|SIGIR ACM]] | date=1985-06-05}}</ref> presented an analysis of the problems that the pairwise orthogonality assumption of the [[vector space model]] (VSM) creates. From here they extended the VSM to the generalized vector space model (GVSM).\u000a\u000a==Definitions==\u000a\u000aGVSM introduces a term to term correlations, which deprecate the pairwise orthogonality assumption. More specifically, the factor considered a new space, where each term vector ''t<sub>i</sub>'' was expressed as a linear combination of ''2<sup>n</sup>'' vectors ''m<sub>r</sub>'' where ''r = 1...2<sup>n</sup>''.\u000a\u000aFor a document ''d<sub>k</sub>'' and a query ''q'' the similarity function now becomes:\u000a\u000a:<math>sim(d_k,q) = \u005cfrac{\u005csum _{j=1}^n \u005csum _{i=1}^n w_{i,k}*w_{j,q}*t_i \u005ccdot t_j }{\u005csqrt{\u005csum _{i=1}^n w_{i,k}^2}*\u005csqrt{\u005csum _{i=1}^n w_{i,q}^2}}</math>\u000a\u000awhere ''t<sub>i</sub>'' and ''t<sub>j</sub>'' are now vectors of a ''2<sup>n</sup>'' dimensional space.\u000a\u000aTerm correlation <math>t_i \u005ccdot t_j</math> can be implemented in several ways. For an example, Wong et al. uses the term occurrence frequency matrix obtained from automatic indexing as input to their algorithm. The term occurrence  and the output is the term correlation between any pair of index terms.\u000a\u000a==Semantic information on GVSM==\u000a\u000aThere are at least two basic directions for embedding term to term relatedness, other than exact keyword matching, into a retrieval model:\u000a# compute semantic correlations between terms\u000a# compute frequency co-occurrence statistics from large corpora\u000a\u000aRecently Tsatsaronis<ref>{{cite | title=A Generalized Vector Space Model for Text Retrieval Based on Semantic Relatedness | url=http://www.aclweb.org/anthology/E/E09/E09-3009.pdf | last= Tsatsaronis | first=George | coauthors=Vicky Panagiotopoulou | publisher=[[Association for Computing Machinery|EACL ACM]] |date=2009-04-02}}</ref> focused on the first approach.\u000a\u000aThey measure semantic relatedness (''SR'') using a thesaurus (''O'') like [[WordNet]]. It considers the path length, captured by compactness (''SCM''), and the path depth, captured by semantic path elaboration (''SPE'').\u000aThey estimate the <math>t_i \u005ccdot t_j</math> inner product by:\u000a\u000a<math>t_i \u005ccdot t_j = SR((t_i, t_j), (s_i, s_j), O)</math>\u000a\u000awhere ''s<sub>i</sub>'' and ''s<sub>j</sub>'' are senses of terms ''t<sub>i</sub>'' and ''t<sub>j</sub>'' respectively, maximizing <math>SCM \u005ccdot SPE</math>.\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a[[Category:Vector space model]]
p65
sg4
S'166'
p66
sg6
VGeneralized vector space model
p67
ssI41
(dp68
g2
V'''Scientific data archiving''' is  the [[Computer_data_storage#Volatility|long-term storage]] of [[scientific data]] and methods. The various scientific journals have differing policies regarding how much of their data and methods scientists are required to store in a public archive, and what is actually archived varies widely between different disciplines. Similarly, the major grant-giving institutions have varying attitudes towards public archival of data. In general, the tradition of science has been for publications to contain sufficient information to allow fellow researchers to replicate and therefore test the research. In recent years this approach has become increasingly strained as   research in some areas depends on large datasets which cannot easily be replicated independently.\u000a\u000a[[Data archiving]] is more important in some fields than others.  In a few fields, all of the data necessary to replicate the work is already available in the journal article.  In drug development, a great deal of data is generated and must be archived so researchers can verify that the reports the drug companies publish accurately reflect the data.\u000a\u000aThe requirement of data archiving is a recent development in the [[history of science]].  It was made possible by advances in [[information technology]] allowing large amounts of data to be stored and accessed from central locations.  For example, the [[American Geophysical Union]] (AGU) adopted their first policy on data archiving in 1993, about three years after the beginning of the [[WWW]].<ref>\u201dPolicy on Referencing Data in and Archiving Data for AGU Publications\u201d [http://www.agu.org/pubs/authors/policies/data_policy.shtml]</ref> This policy mandates that datasets cited in AGU papers must be archived by a recognised data center; it permits the creation of "data papers"; and it establishes AGU's role in maintaining data archives. But it makes no requirements on paper authors to archive their data.\u000a\u000aPrior to organized data archiving, researchers wanting to evaluate or replicate a paper would have to request data and methods information from the author.  The science community expects authors to [[Data sharing (Science)|share supplemental data]].  This process was recognized as wasteful of time and energy and obtained mixed results.  Information could become lost or corrupted over the years.  In some cases, authors simply refuse to provide the information.\u000a\u000aThe need for data archiving and due diligence is greatly increased when the research deals with health issues or public policy formation.<ref>"The Case for Due Diligence When Empirical Research is Used in Policy Formation" by Bruce McCullough and Ross McKitrick. [http://economics.ca/2006/papers/0685.pdf]</ref><ref>[http://gking.harvard.edu/replication.shtml "Data Sharing and Replication" a website by Gary King]</ref>\u000a\u000a==Selected policies by journals==\u000a\u000a===The American Naturalist===\u000a{{quote|[[The American Naturalist]]'' requires authors to deposit the data associated with accepted papers in a public archive. For gene sequence data and phylogenetic trees, deposition in [[GenBank]] or [[TreeBASE]], respectively, is required. There are many possible archives that may suit a particular data set, including the [[Dryad (repository)|Dryad]] repository for ecological and evolutionary biology data. All accession numbers for GenBank, TreeBASE, and Dryad must be included in accepted manuscripts before they go to Production. If the data is deposited somewhere else, please provide a link. If the data is culled from published literature, please deposit the collated data in Dryad for the convenience of your readers. Any impediments to data sharing should be brought to the attention of the editors at the time of submission so that appropriate arrangements can be worked out.|JSTOR<ref>[http://www.jstor.org/page/journal/amernatu/forAuthor.html#data Supporting Data and Material]</ref>}}\u000a\u000a===Journal of Heredity===\u000a{{quote|The primary data underlying the conclusions of an article are critical to the verifiability and transparency of the scientific enterprise, and should be preserved in usable form for decades in the future. For this reason, ''Journal of Heredity'' requires that newly reported nucleotide or amino acid sequences, and structural coordinates, be submitted to appropriate public databases (e.g., GenBank; the [[EMBL Nucleotide Sequence Database]]; DNA Database of Japan; the [[Protein Data Bank]] ; and [[Swiss-Prot]]). Accession numbers must be included in the final version of the manuscript. For other forms of data (e.g., microsatellite genotypes, linkage maps, images), the Journal endorses the principles of the Joint Data Archiving Policy (JDAP) in encouraging all authors to archive primary datasets in an appropriate public archive, such as Dryad, TreeBASE, or the Knowledge Network for Biocomplexity. Authors are encouraged to make data publicly available at time of publication or, if the technology of the archive allows, opt to embargo access to the data for a period up to a year after publication.\u000a\u000aThe American Genetic Association also recognizes the vast investment of individual researchers in generating and curating large datasets. Consequently, we recommend that this investment be respected in secondary analyses or meta-analyses in a gracious collaborative spirit.|oxfordjournals.org<ref>[http://www.oxfordjournals.org/our_journals/jhered/for_authors/msprep_submission.html#4.%20DATA%20ARCHIVING%20POLICY Data archiving policy]</ref>}}\u000a\u000a===Molecular Ecology===\u000a{{quote|[[Molecular Ecology]] expects that data supporting the results in the paper should be archived in an appropriate public archive, such as GenBank, [[Gene Expression Omnibus]], TreeBASE, Dryad, the [[Knowledge Network for Biocomplexity]], your own institutional or funder repository, or as Supporting Information on the Molecular Ecology web site. Data are important products of the scientific enterprise, and they should be preserved and usable for decades in the future. Authors may elect to have the data publicly available at time of publication, or, if the technology of the archive allows, may opt to embargo access to the data for a period up to a year after publication. Exceptions may be granted at the discretion of the editor, especially for sensitive information such as human subject data or the location of endangered species.|Wiley<ref>[http://www.wiley.com/bw/submit.asp?ref=0962-1083&site=1 Policy on data archiving]</ref>}}\u000a\u000a===Nature===\u000a{{quote|Such material must be hosted on an accredited independent site (URL and accession numbers to be provided by the author), or sent to the ''Nature'' journal at submission, either uploaded via the journal's online submission service, or if the files are too large or in an unsuitable format for this purpose, on CD/DVD (five copies). Such material cannot solely be hosted on an author's personal or institutional web site.<ref>[http://www.nature.com/authors/editorial_policies/availability.html "Availability of Data and Materials: The Policy of Nature Magazine]</ref>\u000a\u000a''Nature'' requires the reviewer to determine if all of the supplementary data and methods have been archived.  The policy advises reviewers to consider several questions, including: "Should the authors be asked to provide supplementary methods or data to accompany the paper online? (Such data might include source code for modelling studies, detailed experimental protocols or mathematical derivations.)|[[Nature (journal)|Nature]]<ref>{{cite web|title=Guide to Publication Policies of the Nature Journals|date=March 14, 2007|url=http://www.nature.com/authors/gta.pdf}}</ref>}}\u000a\u000a===''Science''===\u000a{{quote|''Science'' supports the efforts of databases that aggregate published data for the use of the scientific community. Therefore, before publication, large data sets (including microarray data, protein or DNA sequences, and atomic coordinates or electron microscopy maps for macromolecular structures) must be deposited in an approved database and an accession number provided for inclusion in the published paper.<ref>[http://www.sciencemag.org/about/authors/prep/gen_info.dtl#datadep "General Policies of Science Magazine"]</ref>\u000a\u000a"Materials and methods" \u2013 ''Science'' now requests that, in general, authors place the bulk of their description of materials and methods online as supporting material, providing only as much methods description in the print manuscript as is necessary to follow the logic of the text. (Obviously, this restriction will not apply if the paper is fundamentally a study of a new method or technique.)|[[Science (journal)|Science]]<ref>[http://www.sciencemag.org/about/authors/prep/prep_online.dtl \u201dPreparing Your Supporting Online Material\u201d]</ref>}}\u000a\u000a== Royal Society Publishing==\u000a{{quote|As a condition of acceptance authors agree to honour any reasonable request by other researchers for materials, methods, or data necessary to verify the conclusion of the article. Supplementary data up to 10Mb is placed on the Society's website free of charge and is publicly accessible. Large datasets must be deposited in a recognised public domain database by the author prior to submission. The accession number should be provided for inclusion in the published article.|{{citation needed |date=September 2013}}}}\u000a\u000a==Policies by funding agencies==\u000aIn the United States, the [[National Science Foundation]] (NSF) has tightened requirements on data archiving.   Researchers seeking funding from NSF are now required to file a [[data management plan]] as a two-page supplement to the grant application.<ref>[http://news.sciencemag.org/scienceinsider/2010/05/nsf-to-ask-every-grant-applicant.html \u201dNSF to Ask Every Grant Applicant for Data Management Plan\u201d]</ref>\u000a\u000aThe NSF [[Datanet]] initiative has resulted in funding of the '''Data Observation Network for Earth''' ([[DataONE]]) project, which will provide scientific data archiving for ecological and environmental data produced by scientists worldwide. DataONE's stated goal is to preserve and provide access to multi-scale, multi-discipline, and multi-national data. The community of users for DataONE includes scientists, ecosystem managers, policy makers, students, educators, and the public.\u000a\u000a==Data archives==\u000aThe following list refers to scientific data archives. See [[Data archive]] for social science archives. \u000a* [[CISL Research Data Archive]]\u000a* [[Dryad (repository)|Dryad]]\u000a* [[ESO/ST-ECF Science Archive Facility]]\u000a* [http://www.ncdc.noaa.gov/paleo/treering.html International Tree-Ring Data Bank]\u000a* [http://www.icpsr.umich.edu Inter-university Consortium for Political and Social Research]\u000a* [http://knb.ecoinformatics.org Knowledge Network for Biocomplexity]\u000a* [[National Archive of Computerized Data on Aging]]\u000a* National Archive of Criminal Justice Data [http://www.icpsr.umich.edu/nacjd]\u000a* [[National Climatic Data Center]]\u000a* [[National Geophysical Data Center]]\u000a* [[National Snow and Ice Data Center]]\u000a* [[National Oceanographic Data Center]]\u000a* [http://daac.ornl.gov Oak Ridge National Laboratory Distributed Active Archive Center]\u000a* [[PANGAEA (data library)|Pangaea - Data Publisher for Earth & Environmental Science]]\u000a* [[World Data Center]]\u000a* [[DataONE]]\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a==External links==\u000a* [[Registry of Research Data Repositories]] ''re3data.org'' [http://service.re3data.org/search/results?term=]\u000a* Statistical checklist required by ''Nature'' [http://www.nature.com/nature/authors/gta/Statistical_checklist.doc]\u000a* Policies of ''Proceedings of the National Academy of Sciences (U.S.)'' [http://www.pnas.org/misc/iforc.shtml#policies]\u000a* The US National Committee for CODATA [http://www7.nationalacademies.org/usnc-codata/Archiving.html]\u000a* The Role of Data and Program Code Archives in the Future of Economic Research  [http://research.stlouisfed.org/wp/2005/2005-014.pdf]\u000a* Data sharing and replication \u2013 Gary King website [http://gking.harvard.edu/replication.shtml]\u000a* The Case for Due Diligence When Empirical Research is Used in Policy Formation by McCullough and McKitrick [http://economics.ca/2006/papers/0685.pdf]\u000a* Thoughts on Refereed Journal Publication by Chuck Doswell [http://www.cimms.ou.edu/~doswell/pubreviews.html]\u000a* \u201cHow to encourage the right behaviour\u201d An opinion piece published in ''Nature'',  March, 2002.[http://www.nature.com/nature/journal/v416/n6876/full/416001b.html]\u000a* [[NASA Astrophysics Data System]] [http://cdsads.u-strasbg.fr/]\u000a* [[Panton Principles]] for Open Data in Science, at Citizendium [http://en.citizendium.org/wiki/Panton_Principles]\u000a* [[Inter-university Consortium for Political and Social Research]] [http://www.icpsr.umich.edu]\u000a[[Category:Information retrieval]]\u000a[[Category:Knowledge representation]]
p69
sg4
S'41'
p70
sg6
VScientific data archiving
p71
ssI171
(dp72
g2
V'''Statistically Improbable Phrases''', '''Statimprophrases''' or '''SIPs''' constitute a system developed by [[Amazon.com]] to compare all of the books they index in the Search Inside! program and find phrases in each that are the most unlikely to be found in any other book indexed.<ref>{{cite web|url=http://www.amazon.com/gp/search-inside/sipshelp.html|title=What are Statistically Improbable Phrases?|accessdate=2007-12-18|publisher=[[Amazon.com]]}}</ref> The system is used to find the most nearly unique portions of books for use as a summary or keyword.\u000a\u000a== Example == \u000aThe Statistically Improbable Phrases of Darwin's [[On the Origin of Species]] are: ''temperate productions, genera descended, transitional gradations, unknown progenitor, fossiliferous formations, our domestic breeds, modified offspring, doubtful forms, closely allied forms, profitable variations, enormously remote, transitional grades, very distinct species'' and ''mongrel offspring''.<ref>[http://crookedtimber.org/2005/04/02/sociologically-improbable-phrases/ Sociologically Improbable Phrases] Crooked Timber April 2005</ref>\u000a\u000a==See also==\u000a*[[Googlewhack]] \u2014 a pair of words occurring on a single webpage, as indexed by Google\u000a*[[tf-idf]] \u2014 a statistic used in information retrieval and text mining.\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a{{Amazon}}\u000a\u000a[[Category:Amazon.com]]\u000a[[Category:Searching]]\u000a[[Category:Bookselling]]
p73
sg4
S'171'
p74
sg6
VStatistically Improbable Phrases
p75
ssI46
(dp76
g2
V{{Commons category|Sound production technology}}\u000a[[Category:Audio electronics|Production]]\u000a[[Category:Information retrieval]]\u000a[[Category:Sound production|Technology]]
p77
sg4
S'46'
p78
sg6
VCategory:Sound production technology
p79
ssI176
(dp80
g2
V'''Contextual Query Language''' (CQL), previously known as '''Common Query Language''',<ref>[http://www.loc.gov/standards/sru/cql/spec.html CQL: the Contextual Query Language: Specifications] SRU: Search/Retrieval via URL, Standards, Library of Congress</ref> is a [[formal language]] for representing queries to [[information retrieval]] systems such as [[search engine]]s, [[bibliography|bibliographic catalogs]] and [[museum]] collection information. Based on the [[semantics]] of [[Z39.50]], its design objective is that queries be human readable and writable, and that the language be intuitive while maintaining the expressiveness of more complex [[query language]]s. It is being developed and maintained by the Z39.50 Maintenance Agency, part of the [[Library of Congress]].\u000a\u000a== Examples of query syntax ==\u000a\u000aSimple queries:\u000a\u000a<blockquote><tt>dinosaur<br/>\u000a"complete dinosaur"<br/>\u000atitle = "complete dinosaur"<br/>\u000atitle exact "the complete dinosaur"</tt></blockquote>\u000a\u000aQueries using [[Boolean logic]]:\u000a\u000a<blockquote><tt>dinosaur or bird<br/>\u000aPalomar assignment and "ice age"<br/>\u000adinosaur not reptile<br/>\u000adinosaur and bird or dinobird<br/>\u000a(bird or dinosaur) and (feathers or scales)<br/>\u000a"feathered dinosaur" and (yixian or jehol)</tt></blockquote>\u000a\u000aQueries accessing [[index (publishing)|publication indexes]]:\u000a\u000a<blockquote><tt>publicationYear < 1980<br/>\u000alengthOfFemur > 2.4<br/>\u000abioMass >= 100</tt></blockquote>\u000a\u000aQueries based on the proximity of words to each other in a document:\u000a\u000a<blockquote><tt>ribs prox/distance<=5 chevrons<br/>\u000aribs prox/unit=sentence chevrons<br/>\u000aribs prox/distance>0/unit=paragraph chevrons</tt></blockquote>\u000a\u000aQueries across multiple [[Dimension (data warehouse)|dimensions]]:\u000a\u000a<blockquote><tt>date within "2002 2005"<br/>\u000adateRange encloses 2003</tt></blockquote>\u000a\u000aQueries based on [[Relevance (information retrieval)|relevance]]:\u000a\u000a<blockquote><tt>subject any/relevant "fish frog"<br/>\u000asubject any/rel.lr "fish frog"</tt></blockquote>\u000a\u000aThe latter example specifies using a specific [[algorithm]] for [[logistic regression]].<ref>[http://srw.cheshire3.org/contextSets/rel/ Relevance Ranking Context Set version 1.1]</ref>\u000a\u000a== References ==\u000a{{Reflist}}\u000a\u000a== External links ==\u000a* [http://www.loc.gov/standards/sru/cql/ CQL home page]\u000a* [http://www.loc.gov/z3950/agency/ Z39.50 Maintenance Agency]\u000a* [http://zing.z3950.org/cql/intro.html A Gentle Introduction to CQL]\u000a\u000a{{Query languages}}\u000a\u000a{{USGovernment|sourceURL=http://www.loc.gov/standards/sru/cql/}}\u000a{{LOC-stub}}\u000a\u000a[[Category:Searching]]\u000a[[Category:Library science]]\u000a[[Category:Library of Congress]]\u000a[[Category:Query languages]]\u000a[[Category:Knowledge representation languages]]
p81
sg4
S'176'
p82
sg6
VContextual Query Language
p83
ssI51
(dp84
g2
VAn '''index term''', '''subject term''', '''subject heading''', or '''descriptor''', in [[information retrieval]], is a term that captures the essence of the topic of a document. Index terms make up a [[controlled vocabulary]] for use in [[bibliographic record]]s. They are an integral part of bibliographic control, which is the function by which libraries collect, organize and disseminate documents. They are used as keywords to retrieve documents in an information system, for instance, a catalog or a [[search engine]].  A popular form of keywords on the web are [[tag (metadata)|tags]] which are directly visible and can be assigned by non-experts also. Index terms can consist of a word, phrase, or alphanumerical term. They are created by analyzing the document either manually with [[subject indexing]] or automatically with [[Index (search engine)|automatic indexing]] or more sophisticated methods of keyword extraction. Index terms can either come from a controlled vocabulary or be freely assigned.\u000a\u000aKeywords are stored in a [[Index (search engine)|search index]]. Common words like [[article (grammar)|articles]] (a, an, the) and conjunctions (and, or, but) are not treated as keywords because it is inefficient to do so. Almost every English-language site on the Internet has the article "''the''", and so it makes no sense to search for it. The most popular search engine, [[Google]] removed [[stop words]] such as "the" and "a" from its indexes for several years, but then re-introduced them, making certain types of precise search possible again.\u000a\u000aThe term "descriptor" was coined by [[Calvin Mooers]] in 1948. It is in particular used about a preferred term from a [[thesaurus]]. \u000a\u000aThe [[Simple Knowledge Organisation System]] language (SKOS) provides a way to express index terms with [[Resource Description Framework]] for use in the context of [[Semantic Web]].\u000a\u000a==Author keywords==\u000aMany journals and databases provides access (also) to index terms made by authors to the articles being published or represented. The relative quality of indexer-provided index terms and author provided index terms is of interest to research in information retrieval. The quality of both kinds of indexing terms depends, of course, on the qualifications of provider. In general authors have difficulties providing indexing terms that characterizes his document ''relative'' to the other documents in the database. Author keywords are an integral part of literature.\u000a\u000a==Examples==\u000a*[[Canadian Subject Headings]] (CSH)\u000a*[[Library of Congress Subject Headings]] (LCSH)\u000a*[[Medical Subject Headings]] (MeSH)\u000a*[[Polythematic Structured Subject Heading System]] (PSH)\u000a\u000a==See also==\u000a*[[Dynamic keyword insertion]]\u000a<!-- *Key-objects -->\u000a*[[Keyword cloud]]\u000a*[[Keyword density]]\u000a*[[Keyword optimization]]\u000a*[[knowledge tags|Keyword tagging]]\u000a*[[Subject (documents)]]\u000a\u000a== References ==\u000a{{commonscat|Information retrieval}}\u000a*{{cite book|last=Svenonius|first=Elaine|author-link=Elaine Svenonius|title=The intellectual foundation of information organization|date=2009|publisher=MIT Press|location=Cambridge, Mass.|isbn=9780262512619|edition=1st MIT Press pbk.}}\u000a\u000a[[Category:Information retrieval]]\u000a\u000a{{Library-stub}}
p85
sg4
S'51'
p86
sg6
VIndex term
p87
ssI181
(dp88
g2
VA '''reverse telephone directory''' (also known as a '''gray pages''' directory, criss-cross directory or '''reverse phone lookup''') is a collection of telephone numbers and associated customer details. However, unlike a standard [[telephone directory]], where the user uses customer's details (such as name and address) in order to retrieve the telephone number of that person or business, a reverse telephone directory allows users to search by a telephone service number in order to retrieve the customer details for that service.\u000a\u000aReverse telephone directories are used by law enforcement and other emergency services in order to determine the origin of any request for assistance, however these systems include both publicly accessible (listed) and private (unlisted) services. As such, these directories are restricted to internal use only.\u000a\u000aPublicly accessible reverse telephone directories may be provided as part of the standard directory services from the telecommunications carrier in some countries. In other countries these directories are often created by [[phreaking|phone phreaker]]s by collecting the information available via the publicly accessible directories and then providing a search function which allows users to search by the telephone service details.\u000a\u000a==History==\u000aPrinted reverse phone directories have been produced by the telephone companies (in the United States) for decades, and were distributed to the phone companies, law enforcement, and [[public library|public libraries]].<ref>{{cite news | url=http://news.google.com/newspapers?nid=1454&dat=19720102&id=87osAAAAIBAJ&sjid=vgkEAAAAIBAJ&pg=3122,379459 | title=Clinton Directory Issued | date=Jan 2, 1972 | accessdate=9 February 2014 | location=Page 16}}</ref> In the early 1990s, businesses started offering reverse telephone lookups for fees, and by the early 2000s advertising-based reverse directories were available online, prompting occasional alarms about privacy concerns.\u000a\u000a==Australia==\u000aIn 2001, a legal case ''[[Telstra|Telstra Corporation Ltd]] v Desktop Marketing Systems Pty Ltd'' was heard in the Australian Federal Court.<ref>{{cite web|url=http://www.austlii.edu.au/au/cases/cth/federal_ct/2001/612.html|title=Telstra Corporation Limited v Desktop Marketing Systems Pty Ltd (2001) FCA 612 (25 May 2001)|author=[[Federal Court of Australia]]|publisher=Australasian Legal Information Institute|accessdate=2008-01-03}}</ref><ref name=austliiPP>{{cite web|url=http://www.austlii.edu.au/au/journals/PLPR/2001/25.html|title=Private parts - PLPR 25; (2001) 8 PLPR 24|publisher=Australasian Legal Information Institute|accessdate=2008-01-03}}</ref> gave Telstra, the predominant carrier within Australia and the maintainer of the publicly accessible [[White Pages]] (residential) and [[Yellow Pages]] (commercial) directories, [[copyright]] over the content of these directories.\u000a\u000aIn February 2010 a Federal Court of Australia case ''[[Telstra|Telstra Corporation Ltd]] v Phone Directories Company Pty Ltd'' determined that Telstra does not hold copyright in the White Pages or the Yellow Pages.<ref>{{cite news|url=http://www.smh.com.au/business/copyright-to-enter-a-new-dimension-20101215-18y9o.html|title=Copyright to enter a new dimension|newspaper=[[The Sydney Morning Herald]]| first=Malcolm|last=Maiden|date=16 December 2010|accessdate=20 December 2012}}</ref>\u000a\u000aAs it currently{{when|date=October 2014}} stands there is no legal way to ensure a particular number is not listed in the directories currently available.\u000a\u000a==United States==\u000a\u000aIn United States, landline phone subscribers can pay a small fee to exclude their number from the directory. This service is usually called "Your Listing Not Published" and the cost ranges between $0.80 and $1.50 for residential customers.\u000a\u000aAs [[cellular phones]] become more popular, there has been debate about releasing cell phone numbers into public [[4-1-1|411]] and reverse number directories. (S. 1963, the "Wireless 411 Privacy Act" 9/2004). However, opposition led by leading consumer-protection organization [[Consumers Union]] presented several privacy concerns in their congressional [http://www.consumersunion.org/pub/wireless%20411%20senate%20testimony%20final.pdf testimony]. Right now,{{when|date=October 2014}} cell phone numbers are not available in any public 411 or reverse-number directories. However, several information companies provide reverse cell phone lookups that are obtained from utility resources, and are available online. Because there is no central database of cell phone numbers, reverse phone directories that claim to be free cannot return information on those numbers.<ref>{{cite web | url=http://www.ncbi.nlm.nih.gov/pubmed/15652722 | title=Evaluating the utility and accuracy of a reverse telephone directory to identify the location of survey respondents. | publisher=Ncbi.nlm.nih.gov | work=2005 Feb | accessdate=9 February 2014 | author=Schootman M, Jeffe D, Kinman E, Higgs G, Jackson-Thompson J.}}</ref>\u000a\u000aIn recent years{{when|date=October 2014}} community web based services offer a reverse telephone directory of known telemarketers, debt collectors, fund raisers, and other solicitors which contact consumers by telephone.  Users of these services can perform a search of the telephone number which showed up on their caller ID and read through user comments to find the identity of the calling company or individual.\u000a\u000a==United Kingdom==\u000aIn the United Kingdom proper, reverse directory information is not publicly available.<ref>{{cite web | url=http://ico.org.uk/for_organisations/privacy_and_electronic_communications/the_guide/directories_of_subscribers | title=Directories of subscribers | publisher=Information Commissioner's Office | accessdate=9 February 2014}}</ref> However, in the [[Channel Islands]] it is provided in the printed telephone directories. \u000a\u000aAlthough the information is, of necessity, available to emergency services, for other agencies it is treated as 'communication data' in the [[RIPA]] regime and subject to the same controls as requests for lists of and content of calls.\u000a\u000a==References==\u000a{{reflist}}\u000a==External links==\u000a<!-- Do not delete these comments. -->\u000a<!-- Do not put commercial links into this list. Doing so can get you blocked with no further warning. --> \u000a*[http://web.archive.org/web/20010721175437/http://blackpages.2600.org.au/ Wayback Machine (21 July 2001) archive of http://blackpages.2600.org.au]\u000a*[http://www.austlii.edu.au/au/cases/cth/federal_ct/2001/612.html Federal Court of Australia Case 612 (25 May 2001): Telstra Corporation Limited v Desktop Marketing Systems Pty Ltd]\u000a\u000a\u000a[[Category:Telephone numbers]]\u000a[[Category:Directories]]\u000a[[Category:Searching]]
p89
sg4
S'181'
p90
sg6
VReverse telephone directory
p91
ssI56
(dp92
g2
V'''Definition:''' '''Enterprise search''' is the organized retrieval of '''structured''' and '''unstructured''' data within an organization. \u000a\u000a\u000a'''Enterprise search''' is the practice of making content from multiple enterprise-type sources, such as [[database]]s and [[intranet]]s, searchable to a defined audience.\u000a\u000a==Enterprise search summary==\u000a"Enterprise Search" is used to describe the software of search information within an enterprise (though the search function and its results may still be public).<ref>[http://www.aiim.org/What-is-Enterprise-Search What is Enterprise Search?]</ref> Enterprise search can be contrasted with [[web search]], which applies search technology to documents on the open web, and [[desktop search]], which applies search technology to the content on a single computer.\u000a\u000aEnterprise search systems index data and documents from a variety of sources such as: [[file systems]], [[intranets]], [[document management system]]s, [[e-mail]], and [[databases]]. Many enterprise search systems integrate structured and unstructured data in their collections.<ref>[http://www.arma.org/bookstore/files/Delgado.pdf The New Face of Enterprise Search: Bridging Structured and Unstructured Information]</ref> Enterprise search systems also use access controls to enforce a security policy on their users.<ref>[http://www.ideaeng.com/tabId/98/itemId/118/Mapping-Security-Requirements-to-Enterprise-Search.aspx Mapping Security Requirements to Enterprise Search - Part 1: Defining Specific Security Requirements]</ref>\u000a\u000aEnterprise search can be seen as a type of [[vertical search]] of an enterprise.\u000a\u000a==Components of an enterprise search system==\u000aIn an enterprise search system, content goes through various phases from source repository to search results:\u000a\u000a=== Content awareness ===\u000aContent awareness (or "content collection") is usually either a push or pull model. In the push model, a source system is integrated with the search engine in such a way that it connects to it and pushes new content directly to its [[API]]s. This model is used when realtime indexing is important. In the pull model, the software gathers content from sources using a connector such as a [[web crawler]] or a [[database]] connector. The connector typically polls the source with certain intervals to look for new, updated or deleted content.<ref>[http://www.information-management.com/issues/20_7/content_management_data_integration_indexing_metadata-10019105-1.html Understanding Content Collection and Indexing]</ref>\u000a\u000a=== Content processing and analysis ===\u000aContent from different sources may have many different formats or document types, such as XML, HTML, Office document formats or plain text. The content processing phase processes the incoming documents to plain text using document filters. It is also often necessary to normalize content in various ways to improve [[Recall (information retrieval)|recall]] or [[Precision (information retrieval)|precision]]. These may include [[stemming]], [[lemmatization]], [[synonym]] expansion, [[entity extraction]], [[part of speech]] tagging.\u000a\u000aAs part of processing and analysis, [[tokenization (lexical analysis)|tokenization]] is applied to split the content into [[Lexical analysis#Token|tokens]] which is the basic matching unit. It is also common to normalize tokens to lower case to provide case-insensitive search, as well as to normalize accents to provide better recall.<ref>[http://packages.python.org/Whoosh/stemming.html Stemming, Variations, and Accent Folding]</ref>\u000a\u000a=== Indexing ===\u000aThe resulting text is stored in an [[Index (search engine)|index]], which is optimized for quick lookups without storing the full text of the document. The index may contain the dictionary of all unique words in the corpus as well as information about ranking and [[term frequency]].\u000a\u000a=== Query Processing ===\u000aUsing a web page, the user issues a [[Web search query|query]] to the system. The query consists of any terms the user enters as well as navigational actions such as [[faceted search|faceting]] and paging information.\u000a\u000a=== Matching ===\u000aThe processed query is then compared to the stored index, and the search system returns results (or "hits") referencing source documents that match. Some systems are able to present the document as it was indexed.\u000a\u000a==Differences from web search==\u000aBeyond the difference in the kinds of materials being indexed, enterprise search systems also typically include functionality that is not associated with the mainstream [[web search engine]]s. These include:\u000a*Adapters to index content from a variety of repositories, such as [[databases]] and [[content management systems]].\u000a*[[Federated search]], which consists of\u000a# transforming a query and broadcasting it to a group of disparate databases or external content sources with the appropriate syntax,\u000a# merging the results collected from the databases,\u000a# presenting them in a succinct and unified format with minimal duplication, and\u000a# providing a means, performed either automatically or by the portal user, to sort the merged result set.\u000a*[[Enterprise bookmarking]], collaborative [[tag (metadata)|tagging]] systems for capturing knowledge about structured and semi-structured enterprise data.\u000a*[[Entity extraction]] that seeks to locate and classify elements in text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\u000a*[[Faceted search]], a technique for accessing a collection of information represented using a [[faceted classification]], allowing users to explore by filtering available information.\u000a*Access control, usually in the form of an [[Access control list]] (ACL), is often required to restrict access to documents based on individual user identities. There are many types of access control mechanisms for different content sources making this a complex task to address comprehensively in an enterprise search environment (see below).\u000a*[[Text clustering]], which groups the top several hundred search results into topics that are computed on the fly from the search-results descriptions, typically titles, excerpts (snippets), and meta-data.  This technique lets users navigate the content by topic rather than by the meta-data that is used in faceting. Clustering compensates for the problem of incompatible meta-data across multiple enterprise repositories, which hinders the usefulness of faceting.\u000a*[[User interfaces]], which in web search are deliberately kept simple in order not to distract the user from clicking on ads, which generates the revenue.  Although the business model for enterprise search could include showing ads, in practice this is not done.  To enhance end user productivity, enterprise vendors continually experiment with rich UI functionality which occupies significant screen space, which would be problematic for web search.\u000a\u000a==Relevance factors for enterprise search==\u000aThe factors that determine the relevance of search results within the context of an enterprise overlap with but are different from those that apply to web search. In general, enterprise search engines cannot take advantage of the rich [[hyperlink|link structure]] as is found on the web's [[hypertext]] content, however, a new breed of Enterprise search engines based on a bottom-up [[Web 2.0]] technology are providing both a contributory approach and [[hyperlink]]ing within the enterprise. Algorithms like [[PageRank]] exploit hyperlink structure to assign authority to documents, and then use that authority as a query-independent relevance factor. In contrast, enterprises typically have to use other query-independent factors, such as a document's recency or popularity, along with query-dependent factors traditionally associated with [[information retrieval]] algorithms.  Also, the rich functionality of enterprise search UIs, such as clustering and faceting, diminish reliance on ranking as the means to direct the user's attention.\u000a\u000a==Access Control - early binding vs late binding==\u000aSecurity and restricted access to documents is an important matter in Enteprise Search. There are two main approaches to apply restricted access: early binding vs late binding.<ref>[http://enterprisesearch.co/enterprise-search-document-access-control/ Enterprise Search: document access control]</ref>\u000a\u000a===Late binding===\u000aPermissions are analyzed and assigned to documents at query stage. Query engine generates a document set and before returning it to a user this set is filtered based on user access rights. It is costly process but accurate (based on user permissions at the moment of query).\u000a\u000a===Early binding===\u000aPermissions are analyzed and assigned to documents at indexing stage. It is much more effective than late binding, but could be inaccurate (user might be granted or revoked permissions between in the period between indexing and querying).\u000a\u000a==Search Relevance Testing options==\u000aSearch application relevance can be determined by following relevance testing options like<ref>[http://searchhub.org/2009/09/02/debugging-search-application-relevance-issues/  Debugging Search Application Relevance Issues]</ref>\u000a*Focus groups\u000a*Reference evaluation protocol (based on relevance judgements of results from agreed-upon queries performed against common document corpuses)\u000a*Empirical testing\u000a*[[A/B testing]]\u000a*Log analysis on a Beta production site\u000a*Online ratings\u000a\u000a==See also==\u000a*[[Comparison of enterprise search software]]\u000a*[[List of enterprise search vendors]]\u000a*[[List of Search Engines]]\u000a*[[Collaborative search engine]]\u000a*[[Data Defined Storage]] \u000a*[[Enterprise bookmarking]]\u000a*[[Enterprise information access]]\u000a*[[Knowledge management]]\u000a*[[Text mining]]\u000a*[[Faceted search]]\u000a*[[Information Extraction]]\u000a*[[Vertical search|Vertical Search]]\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a{{DEFAULTSORT:Enterprise Search}}\u000a[[Category:Information retrieval]]\u000a[[Category:Searching]]
p93
sg4
S'56'
p94
sg6
VEnterprise search
p95
ssI186
(dp96
g2
V'''Social search''' or a '''social search engine''' is a type of [[web search]] that takes into account the [[Social Graph]] of the person initiating the search query. When applied to web searches the Social-Graph uses established algorithmic or machine-based approaches where relevance is determined by analyzing the text of each document or the link structure of the documents.<ref>[http://searchenginewatch.com/showPage.html?page=3623153 What's the Big Deal With Social Search?], SearchEngineWatch, Aug 15, 2006</ref> Search results produced by '''social search engine''' give more visibility to content created or "touched" by users in the Social Graph.\u000a\u000aSocial search takes many forms, ranging from simple [[social bookmarking|shared bookmarks]] or [[Tag (metadata)|tagging]] of content with descriptive labels to more sophisticated approaches that combine human intelligence with computer [[algorithm]]s.<ref>[http://www2.computer.org/portal/web/csdl/doi/10.1109/MC.2009.87 Chi, Ed H. Information Seeking Can Be Social, Computer, vol. 42, no. 3, pp. 42-46, Mar. 2009, ] {{doi|10.1109/MC.2009.87}}</ref><ref>[http://blog.delver.com/index.php/2008/07/31/taxonomy-of-social-search-approaches/ A Taxonomy of Social Search Approaches], Delver company blog, Jul 31, 2008</ref>\u000a<ref>[http://www.springerlink.com/content/e12233858017h042/ Longo, Luca et al., Enhancing Social Search: A Computational Collective Intelligence Model of Behavioural Traits, Trust and Time. Transactions on Computational Collective Intelligence II, Lecture Notes in Computer Science, Volume 6450. ISBN 978-3-642-17154-3. Springer Berlin Heidelberg, 2010, p. 46 ] {{doi|10.1007/978-3-642-17155-0_3}}</ref><ref>[http://www.springerlink.com/content/gg3p6177pw6h10j8/ Longo, Luca et al., Information Foraging Theory as a Form of Collective Intelligence for Social Search. Computational Collective Intelligence. Semantic  Web, Social Networks and  Multiagent Systems Lecture Notes in Computer Science, 2009, Volume 5796/2009, 63-74] {{doi|10.1007/978-3-642-04441-0_5}}</ref>\u000a\u000aThe search experience takes into account varying sources of metadata, such as collaborative discovery of web pages, tags, social ranking, commenting on bookmarks, news, images, videos, knowledge sharing, podcasts and other web pages. Example forms of user input include social bookmarking or direct interaction with the search results such as promoting or demoting results the user feels are more or less relevant to their query.<ref>[http://venturebeat.com/2008/01/31/googles-marissa-mayer-social-search-is-the-future Google\u2019s Marissa Mayer: Social search is the future], VentureBeat, Jan 31, 2008</ref>\u000a\u000a==History==\u000a\u000aThe term social search began to emerge between 2004 and 2005. The concept of social ranking can be considered to derive from Google's [[PageRank]] algorithm,{{citation needed|date=March 2009}} which assigns importance to web pages based on analysis of the link structure of the web, because PageRank is relying on the collective judgment of webmasters linking to other content on the web. Links, in essence, are positive votes by the webmaster community for their favorite sites.\u000a\u000aIn 2008, there were a few startup companies that focused on ranking search results according to one's [[social graph]] on [[social networks]].<ref>[http://online.wsj.com/public/article/SB121063460767286631.html New Sites Make It Easier To Spy on Your Friends], Wall Street Journal, May 13. 2008</ref><ref>[http://mashable.com/2007/08/27/social-search/ Social Search Guide: 40+ Social Search Engines], Mashable, Aug 27. 2007</ref> Companies in the social search space include  Evam-SOCOTO Wajam, Slangwho, [[Sproose]], [[Mahalo.com|Mahalo]], [[Jumper 2.0]], [[Qitera]], [[Scour Inc.|Scour]], [[Wink Technologies|Wink]], [[Eurekster]], [[Baynote]], [[Delver (Social Search)|Delver]], and OneRiot. Former efforts include [[Wikia Search]]. In 2008, a story on ''[[TechCrunch]]'' showed [[Google]] potentially adding in a voting mechanism to search results similar to [[Digg]]'s methodology.<ref>[http://www.techcrunch.com/2008/07/16/is-this-the-future-of-search/ Is This The Future Of Search?], TechCrunch, July 16, 2008</ref> This suggests growing interest in how social groups can influence and potentially enhance the ability of algorithms to find meaningful data for end users. There are also other services like Sentiment that turn search personal by searching within the users' social circles.\u000a\u000aIn October 2009, [[Google]] rolled out its "Social Search" feature; after a time in [[beta]], the feature was expanded to multiple languages in May 2011. Before the expansion however in 2010 [[Bing]] and [[Google]] were already taking into account re-tweets and Likes when providing search results.<ref>{{cite web|url = http://www.marchpr.com/blog/2013/04/seo-social-media-search/|title = Retweets and Likes influencing search results|date = 10 April 2013|accessdate = 1 December 2014| publisher = March Communications}}</ref> However, after a search deal with Twitter ended without renewal, Google began to retool its Social Search. In January 2012, Google released "Search plus Your World", a further development of Social Search. The feature, which is integrated into Google's regular search as an opt-out feature, pulls references to results from [[Google+]] profiles. The goal was to deliver better, more relevant and personalized search results with this integration. This integration however had some problems in which [[Google+]] still isn't wildly adopted or has much usage among many users.<ref name="HubSpot">{{cite web|url = https://blog.hubspot.com/blog/tabid/6307/bid/34058/Facebook-Announces-New-Social-Search-Feature-Called-Graph-Search.aspx|title = Facebook Announces New Social Search Feature|date = 15 January 2013|accessdate = 1 December 2014| publisher = HubSpot}}</ref>\u000a\u000aIn January 2013, [[Facebook]] announced a new search engine called [[Graph Search]] still in the beta stages. The goal in mind was to accomplish what [[Google]] failed at, skipping the results that are popular to the internet, in favor of the results that are popular within your social circle. Unlike [[Google]], [[Facebook]]'s Graph search differed in two large areas, first, people use Facebook frequently. This allows [[Facebook]] to use all it's user generated content that is uploaded everyday to improve the [[Facebook]] search experience.<ref name="HubSpot"/> Secondly, [[Facebook]] did not incorporate Google into Facebook search, instead Graph Search is powered by [[Bing]].This allows [[Bing]] results to show when Facebook's Graph Search can't find a match.<ref>{{cite web|url = http://www.forbes.com/sites/tomiogeron/2013/01/15/live-facebook-announces-graph-search/|title = Graph Search powered by Bing|date = 15 January 2013|accessdate = 1 December 2014| publisher = Forbes}}</ref>\u000a\u000a==Concerns==\u000a\u000aWhen Google announced "Search plus Your World" the reaction was mixed among tech companies. The company was subsequently criticized by [[Twitter]] for the perceived potential impact of "Search plus Your World" upon web publishers, describing the feature's release to the public as a "bad day for the web", while Google replied that Twitter refused to allow deep search crawling by Google of Twitter's content.<ref>{{cite web|url = http://www.cnbc.com/id/100381337#.|title = Twitter unhappy about Google's social search changes|date = 11 January 2012|accessdate = 11 January 2012|publisher = BBC News}}</ref> The criticism from [[Twitter]] wasn't without merits however, by [[Google]] integrating [[Google+]], they were essentially forcing people to switch from a social network on to theirs in order to improve search results. One famous example occurred when [[Google]] showed a link to Mark Zuckerberg's dormant [[Google+]] account rather than the active [[Facebook]] profile.<ref name="Google pushing Google">{{cite web|url = http://searchengineland.com/googles-knowledge-graph-finally-shows-social-networks-named-google-209171.|title = Google pushing Google+|date = 18 November 2014|accessdate = 1 December 2012|publisher = Third Door Media}}</ref> Further more this affected businesses in which if they do not have time to leverage all other social media sites, they knew they should use [[Google+]] to maximize their efforts since the data shows it impacts rankings more than [[Twitter]] and [[Facebook]].<ref>{{cite web|url = http://www.quicksprout.com/2014/01/31/how-social-signals-impact-search-engine-rankings/#.|title = Google+ impacts ranking more|date = 31 January 2014|accessdate = 1 December 2014|publisher = Quick Sprout}}</ref> in November 2014 these accusations started to die down because Google's Knowledge Graph started to finally show links to [[Facebook]], [[Twitter]], and other social media sites.<ref name="Google pushing Google"/>\u000a\u000a[[Google]] was not the only one that garnished concerns over social search. After the introduction of [[Graph Search]] by [[Facebook]] many pointed out how [[Graph Search]] showed private information that isn't in web search.<ref>{{cite web|url = http://www.forbes.com/sites/tomiogeron/2013/01/15/live-facebook-announces-graph-search/|title = Graph Search results|date = 1 January 2013|accessdate = 1 December 2014|publisher = Forbes}}</ref> Information that was once obscure is now easier to dig up, which is why Facebook urges users to monitor post and pictures users are tagged in and filter and filter any content that users would not want to make public.<ref>{{cite web|url = http://www.forbes.com/sites/larrymagid/2013/01/15/facebooks-new-social-search-what-it-is-and-how-it-affects-your-privacy/|title = Graph Search Privacy Concerns|date = 15 January 2013|accessdate = 1 December 2014|publisher = Forbes}}</ref>\u000a\u000aThis in large points towards the biggest concern toward social search which is that social media networks don't have a vested interest in working with search engines. [[LinkedIn]] for example has taken steps to improve its own individual search functions in order to stray users from external search engines. Even [[Microsoft]] started working with [[Twitter]] in order to integrate some tweets into [[Bing]]'s search results in November 2013. Yet [[Twitter]] has its own search engine which points out how much value their data has and why they'd like to keep it in house.<ref>{{cite web|url = http://venturebeat.com/2014/06/30/microsoft-and-twitter-make-bing-a-better-social-search-engine/|title = Bing's twitter integration|date = 30 June 2014|accessdate = 1 December 2014|publisher = Venture Beat}}</ref> In the end though social search will never be truly comprehensive of the subjects that matter to people unless users opt to be completely public with their information.<ref>{{cite web|url = https://blog.hubspot.com/blog/tabid/6307/bid/34058/Facebook-Announces-New-Social-Search-Feature-Called-Graph-Search.aspx|title = User data will never be competently public|date = 15 January 2013|accessdate = 1 December 2014|publisher = HubSpot}}</ref>\u000a\u000a==Social discovery==\u000aSocial discovery is the use of social preferences and personal information to predict what content will be desirable to the user.<ref name="Bailyn2012">{{cite book|last=Bailyn|first=Evan|title=Outsmarting Social Media: Profiting in the Age of Friendship Marketing|url=http://books.google.com/books?id=M97RiODwKHEC&pg=PT51|accessdate=20 January 2014|date=2012-04-12|publisher=Que Publishing|isbn=9780132861403|pages=51\u2013}}</ref> Technology is used to discover new people and sometimes new experiences shopping, meeting friends or even traveling.<ref>{{cite web|last=Burke|first=Amy|url=http://mashable.com/2013/07/08/social-discovery-apps/|publisher=Mashable|title=Are Social Discovery Apps Too Creepy?}}</ref>  The discovery of new people is often in real-time, enabled by [[mobile apps]]. However, social discovery is not limited to meeting people in real-time, it also leads to sales and revenue for companies via social media.<ref>{{cite web|last=Cubie|first=Gregor|url=http://www.thedrum.com/news/2013/10/02/social-discovery-sites-influence-retail-expanding-rakutens-playcom-numbers-find|publisher=The Drum|title=Social Discovery sites' influence on retail expanding}}</ref>  An example of retail would be the addition of social sharing with music, through the iTunes music store. There is a social component to discovering new music <ref>{{cite web|last=Constine|first=Josh|url=http://techcrunch.com/2013/09/10/bitcovery/|publisher=TechCrunch|title=Bitcovery Brings A Desperately Needed Social Discovery Layer To The iTunes Store}}</ref> Social discovery is at the basis of [[Facebook]]'s profitability, generating ad revenue by targeting the ads to users using the social connections to enhance the commercial appeal.<ref name="Bailyn2012"/>\u000a\u000a==Developments==\u000a\u000a[[Google]] may be falling behind in terms of social search, but in reality they see the potential and importance of this technology with [[Web 3.0]] and [[web semantics]]. The importance of social media lies within how Semantic search works. Semantic search understands much more, including where you are, the time of day, your past history, and many other factors including social connections, and social signals. The first step in order to achieve this will be to teach algorithms to understand the relationship between things.<ref>{{cite web|url = http://www.socialmediatoday.com/content/google-semantic-search|title = Google Semantic Search|date = 28 February 2014|accessdate = 1 December 2014|publisher = Social Media Today}}</ref>\u000a\u000aHowever this is not possible unless social media sites decide to work with search engines, which is difficult since everyone would like to be the main toll bridge to the internet. As we continue on, and more articles are referred by social media sites, the main concern becomes what good is a search engine without the data of users.\u000a\u000aOne development that seeks to redefine search is the combination of [[distributed search]] with social search. The goal is a basic search service whose operation is controlled and maintained by the community itself. This would largely work like Peer to Peer networks in which users provide the data they seems appropriate. Since the data used by search engines belongs to the user they should have absolute control over it. The infrastructure required for a search engine is already available in the from of thousands of idle desktops and extensive residential broadband access.<ref>{{cite web|url = http://www2009.eprints.org/242/|title = Towards Distributed Social Search Engines|accessdate = 1 December 2014|publisher = EPrints}}</ref>\u000a\u000a== See also ==\u000a* [[Collaborative filtering]]\u000a* [[Enterprise bookmarking]]\u000a* [[Human search engine]]\u000a* [[Relevance feedback]]\u000a* [[Social software]]\u000a\u000a== References ==\u000a{{reflist}}\u000a{{Internet search}}\u000a\u000a[[Category:Searching]]\u000a[[Category:Social search| ]]\u000a[[Category:Social software|Search]]
p97
sg4
S'186'
p98
sg6
VSocial search
p99
ssI61
(dp100
g2
VThe '''Matthews correlation coefficient''' is used in [[machine learning]] as a measure of the quality of binary (two-class) [[Binary classification|classifications]]. It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The MCC is in essence a correlation coefficient between the observed and predicted binary classifications; it returns a value between &minus;1 and +1. A coefficient of +1 represents a perfect prediction, 0 no better than random prediction and &minus;1 indicates total disagreement between prediction and observation. The statistic is also known as the [[phi coefficient]]. MCC is related to the [[Pearson's chi-square test|chi-square statistic]] for a 2×2 [[contingency table]]\u000a\u000a: <math>|\u005ctext{MCC}| = \u005csqrt{\u005cfrac{\u005cchi^2}{n}}</math>\u000a\u000awhere ''n'' is the total number of observations.\u000a\u000aWhile there is no perfect way of describing the [[confusion matrix]] of true and false positives and negatives by a single number, the Matthews correlation coefficient is generally regarded as being one of the best such measures{{Citation needed|reason=Source needed for being 'best'|date=December 2014}}. Other measures, such as the proportion of correct predictions (also termed [[accuracy]]), are not useful when the two classes are of very different sizes. For example, assigning every object to the larger set achieves a high proportion of correct predictions, but is not generally a useful classification.\u000a\u000aThe MCC can be calculated directly from the [[confusion matrix]] using the formula:\u000a\u000a: <math>\u000a\u005ctext{MCC} = \u005cfrac{ TP \u005ctimes TN - FP \u005ctimes FN } {\u005csqrt{ (TP + FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }\u000a</math>\u000a\u000aIn this equation, ''TP'' is the number of [[true positive]]s, ''TN'' the number of [[true negative]]s, ''FP'' the number of [[false positive]]s and ''FN'' the number of [[false negative]]s. If any of the four sums in the denominator is zero, the denominator can be arbitrarily set to one; this results in a Matthews correlation coefficient of zero, which can be shown to be the correct limiting value.\u000a\u000aThe measure was introduced in 1975 by Matthews.<ref>{{cite journal|last=Matthews|first=B. W.|title=Comparison of the predicted and observed secondary structure of T4 phage lysozyme|journal=Biochimica et Biophysica Acta (BBA) - Protein Structure|date=1975|volume=405|issue=2|pages=442-451|doi=10.1016/0005-2795(75)90109-9}}</ref> The original formula equal to above was:\u000a: <math>\u000a\u005ctext{N} = TN + TP + FN + FP\u000a</math>\u000a: <math>\u000a\u005ctext{S} = \u005cfrac{ TP + FN } { N }\u000a</math>\u000a: <math>\u000a\u005ctext{P} = \u005cfrac{ TP + FP } { N }\u000a</math>\u000a: <math>\u000a\u005ctext{MCC} = \u005cfrac{ TP / N - S \u005ctimes P } {\u005csqrt{ P S  ( 1 - S)  ( 1 - P ) } }\u000a</math>\u000a\u000aAs a [[Correlation and dependence|correlation coefficient]], the Matthews correlation coefficient is the [[geometric mean]] of the [[regression coefficient]]s of the problem and its [[Dual (mathematics)|dual]]. The component regression coefficients of the Matthews correlation coefficient are [[markedness]] (deltap) and informedness (deltap').<ref name="Perruchet2004">{{cite journal |first1=P. |last1=Perruchet |first2=R. |last2=Peereman |year=2004 |title=The exploitation of distributional information in syllable processing |journal=J. Neurolinguistics |volume=17 |pages=97\u2013119 |doi=10.1016/s0911-6044(03)00059-9}}</ref><ref name="Powers2007">{{cite journal |first=David M W |last=Powers |date=2007/2011 |title=Evaluation: From Precision, Recall and F-Measure  to ROC, Informedness, Markedness & Correlation |journal=Journal of Machine Learning Technologies |volume=2 |issue=1 |pages=37\u201363 |url=http://www.flinders.edu.au/science_engineering/fms/School-CSEM/publications/tech_reps-research_artfcts/TRRA_2007.pdf}}</ref>\u000a\u000a== Confusion Matrix ==\u000a{{main|Confusion matrix}}\u000a\u000a{| class="wikitable" align="right" width=35% style="font-size:98%; margin-left:0.5em; padding:0.25em; background:#f1f5fc;"\u000a|+ Terminology and derivations<br \u000a/>from a confusion matrix\u000a|- valign=top\u000a|\u000a; true positive (TP)\u000a:eqv. with hit\u000a; true negative (TN)\u000a:eqv. with correct rejection\u000a; false positive (FP)\u000a:eqv. with [[false alarm]], [[Type I error]]\u000a; false negative (FN)\u000a:eqv. with miss, [[Type II error]]\u000a----\u000a; [[sensitivity (test)|sensitivity]] or true positive rate (TPR)\u000a:eqv. with [[hit rate]], [[Information retrieval#Recall|recall]]\u000a:<math>\u005cmathit{TPR} = \u005cmathit{TP} / P = \u005cmathit{TP} / (\u005cmathit{TP}+\u005cmathit{FN})</math>\u000a; [[Specificity (tests)|specificity]] (SPC) or True Negative Rate\u000a:<math>\u005cmathit{SPC} = \u005cmathit{TN} / N = \u005cmathit{TN} / (\u005cmathit{FP} + \u005cmathit{TN}) </math>\u000a; [[Information retrieval#Precision|precision]] or [[positive predictive value]] (PPV)\u000a:<math>\u005cmathit{PPV} = \u005cmathit{TP} / (\u005cmathit{TP} + \u005cmathit{FP})</math>\u000a; [[negative predictive value]] (NPV)\u000a:<math>\u005cmathit{NPV} = \u005cmathit{TN} / (\u005cmathit{TN} + \u005cmathit{FN})</math>\u000a; [[Information retrieval#Fall-out|fall-out]] or false positive rate (FPR)\u000a:<math>\u005cmathit{FPR} = \u005cmathit{FP} / N = \u005cmathit{FP} / (\u005cmathit{FP} + \u005cmathit{TN})</math>\u000a; [[false discovery rate]] (FDR)\u000a:<math>\u005cmathit{FDR} = \u005cmathit{FP} / (\u005cmathit{FP} + \u005cmathit{TP}) = 1 - \u005cmathit{PPV} </math>\u000a; Miss Rate or [[Type I and type II errors#False positive and false negative rates|False Negative Rate]] (FNR)\u000a:<math>\u005cmathit{FNR} = \u005cmathit{FN} / (\u005cmathit{FN} + \u005cmathit{TP}) </math>\u000a----\u000a; [[accuracy]] (ACC)\u000a:<math>\u005cmathit{ACC} = (\u005cmathit{TP} + \u005cmathit{TN}) / (P + N)</math>\u000a;[[F1 score]]\u000a: is the [[Harmonic mean#Harmonic mean of two numbers|harmonic mean]] of [[Information retrieval#Precision|precision]] and [[sensitivity (test)|sensitivity]]\u000a:<math>\u005cmathit{F1} = 2 \u005cmathit{TP} / (2 \u005cmathit{TP} + \u005cmathit{FP} + \u005cmathit{FN})</math>\u000a; Matthews correlation coefficient (MCC)\u000a:<math> \u005cfrac{ TP \u005ctimes TN - FP \u005ctimes FN } {\u005csqrt{ (TP+FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }\u000a</math>\u000a\u000a;Informedness\u000a:<math>TPR + SPC - 1</math>\u000a;Markedness\u000a:<math>PPV + NPV - 1</math>\u000a;\u000a<span style="font-size:90%;">''Source: Fawcett (2006).''<ref name=Fawcelt2006>{{cite journal|last=Fawcelt|first=Tom|title=An Introduction to ROC Analysis|journal=Pattern Recognition Letters|date=2006|volume=27|issue=8|pages=861 - 874|doi=10.1016/j.patrec.2005.10.010}}</ref></span>\u000a|}\u000a\u000aLet us define an experiment from '''P''' positive instances and '''N''' negative instances for some condition. The four outcomes can be formulated in a 2×2 ''[[contingency table]]'' or ''[[confusion matrix]]'', as follows:\u000a\u000a{{DiagnosticTesting_Diagram}}\u000a\u000a== See also ==\u000a* [[Phi coefficient]]\u000a* [[F1 score]]\u000a* [[Cramér's V (statistics)|Cramér's V]], a similar measure of association between nominal variables.\u000a* [[Cohen's kappa]]\u2659\u000a\u000a== References ==\u000a\u000a{{Reflist}}\u000a\u000a=== General References ===\u000a* [[Pierre Baldi|Baldi, P.]]; Brunak, S.; Chauvin, Y.; Andersen, C. A. F.; Nielsen, H. Assessing the accuracy of prediction algorithms for classification: an overview" ''Bioinformatics'' 2000, 16, 412&ndash;424. [http://bioinformatics.oxfordjournals.org/cgi/content/abstract/16/5/412]\u000a* Matthews, B.W., Comparison of the predicted and observed secondary structure of T4 phage lysozyme" ''Biochim. Biophys. Acta'' 1975, 405, 442&ndash;451\u000a* Carugo, O., Detailed estimation of bioinformatics prediction reliability through the Fragmented Prediction Performance Plots. BMC Bioinformatics 2007. [http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2148069/]\u000a\u000a{{DEFAULTSORT:Matthews Correlation Coefficient}}\u000a[[Category:Machine learning]]\u000a[[Category:Information retrieval]]\u000a[[Category:Statistical classification]]\u000a[[Category:Computational chemistry]]\u000a[[Category:Cheminformatics]]\u000a[[Category:Bioinformatics]]\u000a[[Category:Statistical ratios]]\u000a[[Category:Summary statistics for contingency tables]]
p101
sg4
S'61'
p102
sg6
VMatthews correlation coefficient
p103
ssI191
(dp104
g2
V'''Variable neighborhood search''' (VNS),<ref>{{cite journal |pages=367\u2013407 |last1 = Hansen  |first1 = P.|last2 = Mladenovic|first2 = N.|last3 = Perez|first3 = J.A.M.|title=Variable neighbourhood search: methods and applications\u000a|volume=175 |journal= Annals of Operations Research |year=2010 |doi=10.1007/s10479-009-0657-6}}</ref> proposed by [[Mladenovi\u0107, Hansen]], 1997,<ref name=".....">{{cite journal\u000a | author = Nenad Mladenovi´c, Pierre Hansen\u000a | year = 1997\u000a | title = Variable neighborhood search\u000a | journal = Computers and Operations Research\u000a | volume = 24\u000a | issue= 11\u000a | pages = 1097\u20131100\u000a | doi=10.1016/s0305-0548(97)00031-2\u000a }}\u000a</ref> is a [[metaheuristic]] method for solving a set of [[combinatorial optimization (mathematics)|combinatorial optimization]] and global optimization problems.\u000aIt explores distant neighborhoods of the current incumbent solution, and moves from there to a new one if and only if an improvement was made. The local search method is applied repeatedly to get from solutions in the neighborhood to local optima.\u000aVNS was designed for approximating solutions of discrete and continuous optimization problems and according to these, it is aimed for solving [[linear programming|linear program]] problems, [[linear programming|integer program]] problems, mixed integer program problems, [[nonlinear programming|nonlinear program]] problems, etc.\u000a\u000a== Introduction ==\u000aVNS systematically changes the neighborhood in two phases: firstly, descent to find a [[local optimum]] and finally, a perturbation phase to get out of the corresponding valley.\u000a\u000aApplications are rapidly increasing in number and pertain to many fields: [[location theory]], [[cluster analysis]], [[scheduling]], [[Vehicle routing problem|vehicle routing]], [[Network planning and design|network design]], lot-sizing, [[artificial intelligence]], engineering, pooling problems, biology, [[Phylogenetics|phylogeny]], [[wikt:reliability|reliability]], geometry, telecommunication design, etc.\u000a\u000aThere are several books important for understanding VNS, such as: ''Handbook of Metaheuristics'', 2010,<ref>{{cite journal |last1=Gendreau|  first1=M.|last2= Potvin|first2=J-Y.|title=Handbook of Metaheuristics|publisher =Springer|year=2010 }}</ref> Handbook of Metaheuristics, 2003<ref>{{cite journal|last1=Glover|  first1=F.|last2= Kochenberger|first2=G.A.|title=Handbook of Metaheuristics|publisher = Kluwer Academic Publishers |year=2003}}</ref> and Search methodologies, 2005.<ref>{{cite journal |last1=Burke|first1=EK.|last2= Kendall | first2=G.| title=Search methodologies. Introductory tutorials in optimization and decision support techniques |journal = Springer|year=2005}}</ref>\u000aEarlier work that motivated this approach can be found in\u000a# Davidson, W.C.,<ref>{{cite journal |last1=Davidson  |first1=W.C.|title=Variable metric algorithm for minimization  |journal= Argonne National Laboratory Report ANL-5990 |year=1959 }}</ref>\u000a# Fletcher, R., Powell, M.J.D.,<ref>{{cite journal |pages=163\u2013168 |last1=Fletcher |first1=R. |last2=Powell |first2=M.J.D. |title=Rapidly convergent descent method for minimization|volume=6 |journal=Comput.J. |year=1963 |doi=10.1093/comjnl/6.2.163}}</ref>\u000a# Mladenovi´c, N.<ref>{{cite journal |pages= 112 |last1=Mladenovi´c |first1=N. |title=A variable neighborhood algorithm\u2014a new metaheuristic for combinatorial optimization | journal=Abstracts of papers presented at Optimization Days, Montr´eal |year=1995 }}\u000a</ref> and 4. Brimberg, J., Mladenovi´c, N.<ref>{{cite journal |pages=1\u201312 |last1=Brimberg |first1=J. |last2 = Mladenovi´c |first2=N. |title=A variable neighborhood algorithm for solving the continuous location-allocation problem |volume=10 |journal=Stud. Locat. Anal. |year=1996}}</ref> Recent surveys on VNS  methodology as well as numerous applications can be found in 4OR, 2008.<ref>{{cite journal |pages=319\u2013360 |last1=Hansen |first1=P. |last2 = Mladenovi´c |first2=N. |last3= Perez| first3=J.A.M|title=Variable neighbourhood search: methods and applications|volume=6 |journal=4OR |year=2008 |doi=10.1007/s10288-008-0089-1}}</ref> and Annals of OR, 2010.\u000a\u000a== Basic description ==\u000aDefine one deterministic [[optimization problem]] with\u000a\u000a<math> \u005cmin {\u005c{f (x)|x \u005cin X, X \u005csubseteq S\u005c}} </math>, (1)\u000a\u000awhere ''S'', ''X'', ''x'', and ''f''  are the solution space, the feasible set, a feasible solution, and a real-valued [[mathematical optimization|objective function]], respectively. If ''S'' is a finite but large set, a combinatorial optimization problem is defined. If <math>{S = R^{n}}</math>, there is continuous optimization model.\u000a\u000aA solution <math>{x^* \u005cin X}</math> is optimal if\u000a\u000a<math> {f (x^{*}) \u005cleq f (x), \u005cqquad \u005cforall{x}\u005c, \u005cin X} </math>.\u000a\u000aExact algorithm for problem (1) is to be found an optimal solution ''x*'', with the validation of its optimal structure, or if it is unrealizable, in procedure have to be shown that there is no  achievable solution, i.e., <math>X =\u005cvarnothing</math>, or the solution is unbounded. CPU time has to be finite and short. For continuous optimization, it is reasonable to allow for some degree of tolerance, i.e., to stop when a feasible solution <math>x^{*}</math> has been found such that\u000a\u000a<math> {f (x^{*}) \u005cleq f (x) + \u005cepsilon, \u005cqquad \u005cforall{x}\u005c, \u005cin X} </math> or\u000a<math> {(f (x^{*})- f (x))/ f (x^{*})  <  \u005cepsilon  , \u005cqquad \u005cforall{x}\u005c, \u005cin X} </math>\u000a\u000aSome heuristics speedily accept an approximate solution, or optimal solution but one with no validation of its optimality.\u000aSome of them have an incorrect certificate, i.e., the solution <math>x_h</math> obtained satisfies\u000a\u000a<math> {(f (x_{h})- f (x))/ f (x_{h})  \u005cleq  \u005cepsilon  , \u005cqquad \u005cforall{x}\u005c, \u005cin X} </math>\u000afor some <math>\u005cepsilon</math>, though this is rarely small.\u000a\u000aHeuristics are faced with the problem of local optima as a result of avoiding boundless computing time.\u000aA local optimum <math>x_L</math> of problem is such that\u000a\u000a<math> {f (x_{L}) \u005cleq f (x), \u005cqquad \u005cforall{x}\u005c, \u005cin N(x_{L}) \u005ccap X} </math>\u000a\u000awhere <math> N(x_{L})</math>  denotes a neighborhood of <math> x_{L} </math>\u000a\u000a== Description ==\u000aAccording to (Mladenovic, 1995), VNS is a metaheuristic which systematically performs the procedure of neighborhood change, both in descent to local minima and in escape from the valleys which contain them.\u000a\u000aVNS is built upon the following perceptions:\u000a\u000a# A local minimum with respect to one neighbourhood structure is not necessarily a local minimum for another neighbourhood structure.\u000a# A global minimum is a local minimum with respect to all possible neighborhood structures.\u000a# For many problems, local minima with respect to one or several neighborhoods are relatively close to each other.\u000a\u000aUnlike many other metaheuristics, the basic schemes of VNS and its extensions are simple and require few, and sometimes no parameters. Therefore, in addition to providing very good solutions, often in simpler ways than other methods, VNS gives insight into the reasons for such a performance, which, in turn, can lead to more efficient and sophisticated implementations.\u000a\u000aThere are several papers where it could be studied among recently mentioned, such as (Hansen and Mladenovi´c 1999, 2001a, 2003, 2005; Moreno-Pérez et al.;<ref>{{cite journal||last1=Moreno-Pérez|first1=JA.|last2=Hansen|first2=P. |last3=Mladenovic|first3=N.| title = Parallel variable neighborhood search|journal=Alba E (ed) Parallel metaheuristics: a new class of algorithms|year=2005}}</ref>)\u000a\u000a==[[Local search (optimization)|Local search]]==\u000a\u000aA local search heuristic is performed through choosing an initial solution x, discovering a direction of descent from x, within a neighbourhood N(x), and proceeding to the minimum of f(x) within N(x) in the same direction. If there is no direction of descent, the heuristic stops; otherwise, it is iterated. Usually the highest direction of descent, also related to as best improvement, is used. This set of rules is summarized in Algorithm 1, where we assume that an initial solution x is given. The output consists of a local minimum, also denoted by x, and its value. Observe that a neighbourhood structure N(x) is defined for all x \u2208 X. At each step, the neighbourhood N(x) of x is explored completely. As this may be timeconsuming, an alternative is to use the first descent heuristic. Vectors <math>x^i \u005cin N(x)</math> are then enumerated systematically and a move is made as soon as a direction for the descent is found. This is summarized in Algorithm 2.\u000a\u000aAlgorithm 1 Best improvement (highest descent) heuristic\u000a\u000aFunction BestImprovement(x)\u000a\u000a  1: repeat\u000a  2:     x' \u2190 x\u000a  3:     x\u2190argmin_{f (y)}, y\u2208N(x)\u000a  4: until ( f (x) \u2265 f (x'))\u000a  5: return x\u000a\u000aAlgorithm 2 First improvement (first descent) heuristic\u000a\u000aFunction FirstImprovement(x)\u000a\u000a  1: repeat\u000a  2:    x' \u2190 x; i\u21900\u000a  3:    repeat\u000a  4:       i\u2190i+1\u000a  5:       x\u2190argmin{ f (x), f (x^i)}, x^i  \u2208 N(x)\u000a  6:    until ( f (x) < f (x^i) or i = |N(x)|)\u000a  7: until ( f (x) \u2265 f (x'))\u000a  8: return x\u000a\u000aLet one denote <math> \u005cmathcal{ N}_k(k=1, . . . ,k_{max}) </math>, a finite set of pre-selected neighborhood structures, and with <math>\u005cmathcal{N}_k(x)</math> the set of solutions in the ''kth'' neighborhood of ''x''.\u000a\u000aOne will also use the notation <math>\u005cmathcal{N'}_k(x), k = 1, . . . , k'_{max} </math> when describing local descent. Neighborhoods <math>\u005cmathcal{N}_k(x)</math> or <math>\u005cmathcal{N'}_k(x)</math> may be induced from one or more [[metric (mathematics)|metric]] (or quasi-metric) functions introduced into a solution space ''S''.\u000aAn optimal solution <math>x_{opt}</math> (or [[maxima and minima|global minimum]]) is a feasible solution where a minimum of problem ( is reached. We call ''x' \u2208 X'' a local minimum of problem with respect to <math>\u005cmathcal{N}_k(x) </math>, if there is no solution <math> x \u005cin \u005cmathcal{N'}_k(x) \u005csubseteq X </math> such that <math>f (x) < f (x')</math>.\u000a\u000aIn order to solve problem by using several neighbourhoods, facts 1\u20133 can be used in three different ways: (i) deterministic; (ii) [[stochastic]]; (iii) both deterministic and stochastic. We first give in Algorithm 3 the steps of the neighbourhood change function which will be used later. Function NeighbourhoodChange() compares the new value f(x') with the incumbent value f(x) obtained in the neighbourhood k (line 1). If an improvement is obtained, k is returned to its initial value and the new incumbent updated (line 2). Otherwise, the next neighbourhood is considered (line 3).\u000a\u000aAlgorithm 3&nbsp;\u2013 Neighborhood change\u000a\u000aFunction NeighborhoodChange (x, x', k)\u000a\u000a<code>\u000a 1: if f (x') < f(x) then\u000a 2:    x \u2190 x' // Make a move\u000a 3:    k \u2190 1 // Initial neighborhood\u000a 4: else\u000a 5:    k \u2190 k+1 // Next neighborhood\u000a\u000a</code>\u000a\u000aWhen VNS does not render good solution, there are several steps which could be helped in process, such as comparing first and best improvement strategies in local search, reducing neighborhood, intensifying shaking, adopting VND, adopting FSS, and experimenting with parameter settings.\u000a\u000aThe Basic VNS (BVNS) method (Mladenovic and Hansen 1997) combines deterministic and stochastic changes of neighbourhood. Its steps are given in Algorithm 4. Often successive neighbourhoods <math> \u005cmathcal{N}_k</math> will be nested. Observe that point x' is generated at random in Step 4 in order to avoid cycling, which might occur if a deterministic rule were applied. In Step 5, the first improvement local search (Algorithm 2) is usually\u000aadopted. However, it can be replaced with best improvement (Algorithm 1).\u000a\u000aAlgorithm 4: Basic VNS\u000a\u000aFunction VNS (x, kmax, tmax );\u000a\u000a<code>\u000a\u000a 1: repeat\u000a 2:    k \u2190 1;\u000a 3:    repeat\u000a 4:       x' \u2190Shake(x, k) /* Shaking */;\u000a 5:       x'' \u2190 FirstImprovement(x' ) /* Local search */;\u000a 6:       NeighbourhoodChange(x, x', k) /* Change neighbourhood */;\u000a 7:    until k = k_max ;\u000a 8:    t \u2190CpuTime()\u000a 9: until t > t_max ;\u000a\u000a</code>\u000a\u000aThe basic VNS is a first improvement [[method of steepest descent|descent method]] with randomization. Without much additional effort, it can be transformed into a descent-ascent method: in NeighbourhoodChange() function, replace also x by x" with some probability, even if the solution is worse than the incumbent. It can also be changed into a best improvement method: make a move to the best neighbourhood k* among all k_max of them.\u000aAnother variant of the basic VNS can be to find a solution x' in the \u201cShaking\u201d step as the best among b (a parameter) randomly generated solutions from the ''k''th neighbourhood. There are two possible variants of this extension: (1) to perform only one local search from the best among b points; (2) to perform all b local searches and then choose the best. In paper (Fleszar and Hindi<ref>{{cite journal|last1=Fleszar|first1=K|last2=Hindi|first2=KS|title=Solving the resource-constrained project scheduling problem by a variable neighborhood search|journal=Eur J Oper Res|year=2004|volume=155|issue=2|pages=402\u2013413|doi=10.1016/s0377-2217(02)00884-6}}</ref>) could be found algorithm.\u000a\u000a== Extensions ==\u000a* VND<ref>{{cite journal|last1=Brimberg|first1=J.|last2=Hansen|first2=P.|last3=Mladenovic|first3=N.|last4=Taillard |first4=E. |title=Improvements and comparison of heuristics for solving the multisource Weber problem|journal=Oper. Res.|year=2000|volume=48 |pages=444\u2013460 |doi=10.1287/opre.48.3.444.12431}}</ref>\u000a:The variable neighborhood descent (VND) method is obtained if a change of neighborhoods is performed in a deterministic way. In the descriptions :of its algorithms, we assume that an initial solution x is given. Most local search heuristics in their descent phase use very few :neighbourhoods. The final solution should be a local minimum with respect to all <math>k_{max}</math> neighbourhoods; hence the chances to reach :a global one are larger when using VND than with a single neighbourhood structure.\u000a* RVNS<ref>{{cite journal|last1=Mladenovic|first1=N.|last2=Petrovic|first2=J.|last3=Kovacevic-Vujcic|first3=V.|last4=Cangalovic |first4=M. |title=Solving spread spectrum radar polyphase code design problem by tabu search and variable neighborhood search|journal=Eur. J. Oper. Res.|year=2003b|volume=151 |pages=389\u2013399 |doi=10.1016/s0377-2217(02)00833-0}}</ref>\u000a\u000a:The reduced VNS (RVNS) method is obtained if random points are selected from <math>\u005cmathcal{N}_k(x)</math> and no descent is made. Rather, the :values of these new points are compared with that of the incumbent and an update takes place in case of improvement. It is assumed that a :stopping condition has been chosen like the maximum [[CPU time]] allowed <math>t_{max}</math> or the maximum number of iterations :between two improvements.\u000a:To simplify the description of the algorithms it is used <math>t_{max}</math> below. Therefore, RVNS uses two parameters: <math>t_{max}</math> :and <math>k_{max}</math>. RVNS is useful in very large instances, for which local search is costly. It has been observed that the best value for :the parameter k_max is often 2. In addition, the maximum number of iterations between two improvements is usually used as a stopping condition. :RVNS is akin to a [[Monte-Carlo method]], but is more systematic.\u000a* Skewed VNS\u000a:The skewed VNS (SVNS) method (Hansen et al.)<ref>{{cite journal|last1=Hansen|first1=P.|last2=Jaumard|first2=B|last3=Mladenovi´c|first3=N|last4=Parreira |first4=A |title=Variable neighborhood search :for weighted maximum satisfiability problem|journal=Les Cahiers du GERAD G\u20132000\u201362, HEC Montréal, Canada|year=2000}}</ref> addresses the :problem of exploring valleys far from the incumbent solution. Indeed, once the best solution in a large region has been found, it is necessary to :go some way to obtain an improved one. Solutions drawn at random in distant neighbourhoods may differ substantially from the incumbent and VNS :can then degenerate, to some extent, into the Multistart heuristic (in which descents are made iteratively from solutions generated at random, a :heuristic which is known not to be very efficient). Consequently, some compensation for distance from the incumbent must be made.\u000a* Variable Neighbourhood Decomposition Search\u000a:The variable neighbourhood decomposition search (VNDS) method (Hansen et al.)<ref>{{cite journal|last1=Hansen|first1=P|last2=Mladenovi´c|first2=N|last3=Pérez-Brito|first3=D |title=Variable neighborhood decomposition :search|journal=J Heuristics|year=2001|volume=7|issue=4|pages=335\u2013350}}</ref> extends the basic VNS into a two-level VNS scheme based upon :decomposition of the problem. For ease of presentation, but without loss of generality, it is assumed that the solution x represents the set of :some elements.\u000a* Parallel VNS\u000a:Several ways of parallelizing VNS have recently been proposed for solving the p-Median problem. In García-López et al.:<ref>{{cite journal|last1=García-López|first1=F|last2=Melián-Batista|first2=B|last3= Moreno-Pérez|first3= JA|last4= |first4=JM :|title=The parallel :variable neighborhood search for the p-median problem|journal=J Heuristics|year=2002|volume=8|issue=3|pages=375\u2013388}}</ref>&nbsp; three of them :are tested: (i) parallelize local search; (ii) augment the number of solutions drawn from the current neighbourhood and make a :local search in :parallel from each of them and (iii) do the same as (ii) but update the information about the best solution found. Three Parallel :VNS strategies :are also suggested for solving the [[Travelling purchaser problem]] in Ochi et al.<ref>{{cite journal|last1=Ochi|first1=LS|last2=Silva|first2=MB|last3= Drummond|first3= L|title=Metaheuristics based on GRASP and VNS for solving traveling purchaser :problem|journal=MIC\u20192001, Porto|year=2001|pages=489\u2013494}}</ref>\u000a* Primal-dual VNS\u000a:For most modern heuristics, the difference in value between the optimal solution and the obtained one is completely unknown. Guaranteed :performance of the primal heuristic may be determined if a [[upper and lower bounds|lower bound]] on the objective function value is known. To :this end, the standard approach is to relax the integrality condition on the primal variables, based on a mathematical programming formulation of :the problem.\u000a:However, when the dimension of the problem is large, even the relaxed problem may be impossible to solve exactly by standard :commercial solvers. :Therefore, it seems a good idea to solve dual relaxed problems heuristically as well. It was obtained guaranteed bounds on :the primal heuristics :performance.  In Primal-dual VNS (PD-VNS) (Hansen et al.)<ref>{{cite journal|last1=Hansen|first1=P|last2=Brimberg|first2=J|last3=Uro\u0161evi´c|first3=D|last4=Mladenovi´c|first4=N|title=Primal-dual variable neighborhood search for the simple plant location problem|journal=INFORMS J Comput|year=2007a|volume=19|issue=4|pages=552\u2013564|doi=10.1287/ijoc.1060.0196}}</ref> one :possible general way to attain both the guaranteed bounds and the exact solution is proposed.\u000a* Variable Neighborhood Branching.)<ref>{{cite journal|last1=Hansen|first1=P.|last2=Mladenovic|first2=N.|last3=Urosevic|first3=D.|title=Variable neighborhood search and local branching|journal=Computers and Operations Research|year=2006|volume=33|pages=3034\u20133045|doi=10.1016/j.cor.2005.02.033}}</ref>\u000a:The mixed integer linear programming (MILP) problem consists of maximizing or minimizing a linear function, subject to equality or inequality :constraints, and integrality restrictions on some of the variables.\u000a* Variable Neighborhood Formulation Space Search .)<ref>{{cite journal|last1=Mladenovic|first1=N.|last2=Plastria|first2=F.|author2-link=Frank Plastria|last3=Urosevic|first3=D.|title=Reformulation descent applied to circle packing problems|journal=Computers and Operations Research|year=2006|volume=32|pages=2419\u20132434|doi=10.1016/j.cor.2004.03.010}}</ref>\u000a:FSS is method which is very useful because, one problem could be defined in addition formulations and moving through formulations is legitimate. :It is proved that local search works within formulations, implying a final solution when started from some initial solution in first formulation. :Local search systematically alternates between different formulations which was investigated for [[Circle packing in a circle|circle packing]] :problem (CPP) where [[stationary point]] for a [[nonlinear programming]] formulation of CPP in [[Cartesian coordinate system|Cartesian coordinates]] is not strictly a stationary point in [[Polar coordinate system|polar coordinates]].\u000a\u000a== Development ==\u000aIn order to make a simple version of VNS, here is the list of steps which should be made. Most of it is very similar with steps in other metaheuristics.\u000a# It is necessary to be involved in problem, give some examples and try to solve them\u000a# Study books, surveys and scientific papers\u000a# Try to test some benchmarks\u000a# Choose appropriate data structure for representing in memory\u000a# Find initial solution\u000a# Calculate objective function\u000a# Design a procedure for Shaking\u000a# Choose an local search heuristic with some moves as drop, add, swap, interchange, etc.\u000a# Compare VNS with other methods from the literature\u000a\u000a== Applications ==\u000aApplications of VNS, or of varieties of VNS are very abundant and numerous. Some fields where it could be found collections of scientific papers:\u000a* Industrial applications\u000a* Design problems in communication\u000a* Location problems\u000a* [[Data mining]]\u000a* [[Graph theory|Graph problems]]\u000a* [[Knapsack problem|Knapsack]] and packing problems\u000a* Mixed integer problems\u000a* Time tabling\u000a* [[Scheduling]]\u000a* [[Vehicle routing problem]]s\u000a* [[Arc routing]] and waste collection\u000a* Fleet sheet problems\u000a* Extended vehicle routing problems\u000a* Problems in biosciences and chemistry\u000a* Continuous optimization\u000a* Other optimization problems\u000a* Discovery science\u000a\u000a== Conclusion ==\u000aVNS implies several features which are presented in Hansen and Mladenovic<ref>{{cite journal|last1=Hansen|first1=P|last2=Mladenovi´c|first2=N|title=Variable neighborhood search|journal=Glover F, Kochenberger G (eds) Handbook\u000aof Metaheuristics|year=2003|issue=Kluwer, Dordrecht|pages=145\u2013184}}</ref> and some are presented here:\u000a\u000a(i) Simplicity: VNS is simple a simple and clear which is universally applicable;\u000a\u000a(ii) Precision: VNS is formulated in precise mathematical definitions;\u000a\u000a(iii) Coherence: all actions of the heuristics for solving problems follow from the VNS principles;\u000a\u000a(iv) Effectiveness: VNS supplies optimal or near-optimal solutions for all or at least most realistic instances;\u000a\u000a(v) Efficiency: VNS takes a moderate computing time to generate optimal or near-optimal solutions;\u000a\u000a(vi) Robustness: the functioning of the VNS is coherent over a variety of instances;\u000a\u000a(vii) User friendliness: VNS has no parameters, so it is easy for understanding, expressing and using;\u000a\u000a(viii) Innovation: VNS is generating new types of application.\u000a\u000a(ix) Generality: VNS is inducing to good results for a wide variety of\u000aproblems;\u000a\u000a(x) Interactivity: VNS allows the user to incorporate his knowledge to improve the resolution process;\u000a\u000a(xi) Multiplicity: VNS is able to produce a certain near-optimal solutions from which the user can choose;\u000a\u000aInterest in VNS is growing quickly, evidenced by the increasing number of papers published each year on this topic (10 years ago, only a few; 5 years ago, about a dozen; and about 50 in 2007).\u000aMoreover, the 18th EURO mini-conference held in Tenerife in November 2005 was entirely devoted to VNS. It led to special issues of [[Institute of Mathematics and its Applications|IMA Journal of Management Mathematics]] in 2007, European Journal of Operational Research (http://www.journals.elsevier.com/european-journal-of-operational-research/), and Journal of Heuristics (http://www.springer.com/mathematics/applications/journal/10732/) in 2008.\u000a\u000a== References ==\u000a{{Reflist}}\u000a\u000a== External links ==\u000a* [http://toledo.mi.sanu.ac.rs/~grujicic/vnsconference EURO Mini Conference XXVIII on Variable Neighbourhood Search]\u000a\u000a[[Category:Searching]]
p105
sg4
S'191'
p106
sg6
VVariable neighborhood search
p107
ssI66
(dp108
g2
V{{multiple issues|\u000a{{Orphan|date=February 2009}}\u000a{{Refimprove|article|date=November 2006}}\u000a}}\u000a\u000a'''Instant indexing''' is a feature offered by [[Internet]] [[search engine]]s that enables users to submit content for immediate inclusion into the [[search engine indexing|index]].\u000a\u000a==Delayed inclusion==\u000aCertain search engine services may require an extended period of time for inclusion, which is seen as a delay and a frustration by [[website]] administrators who wish to have their websites appear in [[search engine results page|search engine results]]{{Citation needed|date=February 2007}}.\u000a\u000aDelayed inclusion may due to the size of the index that the service must maintain or due to corporate, political or social policies{{Citation needed|date=February 2007}}. Some services only index content collected by a [[web crawling|crawler program]] which does not allow for manual adding of content to index{{Citation needed|date=February 2007}}.\u000a\u000a==Criticisms==\u000aA criticism of instant indexing is that certain services filter results manually or via algorithms that prevent instant inclusion to avoid inclusion of content that violates the service's policies.{{Citation needed|date=February 2007}}\u000a\u000aInstant indexing impacts the timeliness of the content included in the index. Given the manner in which many [[web crawling|crawlers]] operate in the case of Internet search engines, websites are only visited if a some other website links to them. Unlinked web sites are never visited (see [[invisible web]]) by the crawler because it cannot reach the website during its traversal. It is assumed that unlinked websites are less authoritative and less popular, and therefore of less quality. Over time, if a website is popular or authoritative, it is assumed that other websites will eventually link to it. If a search engine service provides instant indexing, it bypasses this quality control mechanism by not requiring incoming links. This infers that the search engine's service produces lower quality results.\u000a\u000aSelect search services that offer such a service typically also offer [[paid inclusion]], also referred to as [[pay per click|inorganic search]]. This may reduce the quality of search results.\u000a\u000a==External links==\u000a* {{cite web | url = http://www.web-cite.com/search_marketing/000078.html | title = Don't Blink: Instant Indexing? | publisher = Web-Cite Exposure | date = 2003-03-26 | accessdate = 2006-09-23 |archiveurl = http://web.archive.org/web/20060427184004/http://www.web-cite.com/search_marketing/000078.html <!-- Bot retrieved archive --> |archivedate = 2006-04-27}}\u000a* {{cite web | url = http://www.earthstation9.com/index.html?us_searc.htm | title = The Wonderful World of Search Engines and Web Directories \u2014 A Search Engine Guide | author = Stan Daniloski | publisher = Earth Station 9 | date = 2004-09-17 | accessdate = 2006-09-23}}\u000a\u000a== See also ==\u000a* [[Search engine]]\u000a* [[Search engine indexing]]\u000a* [[Web crawling]]\u000a\u000a[[Category:Internet terminology]]\u000a[[Category:Information retrieval]]\u000a\u000a\u000a{{website-stub}}
p109
sg4
S'66'
p110
sg6
VInstant indexing
p111
ssI196
(dp112
g2
V{{Cat main|Concordance (publishing)}}\u000a[[Category:Biblical studies]]\u000a[[Category:Indexing]]\u000a[[Category:Linguistics]]\u000a[[Category:Reference works]]\u000a[[Category:Searching]]\u000a[[Category:Hypertext]]
p113
sg4
S'196'
p114
sg6
VCategory:Concordances (publishing)
p115
ssI71
(dp116
g2
V{{Use dmy dates|date=July 2013}}\u000a{{multiple issues|\u000a{{notability|Companies|date=August 2012}}\u000a{{refimprove|date=August 2012}}\u000a{{peacock|date=August 2012}}\u000a{{advert|date=August 2012}}\u000a}}\u000a{{Infobox company\u000a| logo = [[Image:30 Digits Logo.jpg|center]]\u000a| name = 30 Digits GmbH\u000a| type = [[Private company|Private]]\u000a| foundation = 2008\u000a| location = [[Munich]], Germany\u000a| area_served = [[Europe]] <br/> [[North America]] <br/> [[South America]] <br/> [[Asia]]\u000a| key_people = Justin Gilbreath (Managing Director) <br/> Mathis Koblin (Director of R&D)\u000a| industry = [[Information access]] <br/> [[Information retrieval]] <br/> [[Web mining]] <br/> [[Open Source software]]\u000a| products = [[Search Engines]] <br/> Information Discovery Suite <br/> [[Apache Lucene]] <br/> [[Apache Solr]] <br/> Web Extractor\u000a| company_slogan = Linking People to Content\u000a| homepage = {{url|http://www.30digits.com}}\u000a}}\u000a\u000a'''30 Digits''' is a privately held information access and retrieval company with headquarters in [[Munich, Germany]]<ref>{{cite web |url=http://www.digitalpublic.de/web-20-suchmaschinen-holen-auf |title=Web 2.0 \u2013 Suchmaschinen holen auf}}</ref> located in the "Münchner Technologie Zentrum".<ref>{{cite web |url=http://www.mtz.de/index.php?id=12 |title=List of companies located in the MTZ (Münchner Technologie Zentrum)}}</ref> The company was founded in 2008 and offers software that is a mix of privately developed code and leading [[Open Source]] technology primarily from the [[Apache Software Foundation]].\u000a\u000aThe company focuses on [[enterprise information access]] solutions from areas ranging from call-center applications to [[enterprise search]] to database offloading. The company also focuses on solutions created out of unstructured content on the web being structured for analysis,<ref>{{cite web |url=http://www.crmmanager.de/magazin/artikel_2165_enterprise_20_wahlkampf.html |title=Enterprise 2.0: Was ein Unternehmen von Obamas Wahlkampf lernen kann}}</ref> often referred to as [[web harvesting]].  This can be for monitoring security threats or observing customer reactions to products.  It can even be used to gather complex address and other details about entities like properties.<ref>{{cite web |url=http://www.prweb.com/releases/2011/03/prweb5186764.htm |title=viewr Selects 30 Digits as Primary Property Data Provider }}</ref>  Sometimes the focuses blend together in areas like Market or Business Intelligence where both internal and external information needs extraction, analysis, and retrieval capabilities.\u000a\u000aIn addition to the software solutions, 30 Digits Professional Services offers services to assist customer in designing and deploying the correct solutions for the challenge at hand. {{citation needed|date=August 2012}} Trainings, support, and consulting are available both on 30 Digits software and the Open Source software they work with like [[Lucene]] and [[Solr]].<ref>{{cite web |url=http://www.aktiv-verzeichnis.de/details/30-digits-gmbh.html |title=Company description from the Aktiv Verzeichnis}}</ref>\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a==External links==\u000a* [http://www.30digits.com  Company website]\u000a* [http://www.imittelstand.de/mittelstandsliste/webcode/ww1213 Article (in German) placing 30 Digits Web Extractor in Top20 Business Intelligence tools for the "Initiative Mittelstand" 2009]\u000a* [http://lucene.apache.org/  Lucene website]\u000a* [http://lucene.apache.org/solr/ Solr website]\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Search engine software]]\u000a[[Category:Software industry]]\u000a[[Category:Software companies of Germany]]\u000a[[Category:Business software]]\u000a[[Category:Companies based in Munich]]\u000a[[Category:Companies of Germany]]\u000a[[Category:Companies of Europe]]
p117
sg4
S'71'
p118
sg6
V30 Digits
p119
ssI201
(dp120
g2
V{{No footnotes|date=July 2011}}\u000aIn [[coding theory]], the '''Lee distance''' is a [[distance]] between two [[String (computer science)|string]]s <math>x_1 x_2 \u005cdots x_n</math> and <math>y_1 y_2 \u005cdots y_n</math> of equal length ''n'' over the ''q''-ary [[alphabet]] {0,&nbsp;1,&nbsp;\u2026,&nbsp;''q''&nbsp;&minus;&nbsp;1} of size ''q''&nbsp;\u2265&nbsp;2.\u000aIt is a [[Metric (mathematics)|metric]], defined as\u000a\u000a: <math>\u005csum_{i=1}^n \u005cmin(|x_i-y_i|,q-|x_i-y_i|).</math>\u000a\u000aIf ''q''&nbsp;=&nbsp;2 the Lee distance coincides with the [[Hamming distance]].\u000a\u000aThe [[metric space]] induced by the Lee distance is a discrete analog of the [[Elliptic geometry|elliptic space]].\u000a\u000a==Example==\u000aIf ''q''&nbsp;=&nbsp;6, then the Lee distance between 3140 and 2543 is 1&nbsp;+&nbsp;2&nbsp;+&nbsp;0&nbsp;+&nbsp;3&nbsp;=&nbsp;6.\u000a\u000a==History and application==\u000aThe Lee distance is named after [[C. Y. Lee (mathematician)|C. Y. Lee]]. It is applied for phase [[modulation]] while the Hamming distance is used in case of orthogonal modulation.\u000a\u000a==References==\u000a* {{Citation|first=C. Y.|last=Lee|title=Some properties of nonbinary [[error-correcting codes]]|journal=[[IEEE Transactions on Information Theory|IRE Transactions on Information Theory]]|volume=4|year=1958|pages=77\u201382|issue=2|doi=10.1109/TIT.1958.1057446}}.\u000a* {{Citation|first=E. R.|last=Berlekamp|authorlink=Elwyn Berlekamp|title=Algebraic Coding Theory|publisher=McGraw-Hill|year=1968}}.\u000a* {{Citation|last1=Deza|first1=E.|first2=M.|last2=Deza|author2-link=Michel Deza|title=Dictionary of Distances|year=2006|publisher=Elsevier|isbn=0-444-52087-2}}.\u000a\u000a[[Category:Coding theory]]\u000a[[Category:String similarity measures]]
p121
sg4
S'201'
p122
sg6
VLee distance
p123
ssI76
(dp124
g2
VThe '''Rocchio algorithm''' is based on a method of [[relevance feedback]] found in [[information retrieval]] systems which stemmed from the [[SMART Information Retrieval System]] around the year 1970. Like many other retrieval systems, the Rocchio feedback approach was developed using the [[Vector Space Model]].  The [[algorithm]] is based on the assumption that most users have a general conception of which documents should be denoted as  [[Relevance (information retrieval)|relevant]] or non-relevant.<ref>Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze: ''An Introduction to Information Retrieval'', page 181. Cambridge University Press, 2009.</ref>  Therefore, the user's search query is revised to include an arbitrary percentage of  relevant and non-relevant documents as a means of increasing the [[search engine]]'s [[Information_retrieval#Recall|recall]], and possibly the precision as well.  The number of  relevant and non-relevant documents allowed to enter a [[Information retrieval|query]] is dictated by the weights of the a, b, c variables listed below in the [[Rocchio_Classification#Algorithm|Algorithm section]].<ref>Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze: ''An Introduction to Information Retrieval'', page 292. Cambridge University Press, 2009.</ref>\u000a\u000a==Algorithm==\u000aThe [[Formula (mathematical logic)|formula]] and variable definitions for Rocchio relevance feedback is as follows:<ref>Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze: ''An Introduction to Information Retrieval'', page 182. Cambridge University Press, 2009.</ref>\u000a\u000a<math> \u005coverrightarrow{Q_m} = \u005cbigl(a \u005ccdot \u005coverrightarrow{Q_o}\u005cbigr) + \u005cbiggl(b \u005ccdot {\u005ctfrac{1}{|D_r|}} \u005ccdot \u005csum_{\u005coverrightarrow{D_j} \u005cin D_r} \u005coverrightarrow{D_j}\u005cbiggr)\u000a- \u005cbiggl(c \u005ccdot {\u005ctfrac{1}{|D_{nr}|}} \u005ccdot \u005csum_{\u005coverrightarrow{D_k} \u005cin D_{nr}} \u005coverrightarrow{D_k}\u005cbiggr) </math>\u000a\u000a{| class="wikitable"\u000a|-\u000a! Variable\u000a! Value\u000a|-\u000a| <math> \u005coverrightarrow{Q_m} </math>\u000a| Modified Query Vector\u000a|-\u000a| <math> \u005coverrightarrow{Q_o} </math>\u000a| Original Query Vector\u000a|-\u000a| <math> \u005coverrightarrow{D_j} </math>\u000a| Related Document Vector\u000a|-\u000a| <math> \u005coverrightarrow{D_k} </math>\u000a| Non-Related Document Vector\u000a|-\u000a| <math> a </math>\u000a| Original Query Weight\u000a|-\u000a| <math> b </math>\u000a| Related Documents Weight\u000a|-\u000a| <math> c </math>\u000a| Non-Related Documents Weight\u000a|-\u000a| <math> D_r </math>\u000a| Set of Related Documents\u000a|-\u000a| <math> D_{nr} </math>\u000a| Set of Non-Related Documents\u000a|}\u000a[[Image:Rocchioclassgraph.jpg|thumb|right|250px|Rocchio Classification]]\u000a\u000aAs demonstrated in the Rocchio formula, the associated weights ('''a''', '''b''', '''c''') are responsible for shaping the modified [[vector space|vector]] in a direction closer, or farther away, from the original query, related documents, and non-related documents.  In particular, the values for '''b''' and '''c''' should be incremented or decremented proportionally to the set of documents classified by the user.  If the user decides that the modified query should not contain terms from either the original query, related documents, or non-related documents, then the corresponding weight ('''a''', '''b''', '''c''') value for the category should be set to 0.\u000a\u000aIn the later part of the algorithm, the variables '''Dr''', and '''Dnr''' are presented to be sets of [[Tuple|vectors]] containing the coordinates of related documents and non-related documents.  Though '''Dr''' and '''Dnr''' are not  vectors themselves, <math> \u005coverrightarrow{Dj} </math> and <math> \u005coverrightarrow{Dk} </math> are the vectors used to iterate through the two sets and form vector [[summation]]s. These summations will be multiplied against the [[Multiplicative inverse]] of their respective document set ('''Dr''', '''Dnr''') to complete the addition or subtraction of related or non-related documents.\u000a\u000aIn order to visualize the changes taking place on the modified vector, please refer to the image below.<ref>Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze: ''An Introduction to Information Retrieval'', page 293. Cambridge University Press, 2009.</ref> As the weights are increased or decreased for a particular category of documents, the coordinates for the modified vector begin to move either closer, or farther away, from the [[centroid]] of the document collection. Thus if the weight is increased for related documents, then the modified vectors [[coordinate]]s will reflect being closer to the centroid of related documents.\u000a\u000a==Time complexity==\u000aThe [[time complexity]] for training and testing the algorithm are listed below and followed by the definition of each [[variable (mathematics)|variable]]. Note that when in testing phase, the time complexity can be reduced to that of calculating the [[euclidean distance]] between a class [[centroid]] and the respective document.  As shown by: <math>\u005cTheta(\u005cvert\u005cmathbb{C}\u005cvert M_{a})</math>.\u000a\u000aTraining = <math>\u005cTheta(\u005cvert\u005cmathbb{D}\u005cvert L_{ave}+\u005cvert\u005cmathbb{C}\u005cvert\u005cvert V\u005cvert)</math> <br>\u000aTesting = <math>\u005cTheta( L_{a}+\u005cvert\u005cmathbb{C}\u005cvert M_{a})= \u005cTheta(\u005cvert\u005cmathbb{C}\u005cvert M_{a})</math> <ref>Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze: ''An Introduction to Information Retrieval'', page 296. Cambridge University Press, 2009.</ref>\u000a\u000a{| class="wikitable"\u000a|-\u000a! Variable\u000a! Value\u000a|-\u000a| <math> \u005cmathbb{D} </math>\u000a| Labeled Document Set\u000a|-\u000a| <math> L_{ave} </math>\u000a| Average Tokens Per Document\u000a|-\u000a| <math> \u005cmathbb{C} </math>\u000a| Class Set\u000a|-\u000a| <math> V </math>\u000a| Vocabulary/Term Set\u000a|-\u000a| <math> L_{a} </math>\u000a| Number of Tokens in Document\u000a|-\u000a| <math> M_{a} </math>\u000a| Number of Types in Document\u000a|}\u000a\u000a==Usage==\u000aThough there are benefits to ranking documents as not-relevant, a [[relevant]] document ranking will result in more precise documents being made available to the user. Therefore, traditional values for the algorithm's weights ('''a''', '''b''', '''c''') in Rocchio Classification are typically around '''a = 1''', '''b = 0.8''', and ''' c = 0.1'''. Modern [[information retrieval]] systems have moved towards eliminating the non-related documents by setting '''c = 0''' and thus only accounting for related documents. Although not all [[Information retrieval|retrieval systems]] have eliminated the need for non-related documents, most have limited the effects on modified query by only accounting for strongest non-related documents in the '''Dnr''' set.\u000a\u000a==Limitations==\u000aThe Rocchio algorithm often fails to classify multimodal classes and relationships. For instance, the country of [[Burma]] was renamed to [[Myanmar]] in 1989. Therefore the two queries of "Burma" and "Myanmar" will appear much farther apart in the [[vector space model]], though they both contain similar origins.<ref>Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze: ''An Introduction to Information Retrieval'', page 296. Cambridge University Press, 2009.</ref>\u000a\u000a== See also ==\u000a*  [[Nearest centroid classifier]], aka Rocchio classifier\u000a\u000a==References==\u000a{{reflist}}\u000a* [http://nlp.stanford.edu/IR-book/pdf/09expand.pdf Relevance Feedback and Query Expansion]\u000a* [http://nlp.stanford.edu/IR-book/pdf/14vcat.pdf Vector Space Classification]\u000a* [http://cs.nyu.edu/courses/fall07/G22.2580-001/lec7.html Data Classification]\u000a\u000a[[Category:Information retrieval]]
p125
sg4
S'76'
p126
sg6
VRocchio algorithm
p127
ssI206
(dp128
g2
VIn [[computer science]], '''edit distance''' is a way of quantifying how dissimilar two [[String (computing)|strings]] (e.g., words) are to one another by counting the minimum number of operations required to transform one string into the other. Edit distances find applications in [[natural language processing]], where automatic [[Spell checker|spelling correction]] can determine candidate corrections for a misspelled word by selecting words from a dictionary that have a low distance to the word in question. In [[bioinformatics]], it can be used to quantify the similarity of [[macromolecule]]s such as [[DNA]], which can be viewed as strings of the letters A, C, G and T.\u000a\u000aSeveral definitions of edit distance exist, using different sets of string operations. One of the most common variants is called [[Levenshtein distance]], named after the Soviet Russian computer scientist [[Vladimir Levenshtein]]. In this version, the allowed operations are the removal or insertion of a single character, or the substitution of one character for another. Levenshtein distance may also simply be called "edit distance", although several variants exist.<ref name="navarro">{{Cite doi/10.1145.2F375360.375365}}</ref>{{rp|32}}\u000a\u000a==Formal definition and properties==\u000aGiven two strings {{mvar|a}} and {{mvar|b}} on an alphabet {{mvar|\u03a3}} (e.g. the set of [[ASCII]] characters, the set of [[byte]]s [0..255], etc.), the edit distance d({{mvar|a}}, {{mvar|b}}) is the minimum-weight series of edit operations that transforms {{mvar|a}} into {{mvar|b}}. One of the simplest sets of edit operations is that defined by Levenshtein in 1966:<ref name="slp"/>\u000a\u000a:'''Insertion''' of a single symbol. If {{mvar|a}} = {{mvar|u}}{{mvar|v}}, then inserting the symbol {{mvar|x}} produces {{mvar|u}}{{mvar|x}}{{mvar|v}}. This can also be denoted \u03b5\u2192{{mvar|x}}, using \u03b5 to denote the empty string.\u000a:'''Deletion''' of a single symbol changes {{mvar|u}}{{mvar|x}}{{mvar|v}} to {{mvar|u}}{{mvar|v}} ({{mvar|x}}\u2192\u03b5).\u000a:'''Substitution''' of a single symbol {{mvar|x}} for a symbol {{mvar|y}} \u2260 {{mvar|x}} changes {{mvar|u}}{{mvar|x}}{{mvar|v}} to {{mvar|u}}{{mvar|y}}{{mvar|v}} ({{mvar|x}}\u2192{{mvar|y}}).\u000a\u000aIn Levenshtein's original definition, each of these operations has unit cost (except that substitution of a character by itself has zero cost), so the Levenshtein distance is equal to the minimum ''number'' of operations required to transform {{mvar|a}} to {{mvar|b}}. A more general definition associates non-negative weight functions {{mvar|w}}<sub>ins</sub>({{mvar|x}}), {{mvar|w}}<sub>del</sub>({{mvar|x}}) and {{mvar|w}}<sub>sub</sub>({{mvar|x}}&nbsp;{{mvar|y}}) with the operations.<ref name="slp">{{cite book |author1=Daniel Jurafsky |author2=James H. Martin |title=Speech and Language Processing |publisher=Pearson Education International |pages=107\u2013111}}</ref>\u000a\u000aAdditional primitive operations have been suggested. A common mistake when typing text is '''transposition''' of two adjacent characters commonly occur, formally characterized by an operation that changes {{mvar|u}}{{mvar|x}}{{mvar|y}}{{mvar|v}} into {{mvar|u}}{{mvar|y}}{{mvar|x}}{{mvar|v}} where {{mvar|x}}, {{mvar|y}} \u2208 {{mvar|\u03a3}}.<ref name="ukkonen83">{{cite conference |author=Esko Ukkonen |title=On approximate string matching |conference=Foundations of Computation Theory |year=1983 |pages=487\u2013495 |publisher=Springer}}</ref><ref name="ssm"/>\u000aFor the task of correcting [[Optical character recognition|OCR]] output, '''merge''' and '''split''' operations have been used which replace a single character into a pair of them or vice-versa.<ref name="ssm">{{cite journal |first1=Klaus U. |last1=Schulz |first2=Stoyan |last2=Mihov |year=2002 |id={{citeseerx|10.1.1.16.652}} |title=Fast string correction with Levenshtein automata |journal=International Journal of Document Analysis and Recognition |volume=5 |issue=1 |pages=67\u201385 |doi=10.1007/s10032-002-0082-8}}</ref>\u000a\u000aOther variants of edit distance are obtained by restricting the set of operations. [[Longest common subsequence]] (LCS) distance is edit distance with insertion and deletion as the only two edit operations, both at unit cost.<ref name="navarro"/>{{rp|37}} Similarly, by only allowing substitutions (again at unit cost), [[Hamming distance]] is obtained; this must be restricted to equal-length strings.<ref name="navarro"/>\u000a[[Jaro\u2013Winkler distance]] can be obtained from an edit distance where only transpositions are allowed.\u000a\u000a===Example===\u000aThe [[Levenshtein distance]] between "kitten" and "sitting" is 3. The minimal edit script that transforms the former into the latter is:\u000a\u000a# '''k'''itten \u2192 '''s'''itten (substitution of "s" for "k")\u000a# sitt'''e'''n \u2192 sitt'''i'''n (substitution of "i" for "e")\u000a# sittin \u2192 sittin'''g''' (insertion of "g" at the end).\u000a\u000aLCS distance (insertions and deletions only) gives a different distance and minimal edit script:\u000a\u000a# delete '''k''' at 0\u000a# insert '''s''' at 0\u000a# delete '''e''' at 4\u000a# insert '''i''' at 4\u000a# insert '''g''' at 6\u000a\u000afor a total cost/distance of 5 operations.\u000a\u000a===Properties===\u000aEdit distance with non-negative cost satisfies the axioms of a [[Metric (mathematics)|metric]], giving rise to a [[metric space]] of strings, when the following conditions are met:<ref name="navarro"/>{{rp|37}}\u000a\u000a* Every edit operation has positive cost;\u000a* for every operation, there is an inverse operation with equal cost.\u000a\u000aWith these properties, the metric axioms are satisfied as follows:\u000a\u000a:{{mvar|d}}({{mvar|a}}, {{mvar|a}}) = 0, since each string can be trivially transformed to itself using exactly zero operations.\u000a:{{mvar|d}}({{mvar|a}}, {{mvar|b}}) > 0 when {{mvar|a}} \u2260 {{mvar|b}}, since this would require at least one operation at non-zero cost.\u000a:{{mvar|d}}({{mvar|a}}, {{mvar|b}}) = {{mvar|d}}({{mvar|b}}, {{mvar|a}}) by equality of the cost of each operation and its inverse.\u000a:Triangle inequality: {{mvar|d}}({{mvar|a}}, {{mvar|c}}) \u2264 {{mvar|d}}({{mvar|a}}, {{mvar|b}}) + {{mvar|d}}({{mvar|b}}, {{mvar|c}}).<ref>{{cite conference |author1=Lei Chen |author2=Raymond Ng |title=On the marriage of L\u209a-norms and edit distance |conference=Proc. 30th Int'l Conf. on Very Large Databases (VLDB) |volume=30 |year=2004}}</ref>\u000a\u000aLevenshtein distance and LCS distance with unit cost satisfy the above conditions, and therefore the metric axioms. Variants of edit distance that are not proper metrics have also been considered in the literature.<ref name="navarro"/>\u000a\u000aOther useful properties of unit-cost edit distances include:\u000a\u000a* LCS distance is bounded above by the sum of lengths of a pair of strings.<ref name="navarro"/>{{rp|37}}\u000a* LCS distance is an upper bound on Levenshtein distance.\u000a* For strings of the same length, Hamming distance is an upper bound on Levenshtein distance.<ref name="navarro"/>\u000a\u000aRegardless of cost/weights, the following property holds of all edit distances:\u000a\u000a* When {{mvar|a}} and {{mvar|b}} share a common prefix, this prefix has no effect on the distance. Formally, when {{mvar|a}} = {{mvar|uv}} and {{mvar|b}} = {{mvar|uw}}, then {{mvar|d}}({{mvar|a}}, {{mvar|b}}) = {{mvar|d}}({{mvar|v}}, {{mvar|w}}).<ref name="ssm"/> This allows speeding up many computations involving edit distance and edit scripts, since common prefixes and suffixes can be skipped in linear time.\u000a\u000a==Computation==\u000a===Basic algorithm===\u000a{{main|Wagner\u2013Fischer algorithm}}\u000aUsing Levenshtein's original operations, the edit distance between <math>a = a_1\u005cldots a_n</math> and <math>b = b_1\u005cldots b_m</math> is given by <math>d_{mn}</math>, defined by the recurrence<ref name="slp"/>\u000a\u000a:<math>d_{i0} = \u005csum_{k=1}^{i} w_\u005cmathrm{del}(b_{k}), \u005cquad  for\u005c; 1 \u005cleq i \u005cleq m</math>\u000a:<math>d_{0j} = \u005csum_{k=1}^{j} w_\u005cmathrm{ins}(a_{k}), \u005cquad  for\u005c; 1 \u005cleq j \u005cleq n</math>\u000a:<math>d_{ij} = \u005cbegin{cases} d_{i-1, j-1} & \u005cquad a_{j} = b_{i}\u005c\u005c \u005cmin \u005cbegin{cases} d_{i-1, j} + w_\u005cmathrm{del}(b_{i})\u005c\u005c d_{i,j-1} + w_\u005cmathrm{ins}(a_{j}) \u005c\u005c d_{i-1,j-1} + w_\u005cmathrm{sub}(a_{j}, b_{i}) \u005cend{cases} & \u005cquad a_{j} \u005cneq b_{i}\u005cend{cases} , \u005cquad  for\u005c; 1 \u005cleq i \u005cleq m, 1 \u005cleq j \u005cleq n.</math>\u000a\u000aThis algorithm can be generalized to handle transpositions by adding another term in the recursive clause's minimization.<ref name="ukkonen83"/>\u000a\u000aThe straightforward, [[Recursion (computer science)|recursive]] way of evaluating this recurrence takes [[exponential time]]. Therefore, it is usually computed using a [[dynamic programming]] algorithm that is commonly credited to [[Wagner\u2013Fischer algorithm|Wagner and Fischer]],<ref>{{cite journal |author1=R. Wagner |author2=M. Fischer |title=The string-to-string correction problem |journal=J. ACM |volume=21 |year=1974 |pages=168\u2013178 |doi=10.1145/321796.321811}}</ref> although it has a history of multiple invention.<ref name="slp"/><ref name="ukkonen83"/>\u000aAfter completion of the Wagner\u2013Fischer algorithm, a minimal sequence of edit operations can be read off as a backtrace of the operations used during the dynamic programming algorithm starting at <math>d_{mn}</math>.\u000a\u000aThis algorithm has a [[time complexity]] of \u0398({{mvar|m}}{{mvar|n}}). When the full dynamic programming table is constructed, its [[space complexity]] is also \u0398({{mvar|m}}{{mvar|n}}); this can be improved to \u0398(min({{mvar|m}},{{mvar|n}})) by observing that at any instant, the algorithm only requires two rows (or two columns) in memory. However, this optimization makes it impossible to read off the minimal series of edit operations.<ref name="ukkonen83"/> A linear-space solution to this problem is offered by [[Hirschberg's algorithm]].<ref>{{cite book |last=Skiena |first=Steven |authorlink=Steven Skiena |title = The Algorithm Design Manual |publisher=[[Springer Science+Business Media]] |edition=2nd |year = 2010 |isbn=1-849-96720-2}}</ref>{{rp|634}}\u000a\u000a===Improved algorithms===\u000aImproving on the Wagner\u2013Fisher algorithm described above, [[Esko Ukkonen|Ukkonen]] describes several variants,<ref>{{cite journal |title=Algorithms for approximate string matching |journal=Information and Control |volume=64 |issue=1\u20133 |year=1985 |url=http://www.cs.helsinki.fi/u/ukkonen/InfCont85.PDF}}</ref> one of which takes two strings and a maximum edit distance {{mvar|s}}, and returns min({{mvar|s}}, {{mvar|d}}). It achieves this by only computing and storing a part of the dynamic programming table around its diagonal. This algorithm takes time O({{mvar|s}}×min({{mvar|m}},{{mvar|n}})), where {{mvar|m}} and {{mvar|n}} are the lengths of the strings. Space complexity is O({{mvar|s}}²) or O({{mvar|s}}), depending on whether the edit sequence needs to be read off.<ref name="ukkonen83"/>\u000a\u000a==Applications==\u000aEdit distance finds applications in [[computational biology]] and natural language processing, e.g. the correction of spelling mistakes or OCR errors, and [[approximate string matching]], where the objective is to find matches for short strings in many longer texts, in situations where a small number of differences is to be expected.\u000a\u000aVarious algorithms exist that solve problems beside the computation of distance between a pair of strings, to solve related types of problems.\u000a\u000a* [[Hirschberg's algorithm]] computes the optimal [[Sequence alignment|alignment]] of two strings, where optimality is defined as minimizing edit distance.\u000a* [[Approximate string matching]] can be formulated in terms of edit distance. Ukkonen's 1985 algorithm takes a string {{mvar|p}}, called the pattern, and a constant {{mvar|k}}; it then builds a [[deterministic finite state automaton]] that finds, in an arbitrary string {{mvar|s}}, a substring whose edit distance to {{mvar|p}} is at most {{mvar|k}}<ref>{{cite journal |author=Esko Ukkonen |title=Finding approximate patterns in strings |journal=J. Algorithms |volume=6 |pages=132\u2013137 |year=1985 |doi=10.1016/0196-6774(85)90023-9}}</ref> (cf. the [[Aho\u2013Corasick string matching algorithm|Aho\u2013Corasick algorithm]], which similarly constructs an automaton to search for any of a number of patterns, but without allowing edit operations). A similar algorithm for approximate string matching is the [[bitap algorithm]], also defined in terms of edit distance.\u000a* [[Levenshtein automaton|Levenshtein automata]] are finite-state machines that recognize a set of strings within bounded edit distance of a fixed reference string.<ref name="ssm"/>\u000a\u000a==References==\u000a{{reflist|30em}}\u000a\u000a[[Category:String similarity measures]]
p129
sg4
S'206'
p130
sg6
VEdit distance
p131
ssI81
(dp132
g2
V{{Underlinked|date=August 2014}}\u000a\u000aThe '''probabilistic relevance model'''<ref>{{citation | author=S. E. Robertson | coauthors=K. S. Jones | title=Relevance weighting of search terms | publisher=Journal of the American Society for Information Science | pages=129\u2013146 | date=May\u2013June 1976 | url=http://portal.acm.org/citation.cfm?id=106783 }}</ref> was devised by Robertson and Jones as a framework for probabilistic models to come.\u000a \u000aIt makes an estimation of the probability of finding if a document ''d<sub>j</sub>'' is relevant to a query ''q''. This model assumes that this probability of relevance depends on the query and document representations. Furthermore, it assumes that there is a portion of all documents that is preferred by the user as the answer set for query ''q''. Such an ideal answer set is called ''R'' and should maximize the overall probability of relevance to that user. The prediction is that documents in this set ''R'' are relevant to the query, while documents not present in the set are non-relevant.\u000a\u000a<math>sim(d_{j},q) = \u005cfrac{P(R|\u005cvec{d}_j)}{P(\u005cbar{R}|\u005cvec{d}_j)}</math>\u000a\u000a==Related models==\u000aThere are some limitations to this framework that need to be addressed by further development:\u000a* There is no accurate estimate for the first run probabilities\u000a* Index terms are not weighted\u000a* Terms are assumed mutually independent\u000a\u000aTo address these and other concerns there are some developed models from the probabilistic relevance framework. The [[Binary Independence Model]] for one, as it is from the same author. The most known derivative of this framework is the [[Probabilistic relevance model (BM25)|Okapi(BM25)]] weighting scheme and it's BM25F brother.\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Probabilistic models]]
p133
sg4
S'81'
p134
sg6
VProbabilistic relevance model
p135
ssI211
(dp136
g2
V{{refimprove|date=February 2010}}\u000a\u000aIn [[information theory]] and [[computer science]], the '''Levenshtein distance''' is a [[string metric]] for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions or substitutions) required to change one word into the other. It is named after [[Vladimir Levenshtein]], who considered this distance in 1965.<ref>{{cite journal |author=\u0412\u043b\u0430\u0434\u0438\u0301\u043c\u0438\u0440 \u0418. \u041b\u0435\u0432\u0435\u043d\u0448\u0442\u0435\u0439\u043d |script-title=ru:\u0414\u0432\u043e\u0438\u0447\u043d\u044b\u0435 \u043a\u043e\u0434\u044b \u0441 \u0438\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435\u043c \u0432\u044b\u043f\u0430\u0434\u0435\u043d\u0438\u0439, \u0432\u0441\u0442\u0430\u0432\u043e\u043a \u0438 \u0437\u0430\u043c\u0435\u0449\u0435\u043d\u0438\u0439 \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432 |language=Russian |trans_title=Binary codes capable of correcting deletions, insertions, and reversals |journal=\u0414\u043e\u043a\u043b\u0430\u0434\u044b \u0410\u043a\u0430\u0434\u0435\u043c\u0438\u0439 \u041d\u0430\u0443\u043a \u0421CCP |volume=163 |issue=4 |pages=845\u20138 |year=1965}} Appeared in English as: {{cite journal |author=Levenshtein, Vladimir I. |title=Binary codes capable of correcting deletions, insertions, and reversals |journal=Soviet Physics Doklady |volume=10 |number=8 |pages=707\u2013710 |date=February 1966  |url=<!--http://profs.sci.univr.it/~liptak/ALBioinfo/files/levenshtein66.pdf right to publish copy of journal unclear: see http://www.sherpa.ac.uk/romeo/search.php?issn=1028-3358&type=issn&la=en/&fIDnum=%7C&mode=simple ; in any event, liptak does not appear to be the author or the translator -->}}</ref>\u000a\u000aLevenshtein distance may also be referred to as '''edit distance''', although that may also denote a larger [[Edit distance|family of distance metrics]].<ref name="navarro">{{Cite doi/10.1145.2F375360.375365}}</ref>{{rp|32}} It is closely related to [[Sequence alignment#Pairwise alignment|pairwise string alignments]].\u000a\u000a== Definition ==\u000aMathematically, the Levenshtein distance between two strings <math>a, b</math> is given by <math>\u005coperatorname{lev}_{a,b}(|a|,|b|)</math> where\u000a\u000a:<math>\u005cqquad\u005coperatorname{lev}_{a,b}(i,j) = \u005cbegin{cases}\u000a  \u005cmax(i,j) & \u005ctext{ if} \u005cmin(i,j)=0, \u005c\u005c\u000a  \u005cmin \u005cbegin{cases}\u000a          \u005coperatorname{lev}_{a,b}(i-1,j) + 1 \u005c\u005c\u000a          \u005coperatorname{lev}_{a,b}(i,j-1) + 1 \u005c\u005c\u000a          \u005coperatorname{lev}_{a,b}(i-1,j-1) + 1_{(a_i \u005cneq b_j)}\u000a       \u005cend{cases} & \u005ctext{ otherwise.}\u000a\u005cend{cases}</math>\u000awhere  <math>1_{(a_i \u005cneq b_j)}</math> is the [[indicator function]] equal to 0 when  <math>a_i = b_j</math> and equal to 1 otherwise.\u000a\u000aNote that the first element in the minimum corresponds to deletion (from <math>a</math> to <math>b</math>), the second to insertion and the third to match or mismatch, depending on whether the respective symbols are the same.\u000a\u000a=== Example ===\u000aFor example, the Levenshtein distance between "kitten" and "sitting" is 3, since the following three edits change one into the other, and there is no way to do it with fewer than three edits:\u000a\u000a# '''k'''itten \u2192 '''s'''itten (substitution of "s" for "k")\u000a# sitt'''e'''n \u2192 sitt'''i'''n (substitution of "i" for "e")\u000a# sittin \u2192 sittin'''g''' (insertion of "g" at the end).\u000a\u000a===Upper and lower bounds===\u000aThe Levenshtein distance has several simple upper and lower bounds. These include:\u000a* It is always at least the difference of the sizes of the two strings.\u000a* It is at most the length of the longer string.\u000a* It is zero if and only if the strings are equal.\u000a* If the strings are the same size, the [[Hamming distance]] is an upper bound on the Levenshtein distance.\u000a* The Levenshtein distance between two strings is no greater than the sum of their Levenshtein distances from a third string ([[triangle inequality]]).\u000a\u000a==Applications==\u000aIn [[approximate string matching]], the objective is to find matches for short strings in many longer texts, in situations where a small number of differences is to be expected. The short strings could come from a dictionary, for instance. Here, one of the strings is typically short, while the other is arbitrarily long. This has a wide range of applications, for instance, [[spell checker]]s, correction systems for [[optical character recognition]], and software to assist natural language translation based on [[translation memory]].\u000a\u000aThe Levenshtein distance can also be computed between two longer strings, but the cost to compute it, which is roughly proportional to the product of the two string lengths, makes this impractical.  Thus, when used to aid in [[fuzzy string searching]] in applications such as [[record linkage]], the compared strings are usually short to help improve speed of comparisons.\u000a\u000a==Relationship with other edit distance metrics==\u000a{{main|Edit distance}}\u000aThere are other popular measures of [[edit distance]], which are calculated using a different set of allowable edit operations. For instance,\u000a* the [[Damerau\u2013Levenshtein distance]] allows insertion, deletion, substitution, and the [[Transposition (mathematics)|transposition]] of two adjacent characters;\u000a* the [[longest common subsequence problem|longest common subsequence]] metric allows only insertion and deletion, not substitution;\u000a* the [[Hamming distance]] allows only substitution, hence, it only applies to strings of the same length.\u000a\u000a[[Edit distance]] is usually defined as a parameterizable metric calculated with a specific set of allowed edit operations, and each operation is assigned a cost (possibly infinite).  This is further generalized by DNA [[sequence alignment]] algorithms such as the [[Smith\u2013Waterman algorithm]], which make an operation's cost depend on where it is applied.\u000a\u000a==Computing Levenshtein distance==\u000a\u000a===Recursive===\u000aThis is a straightforward, but inefficient, recursive [[pseudocode]] implementation of a <code>LevenshteinDistance</code> function that takes two strings, ''s'' and ''t'', together with their lengths, and returns the Levenshtein distance between them:\u000a\u000a<!--\u000a  Please do not add an additional implementation in your language of choice.\u000a  Many of those have been added to and deleted from this article in the past.\u000a  See the talk page archive for relevant discussion\u000a-->\u000a<source lang="C">\u000a// len_s and len_t are the number of characters in string s and t respectively\u000aint LevenshteinDistance(string s, int len_s, string t, int len_t)\u000a{\u000a  /* base case: empty strings */\u000a  if (len_s == 0) return len_t;\u000a  if (len_t == 0) return len_s;\u000a\u000a  /* test if last characters of the strings match */\u000a  if (s[len_s-1] == t[len_t-1])\u000a      cost = 0;\u000a  else\u000a      cost = 1;\u000a\u000a  /* return minimum of delete char from s, delete char from t, and delete char from both */\u000a  return minimum(LevenshteinDistance(s, len_s - 1, t, len_t    ) + 1,\u000a                 LevenshteinDistance(s, len_s    , t, len_t - 1) + 1,\u000a                 LevenshteinDistance(s, len_s - 1, t, len_t - 1) + cost);\u000a}\u000a</source>\u000a\u000aUnfortunately, this straightforward recursive implementation is very inefficient because it recomputes the Levenshtein distance of the same substrings many times.\u000a\u000aA more efficient method would never repeat the same distance calculation. For example, the Levenshtein distance of all possible prefixes might be stored in an array <code>d[][]</code> where <code>d[i][j]</code> is the distance between the first <code>i</code> characters of string <code>s</code> and the first <code>j</code> characters of string <code>t</code>. The table is easy to construct one row at a time starting with row 0. When the entire table has been built, the desired distance is <code>d[len_s][len_t]</code>. While this technique is significantly faster, it will consume <code>len_s * len_t</code> more memory than the straightforward recursive implementation.\u000a\u000a===Iterative with full matrix===\u000a{{main|Wagner\u2013Fischer algorithm}}\u000a::{{small|Note: This section uses 1-based strings instead of 0-based strings}}\u000aComputing the Levenshtein distance is based on the observation that if we reserve a [[Matrix (mathematics)|matrix]] to hold the Levenshtein distances between all [[prefix (computer science)|prefix]]es of the first string and all prefixes of the second, then we can compute the values in the matrix in a [[dynamic programming]] fashion, and thus find the distance between the two full strings as the last value computed.\u000a\u000aThis algorithm, an example of bottom-up [[dynamic programming]], is discussed, with variants, in the 1974 article ''The [[String-to-string correction problem]]'' by Robert A. Wagner and Michael J. Fischer.<ref>{{citation |first=Robert A. |last=Wagner |first2=Michael J. |last2=Fischer |author2-link=Michael J. Fischer |title=The String-to-String Correction Problem |journal=Journal of the ACM |volume=21 |issue=1 |year=1974 |pages=168\u2013173 |doi= 10.1145/321796.321811}}</ref>\u000a\u000aThis is a straightforward pseudocode implementation for a function ''LevenshteinDistance'' that takes two strings, ''s'' of length ''m'', and ''t'' of length ''n'', and returns the Levenshtein distance between them:\u000a\u000a<!--\u000a  Please do not add an additional implementation in your language of choice.\u000a  Many of those have been added to and deleted from this article in the past.\u000a  See the talk page archive for relevant discussion\u000a-->\u000a<!-- choose random language for highlights -->\u000a<source lang="C">\u000aint LevenshteinDistance(char s[1..m], char t[1..n])\u000a{\u000a  // for all i and j, d[i,j] will hold the Levenshtein distance between\u000a  // the first i characters of s and the first j characters of t;\u000a  // note that d has (m+1)*(n+1) values\u000a  declare int d[0..m, 0..n]\u000a \u000a  clear all elements in d // set each element to zero\u000a \u000a  // source prefixes can be transformed into empty string by\u000a  // dropping all characters\u000a  for i from 1 to m\u000a    {\u000a      d[i, 0] := i\u000a    }\u000a \u000a  // target prefixes can be reached from empty source prefix\u000a  // by inserting every character\u000a  for j from 1 to n\u000a    {\u000a      d[0, j] := j\u000a    }\u000a \u000a  for j from 1 to n\u000a    {\u000a      for i from 1 to m\u000a        {\u000a          if s[i] = t[j] then\u000a            d[i, j] := d[i-1, j-1]       // no operation required\u000a          else\u000a            d[i, j] := minimum\u000a                    (\u000a                      d[i-1, j] + 1,  // a deletion\u000a                      d[i, j-1] + 1,  // an insertion\u000a                      d[i-1, j-1] + 1 // a substitution\u000a                    )\u000a        }\u000a    }\u000a \u000a  return d[m, n]\u000a}\u000a</source>\u000a\u000aNote that this implementation does not fit the [[#Definition|definition]] precisely: it always prefers matches, even if insertions or deletions provided a better score. This is equivalent; it can be shown that for every optimal alignment (which induces the Levenshtein distance) there is another optimal alignment that prefers matches in the sense of this implementation.<ref>[http://cs.stackexchange.com/a/2997 Micro-optimisation for edit distance computation: is it valid?]</ref>\u000a\u000aTwo examples of the resulting matrix (hovering over a number reveals the operation performed to get that number):\u000a<center>\u000a{{col-begin|width=auto}}\u000a{{col-break}}\u000a{|class="wikitable"\u000a|-\u000a| \u000a| \u000a!k\u000a!i\u000a!t\u000a!t\u000a!e\u000a!n\u000a|-\u000a| ||0 ||1 ||2 ||3 ||4 ||5 ||6\u000a|-\u000a!s\u000a|1 ||{{H:title|substitution of 'k' for 's'|1}} ||2 ||3 ||4 ||5 ||6\u000a|-\u000a!i\u000a|2 ||2 ||{{H:title|'i' equals 'i'|1}} ||2 ||3 ||4 ||5\u000a|-\u000a!t\u000a|3 ||3 ||2 ||{{H:title|'t' equals 't'|1}} ||2 ||3 ||4\u000a|-\u000a!t\u000a|4 ||4 ||3 ||2 ||{{H:title|'t' equals 't'|1}} ||2 ||3\u000a|-\u000a!i\u000a|5 ||5 ||4 ||3 ||2 ||{{H:title|substitution of 'e' for 'i'|2}} ||3\u000a|-\u000a!n\u000a|6 ||6 ||5 ||4 ||3 ||3 ||{{H:title|'n' equals 'n'|2}}\u000a|-\u000a!g\u000a|7 ||7 ||6 ||5 ||4 ||4 ||{{H:title|insert 'g'|3}}\u000a|}\u000a{{col-break|gap=1em}}\u000a{|class="wikitable"\u000a|\u000a|\u000a!S\u000a!a\u000a!t\u000a!u\u000a!r\u000a!d\u000a!a\u000a!y\u000a|-\u000a| \u000a|0 ||1 ||2 ||3 ||4 ||5 ||6 ||7 ||8\u000a|-\u000a!S\u000a|1 ||{{H:title|'S' equals 'S'|0}} ||{{H:title|delete 'a'|1}} ||{{H:title|delete 't'|2}} ||3 ||4 ||5 ||6 ||7\u000a|-\u000a!u\u000a|2 ||1 ||1 ||2 ||{{H:title|'u' equals 'u'|2}} ||3 ||4 ||5 ||6\u000a|-\u000a!n\u000a|3 ||2 ||2 ||2 ||3 ||{{H:title|substitution of 'r' for 'n'|3}} ||4 ||5 ||6\u000a|-\u000a!d\u000a|4 ||3 ||3 ||3 ||3 ||4 ||{{H:title|'d' equals 'd'|3}} ||4 ||5\u000a|-\u000a!a\u000a|5 ||4 ||3 ||4 ||4 ||4 ||4 ||{{H:title|'a' equals 'a'|3}} ||4\u000a|-\u000a!y\u000a|6 ||5 ||4 ||4 ||5 ||5 ||5 ||4 ||{{H:title|'y' equals 'y'|3}}\u000a|}\u000a{{col-end}}\u000a</center>\u000a\u000aThe [[invariant (mathematics)|invariant]] maintained throughout the algorithm is that we can transform the initial segment <code>s[1..i]</code> into <code>t[1..j]</code> using a minimum of <code>d[i,j]</code> operations. At the end, the bottom-right element of the array contains the answer.\u000a\u000a===Iterative with two matrix rows===\u000aIt turns out that only two rows of the table are needed for the construction if one does not want to reconstruct the edited input strings (the previous row and the current row being calculated).\u000a\u000aThe Levenshtein distance may be calculated iteratively using the following algorithm:<ref>{{Citation |title=Fast, memory efficient Levenshtein algorithm |first=Sten |last=Hjelmqvist |date=26 Mar 2012 |url=http://www.codeproject.com/Articles/13525/Fast-memory-efficient-Levenshtein-algorithm}}</ref>\u000a<syntaxhighlight lang="CSharp">\u000aint LevenshteinDistance(string s, string t)\u000a{\u000a    // degenerate cases\u000a    if (s == t) return 0;\u000a    if (s.Length == 0) return t.Length;\u000a    if (t.Length == 0) return s.Length;\u000a\u000a    // create two work vectors of integer distances\u000a    int[] v0 = new int[t.Length + 1];\u000a    int[] v1 = new int[t.Length + 1];\u000a\u000a    // initialize v0 (the previous row of distances)\u000a    // this row is A[0][i]: edit distance for an empty s\u000a    // the distance is just the number of characters to delete from t\u000a    for (int i = 0; i < v0.Length; i++)\u000a        v0[i] = i;\u000a\u000a    for (int i = 0; i < s.Length; i++)\u000a    {\u000a        // calculate v1 (current row distances) from the previous row v0\u000a\u000a        // first element of v1 is A[i+1][0]\u000a        //   edit distance is delete (i+1) chars from s to match empty t\u000a        v1[0] = i + 1;\u000a\u000a        // use formula to fill in the rest of the row\u000a        for (int j = 0; j < t.Length; j++)\u000a        {\u000a            var cost = (s[i] == t[j]) ? 0 : 1;\u000a            v1[j + 1] = Minimum(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost);\u000a        }\u000a\u000a        // copy v1 (current row) to v0 (previous row) for next iteration\u000a        for (int j = 0; j < v0.Length; j++)\u000a            v0[j] = v1[j];\u000a    }\u000a\u000a    return v1[t.Length];\u000a}\u000a</syntaxhighlight>\u000a\u000a==See also==\u000a{{colbegin||25em}}\u000a*[[agrep]]\u000a*[[Approximate string matching]]\u000a*[[Bitap algorithm]]\u000a*[[Damerau\u2013Levenshtein distance]]\u000a*[[diff]]\u000a*[[MinHash]]\u000a*[[Dynamic time warping]]\u000a*[[Euclidean distance]]\u000a*[[Fuzzy string searching]]\u000a*[[Hamming weight]]\u000a*[[Hirschberg's algorithm]]\u000a*[[Homology (biology)#Sequence homology|Homology of sequences in genetics]]\u000a*[[Hunt\u2013McIlroy algorithm]]\u000a*[[Jaccard index]]\u000a*[[Jaro\u2013Winkler distance]]\u000a*[[Levenshtein automaton]]\u000a*[[Locality-sensitive hashing]]\u000a*[[Longest common subsequence problem]]\u000a*[[Lucene]] (an open source search engine that implements edit distance)\u000a*[[Manhattan distance]]\u000a*[[Metric space]]\u000a*[[Most frequent k characters]]\u000a*[[Needleman\u2013Wunsch algorithm]]\u000a*[[Optimal matching]] algorithm\u000a*[[Sequence alignment]]\u000a*[[Similarity space]] on [[Numerical taxonomy]]\u000a*[[Smith\u2013Waterman algorithm]]\u000a*[[Sørensen similarity index]]\u000a*[[String distance metric]]\u000a*[[Wagner-Fischer algorithm]]\u000a{{colend}}\u000a\u000a==References==\u000a{{reflist|30em}}\u000a\u000a==External links==\u000a{{Wikibooks| R_Programming|Text_Processing#Edit_distance|Levenshtein distance in R}}\u000a{{Wikibooks| Algorithm implementation|Strings/Levenshtein distance|Levenshtein distance}}\u000a*[http://www.postgresql.org/docs/current/static/fuzzystrmatch.html Levenshtein in PostgreSQL]\u000a*{{citation |contribution=Levenshtein distance |title=Dictionary of Algorithms and Data Structures [online] |editor-first=Paul E. |editor-last=Black |publisher=U.S. National Institute of Standards and Technology |date=14 August 2008 |accessdate=3 April 2013 |url=http://www.nist.gov/dads/HTML/Levenshtein.html }}\u000a\u000a{{DEFAULTSORT:Levenshtein Distance}}\u000a[[Category:String similarity measures]]\u000a[[Category:Dynamic programming]]\u000a[[Category:Articles with example pseudocode]]\u000a[[Category:Quantitative linguistics]]
p137
sg4
S'211'
p138
sg6
VLevenshtein distance
p139
ssI86
(dp140
g2
V{{COI|date=April 2010}}\u000aThe online portal '''Greenpilot''' is a service provided by the German National Library of Medicine, ZB MED.\u000a\u000aThe project is funded by the German Research Foundation ([[Deutsche Forschungsgemeinschaft]]) and gets its technical support from  [[Averbis]] Ltd. The portal first went online May 29, 2009 and currently runs in the updated beta version. In the context of the 'Germany - Land of Ideas' (Deutschland - Land der Ideen) initiative under the patronage of the [[President of Germany]] [[Horst Köhler]] the ZB MED was awarded the distinction 'Selected Landmark 2009' (Ausgewählter Ort 2009).<ref>[http://idw-online.de/pages/de/news315583 Pressemitteilung im Informationsdienst Wissenschaft vom 15. Mai 2009 ]</ref>\u000a\u000a==Objective==\u000aThe Greenpilot portal is a [[digital library]] specialised in the fields of Nutritional, Agricultural and Environmental Sciences. It aims to provide researchers in the three fields with a collection of scientific literature which is easy to access and of high quality. Especially the [[gray literature]] is often difficult to find and retrieve for the average user so Greenpilot also aims to make access to these sources easier. The service addresses itself not only to scientists and students but also to the broadly interested public. Greenpilot has been modelled after the corresponding digital library for Medicine, Medpilot,<ref>[http://www.medpilot.de/ Medpilot portal]</ref> also a project of the German National Library of Medicine. The ZB MED has chosen the slogan 'Greenpilot - all about life and science' as a motto. In Greenpilot scientifically relevant databases, library catalogues and websites can be searched by entering a search term and the results are presented in a standardised web interface.\u000a\u000a==Technical Background==\u000aGreenpilot is a search engine based on intuitive search engine technology. The portal's software was developed in the programming language [[Perl]]. The search engine technology is based upon the 'Averbis Search Platform' software developed by the Averbis Ltd. and uses the [[open source]] software [[Lucene]]. Functionally this is an expert search engine which centres around the intelligent semantic connection of search terms by means of a standardised vocabulary. This is made possible by Averbis's MSI software which provides:\u000a\u000a* semantic search optimised for the fields of Medicine and Life Sciences\u000a* a contextual analysis of texts taking synonyms and compounds into account\u000a* multilingual and cross-language search\u000a* linking of lay and expert vocabulary\u000aThe search results are generated from a search index.\u000a\u000aAdditionally a [[metasearch]] can be conducted in order to search other databases not contained in the index. This search is based upon individual results from the specific database searched.\u000a\u000a==Contents==\u000aThe Greenpilot portal integrates various scientifically relevant information resources under a uniform search interface. These resources are diverse and encompass national and international expert databases, library catalogues of national libraries with a focus on specific topics, full text documents from [[open access (publishing)|open access]] journals as well as information contained on about one thousand scientifically relevant websites selected for Greenpilot.\u000aThe following is a list of sources from November 2009:<ref>[http://www.greenpilot.de/beta2/app/misc/help/8cafcf93601eb861aaef86b5ce99ecdc/Datenbanken List of databases in Greenpilot]</ref>\u000a\u000a===Library Catalogues===\u000a* Catalogue of the German National Library of Medicine (ZB MED Nutrition. Environment. Agriculture)\u000a* Catalogue of the German National Library of Medicine (ZB MED Medicine. Health)\u000a* Catalogue of the Bonn University Library\u000a* Library catalogues of scientifically relevant departments within the collective library network (GBV)\u000a* Catalogue of the Federal Ministry of Food, Agriculture and Consumer Protection (BMELV)\u000a* Catalogue of the Johann Heinrich von Thünen-Institut (vTI), Federal Research Institute for Rural Areas, Forestry and Fisheries\u000a* Catalogue of the Julius Kühn-Institut, Federal Research Centre for Cultivated Plants\u000a* Catalogue of the Friedrich Löffler-Institut, Federal Research Institute for Animal Health\u000a* Catalogue of the Max Rubner-Institut, Federal Research Institute for Nutrition and Food\u000a* Catalogue of the Federal Institute for Risk Assessment\u000a* Catalogue of the Leibniz Institute for Marine Science (IFM-GEOMAR)\u000a* Catalogue of the Leibniz Institute for Plant Genetics and Crop Plant Research (IPK-Plant Genetics and Crop Plant)\u000a* Catalogue of the Leibniz Institute for Plant Biochemistry (IPB-Plant Chemistry)\u000a* Catalogue of the special collection inshore and deep-sea fishery\u000a* Catalogue of the University of Veterinary Medicine Hannover (TiHo-Veterinary Sciences)\u000a* Catalogue of the German National Library of Economics (ZBW)\u000a\u000a===Bibliographic databases===\u000a* AGRIS (1975\u20132008), FAO ( Food and Agriculture Organization of the United Nations)\u000a* VITIS-VEA, Viticulture and Enology Abstracts\u000a* Medline (2004\u20132009)\u000a* UFORDAT, Environmental Research Database (UBA)\u000a* ULIDAT, Environmental Literature Database (UBA)\u000a* ELFIS, International Information System for the Agricultural Sciences and Technology\u000a\u000a===Relevant Internet Sources===\u000a* Reviewed list of [[URL]]s selected by the ZB MED Nutrition. Environment. Agriculture\u000a* Open Access journals with full text documents\u000a\u000a===Metasearch===\u000a* GetInfo, the knowledge portal for Technical Science provided by the Library for Technical Sciences (TIB) and the professional information centres FIZ Technik Frankfurt, FIZ Karlsruhe and FIZ CHEMIE Berlin.\u000a* ECONIS, Catalogue of the German National Library of Economics (ZBW).\u000a\u000a==Other Features==\u000a\u000a===Search and results page===\u000a* Search and advanced search\u000a* Context sensitive help function\u000a* [[Truncation]] and [[Boolean function]]s\u000a* Personalised refining of search results by filtering for a specific document type, language or database\u000a* [[Bookmark]]s\u000a\u000a===Document ordering===\u000a* Ordering directly from the results page is made possible by using the document delivery service of the ZB MED or the Electronic Journals Library ([[Elektronische Zeitschriftenbibliothek]]).\u000a\u000a===Personalisation===\u000a* My Greenpilot: a feature requiring the user to sign up for an account. The service is free of charge and offers an overview of ordered documents as well as enabling individual managing of customer data.\u000a\u000a==See also==\u000a*[[List of digital library projects]]\u000a*[[vascoda]]\u000a\u000a==References==\u000a<references />\u000a\u000a==External links==\u000a* [http://www.greenpilot.de Greenpilot website]\u000a* [http://www.zbmed.de/home.html?lang=en Website of the German National Library of Medicine, ZB MED]\u000a* [http://www.land-of-ideas.org Germany - Land of Ideas website]\u000a\u000a{{coord missing|Germany}}\u000a\u000a[[Category:Libraries in Germany]]\u000a[[Category:Information retrieval]]\u000a[[Category:Internet search engines]]
p141
sg4
S'86'
p142
sg6
VGreenpilot
p143
ssI216
(dp144
g2
VThe '''Social Sciences Citation Index''' ('''SSCI''') is an interdisciplinary  [[citation index]] product of  [[Thomson Reuters]]' Healthcare & Science division. It was developed by the [[Institute for Scientific Information]] (ISI) from the [[Science Citation Index]].\u000a\u000aThis citation database covers some 2,474 of the world's leading [[academic journal|journals]] of [[social sciences]] across more than 50 [[academic discipline|disciplines]].<ref>{{cite web\u000a  | title = Social Sciences Citation Index \u000a  | url = http://scientific.thomson.com/products/ssci/\u000a  | accessdate = 2008-06-11 }}</ref> It is made available online through the [[Web of Science]] service for a fee.  This database product provides information to identify the articles  cited most frequently and by what publisher and author.\u000a\u000a== Criticism ==\u000aIn 2004 economists [[Daniel B. Klein]] and Eric Chiang conducted a survey of the Social Sciences Citation Index and identified a bias against free market oriented research. In addition to an ideological bias, Klein and Chiang also identified several methodological deficiencies that encouraged the over-counting of citations, and they argue that the Social Sciences Citation Index does a poor job reflecting the relevance and accuracy of articles.<ref>Daniel Klein and Eric Chiang. [http://econjwatch.org/articles/the-social-science-citation-index-a-black-box-with-an-ideological-bias The Social Science Citation Index: A Black Box\u2014with an Ideological Bias?] ''Econ Journal Watch'', Volume 1, Number 1, April 2004, pp 134-165.</ref>\u000a\u000a==See also==\u000a* [[Arts and Humanities Citation Index]]\u000a* [[Science Citation Index]]\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a==External links==\u000a* [http://thomsonreuters.com/products_services/science/science_products/a-z/social_sciences_citation_index Introduction to SSCI]\u000a\u000a{{Thomson Reuters}}\u000a[[Category:Thomson family]]\u000a[[Category:Thomson Reuters]]\u000a[[Category:Social sciences literature]]\u000a[[Category:Citation indices]]\u000a\u000a{{database-stub}}\u000a{{sci-stub}}
p145
sg4
S'216'
p146
sg6
VSocial Sciences Citation Index
p147
ssI91
(dp148
g2
V'''Fuzzy retrieval''' techniques are based on the [[Extended Boolean model]] and the [[Fuzzy set]] theory. There are two classical fuzzy retrieval models: Mixed Min and Max (MMM) and the Paice model. Both models do not provide a way of evaluating query weights, however this is considered by the [[Extended Boolean model|P-norms]] algorithm.\u000a\u000a==Mixed Min and Max model (MMM)==\u000a\u000aIn fuzzy-set theory, an element has a varying degree of membership, say ''d<sub>A</sub>'', to a given set ''A'' instead of the traditional membership choice (is an element/is not an element).<br />\u000aIn MMM<ref>{{citation | last=Fox | first=E. A. | coauthors=S. Sharat | year=1986 | title=A Comparison of Two Methods for Soft Boolean Interpretation in Information Retrieval | publisher=Technical Report TR-86-1, Virginia Tech, Department of Computer Science}}</ref> each index term has a fuzzy set associated with it. A document's weight with respect to an index term ''A'' is considered to be the degree of membership of the document in the fuzzy set associated with ''A''. The degree of membership for union and intersection are defined as follows in Fuzzy set theory:<br/>\u000a:<math>d_{A\u005ccap B}= min(d_A, d_B)</math>\u000a:<math>d_{A\u005ccup B}= max(d_A,d_B)</math>\u000a\u000aAccording to this, documents that should be retrieved for a query of the form ''A or B'', should be in the fuzzy set associated with the union of the two sets ''A'' and ''B''. Similarly, the documents that should be retrieved for a query of the form ''A and B'', should be in the fuzzy set associated with the intersection of the two sets. Hence, it is possible to define the similarity of a document to the ''or'' query to be ''max(d<sub>A</sub>, d<sub>B</sub>)'' and the similarity of the document to the ''and'' query to be ''min(d<sub>A</sub>, d<sub>B</sub>)''. The MMM model tries to soften the Boolean operators by considering the query-document similarity to be a linear combination of the ''min'' and ''max'' document weights.\u000a\u000aGiven a document ''D'' with index-term weights ''d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>'' for terms ''A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub>'', and the queries:\u000a\u000a''Q<sub>or</sub> = (A<sub>1</sub> or A<sub>2</sub> or ... or A<sub>n</sub>)''<br />\u000a''Q<sub>and</sub> = (A<sub>1</sub> and A<sub>2</sub> and ... and A<sub>n</sub>)''\u000a\u000athe query-document similarity in the MMM model is computed as follows:\u000a\u000a''SlM(Q<sub>or</sub>, D) = C<sub>or1</sub> * max(d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>) + C<sub>or2</sub> * min(d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>)''<br />\u000a''SlM(Q<sub>and</sub>, D) = C<sub>and1</sub> * min(d<sub>A1</sub>, d<sub>A2</sub>, ..., d<sub>An</sub>) + C<sub>and2</sub> * max(d<sub>A1</sub>, d<sub>A2</sub> ..., d<sub>An</sub>)''\u000a\u000awhere ''C<sub>or1</sub>, C<sub>or2</sub>'' are "softness" coefficients for the ''or'' operator, and ''C<sub>and1</sub>, C<sub>and2</sub>'' are softness coefficients for the ''and'' operator. Since we would like to give the maximum of the document weights more importance while considering an ''or'' query and the minimum more importance while considering an ''and'' query, generally we have ''C<sub>or1</sub> > C<sub>or2</sub> and C<sub>and1</sub> > C<sub>and2</sub>''. For simplicity it is generally assumed that ''C<sub>or1</sub> = 1 - C<sub>or2</sub>'' and ''C<sub>and1</sub> = 1 - C<sub>and2</sub>''.\u000a\u000aLee and Fox<ref name="leefox">{{citation | last=Lee | first=W. C. | coauthors=E. A. Fox | year=1988 | title=Experimental Comparison of Schemes for Interpreting Boolean Queries}}</ref> experiments indicate that the best performance usually occurs with ''C<sub>and1</sub>'' in the range [0.5, 0.8] and with ''C<sub>or1</sub>'' > 0.2. In general, the computational cost of MMM is low, and retrieval effectiveness is much better than with the [[Standard Boolean model]].\u000a\u000a==Paice model==\u000a\u000aThe Paice model<ref>{{citation | last=Paice | first=C. P. | year=1984 | title=Soft Evaluation of Boolean Search Queries in Information Retrieval Systems | publisher=Information Technology, Res. Dev. Applications, 3(1), 33-42 }}</ref> is a general extension to the MMM model. In comparison to the MMM model that considers only the minimum and maximum weights for the index terms, the Paice model incorporates all of the term weights when calculating the similarity:\u000a\u000a:<math>S(D,Q) = \u005csum_{i=1}^n\u005cfrac{r^{i-1}*w_{di}}{\u005csum_{j=1}^n r^{j-1}}</math>\u000a\u000awhere ''r'' is a constant coefficient and ''w<sub>di</sub>'' is arranged in ascending order for ''and'' queries and descending order for ''or'' queries. When n = 2 the Paice model shows the same behavior as the MMM model.\u000a\u000aThe experiments of Lee and Fox<ref name="leefox"/> have shown that setting the ''r'' to 1.0 for ''and'' queries and 0.7 for ''or'' queries gives good retrieval effectiveness. The computational cost for this model is higher than that for the MMM model. This is because the MMM model only requires the determination of ''min'' or ''max'' of a set of term weights each time an ''and'' or ''or'' clause is considered, which can be done in ''O(n)''. The Paice model requires the term weights to be sorted in ascending or descending order, depending on whether an ''and'' clause or an ''or'' clause is being considered. This requires at least an ''0(n log n)'' sorting algorithm. A good deal of floating point calculation is needed too.\u000a\u000a==Improvements over the Standard Boolean model==\u000aLee and Fox<ref name="leefox"/> compared the Standard Boolean model with MMM and Paice models with three test collections, CISI, CACM and INSPEC. These are the reported results for average mean precision improvement:\u000a{| class="wikitable"\u000a|-\u000a!\u000a! CISI\u000a! CACM\u000a! INSPEC\u000a|-\u000a! MMM\u000a| 68%\u000a| 109%\u000a| 195%\u000a|-\u000a! Paice\u000a| 77%\u000a| 104%\u000a| 206%\u000a|}\u000a\u000aThese are very good improvements over the Standard model. MMM is very close to Paice and P-norm results which indicates that it can be a very good technique, and is the most efficient of the three.\u000a\u000a==Recent work==\u000a\u000aRecently '''Kang ''et al.'''.<ref>{{citation | title=Fuzzy Information Retrieval Indexed by Concept Identification | url=http://www.springerlink.com/content/ac96v4qf4f8adatp/ | last=Kang | first=Bo-Yeong | coauthors=Dae-Won Kim, Hae-Jung Kim | publisher=Springer Berlin / Heidelberg | year=2005}}</ref> have devised a fuzzy retrieval system indexed by concept identification.\u000a\u000aIf we look at documents on a pure [[Tf-idf]] approach, even eliminating stop words, there will be words more relevant to the topic of the document than others and they will have the same weight because they have the same term frequency. If we take into account the user intent on a query we can better weight the terms of a document. Each term can be identified as a concept in a certain lexical chain that translates the importance of that concept for that document.<br />\u000aThey report improvements over Paice and P-norm on the average precision and recall for the Top-5 retrieved documents.\u000a\u000aZadrozny<ref>{{citation | title=Fuzzy information retrieval model revisited | doi=10.1016/j.fss.2009.02.012 | first=S\u0142awomir | last=Zadrozny | coauthors=Nowacka, Katarzyna | year=2009 | publisher=Elsevier North-Holland, Inc.}}</ref> revisited the fuzzy information retrieval model. He further extends the fuzzy extended Boolean model by:\u000a* assuming linguistic terms as importance weights of keywords also in documents\u000a* taking into account the uncertainty concerning the representation of documents and queries\u000a* interpreting the linguistic terms in the representation of documents and queries as well as their matching in terms of the Zadeh\u2019s fuzzy logic (calculus of linguistic statements)\u000a* addressing some pragmatic aspects of the proposed model, notably the techniques of indexing documents and queries\u000a\u000aThe proposed model makes it possible to grasp both imprecision and uncertainty concerning the textual information representation and retrieval.\u000a\u000a==See also==\u000a*[[Information retrieval]]\u000a\u000a==Further reading==\u000a* {{citation | title=Information Retrieval: Algorithms and Data structures; Extended Boolean model | last=Fox | first=E. | coauthors=S. Betrabet , M. Koushik , W. Lee | year=1992 | publisher=Prentice-Hall, Inc. | url=http://www.scribd.com/doc/13742235/Information-Retrieval-Data-Structures-Algorithms-William-B-Frakes}}\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a{{DEFAULTSORT:Fuzzy Retrieval}}\u000a[[Category:Information retrieval]]
p149
sg4
S'91'
p150
sg6
VFuzzy retrieval
p151
ssI221
(dp152
g2
V'''Islamic World Science Citation Database''' (ISC) is a [[citation index]] established by the Iranian [[Ministry of Science, Research and Technology]] after it was approved by the [[Organisation of the Islamic Conference]].  It only indexes journals from the [[Islamic world]].\u000a\u000aIt was announced in [[Baku]], Azerbaijan during the Fourth Islamic Conference of the Ministers of Higher Education and Scientific Research held in October 2008.<ref>{{cite news | url = http://www.scidev.net/en/science-communication/science-publishing/news/islamic-countries-to-get-own-science-citation-inde.html | title = Islamic countries to get own science citation index | author = Wagdy Sawahel | date = 17 October 2008 | publisher = [[SciDev.Net]] }}</ref>  It is managed by the Islamic World Science Citation Center, located in [[Shiraz]].\u000a\u000aIn 2009, ISC partnered with [[Scopus]] that allows ISC's publications to be indexed in Scopus.<ref>{{cite journal | journal = [[Library Connect]] | title = The Islamic World Science Citation Database partnership with Scopus brings greater visibility to Islamic researchers | url = http://libraryconnect.elsevier.com/lcn/0703/lcn070319.html | author = Ahmed Rostom | volume = 7 | issue = 3 | date = August 2009 | issn = 1549-3725 }}</ref>\u000a\u000a== References ==\u000a{{Reflist}}\u000a\u000a==See also==\u000a* [[Academic publishing]]\u000a* [[List of academic databases and search engines]]\u000a* [[Impact factor]]\u000a\u000a== External links ==\u000a* {{Official website|http://www.isc.gov.ir/isce.htm}}\u000a\u000a[[Category:Bibliographic databases]]\u000a[[Category:Online databases]]\u000a[[Category:Citation indices]]\u000a[[Category:Research management]]\u000a[[Category:Databases in Iran]]\u000a\u000a\u000a{{science-journal-stub}}\u000a{{islam-stub}}
p153
sg4
S'221'
p154
sg6
VIslamic World Science Citation Database
p155
ssI96
(dp156
g2
V'''Multi-document summarization''' is an automatic procedure aimed at [[information extraction|extraction of information]] from multiple texts written about the same topic. Resulting summary report allows individual users, such as professional information consumers, to quickly familiarize themselves with information contained in a large cluster of documents. In such a way, multi-document summarization systems are complementing the [[news aggregators]] performing the next step down the road of coping with [[information overload]].\u000a\u000a==Key benefits==\u000aMulti-[[document summarization]] creates information reports that are both concise and comprehensive.\u000aWith different opinions being put together & outlined, every topic is described from multiple perspectives within a single document.\u000aWhile the goal of a brief summary is to simplify information search and cut the time by pointing to the most relevant source documents, comprehensive multi-document summary should itself contain the required information, hence limiting the need for accessing original files to cases when refinement is required.\u000aAutomatic summaries present information extracted from multiple sources algorithmically, without any editorial touch or subjective human intervention, thus making it completely unbiased.\u000a\u000a==Technological challenges==\u000aThe multi-document summarization task has turned out to be much more complex than [[automatic summarization|summarizing a single document]], even a very large one. This difficulty arises from inevitable thematic diversity within a large set of documents. A good summarization technology aims to combine the main themes with completeness, readability, and conciseness. Document Understanding Conferences,<ref>http://www-nlpir.nist.gov/projects/duc/index.html</ref> conducted annually by [[NIST]], have developed sophisticated evaluation criteria for techniques accepting the multi-document summarization challenge.\u000a\u000aAn ideal multi-document summarization system does not simply shorten the source texts but presents information organized around the key aspects to represent a wider diversity of views on the topic. When such quality is achieved, an automatic multi-document summary is perceived more like an overview of a given topic. The latter implies that such text compilations should also meet other basic requirements for an overview text compiled by a human. The multi-document summary quality criteria are as follows:\u000a*clear structure, including an outline of the main content, from which it is easy to navigate to the full text sections\u000a*text within sections is divided into meaningful paragraphs\u000a*gradual transition from more general to more specific thematic aspects\u000a*good [[readability]]\u000a\u000aThe latter point deserves additional note - special care is taken in order to ensure that the automatic overview shows:\u000a*no paper-unrelated "[[communication noise|information noise]]" from the respective documents (e.g., web pages)\u000a*no dangling references to what is not mentioned or explained in the overview\u000a*no text breaks across a sentence\u000a*no semantic [[Redundancy (information theory)|redundancy]].\u000a\u000a==Real-life systems==\u000aThe multi-document summarization technology is now coming of age - a view supported by a choice of advanced web-based systems that are currently available.\u000a* Ultimate Research Assistant<ref>http://ultimate-research-assistant.com/</ref> - performs text mining on Internet search results to help summarize and organize them and make it easier for the user to perform online research. Specific text mining techniques used by the tool include concept extraction, text summarization, hierarchical concept clustering (e.g., automated taxonomy generation), and various visualization techniques, including tag clouds and mind maps. \u000a* iResearch Reporter<ref>http://www.iresearch-reporter.com/</ref> - Commercial Text Extraction and Text Summarization system, free demo site accepts user-entered query, passes it on to Google search engine, retrieves multiple relevant documents, produces categorized, easily  readable natural language summary reports covering multiple documents in retrieved set, all extracts linked to original documents on the Web, post-processing, entity extraction, event and relationship extraction, text extraction, extract clustering, linguistic analysis, multi-document, full text, natural language processing, categorization rules, clustering, linguistic analysis, text summary construction tool set.\u000a* Newsblaster<ref>http://newsblaster.cs.columbia.edu</ref> is a system that helps users find news that is of the most interest to them. The system automatically collects, clusters, categorizes, and summarizes news from several sites on the web ([[CNN]], [[Reuters]], [[Fox News]], etc.) on a daily basis, and it provides users an interface to browse the results.\u000a* NewsInEssence<ref>http://www.newsinessence.com</ref> may be used to retrieve and summarize a cluster of articles from the web. It can start from a [[Uniform Resource Locator|URL]] and retrieve documents that are similar, or it can retrieve documents that match a given set of keywords. NewsInEssence also downloads news articles daily and produces news clusters from them.\u000a* NewsFeed Researcher<ref>http://newsfeedresearcher.com</ref> is a news portal performing continuous [[automatic summarization]] of documents initially clustered by the [[news aggregators]] (e.g., [[Google News]]). NewsFeed Researcher is backed by a free online engine covering major events related to business, technology, U.S. and international news. This tool is also available in on-demand mode allowing a user to build a summaries on selected topics.\u000a* Scrape This<ref>http://www.scrapethis.com</ref> is like a search engine, but instead of providing links to the most relevant websites based on a query, it scrapes the pertinent information off of the relevant websites and provides the user with a consolidated multi-document summary, along with dictionary definitions, images, and videos.\u000a* JistWeb<ref>http://www.jastatechnologies.com/productList.html</ref> is a query specific multiple document summariser.\u000a\u000aAs auto-generated multi-document summaries increasingly resemble the overviews written by a human, their use of extracted text snippets may one day face [[copyright]] issues in relation to the [[fair use]] copyright concept.\u000a\u000a==Bibliography==\u000a* Günes Erkan and Dragomir R. Radev. Lexrank: Graph-based centrality as salience in text summarization. Journal of Artificial Intelligence Research (JAIR), 2004. [http://clair.si.umich.edu/~radev/papers/lprj.pdf]\u000a* Dragomir R. Radev, Hongyan Jing, Malgorzata Sty\u015b, and Daniel Tam. Centroid-based summarization of multiple documents. Information Processing and Management, 40:919\u2013938, December 2004. [http://clair.si.umich.edu/~radev/papers/centroid.pdf]\u000a* Kathleen R. McKeown and Dragomir R. Radev. Generating summaries of multiple news articles. In Proceedings, ACM Conference on Research and Development in Information Retrieval SIGIR'95, pages 74\u201382, Seattle, Washington, July 1995. [http://clair.si.umich.edu/~radev/papers/sigir95.pdf]\u000a* C.-Y. Lin, E. Hovy, "From single to multi-document summarization: A prototype system and its evaluation", In "Proceedings of the ACL", pp.&nbsp;457\u2013464, 2002\u000a*Kathleen McKeown, Rebecca J. Passonneau, David K. Elson, Ani Nenkova, Julia Hirschberg, "Do Summaries Help? A Task-Based Evaluation of Multi-Document Summarization", SIGIR\u201905, Salvador, Brazil, August 15\u201319, 2005 [http://www.cs.columbia.edu/~ani/papers/f98-mckeown.pdf]\u000a*R. Barzilay, N. Elhadad, K. R. McKeown, "Inferring strategies for sentence ordering in multidocument news summarization", Journal of Artificial Intelligence Research, v. 17, pp.&nbsp;35\u201355, 2002\u000a*M. Soubbotin, S. Soubbotin, "Trade-Off Between Factors Influencing Quality of the Summary", Document Understanding Workshop (DUC), Vancouver, B.C., Canada, October 9\u201310, 2005 [http://duc.nist.gov/pubs/2005papers/freetext.sergei.pdf]\u000a* C Ravindranath Chowdary, and P. Sreenivasa Kumar. "Esum: an efficient system for query-specific multi-document summarization." In ECIR (Advances in Information Retrieval), pp.&nbsp;724\u2013728. Springer Berlin Heidelberg, 2009.\u000a\u000a==See also==\u000a* [[Automatic summarization]]\u000a* [[Text mining]]\u000a* [[News aggregators]]\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a==External links==\u000a{{External links|date=September 2010}}\u000a*[http://www-nlpir.nist.gov/projects/duc/index.html Document Understanding Conferences]\u000a*[http://www1.cs.columbia.edu/nlp/projects.html Columbia NLP Projects]\u000a*[http://lada.si.umich.edu:8080/clair/nie1/nie.cgi NewsInEssence: Web-based News Summarization]\u000a\u000a{{Natural Language Processing}}\u000a\u000a{{DEFAULTSORT:Multi-Document Summarization}}\u000a[[Category:Natural language processing]]\u000a[[Category:Information retrieval]]
p157
sg4
S'96'
p158
sg6
VMulti-document summarization
p159
ssI226
(dp160
g2
V'''SCImago Journal Rank''' (SJR indicator) is a measure of scientific influence of [[academic journal|scholarly journal]]s that accounts for both the number of [[citation]]s received by a journal and the importance or prestige of the journals where such citations come from. The SJR indicator is a variant of the [[centrality|eigenvector centrality measure]] used in network theory. Such measures establish the importance of a node in a network based on the principle that connections to high-scoring nodes contribute more to the score of the node. The SJR indicator, which is inspired by the [[PageRank]] algorithm, has been developed to be used in extremely large and heterogeneous journal citation networks. It is a size-independent indicator and its values order journals by their "average prestige per article" and can be used for journal comparisons in science evaluation processes.\u000a\u000aThe ''SJR indicator'' is a free journal metric which uses an algorithm similar to [[PageRank]] and provides an alternative to the [[impact factor]] (IF), which is based on data from the [[Science Citation Index]].<ref>{{cite journal | url = http://www.nature.com/news/2008/080102/full/451006a.html | title= Free journal-ranking tool enters citation market | journal = [[Nature (journal)|Nature]] | date= 2 January 2008 | volume= 451 | issue= 6 | doi= 10.1038/451006a | author = Declan Butler | pmid= 18172465 | pages= 6 |accessdate=14 May 2010}}</ref><ref>{{cite journal | url = http://www.fasebj.org/cgi/content/short/22/8/2623 | title = Comparison of SCImago journal rank indicator with journal impact factor | author= Matthew E. Falagas et al | doi = 10.1096/fj.08-107938 | journal = [[The FASEB Journal]] | year = 2008 | issue = 22 | pages = 2623\u20132628 | pmid = 18408168 | volume = 22 }}</ref> Average citations per document in a 2-year period, abbreviated as Cites per Doc. (2y), is another index that measures the scientific impact of an average article published in the journal. It is computed using the same formula that journal [[impact factor]] ([[Thomson Reuters]]).\u000a\u000a== Rationale ==\u000aIf scientific impact is considered related to the number of endorsements, in the form of citations, a journal receives, then prestige can be understood as a combination of the number of endorsements and the prestige or importance of the journals issuing them. The ''SJR indicator'' assigns different values to citations depending on the importance of the journals where they come from. This way, citations coming from highly important journals will be more valuable and hence will provide more prestige to the journals receiving them. The calculation of the ''SJR indicator'' is very similar to the ''[[Eigenfactor]] score'', with the former being based on the [[Scopus]] database and the latter on the ISI [[Web of Science]] database.<ref>{{cite web | title=SCImago Journal & Country Rank (SJR) as an alternative to Thomson Reuters's Impact Factor and EigenFactor | url=http://www.scimagojr.com/news.php?id=41 | date=21 Aug 2008 | accessdate=20 September 2012}}</ref>\u000a\u000a== Computation ==\u000aThe SJR indicator computation is carried out using an iterative [[algorithm]] that distributes prestige values among the journals until a steady-state solution is reached. The SJR algorithm begins by setting an identical amount of prestige to each journal, then using an iterative procedure, this prestige is redistributed in a process where journals transfer their achieved prestige to each other through citations. The process ends up when the difference between journal prestige values in consecutive iterations do not reach a minimum threshold value any more. The process is developed in two phases, (a) the computation of ''Prestige SJR'' (''PSJR'') for each journal: a size-dependent measure that reflects the whole journal prestige, and (b) the normalization of this measure to achieve a size-independent measure of prestige, the ''SJR indicator''.\u000a\u000a== See also ==\u000a* [[Journal Citation Reports]]\u000a* [[Citation index]]\u000a* [[Eigenfactor]]\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a== External links ==\u000a* {{official website|http://www.scimagojr.com/}}\u000a* [http://blogs.openaccesscentral.com/blogs/bmcblog/entry/scimago_a_new_source_of SCImago \u2013 a new source of journal metrics offering a wealth of free data on open access journals]\u000a* [http://www.earlham.edu/~peters/fos/2008/01/more-on-scimago-journal-rank-v-impact.html More on SCImago Journal Rank v. Impact Factors]\u000a\u000a{{DEFAULTSORT:Scimago journal rank}}\u000a[[Category:Citation indices]]\u000a[[Category:Academic publishing]]
p161
sg4
S'226'
p162
sg6
VSCImago Journal Rank
p163
ssI101
(dp164
g2
V'''Adversarial information retrieval''' ('''adversarial IR''') is a topic in [[information retrieval]] related to strategies for working with a data source where some portion of it has been manipulated maliciously.  Tasks can include gathering, indexing, filtering, retrieving and ranking information from such a data source. Adversarial IR includes the study of methods to detect, isolate, and defeat such manipulation.\u000a\u000aOn the Web, the predominant form of such manipulation is [[spamdexing|search engine spamming]] (also known as spamdexing), which involves employing various techniques to disrupt the activity of [[web search engines]], usually for financial gain. Examples of spamdexing are [[Google bomb|link-bombing]], [[comment spam (disambiguation)|comment]] or [[referrer spam]], [[spam blog]]s (splogs), malicious tagging.  [[Reverse engineering]] of [[ranking function|ranking algorithms]], [[Ad filtering|advertisement blocking]], and [[web content filtering]] may also be considered forms of adversarial [[data manipulation]].<ref>B. Davison, M. Najork, and T. Converse (2006), [http://wayback.archive.org/web/20090320173324/http://www.acm.org/sigs/sigir/forum/2006D/2006d_sigirforum_davison.pdf SIGIR Worksheet Report: Adversarial Information Retrieval on the Web (AIRWeb 2006)]</ref>\u000a\u000aActivities intended to poison the supply of useful data make search engines less useful for users. If search engines are more exclusionary they risk becoming more like directories and less dynamic.\u000a\u000a== Topics ==\u000aTopics related to Web spam (spamdexing):\u000a\u000a* [[Link spam]]\u000a* [[Keyword spamming]]\u000a* [[Cloaking]]\u000a* Malicious tagging\u000a* Spam related to blogs, including [[spam in blogs|comment spam]], [[spam blog|splogs]], and [[sping|ping spam]]\u000a\u000aOther topics:\u000a* [[Click fraud]] detection\u000a* Reverse engineering of  [[search engine]]'s [[ranking]] algorithm\u000a* Web [[content filtering]]\u000a* [[Ad filtering|Advertisement blocking]]\u000a* Stealth [[web crawling|crawling]]\u000a*[[Troll (Internet)]]\u000a* Malicious tagging or voting in [[social networks]]\u000a* [[Astroturfing]]\u000a* [[Sockpuppetry]]\u000a\u000a== History ==\u000aThe term "adversarial information retrieval" was first coined in 2000 by [[Andrei Broder]] (then Chief Scientist at [[Alta Vista]]) during the Web plenary session at the [[Text Retrieval Conference|TREC]]-9 conference.<ref>D. Hawking and N. Craswell (2004), [http://es.csiro.au/pubs/trecbook_for_website.pdf Very Large Scale Retrieval and Web Search (Preprint version)]</ref>\u000a\u000a== See also ==\u000a*[[Spamdexing]]\u000a*[[Information retrieval]]\u000a\u000a== References ==\u000a{{reflist}}\u000a\u000a== External links ==\u000a*[http://airweb.cse.lehigh.edu/ AIRWeb]: series of workshops on Adversarial Information Retrieval on the Web\u000a*[http://webspam.lip6.fr/ Web Spam Challenge]: competition for researchers on Web Spam Detection\u000a*[http://wayback.archive.org/web/20100217125910/http://barcelona.research.yahoo.net/webspam/ Web Spam Datasets]: datasets for research on Web Spam Detection\u000a\u000a{{DEFAULTSORT:Adversarial Information Retrieval}}\u000a[[Category:Information retrieval]]\u000a[[Category:Internet fraud]]\u000a[[Category:Searching]]
p165
sg4
S'101'
p166
sg6
VAdversarial information retrieval
p167
ssI231
(dp168
g2
V'''Google Web History''' (previously '''Google Search History''') is a feature of [[Google Search]] and provided by [[Google]], in which all search queries and results that a user clicks on are recorded. The feature is only available for users logged into a [[Google Account]]. The feature was renamed from Search History to Web History on April 19, 2007.<ref>[http://searchengineland.com/google-search-history-expands-becomes-web-history-11016 "Google Search History Expands, Becomes Web History"]. Like all web hostory, google web history take up space and data on your phone, which is why many people choose to clear their hostory.  Search Engine Land. Retrieved July 12, 2010.</ref> A user's Web History is used to personalize search results with the help of [[Google Personalized Search]]<ref>[http://www.businessweek.com/the_thread/techbeat/archives/2009/12/google_gets_real-time_personalized_search.html "Google Gets Real-Time, Personalized Search"]. ''Business Week''. Retrieved July 12, 2010.</ref> and in [[Google Now]].\u000a\u000a==References== \u000aGoogle search engine searches more than just your questions, it matches the words you search with other online posts and files that have the same words, so you get more options and more answers, if you don't find what you're searching for, try rewording your question, often you will discover your question popping up after you type only a few words, and then you can go directly to the answer you were searching for. Google makes it possible and easy for everyone.\u000a{{Reflist}}\u000a\u000a==External links==\u000a* [http://history.google.com/history/ Google Web History] Also via redirect at [http://google.com/psearch]\u000a\u000a{{Google Inc.}}\u000a\u000a{{Google-stub}}\u000a\u000a[[Category:Google Search|Web History]]\u000a[[Category:Personalized search]]
p169
sg4
S'231'
p170
sg6
VGoogle Web History
p171
ssI106
(dp172
g2
V{{refimprove|date=March 2009}}\u000aA '''policy framework''' is a logical structure that is established to organize policy documentation into groupings and categories that make it easier for employees to find and understand the contents of various [[policy]] documents. Policy frameworks can also be used to help in the planning and development of the policies for an organization.\u000a\u000a==Principles==\u000a[[State Services Commission]] of [[New Zealand]] outlines eleven principles of policy framework as below.<ref>http://www.ssc.govt.nz/Documents/policy_framework_for_Government_.htm</ref>\u000a\u000a===Availability===\u000aGovernment departments should make information available easily, widely and equitably to the people of New Zealand (except where reasons preclude such availability as specified in legislation).....\u000a\u000a===Coverage===\u000aGovernment departments should make the following information increasingly available on an electronic basis:\u000a* all published material or material already in the public domain\u000a* all policies that could be released publicly\u000a* all information created or collected on a statutory basis (subject to commercial sensitivity and privacy considerations)\u000a* all documents that the public may be required to complete\u000a* corporate documentation in which the public would be interested\u000a\u000a===Pricing=== \u000aa) Free dissemination of Government-held information is appropriate where:\u000a* dissemination to a target audience is desirable for a public policy purpose, or\u000a* a charge to recover the cost of dissemination is not feasible or cost-effective\u000a\u000ab) Pricing to recover the cost of dissemination is appropriate where:\u000a* there is no particular public policy reason to disseminate the information, and \u000a* a charge to recover the cost of dissemination is both feasible and cost effective\u000a\u000ac) Pricing to recover the cost of transformation is appropriate where:\u000a* pricing to recover the cost of dissemination is appropriate, and\u000a* there is an avoidable cost involved in transforming the information from the form in which it is held into a form preferred by the recipient, where it is feasible and cost-effective to recover in addition to the cost of dissemination\u000a\u000ad) Pricing to recover the full costs of information production and dissemination is appropriate where:\u000a* the information is created for the commercial purpose of sale at a profit, and \u000a* to do so would not breach the other pricing principles\u000a\u000a===Ownership===\u000aGovernment-held information, created or collected by any person employed or engaged by the Crown is a strategic resource 'owned' by the Government as a steward on behalf of the public.\u000a\u000a===Stewardship===\u000aGovernment departments are stewards of Government-held information, and it is their responsibility to implement good information management.\u000a\u000a===Collection===\u000aGovernment departments should only collect information for specified public policy, operational business or legislative purposes.\u000a\u000a===Copyright===\u000aInformation created by departments is subject to Crown copyright but where wide dissemination is desirable, the Crown should permit use of its copyrights subject to acknowledgement of source.\u000a \u000a===Preservation===\u000aGovernment-held information should be preserved only where a public business need, legislative or policy requirement, or a historical or archival reason, exists.\u000a\u000a===Quality===\u000aThe key qualities underpinning Government-held information include accuracy, relevancy, timeliness, consistency and collection without bias so that the information supports the purposes for which it is collected.\u000a\u000a===Integrity===\u000aThe integrity of Government-held information will be achieved when:\u000a* all guarantees and conditions surrounding the information are met\u000a* the principles are clear and communicated\u000a* any situation relating to Government-held information is handled openly and consistently\u000a* those affected by changes to Government-held information are consulted on those changes\u000a* those charged as independent guardians of the public interest  (e.g. the Ombudsman) have confidence in the ability of departments to manage the information well\u000a* there are minimum exceptions to the principles.\u000a\u000a===Privacy===\u000aThe principles of the Privacy Act 1993 apply.\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a{{DEFAULTSORT:Policy Framework}}\u000a[[Category:Information retrieval]]\u000a[[Category:Government of New Zealand]]
p173
sg4
S'106'
p174
sg6
VPolicy framework
p175
ssI236
(dp176
g2
V{{EngvarB|date=February 2014}}\u000a{{Use dmy dates|date=February 2014}}\u000a{{Infobox company\u000a| name             = Shazam Entertainment Ltd.\u000a| logo             = [[File:Shazam logo.png|160px]]\u000a| caption          = \u000a| type             = \u000a| traded_as        = \u000a| genre            = <!-- Only used with media and publishing companies -->\u000a| fate             = \u000a| predecessor      = \u000a| successor        = \u000a| foundation       = United States ({{Start date|1999}})\u000a| founder          = {{unbulleted list|Chris Barton|Philip Inghelbrecht|Dhiraj Mukherjee|Avery Wang}}\u000a| defunct          = <!-- {{End date|df=yes|YYYY|MM|DD}} -->\u000a| location_city    = London\u000a| location_country = United Kingdom\u000a| location         = \u000a| locations        = 7 offices (2014)\u000a| area_served      = Worldwide\u000a| key_people       = {{unbulleted list|Rich Riley (CEO)|Andrew Fisher (Executive chairman)}}\u000a| industry         = \u000a| products         = [[Application software|Apps]]\u000a| services         = \u000a| revenue          = \u000a| operating_income = \u000a| net_income       = \u000a| aum              = <!-- Only used with financial services companies -->\u000a| assets           = \u000a| equity           = \u000a| num_employees    = \u000a| divisions        = \u000a| subsid           = \u000a| homepage         = {{URL|//www.shazam.com/}} \u000a| footnotes        = \u000a| intl             = \u000a}}\u000a'''Shazam''' is a British app for smartphones, PCs<ref>{{Cite web|url = http://apps.microsoft.com/windows/en-au/app/shazam/5593d150-02c7-4714-ab8f-007d5d251688|title = Shazam|date = |accessdate = 7 January 2015|website = Shazam app for Windows in the Windows Store|publisher = Microsoft Corporation|last = |first = }}</ref> and Macs, which is best known for its music identification capabilities. Shazam Entertainment Limited was founded in 1999 by Chris Barton, Philip Inghelbrecht, Avery Wang and Dhiraj Mukherjee.<ref name="DirectorDec2009">{{cite news | url=http://www.director.co.uk/magazine/2009/11%20December/shazam_63_04.html | title=Shazam names that tune | date=December 2009 | accessdate=26 September 2012 | last=Woodward | first=David | newspaper=Director}}</ref> The company is best known for its music identification technology, but has expanded to integrations with cinema, advertising, TV and retail environments.<ref>http://www.billboard.com/biz/articles/news/digital-and-mobile/6207061/shazam-launches-resonate-tv-sales-platform</ref>\u000a\u000aShazam uses a smartphone or Mac's built-in microphone to gather a brief sample of audio being played.  It creates an [[acoustic fingerprint]] based on the sample, and compares it against a central database for a match.  If it finds a match, it sends information such as the artist, song title, and album back to the user. Some implementations of Shazam incorporate relevant links to services such as [[iTunes]], [[YouTube]], [[Spotify]] or [[Zune]]. In December of 2013, Shazam was one of the top ten apps in the world, according to its CEO.<ref>http://video.cnbc.com/gallery/?video=3000222563#.</ref> The Shazam app has more than 100 million monthly active users and has been used on more than 500 million mobile devices.<ref>http://thenextweb.com/insider/2014/08/20/shazam-now-100-million-monthly-active-users-mobile/</ref> In October of 2014, Shazam announced its technology has been used to identify 15 billion songs.<ref>http://www.siliconrepublic.com/digital-life/item/38714-15-billion-songs-have-been</ref>\u000a==Features==\u000aShazam offers two types of applications; a free app simply called Shazam and a paid app called Shazam Encore. The service was expanded in September 2012 to enable TV users in the US to identify featured music, access cast information and get links to show information online, as well as adding social networking capabilities.<ref name="TV tags"/>\u000a\u000aIn February of 2014, Shazam announced a redesign of the app, which included a new look and additional features, including lyric-viewing options, access to music videos and related videos, unique recommendations, improved biographies and discographies and additional functionality for use with TV shows. The update also featured a News Feed, and Auto-Shazam, a feature introduced in December of 2013, which runs in the background of users\u2019 mobile devices to automatically identify media.<ref>http://www.digitaltveurope.net/151662/shazam-unveils-app-redesign/</ref>  \u000a\u000aIn July of 2014, Shazam announced the launch of Shazam for Mac, a desktop version of the app, which when enabled, runs in the background and automatically recognizes any song played on or near the computer, including songs playing in the background of TV shows or YouTube videos.<ref>http://mashable.com/2014/07/31/shazam-mac-app/</ref> Apple\u2019s launch of iOS 8 in September of 2014 came with the seamless integration of Shazam into Apple\u2019s intelligent personal assistant Siri function.<ref>http://www.jbgnews.com/2014/09/shazam-partners-with-apple-to-bring-music-recognition-to-siri/504608.html</ref> \u000a\u000a==Devices==\u000aShazam is a free or low-cost application that runs on [[Android (operating system)|Android]], [[Apple Inc.|Apple]] [[iPhone]] iOS, [[BlackBerry]] OS, and [[Windows Phone|Windows]] systems. The application is similar on most phones and the result is shown on the screen complete with details on Artist, Album, Title, Genre, Music label, lyrics, a thumbnail image of the song/album artwork, links to download the song on [[iTunes]] or the [[Amazon MP3]] store and, where relevant, show the song's video on YouTube and give the option of playing the song on [[Rdio]]. Shazam is also available for Mac, as a desktop application.<ref>http://mashable.com/2014/07/31/shazam-mac-app/ </ref> \u000a\u000a== Function ==\u000aShazam works by analyzing the captured sound and seeking a match based on an [[acoustic fingerprint]] in a database of more than 11 million songs.<ref>[//www.shazam.com/music/web/about.html Shazam \u2013 About Shazam<!-- Bot generated title -->]</ref>\u000a\u000a[[File:Spectrogram of violin.png|thumb|A spectrogram of the sound of a violin.]]\u000a[[File:Target zone2.png|thumb|The target zone of a song scanned by Shazam.{{clarify|date=September 2012}}]]\u000aShazam identifies songs based on an audio fingerprint based on a time-frequency graph called a [[spectrogram]].\u000a\u000aShazam stores a catalogue of audio fingerprints in a database. The user tags a song for 10 seconds and the application creates an audio fingerprint.\u000a\u000aOnce it creates the fingerprint of the audio, Shazam starts the search for matches in the database. If there is a match, it returns the information to the user; otherwise it returns a "song not known" dialogue.<ref>[http://soyoucode.com/2011/how-does-shazam-recognize-song How does Shazam work to recognize a song ? | So, you code ?<!-- Bot generated title -->]</ref>\u000a\u000aShazam can identify prerecorded music being broadcast from any source, such as a radio, television, cinema or music in a club, provided that the background noise level is not high enough to prevent an acoustic fingerprint being taken, and that the song is present in the software's database.\u000a\u000a==History==\u000aThe company was founded in 1999 by Barton and Inghelbrecht, who were students at [[University of California, Berkeley]], and Mukherjee, who worked at a London-based internet consulting firm called Viant.{{Citation needed|date=September 2013}} In need of a digital signal processing specialist, the founding team then hired Wang, who was a PhD student from [[Stanford University]]. {{as of|September 2012}}, Wang is the only member of the original team to remain in the company,<ref name="DirectorDec2009" /> and serves as Shazam's Chief Scientist.<ref name="Shazam Team">{{cite web|title=About Shazam \u2013 Team|url=//www.shazam.com/music/web/team.html|accessdate=27 September 2012}}</ref>\u000a\u000a[[Rich Riley]] joined Shazam as CEO in April 2013 to increase the company\u2019s growth,<ref>http://www.huffingtonpost.co.uk/2013/08/30/shazam-rich-riley_n_3762179.html</ref> after over 13 years at Yahoo!<ref>http://www.billboard.com/biz/articles/news/digital-and-mobile/1560025/shazam-names-rich-riley-new-ceo-aiming-for-eventual-ipo </ref> and with more than 17 years of experience as an entrepreneur and leading Internet executive.<ref>http://www.crunchbase.com/person/rich-riley </ref> "I look forward to extending our dominance in media engagement, from our roots in music to our leadership position in second-screen TV and want to ensure that Shazam is the company that helps people recognize and engage with the world around them,\u201d Riley said in a statement at the time.<ref>http://www.billboard.com/biz/articles/news/digital-and-mobile/1560025/shazam-names-rich-riley-new-ceo-aiming-for-eventual-ipo </ref> Riley replaced Andrew Fisher, who was hired from [[Infospace]] into the CEO role in 2005 to strengthen industry partnerships and grow the userbase.<ref name=DirectorDec2009 /> Fisher is now executive chairman.\u000a\u000a===Partnerships===\u000aThe first partnership was with Entertainment UK, part of Woolworths, whom they approached to digitise their music catalogue of 1.5 million songs in return for permission to create a proprietary database. As the service grew to have a worldwide userbase, it needed to keep its database up-to-date, which it does by having relationships with labels globally.<ref name="DirectorDec2009" /> By December 2008, the database had grown to 8 million songs.<ref>{{cite news|last=Reisinger|first=Don|title=Shazam adds 2 million tracks to music library|url=http://news.cnet.com/8301-17939_109-10113274-2.html|accessdate=29 September 2012|newspaper=CNET|date=4 December 2008}}</ref>\u000a\u000aIn February 2013, Shazam announced a partnership with the music store [[Beatport]], adding its library of [[electronic music]] to the service.<ref name=bb-shazambeatport>{{cite web|title=Beatport's Matthew Adell on Shazam Deal, Why Music Biz Is a 'Disaster Model'|url=http://www.billboard.com/biz/articles/news/digital-and-mobile/1538517/beatports-matthew-adell-on-shazam-deal-why-music-biz-is|work=Billboard.biz|accessdate=21 September 2013}}</ref> On 3 April 2013, Shazam announced an exclusive partnership with [[Saavn]], an Indian online music streaming service. The deal will add nearly 1 million songs in [[Languages of India|Indian languages]] to Shazam's database.<ref>[http://www.financialmirror.com/newsml_story.php?id=5458 Shazam Forms Exclusive New Partnership with Saavn for the Best Indian Music Discovery Experience<!-- Bot generated title -->]</ref><ref>{{cite news| url=http://blogs.wsj.com/speakeasy/2013/04/03/shazam-broadens-its-horizons/ | work=The Wall Street Journal | title=Shazam Broadens Its Horizons \u2013 Speakeasy \u2013 WSJ}}</ref><ref>[http://techcrunch.com/2013/04/03/shazam-partners-with-the-spotify-of-india-saavn-to-improve-its-south-asian-music-recognition/ Shazam Partners With The \u2018Spotify Of India\u2019, Saavn, To Improve Its South Asian Music Recognition | TechCrunch<!-- Bot generated title -->]</ref><ref>[http://www.medianama.com/2013/04/223-shazam-saavn-tieup/ Updated: Shazam Ties Up With Saavn To Identify Hindi & Regional Music; Implications \u2013 MediaNama<!-- Bot generated title -->]</ref> In July 2014, Shazam announced a partnership with Rdio that allows Shazam users to stream full songs within the app.<ref>http://www.billboard.com/biz/articles/news/digital-and-mobile/6157583/shazam-partners-with-rdio-to-stream-full-songs-inside </ref>\u000a\u000aIn addition to music, Shazam has announced collaborations with partners across television, advertising and cinema. In May of 2014, NCM Media Networks announced a partnership with Shazam to incorporate Shazam into FirstLook pre-show segments that run in Regal, AMC and Cinemark theaters.<ref>http://techcrunch.com/2014/05/14/shazam-partners-with-ncm/ </ref> In November of 2014, NCM and Shazam announced that NCM FirstLook pre-shows are now Shazam enabled on over 20,000 movie screens across the United States.<ref>http://mashable.com/2014/11/07/shazam-firstlook/ </ref>\u000a\u000aIn August of 2014, Shazam announced the launch of Resonate, a sales product that allows TV networks to access its technology and user base. The news included the announcement of partnerships with AMC, A+E, dick clark productions and FUSE.<ref>http://www.billboard.com/biz/articles/news/digital-and-mobile/6207061/shazam-launches-resonate-tv-sales-platform </ref>\u000a\u000aShazam recently announced a partnership with Sun Broadcast Group on Shazam for Radio, a new offering that will allow radio stations to push customized content to listeners on Sun Broadcast\u2019s over 8,000 radio stations in the U.S.<ref>http://thenextweb.com/insider/2014/10/09/shazam-makes-big-move-interactive-radio-content/ </ref>\u000a\u000a===Early days of the service===\u000aInitially, in 2002, the service was launched only in the UK and was known as "2580", as the number was the [[shortcode]] that customers dialled from their mobile phone to get music recognised.<ref name=DirectorDec2009 /> The phone would automatically hang up after 30 seconds. A result was then sent to the user in the form of a text message containing the song title and artist name. At a later date, the service also began to add hyperlinks in the text message to allow the user to download the song online.<ref name=CNETUKApril06>{{cite news|last=Lim|first=Andrew|title=Shazam & AQA: The answer is on your mobile|url=http://crave.cnet.co.uk/mobiles/shazam-and-aqa-the-answer-is-on-your-mobile-49264359/|accessdate=29 September 2012|newspaper=CNET UK|date=24 April 2006}}</ref>\u000a\u000aShazam launched in the US on the AT&T Wireless network in 2004 in a joint offering with Musicphone, a now defunct San Francisco-based company. The service was free at launch with AT&T saying that it would charge USD0.99 for each use in future.<ref name="cnet040415">{{cite news | url=http://news.cnet.com/Dial-that-tune-comes-to-U.S./2110-1039_3-5192105.html | title=Dial-that-tune comes to U.S. | work=CNET | date=15 April 2004 | accessdate=29 September 2012 | author=Charny, Ben}}</ref>\u000a\u000aIn 2006, users were charged £0.60 per call or had unlimited use for £4.50 a month, as well as an online service to keep track of all tags.<ref name=CNETUKApril06/>\u000a\u000a===Smartphone app===\u000aShazam for iPhone 2.0 debuted on 10 July 2008, with the launch of Apple's App Store. The free app simplified the service by enabling the user to launch iTunes and buy the song directly if the user was on a Wi-Fi connection <ref name=CNET080710>{{cite news|last=Rosoff|first=Matt|title=Shazam on iPhone could change music discovery|url=http://news.cnet.com/8301-13526_3-9988219-27.html|accessdate=29 September 2012|newspaper=CNET|date=10 July 2008}}</ref> (at the time, iTunes did not allow music downloads over 3G). It was also possible to launch the iPhone YouTube app, if a video was available.<ref name=CNET080716>{{cite news|last=Dolcourt|first=Jessica|title=First Look video: Shazam for iPhone|url=http://download.cnet.com/8301-2007_4-9992639-12.html|accessdate=29 September 2012|newspaper=CNET|date=16 July 2008}}</ref>\u000a\u000aIn 2008, the service struggled to identify classical music.<ref>{{cite news|last=Ho|first=Kevin|title=iPhone apps: Testing Shazam's limits \u2013 classical music|url=http://news.cnet.com/8301-13544_3-9993320-35.html|accessdate=29 September 2012|newspaper=CNET|date=17 July 2008}}</ref>\u000a\u000aShazam launched on the [[Android operating system|Android platform]] in October 2008. The Android app connected to [[Amazon Appstore|Amazon's MP3 store]] instead of iTunes.<ref name=AndroidLaunch>{{cite news|last=Reisinger|first=Don|title=Shazam moves to Android, works with Amazon MP3 Store|url=http://news.cnet.com/8301-17939_109-10071167-2.html|accessdate=29 September 2012|newspaper=CNET|date=21 October 2008}}</ref>\u000a\u000aAlongside the iOS 3 update in July 2009, Shazam updated its app to include a number of new features: marking the tag with GPS coordinates; sending tags to others as 'postcards', enabling them to buy the song; and Twitter integration.<ref>{{cite news|last=Lee|first=Nicola|title=Latest Shazam lets you track musical journey in iPhone OS 3.0|url=http://download.cnet.com/8301-2007_4-10267205-12.html|accessdate=29 September 2012|newspaper=CNET|date=17 June 2009}}</ref>\u000a\u000aThe app launched on the [[Windows Marketplace for Mobile|Windows Mobile Marketplace]] in October 2009 as a [[freemium]] offering, with the first release of Shazam Encore. The free version was now limited to five tags per month: users typically tagged ten songs per month. Encore, priced at USD4.69, added several features such as song popularity charts and recommendations.<ref name=CNETWindowsLaunch>{{cite news|last=Dolcourt|first=Jessica|title=Shazam debuts in Windows Marketplace for Mobile|url=http://reviews.cnet.com/8301-12261_7-10368986-10356022.html|accessdate=30 September 2012|newspaper=CNET|date=7 October 2009}}</ref> Encore first appeared for iPhone in November 2009.<ref>{{cite news|last=Dolcourt|first=Jessica|title=Shazam iPhone app gets premium Encore|url=http://download.cnet.com/8301-2007_4-10393035-12.html|accessdate=30 September 2012|newspaper=CNET|date=9 November 2009}}</ref>\u000a\u000aBy December 2009, Shazam was downloaded 10 million times in 150 countries across 350 mobile operators. Around eight percent of users purchased a track after it was identified by the service.<ref name=DirectorDec2009 /> Its success led to a funding round from [[Kleiner Perkins Caufield & Byers]] in October 2009.<ref name=DirectorDec2009 /><ref>{{cite news|last=Saint|first=Nick|title=Shazam Draws Investment, Is Already Profitable|url=http://www.businessinsider.com/shazam-draws-investment-is-already-profitable-2009-10|accessdate=30 September 2012|newspaper=Business Insider|date=15 October 2009}}</ref> In January 2011, Apple announced that Shazam was the fourth most downloaded free app of all time on the App Store, while rival [[SoundHound]] had the top paid iPad app.<ref>{{cite news|last=Reisinger|first=Don|title=Apple reveals top apps of all time|url=http://news.cnet.com/8301-13506_3-20028889-17.html|accessdate=30 September 2012|newspaper=CNET|date=19 January 2011}}</ref>\u000a\u000aEarly adopters of the free application are still allowed unlimited tagging.<ref>[http://androidforums.com/android-applications/132182-shazam-how-preserve-unlimited-tagging-feature-after-reflash-root.html#post1488306 Shazam: How to preserve the "unlimited tagging" feature after REFLASH and Root? \u2013 Android Forums<!-- Bot generated title -->]</ref>\u000a\u000a[[GetJar]], an app store for Android, Blackberry and Symbian, added Shazam in November 2010.<ref>{{cite news|last=Reisinger|first=Don|title=AT&T ladles out GetJar apps \u2013 iPhone excluded|url=http://news.cnet.com/8301-13506_3-20022340-17.html|accessdate=30 September 2012|newspaper=CNET|date=10 November 2010}}</ref>\u000a\u000aIn January 2011, Shazam and [[Spotify]] announced a partnership for iOS and Android to help users identify music with Shazam and listen to tracks through Spotify.<ref>{{cite news|last=Morris|first=Natali|title=Space love|url=http://cnettv.cnet.com/8301-13991_53-20028388-10391624.html|accessdate=30 September 2012|newspaper=CNET|date=13 January 2011}}</ref>\u000a\u000aWhile Shazam already had Facebook and Twitter share buttons, deeper Facebook integration was released in March 2011. With Shazam Friends users can see what their Facebook friends have tagged, listen to the tracks and buy them.<ref>{{cite news|last=McCarthy|first=Caroline|title=Music app Shazam gets new Facebook features|url=http://news.cnet.com/8301-13577_3-20045965-36.html|accessdate=1 October 2012|newspaper=CNET|date=22 March 2011}}</ref>\u000a\u000aWith Shazam 5.0, released in April 2012, the app begins 'listening' as soon as it is launched and can take as little as one second to identify media. In addition to music, the app can identify TV programs and ads, if they are Shazam-enabled.<ref>{{cite news|last=Parker|first=Jason|title=Shazam for iOS adds TV to its list of media it can identify|url=http://reviews.cnet.com/8301-19512_7-57408964-233/shazam-for-ios-adds-tv-to-its-list-of-media-it-can-identify/|accessdate=1 October 2012|newspaper=CNET|date=3 April 2012}}</ref>\u000a\u000aIn August 2012, Shazam announced the service had been used to tag five billion songs, TV shows and advertisements. In addition, Shazam claimed to have over 225 million users across 200 countries.<ref>{{cite news|last=Sawers|first=Paul|title=Shazam: Five billion songs, TV shows and ads tagged|url=http://thenextweb.com/insider/2012/08/07/shazam-five-billion-songs-tv-shows-and-ads-tagged/|accessdate=30 September 2012|newspaper=The Next Web|date=7 August 2012}}</ref> A month later, the service claimed to have more than 250 million users with 2 million active users per week.<ref name="TV tags">{{cite news|last=Kinder|first=Lucy|title=Shazam hits 250 million users and adds TV tagging capability|url=http://www.telegraph.co.uk/technology/news/9547632/Shazam-hits-250-million-users-and-adds-TV-tagging-capability.html|accessdate=17 September 2012|newspaper=The Telegraph|date=17 September 2012|location=London}}</ref> The Shazam app currently has more than 100 million monthly active users and has been used on more than 500 million mobile devices.<ref>http://thenextweb.com/insider/2014/08/20/shazam-now-100-million-monthly-active-users-mobile/ </ref> In October of 2014, Shazam announced its technology has been used to identify 15 billion songs.<ref>http://www.siliconrepublic.com/digital-life/item/38714-15-billion-songs-have-been </ref>\u000a\u000aThe Shazam app was listed among Techland's 50 Best Android Applications for 2013.<ref>{{cite news |url=http://techland.time.com/2013/07/01/50-best-android-apps-for-2013/slide/pulse-news/ | title=50 Best Android Apps for 2013 | author=Jared Newman | work=Techland | accessdate=30 June 2013 | date=1 July 2013}}</ref>\u000a\u000aIn August 2014, Shazam announced there would be no more updates for Shazam(RED) after August 7.<ref>[https://support.shazam.com/hc/en-us/articles/202604996-Important-News-About-SHAZAM-RED Important News About Shazam(RED)] \u2014 Shazam Support</ref> Current users are advised to switch to the free version with tags transferred and ads removed (for free).\u000a\u000aApple\u2019s launch of iOS 8 in September of 2014 came with the seamless integration of Shazam into Apple\u2019s intelligent personal assistant Siri function.<ref>http://www.jbgnews.com/2014/09/shazam-partners-with-apple-to-bring-music-recognition-to-siri/504608.html </ref>\u000a\u000aIn October of 2014, Shazam introduced version 8.0 of the app, which features a new and improved News feed, as well as a section featuring Shazam charts and an \u201cexplore\u201d option which lets user explore Shazamed tracks near them and around the world.<ref>http://appadvice.com/appnn/2014/10/shazam-8-0-features-interactive-notifications-in-ios-8-revamped-news-feed-and-more </ref>\u000a\u000a===Desktop app=== \u000aShazam announced the launch of Shazam for Mac, a desktop application, in July of 2014. When enabled, the app runs in the background of a Mac and automatically recognizes any song played on or near the computer, including songs playing in the background of TV shows or YouTube videos.<ref>http://mashable.com/2014/07/31/shazam-mac-app/ </ref>\u000a\u000a==Similar apps==\u000a\u000a*[[SoundHound]], previously known as Midomi, uses [[Query by humming]] to identify songs.{{citation needed|date=October 2012}}\u000a*[[Gracenote]]'s MusicID-Stream has the main advantage of having the largest database of all music IDs (with more than 28 million songs).{{citation needed|date=October 2012}}\u000a*Musipedia is a music search engine that works differently from others because instead of using techniques to identify recorded music, it can identify pieces of music from a single melody or rhythm.{{citation needed|date=October 2012}}\u000a*Play by Yahoo Music.\u000a*Bing music identification.\u000a*Sony TrackID\u000a*Path also has a music-identification feature.<ref>{{cite news|last=Cabebe|first=Jaymar|title=Path: The smaller, simpler alternative to Facebook|url=http://news.cnet.com/8301-1035_3-57416066-94/path-the-smaller-simpler-alternative-to-facebook/|accessdate=1 October 2012|newspaper=CNET|date=18 April 2012}}</ref>\u000a*Stream That Song by Orange Innovation UK Ltd\u000a\u000a==Patent infringement lawsuit==\u000aIn May 2009, Tune Hunter accused Shazam of violating {{US Patent|6941275}}, which covers music identification and purchase in a portable device.<ref>{{cite news|last=Ogg|first=Erica|title=Apple, AT&T, Samsung, Verizon, and others sued over Shazam app|url=http://news.cnet.com/8301-13579_3-10241309-37.html|accessdate=29 September 2012|newspaper=CNET|date=14 May 2009}}</ref> Shazam settled the case in January 2010.<ref>{{cite news\u000a|title=Shazam Settles Patent Infringement Case With Tune Hunter\u000a|url=http://techcrunch.com/2010/01/06/shazam-tune-hunter-settlement/\u000a|date=Jan 6, 2010\u000a|first=Robin\u000a|last=Wauters\u000a}}</ref>\u000a\u000a==Funding==\u000a\u000aAs of September 2012, Shazam had raised $32 million in funding.<ref name="Techcrunch">{{cite news|last=Kincaid|first=Jason|title=Shazam Raises A Huge Round to the Tune of $32 Million|url=http://techcrunch.com/2011/06/22/shazam-raises-a-huge-round-to-the-tune-of-32-million/|accessdate=20 September 2012|newspaper=TechCrunch|date=22 June 2011}}</ref> In July 2013, [[Carlos Slim]] invested $40 million in Shazam for an undisclosed share.<ref>[http://www.ft.com/intl/cms/s/0/97d2c46a-e58d-11e2-8d0b-00144feabdc0.html#axzz2ag6DhVhD Carlos Slim invests $40m in music app Shazam \u2013 FT.com<!-- Bot generated title -->]</ref> And in March of 2014, Shazam confirmed another $20 million in new funding, raising the total value of the company to half a billion dollars.<ref>http://www.billboard.com/biz/articles/5930359/shazam-confirms-20m-in-new-funding-raising-value-to-500m </ref>\u000a\u000a==See also==\u000a* [[Query by humming]]\u000a* [[Acoustic fingerprint]]\u000a* [[Spectrogram]]\u000a* [[Sound recording copyright symbol]]\u000a\u000a==References==\u000a{{Reflist|30em}}\u000a\u000a==Further reading==\u000a* {{cite news |last=Dredge |first=Stuart |title=Shazam: 'TV advertising is going to become our primary revenue stream' |url=http://www.guardian.co.uk/media/appsblog/2013/feb/27/shazam-tv-advertising-future |accessdate=27 February 2013 |newspaper=[[The Guardian]] |date=27 February 2013|location=London}}\u000a\u000a==External links==\u000a* {{Official website|www.shazam.com/music/web/home.html}}\u000a\u000a[[Category:Companies based in London]]\u000a[[Category:Acoustic fingerprinting]]\u000a[[Category:Android (operating system) software]]\u000a[[Category:BlackBerry software]]\u000a[[Category:IOS software]]\u000a[[Category:Symbian software]]\u000a[[Category:Music search engines]]\u000a[[Category:Companies established in 1999]]\u000a[[Category:Windows Phone software]]
p177
sg4
S'236'
p178
sg6
VShazam (service)
p179
ssI111
(dp180
g2
V{{Multiple issues|\u000a{{expert-subject|Computer science|date=January 2015}}\u000a{{COI|date=February 2009}}\u000a}}\u000a\u000a'''XML retrieval''', or XML Information Retrieval, is the content-based retrieval of documents structured with [[XML]] (eXtensible Markup Language). As such it is used for computing [[Relevance (information retrieval)|relevance]] of XML documents.<ref>{{Cite web|url=ftp://ftp.tm.informatik.uni-frankfurt.de/pub/papers/ir/An%20Architecture%20for%20XML%20Information%20Retrieval%20in%20a%20Peer-to-Peer%20Environment_2007.pdf|title=An Architecture for XML Information Retrieval in a Peer-to-Peer Environment|last=Winter|first=Judith|author2=Drobnik, Oswald |date=November 9, 2007|publisher=ACM|accessdate=2009-02-10}}</ref>\u000a\u000a==Queries==\u000aMost XML retrieval approaches do so based on techniques from the [[information retrieval]] (IR) area, e.g. by computing the similarity between a query consisting of keywords (query terms) and the document. However, in XML-Retrieval the query can also contain [[Data structure|structural]] [[Hint (SQL)|hints]]. So-called "content and structure" (CAS) queries enable users to specify what structure the requested content can or must have.\u000a\u000a==Exploiting XML structure==\u000aTaking advantage of the [[Self-documenting|self-describing]] structure of XML documents can improve the search for XML documents significantly. This includes the use of CAS queries, the weighting of different XML elements differently and the focused retrieval of subdocuments.\u000a\u000a==Ranking==\u000aRanking in XML-Retrieval can incorporate both content relevance and structural similarity, which is the resemblance between the structure given in the query and the structure of the document. Also, the retrieval units resulting from an XML query may not always be entire documents, but can be any deeply nested XML elements, i.e. dynamic documents. The aim is to find the smallest retrieval unit that is highly relevant. Relevance can be defined according to the notion of specificity, which is the extent to which a retrieval unit focuses on the topic of request.<ref name="INEX2006">{{Cite web|url=http://www.cs.otago.ac.nz/homepages/andrew/2006-10.pdf|title=Overview of INEX 2006|last=Malik|first=Saadia|author2=Trotman, Andrew |author3=Lalmas, Mounia |author4= Fuhr, Norbert |year=2007|work=Proceedings of the Fifth Workshop of the INitiative for the Evaluation of XML Retrieval|accessdate=2009-02-10}}</ref>\u000a\u000a==Existing XML search engines==\u000aAn overview of two potential approaches is available.<ref>{{Cite web|url=http://www.sigmod.org/record/issues/0612/p16-article-yahia.pdf|title=XML Search: Languages, INEX and Scoring|last=Amer-Yahia|first=Sihem|author2=Lalmas, Mounia |year=2006|publisher=SIGMOD Rec. Vol. 35, No. 4|accessdate=2009-02-10}} {{Dead link|date=October 2010|bot=H3llBot}}</ref><ref>{{Cite web|url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.5986&rep=rep1&type=pdf|title=XML Retrieval: A Survey|last=Pal|first=Sukomal|date=June 30, 2006|publisher=Technical Report, CVPR|accessdate=2013-07-04}}</ref> The INitiative for the Evaluation of XML-Retrieval (''INEX'') was founded in 2002 and provides a platform for evaluating such [[algorithm]]s.<ref name="INEX2006" /> Three different areas influence XML-Retrieval:<ref name="INEX2002">{{Cite web|url=http://www.is.informatik.uni-duisburg.de/bib/pdf/ir/Fuhr_etal:02a.pdf|title=INEX: Initiative for the Evaluation of XML Retrieval|last=Fuhr|first=Norbert|author2=Gövert, N. |author3=Kazai, Gabriella |author4= Lalmas, Mounia |year=2003|work=Proceedings of the First INEX Workshop, Dagstuhl, Germany, 2002|publisher=ERCIM Workshop Proceedings, France|accessdate=2009-02-10}}</ref>\u000a\u000a===Traditional XML query languages===\u000a[[Query language]]s such as the [[W3C]] standard [[XQuery]]<ref>{{Cite web|url=http://www.w3.org/TR/2007/REC-xquery-20070123/|title=XQuery 1.0: An XML Query Language|last=Boag|first=Scott|author2=Chamberlin, Don |author3=Fernández, Mary F. |author4=Florescu, Daniela |author5=Robie, Jonathan |author6= Siméon, Jérôme |date=23 January 2007|work=W3C Recommendation|publisher=World Wide Web Consortium|accessdate=2009-02-10}}</ref> supply complex queries, but only look for exact matches. Therefore, they need to be extended to allow for vague search with relevance computing. Most XML-centered approaches imply a quite exact knowledge of the documents' [[Database schema|schemas]].<ref name="Schlieder2002">{{Cite journal|url=http://web.archive.org/web/20070610002349/http://www.cis.uni-muenchen.de/people/Meuss/Pub/JASIS02.ps.gz|title=Querying and Ranking XML Documents|last=Schlieder|first=Torsten|author2=Meuss, Holger |year=2002|work= Journal of the American Society for Information Science and Technology, Vol. 53, No. 6|accessdate=2009-02-10}}</ref>\u000a\u000a===Databases===\u000aClassic [[database]] systems have adopted the possibility to store [[Semi-structured model|semi-structured data]]<ref name="INEX2002" /> and resulted in the development of [[XML database]]s. Often, they are very formal, concentrate more on searching than on ranking, and are used by experienced users able to formulate complex queries.\u000a\u000a===Information retrieval===\u000aClassic information retrieval models such as the [[vector space model]] provide relevance ranking, but do not include document structure; only flat queries are  supported. Also, they apply a static document concept, so retrieval units usually are entire documents.<ref name="Schlieder2002"/> They can be extended to consider structural information and dynamic document retrieval. Examples for approaches extending the vector space models are available: they use document [[subtree]]s (index terms plus structure) as dimensions of the vector space.<ref>{{Cite web|url=http://www.cobase.cs.ucla.edu/tech-docs/sliu/SIGIR04.pdf|title=Configurable Indexing and Ranking for XML Information Retrieval|last=Liu|first=Shaorong|author2=Zou, Qinghua |author3=Chu, Wesley W. |year=2004|work=SIGIR'04|publisher=ACM|accessdate=2009-02-10}}</ref>\u000a\u000a==See also==\u000a*[[Document retrieval]]\u000a*[[Information retrieval applications]]\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a{{DEFAULTSORT:Xml-Retrieval}}\u000a[[Category:XML]]\u000a[[Category:Information retrieval]]
p181
sg4
S'111'
p182
sg6
VXML retrieval
p183
ssI116
(dp184
g2
V'''Online search''' is the process of interactively searching for and retrieving requested information via a computer from [[database]]s that are [[online]].<ref name="whatis?">{{cite journal|last1=Hawkins|first1= Donald T.|last2= Brown|first2= Carolyn P.|date=Jan 1980|title=What Is an Online Search?|journal=Online|volume=4|issue=1|pages=12\u201318|id=Eric:EJ214713| accessdate=2011-04-04}}</ref> Interactive searches became possible in the 1980s with the advent of faster databases and [[smart terminal]]s.<ref name="whatis?"/> In contrast, [[computerized batch searching]] was prevalent in the 1960s and 1970s.<ref name="whatis?"/> Today, searches through [[web search engine]]s constitute the majority of online searches.\u000a\u000aOnline searches often supplement reference transactions.\u000a\u000a==References==\u000a{{reflist}}\u000a\u000a{{Internet search}}\u000a\u000a[[Category:Internet terminology]]\u000a[[Category:Information retrieval]]\u000a\u000a\u000a{{web-stub}}
p185
sg4
S'116'
p186
sg6
VOnline search
p187
ssI121
(dp188
g2
V{{Notability|Companies|date=July 2011}}\u000a\u000a'''Ness Computing''' is a personal search company. It was acquired by OpenTable in 2014 and is being shut down in April.<ref>{{cite web|last=Lunden|first=Ingrid|title=OpenTable Buys Ness For $17.3M|url=http://techcrunch.com/2014/02/06/opentable-ness/|work=TechCrunch|accessdate=26 March 2014}}</ref> \u000a\u000aIt was founded in October 2009 by Corey Reese,<ref>http://www.linkedin.com/in/coreyreese</ref> Paul Twohey,<ref>http://www.linkedin.com/in/twohey</ref> Nikhil Raghavan,<ref>http://www.linkedin.com/in/nikhilraghavan</ref> and Steven Schlansker.<ref>http://www.linkedin.com/in/stevenschlansker</ref> The company is headquartered in Los Altos, California.\u000a\u000aThe company, whose mission is to make search personal, is sometimes referred to as the "Palantir for fun". It aims to help people make decisions about dining, nightlife, entertainment, shopping, music, travel and more. \u000a\u000aNess' mission is to make search personal. The company refers to its technology as the "Likeness Engine", a combination of a [[recommendation engine]] that uses [[machine learning]] to look at data from diverse sources and a traditional [[search engine]] that serves up results based on these signals. \u000a\u000aThe free Ness Dining App (for iPhone) has been referred to as the [[Netflix]] <ref>http://eater.com/archives/2011/08/26/ness-iphone-app-recommends-restaurants-using-likeness-score.php</ref> or [[Pandora]] <ref>http://gigaom.com/2011/08/25/ness-restaurant-app/</ref> for restaurants. Based on a user's ratings and preferences, the service will deliver recommendations for a particular time, location, price range, and cuisine preference. Users may view the menu for a place via SinglePlatform,<ref>http://www.singleplatform.com/</ref> browse [[Instagram]] photos tagged at the restaurant, and make reservations in the app via [[OpenTable]]. The app is free and available in the [[App Store (iOS)]].\u000a\u000a==References==\u000a{{Reflist}}\u000a\u000a[[Category:Information retrieval]]\u000a[[Category:Software companies based in California]]
p189
sg4
S'121'
p190
sg6
VNess Computing
p191
ssI126
(dp192
g2
V{{cat main|Substring index}}\u000a\u000a[[Category:String (computer science)]]\u000a[[Category:Algorithms on strings]]\u000a[[Category:String data structures]]\u000a[[Category:Database index techniques]]\u000a[[Category:Information retrieval]]\u000a[[Category:Bioinformatics algorithms]]
p193
sg4
S'126'
p194
sg6
VCategory:Substring indices
p195
ss.